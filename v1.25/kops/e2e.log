{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
May  1 22:34:54.882: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:34:54.884: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May  1 22:34:55.432: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May  1 22:34:55.775: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May  1 22:34:55.775: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May  1 22:34:55.775: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May  1 22:34:55.882: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'aws-cloud-controller-manager' (0 seconds elapsed)
May  1 22:34:55.882: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May  1 22:34:55.882: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'ebs-csi-node' (0 seconds elapsed)
May  1 22:34:55.882: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kops-controller' (0 seconds elapsed)
May  1 22:34:55.882: INFO: e2e test version: v1.25.9
May  1 22:34:55.985: INFO: kube-apiserver version: v1.25.9
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
May  1 22:34:55.985: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:34:56.091: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [1.209 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    May  1 22:34:54.882: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:34:54.884: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    May  1 22:34:55.432: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    May  1 22:34:55.775: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    May  1 22:34:55.775: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
    May  1 22:34:55.775: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    May  1 22:34:55.882: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'aws-cloud-controller-manager' (0 seconds elapsed)
    May  1 22:34:55.882: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    May  1 22:34:55.882: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'ebs-csi-node' (0 seconds elapsed)
    May  1 22:34:55.882: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kops-controller' (0 seconds elapsed)
    May  1 22:34:55.882: INFO: e2e test version: v1.25.9
    May  1 22:34:55.985: INFO: kube-apiserver version: v1.25.9
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    May  1 22:34:55.985: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:34:56.091: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:34:56.112
May  1 22:34:56.112: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller 05/01/23 22:34:56.113
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:34:56.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:34:56.636
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
May  1 22:34:56.843: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 05/01/23 22:34:57.053
STEP: Checking rc "condition-test" has the desired failure condition set 05/01/23 22:34:57.16
STEP: Scaling down rc "condition-test" to satisfy pod quota 05/01/23 22:34:57.264
May  1 22:34:57.474: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 05/01/23 22:34:57.475
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
May  1 22:34:57.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-172" for this suite. 05/01/23 22:34:57.683
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":1,"skipped":11,"failed":0}
------------------------------
• [1.677 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:34:56.112
    May  1 22:34:56.112: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replication-controller 05/01/23 22:34:56.113
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:34:56.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:34:56.636
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    May  1 22:34:56.843: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 05/01/23 22:34:57.053
    STEP: Checking rc "condition-test" has the desired failure condition set 05/01/23 22:34:57.16
    STEP: Scaling down rc "condition-test" to satisfy pod quota 05/01/23 22:34:57.264
    May  1 22:34:57.474: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 05/01/23 22:34:57.475
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    May  1 22:34:57.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-172" for this suite. 05/01/23 22:34:57.683
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:34:57.791
May  1 22:34:57.791: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 22:34:57.792
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:34:58.105
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:34:58.311
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
STEP: creating an Endpoint 05/01/23 22:34:58.622
STEP: waiting for available Endpoint 05/01/23 22:34:58.727
STEP: listing all Endpoints 05/01/23 22:34:58.831
STEP: updating the Endpoint 05/01/23 22:34:58.935
STEP: fetching the Endpoint 05/01/23 22:34:59.144
STEP: patching the Endpoint 05/01/23 22:34:59.248
STEP: fetching the Endpoint 05/01/23 22:34:59.458
STEP: deleting the Endpoint by Collection 05/01/23 22:34:59.562
STEP: waiting for Endpoint deletion 05/01/23 22:34:59.671
STEP: fetching the Endpoint 05/01/23 22:34:59.774
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 22:34:59.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2041" for this suite. 05/01/23 22:34:59.984
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":2,"skipped":12,"failed":0}
------------------------------
• [2.300 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:34:57.791
    May  1 22:34:57.791: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 22:34:57.792
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:34:58.105
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:34:58.311
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3210
    STEP: creating an Endpoint 05/01/23 22:34:58.622
    STEP: waiting for available Endpoint 05/01/23 22:34:58.727
    STEP: listing all Endpoints 05/01/23 22:34:58.831
    STEP: updating the Endpoint 05/01/23 22:34:58.935
    STEP: fetching the Endpoint 05/01/23 22:34:59.144
    STEP: patching the Endpoint 05/01/23 22:34:59.248
    STEP: fetching the Endpoint 05/01/23 22:34:59.458
    STEP: deleting the Endpoint by Collection 05/01/23 22:34:59.562
    STEP: waiting for Endpoint deletion 05/01/23 22:34:59.671
    STEP: fetching the Endpoint 05/01/23 22:34:59.774
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 22:34:59.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2041" for this suite. 05/01/23 22:34:59.984
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:35:00.091
May  1 22:35:00.091: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset 05/01/23 22:35:00.092
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:35:00.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:35:00.612
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 05/01/23 22:35:00.819
STEP: Verify that the required pods have come up 05/01/23 22:35:00.925
May  1 22:35:01.030: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 05/01/23 22:35:01.03
May  1 22:35:01.030: INFO: Waiting up to 5m0s for pod "test-rs-s26jp" in namespace "replicaset-5684" to be "running"
May  1 22:35:01.030: INFO: Waiting up to 5m0s for pod "test-rs-j4p8q" in namespace "replicaset-5684" to be "running"
May  1 22:35:01.030: INFO: Waiting up to 5m0s for pod "test-rs-kcvn8" in namespace "replicaset-5684" to be "running"
May  1 22:35:01.135: INFO: Pod "test-rs-s26jp": Phase="Pending", Reason="", readiness=false. Elapsed: 104.448802ms
May  1 22:35:01.135: INFO: Pod "test-rs-kcvn8": Phase="Pending", Reason="", readiness=false. Elapsed: 104.332146ms
May  1 22:35:01.135: INFO: Pod "test-rs-j4p8q": Phase="Pending", Reason="", readiness=false. Elapsed: 104.350382ms
May  1 22:35:03.240: INFO: Pod "test-rs-kcvn8": Phase="Running", Reason="", readiness=true. Elapsed: 2.209128897s
May  1 22:35:03.240: INFO: Pod "test-rs-kcvn8" satisfied condition "running"
May  1 22:35:03.240: INFO: Pod "test-rs-j4p8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209263527s
May  1 22:35:03.240: INFO: Pod "test-rs-s26jp": Phase="Running", Reason="", readiness=true. Elapsed: 2.209399775s
May  1 22:35:03.240: INFO: Pod "test-rs-s26jp" satisfied condition "running"
May  1 22:35:05.240: INFO: Pod "test-rs-j4p8q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209476088s
May  1 22:35:07.240: INFO: Pod "test-rs-j4p8q": Phase="Running", Reason="", readiness=true. Elapsed: 6.209025538s
May  1 22:35:07.240: INFO: Pod "test-rs-j4p8q" satisfied condition "running"
May  1 22:35:07.344: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 05/01/23 22:35:07.344
STEP: DeleteCollection of the ReplicaSets 05/01/23 22:35:07.448
STEP: After DeleteCollection verify that ReplicaSets have been deleted 05/01/23 22:35:07.555
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
May  1 22:35:07.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5684" for this suite. 05/01/23 22:35:07.764
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":3,"skipped":25,"failed":0}
------------------------------
• [SLOW TEST] [7.781 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:35:00.091
    May  1 22:35:00.091: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replicaset 05/01/23 22:35:00.092
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:35:00.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:35:00.612
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 05/01/23 22:35:00.819
    STEP: Verify that the required pods have come up 05/01/23 22:35:00.925
    May  1 22:35:01.030: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 05/01/23 22:35:01.03
    May  1 22:35:01.030: INFO: Waiting up to 5m0s for pod "test-rs-s26jp" in namespace "replicaset-5684" to be "running"
    May  1 22:35:01.030: INFO: Waiting up to 5m0s for pod "test-rs-j4p8q" in namespace "replicaset-5684" to be "running"
    May  1 22:35:01.030: INFO: Waiting up to 5m0s for pod "test-rs-kcvn8" in namespace "replicaset-5684" to be "running"
    May  1 22:35:01.135: INFO: Pod "test-rs-s26jp": Phase="Pending", Reason="", readiness=false. Elapsed: 104.448802ms
    May  1 22:35:01.135: INFO: Pod "test-rs-kcvn8": Phase="Pending", Reason="", readiness=false. Elapsed: 104.332146ms
    May  1 22:35:01.135: INFO: Pod "test-rs-j4p8q": Phase="Pending", Reason="", readiness=false. Elapsed: 104.350382ms
    May  1 22:35:03.240: INFO: Pod "test-rs-kcvn8": Phase="Running", Reason="", readiness=true. Elapsed: 2.209128897s
    May  1 22:35:03.240: INFO: Pod "test-rs-kcvn8" satisfied condition "running"
    May  1 22:35:03.240: INFO: Pod "test-rs-j4p8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209263527s
    May  1 22:35:03.240: INFO: Pod "test-rs-s26jp": Phase="Running", Reason="", readiness=true. Elapsed: 2.209399775s
    May  1 22:35:03.240: INFO: Pod "test-rs-s26jp" satisfied condition "running"
    May  1 22:35:05.240: INFO: Pod "test-rs-j4p8q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209476088s
    May  1 22:35:07.240: INFO: Pod "test-rs-j4p8q": Phase="Running", Reason="", readiness=true. Elapsed: 6.209025538s
    May  1 22:35:07.240: INFO: Pod "test-rs-j4p8q" satisfied condition "running"
    May  1 22:35:07.344: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 05/01/23 22:35:07.344
    STEP: DeleteCollection of the ReplicaSets 05/01/23 22:35:07.448
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 05/01/23 22:35:07.555
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    May  1 22:35:07.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5684" for this suite. 05/01/23 22:35:07.764
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:35:07.873
May  1 22:35:07.873: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 22:35:07.874
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:35:08.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:35:08.394
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
STEP: creating a Service 05/01/23 22:35:08.704
STEP: watching for the Service to be added 05/01/23 22:35:08.815
May  1 22:35:08.918: INFO: Found Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
May  1 22:35:08.918: INFO: Service test-service-8bgq4 created
STEP: Getting /status 05/01/23 22:35:08.918
May  1 22:35:09.023: INFO: Service test-service-8bgq4 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 05/01/23 22:35:09.023
STEP: watching for the Service to be patched 05/01/23 22:35:09.131
May  1 22:35:09.235: INFO: observed Service test-service-8bgq4 in namespace services-5280 with annotations: map[] & LoadBalancer: {[]}
May  1 22:35:09.235: INFO: Found Service test-service-8bgq4 in namespace services-5280 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
May  1 22:35:09.235: INFO: Service test-service-8bgq4 has service status patched
STEP: updating the ServiceStatus 05/01/23 22:35:09.235
May  1 22:35:09.447: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 05/01/23 22:35:09.447
May  1 22:35:09.550: INFO: Observed Service test-service-8bgq4 in namespace services-5280 with annotations: map[] & Conditions: {[]}
May  1 22:35:09.550: INFO: Observed event: &Service{ObjectMeta:{test-service-8bgq4  services-5280  9105d11a-3cf0-4458-9ea0-4fd7b14f612d 1754 0 2023-05-01 22:35:08 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-05-01 22:35:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-05-01 22:35:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.71.103.208,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.71.103.208],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
May  1 22:35:09.551: INFO: Found Service test-service-8bgq4 in namespace services-5280 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May  1 22:35:09.551: INFO: Service test-service-8bgq4 has service status updated
STEP: patching the service 05/01/23 22:35:09.551
STEP: watching for the Service to be patched 05/01/23 22:35:09.66
May  1 22:35:09.763: INFO: observed Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true]
May  1 22:35:09.763: INFO: observed Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true]
May  1 22:35:09.763: INFO: observed Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true]
May  1 22:35:09.764: INFO: Found Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service:patched test-service-static:true]
May  1 22:35:09.764: INFO: Service test-service-8bgq4 patched
STEP: deleting the service 05/01/23 22:35:09.764
STEP: watching for the Service to be deleted 05/01/23 22:35:09.88
May  1 22:35:09.984: INFO: Observed event: ADDED
May  1 22:35:09.984: INFO: Observed event: MODIFIED
May  1 22:35:09.984: INFO: Observed event: MODIFIED
May  1 22:35:09.984: INFO: Observed event: MODIFIED
May  1 22:35:09.984: INFO: Found Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
May  1 22:35:09.985: INFO: Service test-service-8bgq4 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 22:35:09.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5280" for this suite. 05/01/23 22:35:10.114
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":4,"skipped":29,"failed":0}
------------------------------
• [2.347 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:35:07.873
    May  1 22:35:07.873: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 22:35:07.874
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:35:08.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:35:08.394
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3394
    STEP: creating a Service 05/01/23 22:35:08.704
    STEP: watching for the Service to be added 05/01/23 22:35:08.815
    May  1 22:35:08.918: INFO: Found Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    May  1 22:35:08.918: INFO: Service test-service-8bgq4 created
    STEP: Getting /status 05/01/23 22:35:08.918
    May  1 22:35:09.023: INFO: Service test-service-8bgq4 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 05/01/23 22:35:09.023
    STEP: watching for the Service to be patched 05/01/23 22:35:09.131
    May  1 22:35:09.235: INFO: observed Service test-service-8bgq4 in namespace services-5280 with annotations: map[] & LoadBalancer: {[]}
    May  1 22:35:09.235: INFO: Found Service test-service-8bgq4 in namespace services-5280 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    May  1 22:35:09.235: INFO: Service test-service-8bgq4 has service status patched
    STEP: updating the ServiceStatus 05/01/23 22:35:09.235
    May  1 22:35:09.447: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 05/01/23 22:35:09.447
    May  1 22:35:09.550: INFO: Observed Service test-service-8bgq4 in namespace services-5280 with annotations: map[] & Conditions: {[]}
    May  1 22:35:09.550: INFO: Observed event: &Service{ObjectMeta:{test-service-8bgq4  services-5280  9105d11a-3cf0-4458-9ea0-4fd7b14f612d 1754 0 2023-05-01 22:35:08 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-05-01 22:35:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-05-01 22:35:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.71.103.208,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.71.103.208],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    May  1 22:35:09.551: INFO: Found Service test-service-8bgq4 in namespace services-5280 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    May  1 22:35:09.551: INFO: Service test-service-8bgq4 has service status updated
    STEP: patching the service 05/01/23 22:35:09.551
    STEP: watching for the Service to be patched 05/01/23 22:35:09.66
    May  1 22:35:09.763: INFO: observed Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true]
    May  1 22:35:09.763: INFO: observed Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true]
    May  1 22:35:09.763: INFO: observed Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service-static:true]
    May  1 22:35:09.764: INFO: Found Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service:patched test-service-static:true]
    May  1 22:35:09.764: INFO: Service test-service-8bgq4 patched
    STEP: deleting the service 05/01/23 22:35:09.764
    STEP: watching for the Service to be deleted 05/01/23 22:35:09.88
    May  1 22:35:09.984: INFO: Observed event: ADDED
    May  1 22:35:09.984: INFO: Observed event: MODIFIED
    May  1 22:35:09.984: INFO: Observed event: MODIFIED
    May  1 22:35:09.984: INFO: Observed event: MODIFIED
    May  1 22:35:09.984: INFO: Found Service test-service-8bgq4 in namespace services-5280 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    May  1 22:35:09.985: INFO: Service test-service-8bgq4 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 22:35:09.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5280" for this suite. 05/01/23 22:35:10.114
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:35:10.222
May  1 22:35:10.222: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-watch 05/01/23 22:35:10.223
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:35:10.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:35:10.743
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
May  1 22:35:10.950: INFO: >>> kubeConfig: /root/.kube/config
STEP: Creating first CR  05/01/23 22:35:13.715
May  1 22:35:13.821: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:13Z]] name:name1 resourceVersion:1787 uid:6aa6ebc8-b2cd-441d-964c-a13b84147e17] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 05/01/23 22:35:23.821
May  1 22:35:23.927: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:23Z]] name:name2 resourceVersion:1824 uid:0077e187-ae93-49eb-a3aa-02c14e37fbc0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 05/01/23 22:35:33.929
May  1 22:35:34.036: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:33Z]] name:name1 resourceVersion:1855 uid:6aa6ebc8-b2cd-441d-964c-a13b84147e17] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 05/01/23 22:35:44.036
May  1 22:35:44.144: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:44Z]] name:name2 resourceVersion:1888 uid:0077e187-ae93-49eb-a3aa-02c14e37fbc0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 05/01/23 22:35:54.148
May  1 22:35:54.255: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:33Z]] name:name1 resourceVersion:1919 uid:6aa6ebc8-b2cd-441d-964c-a13b84147e17] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 05/01/23 22:36:04.259
May  1 22:36:04.365: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:44Z]] name:name2 resourceVersion:1951 uid:0077e187-ae93-49eb-a3aa-02c14e37fbc0] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 22:36:14.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8764" for this suite. 05/01/23 22:36:14.685
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":5,"skipped":73,"failed":0}
------------------------------
• [SLOW TEST] [64.570 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:35:10.222
    May  1 22:35:10.222: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-watch 05/01/23 22:35:10.223
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:35:10.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:35:10.743
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    May  1 22:35:10.950: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Creating first CR  05/01/23 22:35:13.715
    May  1 22:35:13.821: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:13Z]] name:name1 resourceVersion:1787 uid:6aa6ebc8-b2cd-441d-964c-a13b84147e17] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 05/01/23 22:35:23.821
    May  1 22:35:23.927: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:23Z]] name:name2 resourceVersion:1824 uid:0077e187-ae93-49eb-a3aa-02c14e37fbc0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 05/01/23 22:35:33.929
    May  1 22:35:34.036: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:33Z]] name:name1 resourceVersion:1855 uid:6aa6ebc8-b2cd-441d-964c-a13b84147e17] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 05/01/23 22:35:44.036
    May  1 22:35:44.144: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:44Z]] name:name2 resourceVersion:1888 uid:0077e187-ae93-49eb-a3aa-02c14e37fbc0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 05/01/23 22:35:54.148
    May  1 22:35:54.255: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:33Z]] name:name1 resourceVersion:1919 uid:6aa6ebc8-b2cd-441d-964c-a13b84147e17] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 05/01/23 22:36:04.259
    May  1 22:36:04.365: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-05-01T22:35:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-05-01T22:35:44Z]] name:name2 resourceVersion:1951 uid:0077e187-ae93-49eb-a3aa-02c14e37fbc0] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 22:36:14.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-8764" for this suite. 05/01/23 22:36:14.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:36:14.793
May  1 22:36:14.793: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/01/23 22:36:14.795
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:36:15.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:36:15.314
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e in namespace container-probe-6872 05/01/23 22:36:15.52
May  1 22:36:15.635: INFO: Waiting up to 5m0s for pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e" in namespace "container-probe-6872" to be "not pending"
May  1 22:36:15.739: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 104.516709ms
May  1 22:36:17.844: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20885357s
May  1 22:36:19.844: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e": Phase="Running", Reason="", readiness=true. Elapsed: 4.208904936s
May  1 22:36:19.844: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e" satisfied condition "not pending"
May  1 22:36:19.844: INFO: Started pod busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e in namespace container-probe-6872
STEP: checking the pod's current state and verifying that restartCount is present 05/01/23 22:36:19.844
May  1 22:36:19.948: INFO: Initial restart count of pod busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e is 0
STEP: deleting the pod 05/01/23 22:40:22.015
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  1 22:40:22.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6872" for this suite. 05/01/23 22:40:22.233
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":6,"skipped":87,"failed":0}
------------------------------
• [SLOW TEST] [247.546 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:36:14.793
    May  1 22:36:14.793: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/01/23 22:36:14.795
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:36:15.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:36:15.314
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e in namespace container-probe-6872 05/01/23 22:36:15.52
    May  1 22:36:15.635: INFO: Waiting up to 5m0s for pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e" in namespace "container-probe-6872" to be "not pending"
    May  1 22:36:15.739: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 104.516709ms
    May  1 22:36:17.844: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20885357s
    May  1 22:36:19.844: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e": Phase="Running", Reason="", readiness=true. Elapsed: 4.208904936s
    May  1 22:36:19.844: INFO: Pod "busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e" satisfied condition "not pending"
    May  1 22:36:19.844: INFO: Started pod busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e in namespace container-probe-6872
    STEP: checking the pod's current state and verifying that restartCount is present 05/01/23 22:36:19.844
    May  1 22:36:19.948: INFO: Initial restart count of pod busybox-9379f5e8-2ba8-4274-a2be-675fce747f2e is 0
    STEP: deleting the pod 05/01/23 22:40:22.015
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  1 22:40:22.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6872" for this suite. 05/01/23 22:40:22.233
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:40:22.34
May  1 22:40:22.340: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 22:40:22.342
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:22.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:22.862
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 05/01/23 22:40:23.069
STEP: fetching the ConfigMap 05/01/23 22:40:23.175
STEP: patching the ConfigMap 05/01/23 22:40:23.279
STEP: listing all ConfigMaps in all namespaces with a label selector 05/01/23 22:40:23.385
STEP: deleting the ConfigMap by collection with a label selector 05/01/23 22:40:23.489
STEP: listing all ConfigMaps in test namespace 05/01/23 22:40:23.596
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
May  1 22:40:23.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9034" for this suite. 05/01/23 22:40:23.804
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":7,"skipped":89,"failed":0}
------------------------------
• [1.571 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:40:22.34
    May  1 22:40:22.340: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 22:40:22.342
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:22.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:22.862
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 05/01/23 22:40:23.069
    STEP: fetching the ConfigMap 05/01/23 22:40:23.175
    STEP: patching the ConfigMap 05/01/23 22:40:23.279
    STEP: listing all ConfigMaps in all namespaces with a label selector 05/01/23 22:40:23.385
    STEP: deleting the ConfigMap by collection with a label selector 05/01/23 22:40:23.489
    STEP: listing all ConfigMaps in test namespace 05/01/23 22:40:23.596
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 22:40:23.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9034" for this suite. 05/01/23 22:40:23.804
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:40:23.913
May  1 22:40:23.913: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 22:40:23.914
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:24.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:24.433
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 05/01/23 22:40:24.639
May  1 22:40:24.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075" in namespace "projected-888" to be "Succeeded or Failed"
May  1 22:40:24.851: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Pending", Reason="", readiness=false. Elapsed: 104.435825ms
May  1 22:40:26.964: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.216653333s
May  1 22:40:28.956: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Pending", Reason="", readiness=false. Elapsed: 4.2087887s
May  1 22:40:30.956: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.209054514s
STEP: Saw pod success 05/01/23 22:40:30.956
May  1 22:40:30.956: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075" satisfied condition "Succeeded or Failed"
May  1 22:40:31.060: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075 container client-container: <nil>
STEP: delete the pod 05/01/23 22:40:31.176
May  1 22:40:31.288: INFO: Waiting for pod downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075 to disappear
May  1 22:40:31.391: INFO: Pod downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  1 22:40:31.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-888" for this suite. 05/01/23 22:40:31.497
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":8,"skipped":100,"failed":0}
------------------------------
• [SLOW TEST] [7.690 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:40:23.913
    May  1 22:40:23.913: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 22:40:23.914
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:24.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:24.433
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 05/01/23 22:40:24.639
    May  1 22:40:24.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075" in namespace "projected-888" to be "Succeeded or Failed"
    May  1 22:40:24.851: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Pending", Reason="", readiness=false. Elapsed: 104.435825ms
    May  1 22:40:26.964: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Pending", Reason="", readiness=false. Elapsed: 2.216653333s
    May  1 22:40:28.956: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Pending", Reason="", readiness=false. Elapsed: 4.2087887s
    May  1 22:40:30.956: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.209054514s
    STEP: Saw pod success 05/01/23 22:40:30.956
    May  1 22:40:30.956: INFO: Pod "downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075" satisfied condition "Succeeded or Failed"
    May  1 22:40:31.060: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075 container client-container: <nil>
    STEP: delete the pod 05/01/23 22:40:31.176
    May  1 22:40:31.288: INFO: Waiting for pod downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075 to disappear
    May  1 22:40:31.391: INFO: Pod downwardapi-volume-c3793fa2-6fc2-4eec-bb5f-a7fcf333f075 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  1 22:40:31.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-888" for this suite. 05/01/23 22:40:31.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:40:31.603
May  1 22:40:31.603: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container 05/01/23 22:40:31.604
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:31.918
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:32.124
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 05/01/23 22:40:32.331
May  1 22:40:32.331: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
May  1 22:40:36.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5262" for this suite. 05/01/23 22:40:36.296
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":9,"skipped":114,"failed":0}
------------------------------
• [4.798 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:40:31.603
    May  1 22:40:31.603: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename init-container 05/01/23 22:40:31.604
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:31.918
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:32.124
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 05/01/23 22:40:32.331
    May  1 22:40:32.331: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    May  1 22:40:36.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5262" for this suite. 05/01/23 22:40:36.296
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:40:36.403
May  1 22:40:36.403: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pod-network-test 05/01/23 22:40:36.405
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:36.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:36.924
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-8240 05/01/23 22:40:37.13
STEP: creating a selector 05/01/23 22:40:37.13
STEP: Creating the service pods in kubernetes 05/01/23 22:40:37.13
May  1 22:40:37.130: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  1 22:40:37.765: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8240" to be "running and ready"
May  1 22:40:37.869: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 104.082497ms
May  1 22:40:37.870: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:40:39.975: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209308515s
May  1 22:40:39.975: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:40:41.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.209130839s
May  1 22:40:41.975: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:43.976: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.210113209s
May  1 22:40:43.976: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:45.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.208836872s
May  1 22:40:45.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:47.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.209714734s
May  1 22:40:47.975: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:49.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.208484548s
May  1 22:40:49.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:51.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.208455376s
May  1 22:40:51.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:53.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.209682377s
May  1 22:40:53.975: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:55.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.208441359s
May  1 22:40:55.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:40:57.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 20.209309617s
May  1 22:40:57.975: INFO: The phase of Pod netserver-0 is Running (Ready = true)
May  1 22:40:57.975: INFO: Pod "netserver-0" satisfied condition "running and ready"
May  1 22:40:58.079: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8240" to be "running and ready"
May  1 22:40:58.183: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 104.147287ms
May  1 22:40:58.183: INFO: The phase of Pod netserver-1 is Running (Ready = true)
May  1 22:40:58.183: INFO: Pod "netserver-1" satisfied condition "running and ready"
May  1 22:40:58.288: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8240" to be "running and ready"
May  1 22:40:58.392: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 103.936225ms
May  1 22:40:58.392: INFO: The phase of Pod netserver-2 is Running (Ready = true)
May  1 22:40:58.392: INFO: Pod "netserver-2" satisfied condition "running and ready"
May  1 22:40:58.496: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-8240" to be "running and ready"
May  1 22:40:58.600: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 104.076273ms
May  1 22:40:58.600: INFO: The phase of Pod netserver-3 is Running (Ready = true)
May  1 22:40:58.600: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 05/01/23 22:40:58.704
May  1 22:40:58.810: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8240" to be "running"
May  1 22:40:58.914: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.758414ms
May  1 22:41:01.018: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208346307s
May  1 22:41:01.019: INFO: Pod "test-container-pod" satisfied condition "running"
May  1 22:41:01.122: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
May  1 22:41:01.123: INFO: Breadth first check of 100.123.145.198 on host 172.20.44.200...
May  1 22:41:01.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.123.145.198&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:41:01.227: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:41:01.228: INFO: ExecWithOptions: Clientset creation
May  1 22:41:01.228: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.123.145.198%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  1 22:41:01.956: INFO: Waiting for responses: map[]
May  1 22:41:01.956: INFO: reached 100.123.145.198 after 0/1 tries
May  1 22:41:01.956: INFO: Breadth first check of 100.96.36.6 on host 172.20.48.211...
May  1 22:41:02.060: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.96.36.6&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:41:02.060: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:41:02.061: INFO: ExecWithOptions: Clientset creation
May  1 22:41:02.061: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.36.6%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  1 22:41:02.763: INFO: Waiting for responses: map[]
May  1 22:41:02.763: INFO: reached 100.96.36.6 after 0/1 tries
May  1 22:41:02.763: INFO: Breadth first check of 100.105.72.133 on host 172.20.62.149...
May  1 22:41:02.867: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.105.72.133&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:41:02.867: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:41:02.868: INFO: ExecWithOptions: Clientset creation
May  1 22:41:02.868: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.105.72.133%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  1 22:41:03.581: INFO: Waiting for responses: map[]
May  1 22:41:03.581: INFO: reached 100.105.72.133 after 0/1 tries
May  1 22:41:03.581: INFO: Breadth first check of 100.101.231.132 on host 172.20.39.145...
May  1 22:41:03.685: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.101.231.132&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:41:03.685: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:41:03.686: INFO: ExecWithOptions: Clientset creation
May  1 22:41:03.686: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.101.231.132%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  1 22:41:04.431: INFO: Waiting for responses: map[]
May  1 22:41:04.431: INFO: reached 100.101.231.132 after 0/1 tries
May  1 22:41:04.431: INFO: Going to retry 0 out of 4 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
May  1 22:41:04.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8240" for this suite. 05/01/23 22:41:04.536
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":10,"skipped":131,"failed":0}
------------------------------
• [SLOW TEST] [28.239 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:40:36.403
    May  1 22:40:36.403: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pod-network-test 05/01/23 22:40:36.405
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:40:36.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:40:36.924
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-8240 05/01/23 22:40:37.13
    STEP: creating a selector 05/01/23 22:40:37.13
    STEP: Creating the service pods in kubernetes 05/01/23 22:40:37.13
    May  1 22:40:37.130: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    May  1 22:40:37.765: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8240" to be "running and ready"
    May  1 22:40:37.869: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 104.082497ms
    May  1 22:40:37.870: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:40:39.975: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209308515s
    May  1 22:40:39.975: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:40:41.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.209130839s
    May  1 22:40:41.975: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:43.976: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.210113209s
    May  1 22:40:43.976: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:45.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.208836872s
    May  1 22:40:45.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:47.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.209714734s
    May  1 22:40:47.975: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:49.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.208484548s
    May  1 22:40:49.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:51.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.208455376s
    May  1 22:40:51.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:53.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.209682377s
    May  1 22:40:53.975: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:55.974: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.208441359s
    May  1 22:40:55.974: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:40:57.975: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 20.209309617s
    May  1 22:40:57.975: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    May  1 22:40:57.975: INFO: Pod "netserver-0" satisfied condition "running and ready"
    May  1 22:40:58.079: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8240" to be "running and ready"
    May  1 22:40:58.183: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 104.147287ms
    May  1 22:40:58.183: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    May  1 22:40:58.183: INFO: Pod "netserver-1" satisfied condition "running and ready"
    May  1 22:40:58.288: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8240" to be "running and ready"
    May  1 22:40:58.392: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 103.936225ms
    May  1 22:40:58.392: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    May  1 22:40:58.392: INFO: Pod "netserver-2" satisfied condition "running and ready"
    May  1 22:40:58.496: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-8240" to be "running and ready"
    May  1 22:40:58.600: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 104.076273ms
    May  1 22:40:58.600: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    May  1 22:40:58.600: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 05/01/23 22:40:58.704
    May  1 22:40:58.810: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8240" to be "running"
    May  1 22:40:58.914: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.758414ms
    May  1 22:41:01.018: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208346307s
    May  1 22:41:01.019: INFO: Pod "test-container-pod" satisfied condition "running"
    May  1 22:41:01.122: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    May  1 22:41:01.123: INFO: Breadth first check of 100.123.145.198 on host 172.20.44.200...
    May  1 22:41:01.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.123.145.198&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:41:01.227: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:41:01.228: INFO: ExecWithOptions: Clientset creation
    May  1 22:41:01.228: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.123.145.198%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  1 22:41:01.956: INFO: Waiting for responses: map[]
    May  1 22:41:01.956: INFO: reached 100.123.145.198 after 0/1 tries
    May  1 22:41:01.956: INFO: Breadth first check of 100.96.36.6 on host 172.20.48.211...
    May  1 22:41:02.060: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.96.36.6&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:41:02.060: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:41:02.061: INFO: ExecWithOptions: Clientset creation
    May  1 22:41:02.061: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.36.6%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  1 22:41:02.763: INFO: Waiting for responses: map[]
    May  1 22:41:02.763: INFO: reached 100.96.36.6 after 0/1 tries
    May  1 22:41:02.763: INFO: Breadth first check of 100.105.72.133 on host 172.20.62.149...
    May  1 22:41:02.867: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.105.72.133&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:41:02.867: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:41:02.868: INFO: ExecWithOptions: Clientset creation
    May  1 22:41:02.868: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.105.72.133%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  1 22:41:03.581: INFO: Waiting for responses: map[]
    May  1 22:41:03.581: INFO: reached 100.105.72.133 after 0/1 tries
    May  1 22:41:03.581: INFO: Breadth first check of 100.101.231.132 on host 172.20.39.145...
    May  1 22:41:03.685: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.105.72.134:9080/dial?request=hostname&protocol=udp&host=100.101.231.132&port=8081&tries=1'] Namespace:pod-network-test-8240 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:41:03.685: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:41:03.686: INFO: ExecWithOptions: Clientset creation
    May  1 22:41:03.686: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-8240/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.105.72.134%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.101.231.132%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  1 22:41:04.431: INFO: Waiting for responses: map[]
    May  1 22:41:04.431: INFO: reached 100.101.231.132 after 0/1 tries
    May  1 22:41:04.431: INFO: Going to retry 0 out of 4 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    May  1 22:41:04.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-8240" for this suite. 05/01/23 22:41:04.536
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:41:04.642
May  1 22:41:04.642: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir-wrapper 05/01/23 22:41:04.643
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:41:04.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:41:05.164
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 05/01/23 22:41:05.37
STEP: Creating RC which spawns configmap-volume pods 05/01/23 22:41:10.753
May  1 22:41:11.155: INFO: Pod name wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b: Found 5 pods out of 5
STEP: Ensuring each pod is running 05/01/23 22:41:11.155
May  1 22:41:11.155: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:11.259: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.174864ms
May  1 22:41:13.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208928627s
May  1 22:41:15.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.208851971s
May  1 22:41:17.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21004848s
May  1 22:41:19.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210292145s
May  1 22:41:21.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209515782s
May  1 22:41:23.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.209219488s
May  1 22:41:25.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Running", Reason="", readiness=true. Elapsed: 14.209789848s
May  1 22:41:25.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2" satisfied condition "running"
May  1 22:41:25.365: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:25.470: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf": Phase="Pending", Reason="", readiness=false. Elapsed: 104.929928ms
May  1 22:41:27.575: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf": Phase="Running", Reason="", readiness=true. Elapsed: 2.210399846s
May  1 22:41:27.575: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf" satisfied condition "running"
May  1 22:41:27.575: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-k9rk6" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:27.680: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-k9rk6": Phase="Running", Reason="", readiness=true. Elapsed: 104.574745ms
May  1 22:41:27.680: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-k9rk6" satisfied condition "running"
May  1 22:41:27.680: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-sfs6w" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:27.786: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-sfs6w": Phase="Running", Reason="", readiness=true. Elapsed: 105.911006ms
May  1 22:41:27.786: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-sfs6w" satisfied condition "running"
May  1 22:41:27.786: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-t5zjc" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:27.890: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-t5zjc": Phase="Running", Reason="", readiness=true. Elapsed: 104.46938ms
May  1 22:41:27.890: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-t5zjc" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b in namespace emptydir-wrapper-7976, will wait for the garbage collector to delete the pods 05/01/23 22:41:27.89
May  1 22:41:28.252: INFO: Deleting ReplicationController wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b took: 106.239594ms
May  1 22:41:28.352: INFO: Terminating ReplicationController wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b pods took: 100.45997ms
STEP: Creating RC which spawns configmap-volume pods 05/01/23 22:41:31.258
May  1 22:41:31.492: INFO: Pod name wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a: Found 5 pods out of 5
STEP: Ensuring each pod is running 05/01/23 22:41:31.492
May  1 22:41:31.492: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:31.596: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 104.528554ms
May  1 22:41:33.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209674362s
May  1 22:41:35.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209740899s
May  1 22:41:37.703: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 6.211145936s
May  1 22:41:39.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209593809s
May  1 22:41:41.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209708408s
May  1 22:41:43.702: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 12.21056237s
May  1 22:41:45.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Running", Reason="", readiness=true. Elapsed: 14.209783472s
May  1 22:41:45.702: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l" satisfied condition "running"
May  1 22:41:45.702: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-d6b7r" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:45.806: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-d6b7r": Phase="Running", Reason="", readiness=true. Elapsed: 104.448663ms
May  1 22:41:45.806: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-d6b7r" satisfied condition "running"
May  1 22:41:45.806: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mhmfk" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:45.911: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mhmfk": Phase="Running", Reason="", readiness=true. Elapsed: 104.851336ms
May  1 22:41:45.911: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mhmfk" satisfied condition "running"
May  1 22:41:45.911: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mk57c" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:46.016: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mk57c": Phase="Running", Reason="", readiness=true. Elapsed: 104.66368ms
May  1 22:41:46.016: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mk57c" satisfied condition "running"
May  1 22:41:46.016: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-t4vfk" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:46.120: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-t4vfk": Phase="Running", Reason="", readiness=true. Elapsed: 104.497999ms
May  1 22:41:46.120: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-t4vfk" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a in namespace emptydir-wrapper-7976, will wait for the garbage collector to delete the pods 05/01/23 22:41:46.12
May  1 22:41:46.482: INFO: Deleting ReplicationController wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a took: 106.329325ms
May  1 22:41:46.583: INFO: Terminating ReplicationController wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a pods took: 101.151371ms
STEP: Creating RC which spawns configmap-volume pods 05/01/23 22:41:49.789
May  1 22:41:50.010: INFO: Pod name wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2: Found 5 pods out of 5
STEP: Ensuring each pod is running 05/01/23 22:41:50.01
May  1 22:41:50.011: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:41:50.115: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 104.630311ms
May  1 22:41:52.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210812989s
May  1 22:41:54.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210779623s
May  1 22:41:56.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210029629s
May  1 22:41:58.222: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.211280448s
May  1 22:42:00.220: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209568851s
May  1 22:42:02.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 12.210885255s
May  1 22:42:04.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 14.210742192s
May  1 22:42:06.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Running", Reason="", readiness=true. Elapsed: 16.210018095s
May  1 22:42:06.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w" satisfied condition "running"
May  1 22:42:06.221: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-d7ptx" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:42:06.326: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-d7ptx": Phase="Running", Reason="", readiness=true. Elapsed: 105.347079ms
May  1 22:42:06.326: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-d7ptx" satisfied condition "running"
May  1 22:42:06.326: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-dctm7" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:42:06.431: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-dctm7": Phase="Running", Reason="", readiness=true. Elapsed: 104.552551ms
May  1 22:42:06.431: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-dctm7" satisfied condition "running"
May  1 22:42:06.431: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-lgrxl" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:42:06.535: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-lgrxl": Phase="Running", Reason="", readiness=true. Elapsed: 104.38677ms
May  1 22:42:06.535: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-lgrxl" satisfied condition "running"
May  1 22:42:06.535: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-zs7fl" in namespace "emptydir-wrapper-7976" to be "running"
May  1 22:42:06.640: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-zs7fl": Phase="Running", Reason="", readiness=true. Elapsed: 104.283082ms
May  1 22:42:06.640: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-zs7fl" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2 in namespace emptydir-wrapper-7976, will wait for the garbage collector to delete the pods 05/01/23 22:42:06.64
May  1 22:42:07.003: INFO: Deleting ReplicationController wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2 took: 107.400138ms
May  1 22:42:07.104: INFO: Terminating ReplicationController wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2 pods took: 101.088163ms
STEP: Cleaning up the configMaps 05/01/23 22:42:09.605
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
May  1 22:42:14.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7976" for this suite. 05/01/23 22:42:15.004
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":11,"skipped":149,"failed":0}
------------------------------
• [SLOW TEST] [70.467 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:41:04.642
    May  1 22:41:04.642: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir-wrapper 05/01/23 22:41:04.643
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:41:04.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:41:05.164
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 05/01/23 22:41:05.37
    STEP: Creating RC which spawns configmap-volume pods 05/01/23 22:41:10.753
    May  1 22:41:11.155: INFO: Pod name wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b: Found 5 pods out of 5
    STEP: Ensuring each pod is running 05/01/23 22:41:11.155
    May  1 22:41:11.155: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:11.259: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.174864ms
    May  1 22:41:13.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208928627s
    May  1 22:41:15.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.208851971s
    May  1 22:41:17.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21004848s
    May  1 22:41:19.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210292145s
    May  1 22:41:21.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209515782s
    May  1 22:41:23.364: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.209219488s
    May  1 22:41:25.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2": Phase="Running", Reason="", readiness=true. Elapsed: 14.209789848s
    May  1 22:41:25.365: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-5p7x2" satisfied condition "running"
    May  1 22:41:25.365: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:25.470: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf": Phase="Pending", Reason="", readiness=false. Elapsed: 104.929928ms
    May  1 22:41:27.575: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf": Phase="Running", Reason="", readiness=true. Elapsed: 2.210399846s
    May  1 22:41:27.575: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-g8mgf" satisfied condition "running"
    May  1 22:41:27.575: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-k9rk6" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:27.680: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-k9rk6": Phase="Running", Reason="", readiness=true. Elapsed: 104.574745ms
    May  1 22:41:27.680: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-k9rk6" satisfied condition "running"
    May  1 22:41:27.680: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-sfs6w" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:27.786: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-sfs6w": Phase="Running", Reason="", readiness=true. Elapsed: 105.911006ms
    May  1 22:41:27.786: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-sfs6w" satisfied condition "running"
    May  1 22:41:27.786: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-t5zjc" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:27.890: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-t5zjc": Phase="Running", Reason="", readiness=true. Elapsed: 104.46938ms
    May  1 22:41:27.890: INFO: Pod "wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b-t5zjc" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b in namespace emptydir-wrapper-7976, will wait for the garbage collector to delete the pods 05/01/23 22:41:27.89
    May  1 22:41:28.252: INFO: Deleting ReplicationController wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b took: 106.239594ms
    May  1 22:41:28.352: INFO: Terminating ReplicationController wrapped-volume-race-cf9af940-7c28-4945-b6fe-29aa1d20442b pods took: 100.45997ms
    STEP: Creating RC which spawns configmap-volume pods 05/01/23 22:41:31.258
    May  1 22:41:31.492: INFO: Pod name wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a: Found 5 pods out of 5
    STEP: Ensuring each pod is running 05/01/23 22:41:31.492
    May  1 22:41:31.492: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:31.596: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 104.528554ms
    May  1 22:41:33.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209674362s
    May  1 22:41:35.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209740899s
    May  1 22:41:37.703: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 6.211145936s
    May  1 22:41:39.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209593809s
    May  1 22:41:41.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209708408s
    May  1 22:41:43.702: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Pending", Reason="", readiness=false. Elapsed: 12.21056237s
    May  1 22:41:45.701: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l": Phase="Running", Reason="", readiness=true. Elapsed: 14.209783472s
    May  1 22:41:45.702: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-8vg5l" satisfied condition "running"
    May  1 22:41:45.702: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-d6b7r" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:45.806: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-d6b7r": Phase="Running", Reason="", readiness=true. Elapsed: 104.448663ms
    May  1 22:41:45.806: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-d6b7r" satisfied condition "running"
    May  1 22:41:45.806: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mhmfk" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:45.911: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mhmfk": Phase="Running", Reason="", readiness=true. Elapsed: 104.851336ms
    May  1 22:41:45.911: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mhmfk" satisfied condition "running"
    May  1 22:41:45.911: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mk57c" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:46.016: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mk57c": Phase="Running", Reason="", readiness=true. Elapsed: 104.66368ms
    May  1 22:41:46.016: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-mk57c" satisfied condition "running"
    May  1 22:41:46.016: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-t4vfk" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:46.120: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-t4vfk": Phase="Running", Reason="", readiness=true. Elapsed: 104.497999ms
    May  1 22:41:46.120: INFO: Pod "wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a-t4vfk" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a in namespace emptydir-wrapper-7976, will wait for the garbage collector to delete the pods 05/01/23 22:41:46.12
    May  1 22:41:46.482: INFO: Deleting ReplicationController wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a took: 106.329325ms
    May  1 22:41:46.583: INFO: Terminating ReplicationController wrapped-volume-race-8cd9bf6e-b714-4926-8754-d1bff97ae52a pods took: 101.151371ms
    STEP: Creating RC which spawns configmap-volume pods 05/01/23 22:41:49.789
    May  1 22:41:50.010: INFO: Pod name wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2: Found 5 pods out of 5
    STEP: Ensuring each pod is running 05/01/23 22:41:50.01
    May  1 22:41:50.011: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:41:50.115: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 104.630311ms
    May  1 22:41:52.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210812989s
    May  1 22:41:54.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210779623s
    May  1 22:41:56.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210029629s
    May  1 22:41:58.222: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.211280448s
    May  1 22:42:00.220: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209568851s
    May  1 22:42:02.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 12.210885255s
    May  1 22:42:04.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Pending", Reason="", readiness=false. Elapsed: 14.210742192s
    May  1 22:42:06.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w": Phase="Running", Reason="", readiness=true. Elapsed: 16.210018095s
    May  1 22:42:06.221: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-9qr2w" satisfied condition "running"
    May  1 22:42:06.221: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-d7ptx" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:42:06.326: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-d7ptx": Phase="Running", Reason="", readiness=true. Elapsed: 105.347079ms
    May  1 22:42:06.326: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-d7ptx" satisfied condition "running"
    May  1 22:42:06.326: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-dctm7" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:42:06.431: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-dctm7": Phase="Running", Reason="", readiness=true. Elapsed: 104.552551ms
    May  1 22:42:06.431: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-dctm7" satisfied condition "running"
    May  1 22:42:06.431: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-lgrxl" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:42:06.535: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-lgrxl": Phase="Running", Reason="", readiness=true. Elapsed: 104.38677ms
    May  1 22:42:06.535: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-lgrxl" satisfied condition "running"
    May  1 22:42:06.535: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-zs7fl" in namespace "emptydir-wrapper-7976" to be "running"
    May  1 22:42:06.640: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-zs7fl": Phase="Running", Reason="", readiness=true. Elapsed: 104.283082ms
    May  1 22:42:06.640: INFO: Pod "wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2-zs7fl" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2 in namespace emptydir-wrapper-7976, will wait for the garbage collector to delete the pods 05/01/23 22:42:06.64
    May  1 22:42:07.003: INFO: Deleting ReplicationController wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2 took: 107.400138ms
    May  1 22:42:07.104: INFO: Terminating ReplicationController wrapped-volume-race-03d3eb64-05f6-4980-aca9-51635a6b38e2 pods took: 101.088163ms
    STEP: Cleaning up the configMaps 05/01/23 22:42:09.605
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    May  1 22:42:14.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-7976" for this suite. 05/01/23 22:42:15.004
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:42:15.111
May  1 22:42:15.112: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context 05/01/23 22:42:15.113
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:15.427
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:15.635
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 05/01/23 22:42:15.841
May  1 22:42:15.948: INFO: Waiting up to 5m0s for pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be" in namespace "security-context-7086" to be "Succeeded or Failed"
May  1 22:42:16.052: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be": Phase="Pending", Reason="", readiness=false. Elapsed: 103.979594ms
May  1 22:42:18.158: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209425558s
May  1 22:42:20.157: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208484171s
STEP: Saw pod success 05/01/23 22:42:20.157
May  1 22:42:20.157: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be" satisfied condition "Succeeded or Failed"
May  1 22:42:20.263: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be container test-container: <nil>
STEP: delete the pod 05/01/23 22:42:20.378
May  1 22:42:20.492: INFO: Waiting for pod security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be to disappear
May  1 22:42:20.596: INFO: Pod security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
May  1 22:42:20.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7086" for this suite. 05/01/23 22:42:20.702
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":12,"skipped":171,"failed":0}
------------------------------
• [SLOW TEST] [5.697 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:42:15.111
    May  1 22:42:15.112: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename security-context 05/01/23 22:42:15.113
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:15.427
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:15.635
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 05/01/23 22:42:15.841
    May  1 22:42:15.948: INFO: Waiting up to 5m0s for pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be" in namespace "security-context-7086" to be "Succeeded or Failed"
    May  1 22:42:16.052: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be": Phase="Pending", Reason="", readiness=false. Elapsed: 103.979594ms
    May  1 22:42:18.158: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209425558s
    May  1 22:42:20.157: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208484171s
    STEP: Saw pod success 05/01/23 22:42:20.157
    May  1 22:42:20.157: INFO: Pod "security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be" satisfied condition "Succeeded or Failed"
    May  1 22:42:20.263: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be container test-container: <nil>
    STEP: delete the pod 05/01/23 22:42:20.378
    May  1 22:42:20.492: INFO: Waiting for pod security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be to disappear
    May  1 22:42:20.596: INFO: Pod security-context-5ff13e6b-a25d-4c38-abee-b7d5b7a534be no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    May  1 22:42:20.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7086" for this suite. 05/01/23 22:42:20.702
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:42:20.812
May  1 22:42:20.812: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 22:42:20.813
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:21.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:21.335
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-23394d67-b8a2-4673-911f-7261186a251d 05/01/23 22:42:21.542
STEP: Creating a pod to test consume configMaps 05/01/23 22:42:21.647
May  1 22:42:21.755: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2" in namespace "projected-8053" to be "Succeeded or Failed"
May  1 22:42:21.858: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 103.855117ms
May  1 22:42:23.964: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2": Phase="Running", Reason="", readiness=false. Elapsed: 2.209318268s
May  1 22:42:25.963: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208365855s
STEP: Saw pod success 05/01/23 22:42:25.963
May  1 22:42:25.963: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2" satisfied condition "Succeeded or Failed"
May  1 22:42:26.067: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 22:42:26.174
May  1 22:42:26.286: INFO: Waiting for pod pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2 to disappear
May  1 22:42:26.389: INFO: Pod pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  1 22:42:26.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8053" for this suite. 05/01/23 22:42:26.494
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":13,"skipped":219,"failed":0}
------------------------------
• [SLOW TEST] [5.788 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:42:20.812
    May  1 22:42:20.812: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 22:42:20.813
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:21.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:21.335
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-23394d67-b8a2-4673-911f-7261186a251d 05/01/23 22:42:21.542
    STEP: Creating a pod to test consume configMaps 05/01/23 22:42:21.647
    May  1 22:42:21.755: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2" in namespace "projected-8053" to be "Succeeded or Failed"
    May  1 22:42:21.858: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 103.855117ms
    May  1 22:42:23.964: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2": Phase="Running", Reason="", readiness=false. Elapsed: 2.209318268s
    May  1 22:42:25.963: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208365855s
    STEP: Saw pod success 05/01/23 22:42:25.963
    May  1 22:42:25.963: INFO: Pod "pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2" satisfied condition "Succeeded or Failed"
    May  1 22:42:26.067: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 22:42:26.174
    May  1 22:42:26.286: INFO: Waiting for pod pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2 to disappear
    May  1 22:42:26.389: INFO: Pod pod-projected-configmaps-d12a39a9-0d7e-4a2e-b5af-bf44591f23a2 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  1 22:42:26.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8053" for this suite. 05/01/23 22:42:26.494
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:42:26.601
May  1 22:42:26.601: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 22:42:26.602
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:26.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:27.122
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 05/01/23 22:42:27.328
May  1 22:42:27.435: INFO: Waiting up to 5m0s for pod "downward-api-8c1a5347-320a-4188-959d-123d84257530" in namespace "downward-api-4578" to be "Succeeded or Failed"
May  1 22:42:27.539: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530": Phase="Pending", Reason="", readiness=false. Elapsed: 104.121414ms
May  1 22:42:29.644: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209720674s
May  1 22:42:31.643: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208257352s
STEP: Saw pod success 05/01/23 22:42:31.643
May  1 22:42:31.643: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530" satisfied condition "Succeeded or Failed"
May  1 22:42:31.747: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-8c1a5347-320a-4188-959d-123d84257530 container dapi-container: <nil>
STEP: delete the pod 05/01/23 22:42:31.86
May  1 22:42:31.973: INFO: Waiting for pod downward-api-8c1a5347-320a-4188-959d-123d84257530 to disappear
May  1 22:42:32.077: INFO: Pod downward-api-8c1a5347-320a-4188-959d-123d84257530 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
May  1 22:42:32.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4578" for this suite. 05/01/23 22:42:32.182
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":14,"skipped":220,"failed":0}
------------------------------
• [SLOW TEST] [5.687 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:42:26.601
    May  1 22:42:26.601: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 22:42:26.602
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:26.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:27.122
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 05/01/23 22:42:27.328
    May  1 22:42:27.435: INFO: Waiting up to 5m0s for pod "downward-api-8c1a5347-320a-4188-959d-123d84257530" in namespace "downward-api-4578" to be "Succeeded or Failed"
    May  1 22:42:27.539: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530": Phase="Pending", Reason="", readiness=false. Elapsed: 104.121414ms
    May  1 22:42:29.644: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209720674s
    May  1 22:42:31.643: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208257352s
    STEP: Saw pod success 05/01/23 22:42:31.643
    May  1 22:42:31.643: INFO: Pod "downward-api-8c1a5347-320a-4188-959d-123d84257530" satisfied condition "Succeeded or Failed"
    May  1 22:42:31.747: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-8c1a5347-320a-4188-959d-123d84257530 container dapi-container: <nil>
    STEP: delete the pod 05/01/23 22:42:31.86
    May  1 22:42:31.973: INFO: Waiting for pod downward-api-8c1a5347-320a-4188-959d-123d84257530 to disappear
    May  1 22:42:32.077: INFO: Pod downward-api-8c1a5347-320a-4188-959d-123d84257530 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    May  1 22:42:32.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4578" for this suite. 05/01/23 22:42:32.182
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:42:32.288
May  1 22:42:32.288: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 22:42:32.289
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:32.602
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:32.808
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-298f353d-081c-493b-b8be-1b3fc64d7dd1 05/01/23 22:42:33.015
STEP: Creating a pod to test consume secrets 05/01/23 22:42:33.12
May  1 22:42:33.230: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf" in namespace "projected-7822" to be "Succeeded or Failed"
May  1 22:42:33.334: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf": Phase="Pending", Reason="", readiness=false. Elapsed: 103.89373ms
May  1 22:42:35.438: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208727746s
May  1 22:42:37.439: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209481258s
STEP: Saw pod success 05/01/23 22:42:37.439
May  1 22:42:37.439: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf" satisfied condition "Succeeded or Failed"
May  1 22:42:37.543: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf container projected-secret-volume-test: <nil>
STEP: delete the pod 05/01/23 22:42:37.65
May  1 22:42:37.760: INFO: Waiting for pod pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf to disappear
May  1 22:42:37.864: INFO: Pod pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  1 22:42:37.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7822" for this suite. 05/01/23 22:42:37.969
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":15,"skipped":225,"failed":0}
------------------------------
• [SLOW TEST] [5.787 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:42:32.288
    May  1 22:42:32.288: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 22:42:32.289
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:32.602
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:32.808
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-298f353d-081c-493b-b8be-1b3fc64d7dd1 05/01/23 22:42:33.015
    STEP: Creating a pod to test consume secrets 05/01/23 22:42:33.12
    May  1 22:42:33.230: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf" in namespace "projected-7822" to be "Succeeded or Failed"
    May  1 22:42:33.334: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf": Phase="Pending", Reason="", readiness=false. Elapsed: 103.89373ms
    May  1 22:42:35.438: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208727746s
    May  1 22:42:37.439: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209481258s
    STEP: Saw pod success 05/01/23 22:42:37.439
    May  1 22:42:37.439: INFO: Pod "pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf" satisfied condition "Succeeded or Failed"
    May  1 22:42:37.543: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf container projected-secret-volume-test: <nil>
    STEP: delete the pod 05/01/23 22:42:37.65
    May  1 22:42:37.760: INFO: Waiting for pod pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf to disappear
    May  1 22:42:37.864: INFO: Pod pod-projected-secrets-cd59744e-b8cf-4957-8bef-cd8597e891cf no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  1 22:42:37.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7822" for this suite. 05/01/23 22:42:37.969
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:42:38.076
May  1 22:42:38.076: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime 05/01/23 22:42:38.077
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:38.39
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:38.596
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 05/01/23 22:42:38.802
STEP: wait for the container to reach Succeeded 05/01/23 22:42:38.908
STEP: get the container status 05/01/23 22:42:43.43
STEP: the container should be terminated 05/01/23 22:42:43.534
STEP: the termination message should be set 05/01/23 22:42:43.534
May  1 22:42:43.534: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 05/01/23 22:42:43.534
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
May  1 22:42:43.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4942" for this suite. 05/01/23 22:42:43.855
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":16,"skipped":244,"failed":0}
------------------------------
• [SLOW TEST] [5.885 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:42:38.076
    May  1 22:42:38.076: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-runtime 05/01/23 22:42:38.077
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:38.39
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:38.596
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 05/01/23 22:42:38.802
    STEP: wait for the container to reach Succeeded 05/01/23 22:42:38.908
    STEP: get the container status 05/01/23 22:42:43.43
    STEP: the container should be terminated 05/01/23 22:42:43.534
    STEP: the termination message should be set 05/01/23 22:42:43.534
    May  1 22:42:43.534: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 05/01/23 22:42:43.534
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    May  1 22:42:43.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4942" for this suite. 05/01/23 22:42:43.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:42:43.964
May  1 22:42:43.964: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/01/23 22:42:43.966
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:44.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:44.486
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2408 05/01/23 22:42:44.692
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-2408 05/01/23 22:42:44.799
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2408 05/01/23 22:42:44.907
May  1 22:42:45.011: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May  1 22:42:55.117: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 05/01/23 22:42:55.117
May  1 22:42:55.222: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 22:42:56.896: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 22:42:56.896: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 22:42:56.896: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 22:42:57.001: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  1 22:43:07.108: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  1 22:43:07.108: INFO: Waiting for statefulset status.replicas updated to 0
May  1 22:43:07.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999513s
May  1 22:43:08.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.895673727s
May  1 22:43:09.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.791377392s
May  1 22:43:10.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.686617791s
May  1 22:43:11.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.5820713s
May  1 22:43:13.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.477289666s
May  1 22:43:14.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.372536402s
May  1 22:43:15.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.267600057s
May  1 22:43:16.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.161680625s
May  1 22:43:17.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 56.156616ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2408 05/01/23 22:43:18.471
May  1 22:43:18.576: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 22:43:19.685: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  1 22:43:19.685: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  1 22:43:19.685: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  1 22:43:19.685: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 22:43:20.814: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  1 22:43:20.814: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  1 22:43:20.814: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  1 22:43:20.814: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 22:43:21.935: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  1 22:43:21.936: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  1 22:43:21.936: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  1 22:43:22.040: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  1 22:43:22.040: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  1 22:43:22.040: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 05/01/23 22:43:22.04
May  1 22:43:22.145: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 22:43:23.261: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 22:43:23.261: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 22:43:23.261: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 22:43:23.261: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 22:43:24.394: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 22:43:24.394: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 22:43:24.394: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 22:43:24.394: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 22:43:25.502: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 22:43:25.502: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 22:43:25.502: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 22:43:25.502: INFO: Waiting for statefulset status.replicas updated to 0
May  1 22:43:25.608: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May  1 22:43:35.818: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  1 22:43:35.818: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  1 22:43:35.818: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  1 22:43:36.133: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
May  1 22:43:36.133: INFO: ss-0  i-02d061b30635c230c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:42:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:42:44 +0000 UTC  }]
May  1 22:43:36.134: INFO: ss-1  i-0627b78ff917cf2ae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  }]
May  1 22:43:36.134: INFO: ss-2  i-00fed7c0a42791aae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  }]
May  1 22:43:36.134: INFO: 
May  1 22:43:36.134: INFO: StatefulSet ss has not reached scale 0, at 3
May  1 22:43:37.238: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
May  1 22:43:37.238: INFO: ss-2  i-00fed7c0a42791aae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  }]
May  1 22:43:37.238: INFO: 
May  1 22:43:37.238: INFO: StatefulSet ss has not reached scale 0, at 1
May  1 22:43:38.342: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.790985262s
May  1 22:43:39.447: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.686794097s
May  1 22:43:40.551: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.582571489s
May  1 22:43:41.656: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.477954752s
May  1 22:43:42.760: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.373475178s
May  1 22:43:43.864: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.269022614s
May  1 22:43:44.969: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.164530162s
May  1 22:43:46.073: INFO: Verifying statefulset ss doesn't scale past 0 for another 60.584969ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2408 05/01/23 22:43:47.073
May  1 22:43:47.177: INFO: Scaling statefulset ss to 0
May  1 22:43:47.500: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  1 22:43:47.604: INFO: Deleting all statefulset in ns statefulset-2408
May  1 22:43:47.708: INFO: Scaling statefulset ss to 0
May  1 22:43:48.021: INFO: Waiting for statefulset status.replicas updated to 0
May  1 22:43:48.125: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  1 22:43:48.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2408" for this suite. 05/01/23 22:43:48.543
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":17,"skipped":302,"failed":0}
------------------------------
• [SLOW TEST] [64.685 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:42:43.964
    May  1 22:42:43.964: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/01/23 22:42:43.966
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:42:44.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:42:44.486
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2408 05/01/23 22:42:44.692
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-2408 05/01/23 22:42:44.799
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2408 05/01/23 22:42:44.907
    May  1 22:42:45.011: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    May  1 22:42:55.117: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 05/01/23 22:42:55.117
    May  1 22:42:55.222: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 22:42:56.896: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 22:42:56.896: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 22:42:56.896: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 22:42:57.001: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    May  1 22:43:07.108: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    May  1 22:43:07.108: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 22:43:07.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999513s
    May  1 22:43:08.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.895673727s
    May  1 22:43:09.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.791377392s
    May  1 22:43:10.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.686617791s
    May  1 22:43:11.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.5820713s
    May  1 22:43:13.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.477289666s
    May  1 22:43:14.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.372536402s
    May  1 22:43:15.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.267600057s
    May  1 22:43:16.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.161680625s
    May  1 22:43:17.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 56.156616ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2408 05/01/23 22:43:18.471
    May  1 22:43:18.576: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 22:43:19.685: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    May  1 22:43:19.685: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  1 22:43:19.685: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  1 22:43:19.685: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 22:43:20.814: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    May  1 22:43:20.814: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  1 22:43:20.814: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  1 22:43:20.814: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 22:43:21.935: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    May  1 22:43:21.936: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  1 22:43:21.936: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  1 22:43:22.040: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    May  1 22:43:22.040: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    May  1 22:43:22.040: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 05/01/23 22:43:22.04
    May  1 22:43:22.145: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 22:43:23.261: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 22:43:23.261: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 22:43:23.261: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 22:43:23.261: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 22:43:24.394: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 22:43:24.394: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 22:43:24.394: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 22:43:24.394: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-2408 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 22:43:25.502: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 22:43:25.502: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 22:43:25.502: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 22:43:25.502: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 22:43:25.608: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    May  1 22:43:35.818: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    May  1 22:43:35.818: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    May  1 22:43:35.818: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    May  1 22:43:36.133: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
    May  1 22:43:36.133: INFO: ss-0  i-02d061b30635c230c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:42:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:42:44 +0000 UTC  }]
    May  1 22:43:36.134: INFO: ss-1  i-0627b78ff917cf2ae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  }]
    May  1 22:43:36.134: INFO: ss-2  i-00fed7c0a42791aae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  }]
    May  1 22:43:36.134: INFO: 
    May  1 22:43:36.134: INFO: StatefulSet ss has not reached scale 0, at 3
    May  1 22:43:37.238: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
    May  1 22:43:37.238: INFO: ss-2  i-00fed7c0a42791aae  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 22:43:07 +0000 UTC  }]
    May  1 22:43:37.238: INFO: 
    May  1 22:43:37.238: INFO: StatefulSet ss has not reached scale 0, at 1
    May  1 22:43:38.342: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.790985262s
    May  1 22:43:39.447: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.686794097s
    May  1 22:43:40.551: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.582571489s
    May  1 22:43:41.656: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.477954752s
    May  1 22:43:42.760: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.373475178s
    May  1 22:43:43.864: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.269022614s
    May  1 22:43:44.969: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.164530162s
    May  1 22:43:46.073: INFO: Verifying statefulset ss doesn't scale past 0 for another 60.584969ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2408 05/01/23 22:43:47.073
    May  1 22:43:47.177: INFO: Scaling statefulset ss to 0
    May  1 22:43:47.500: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  1 22:43:47.604: INFO: Deleting all statefulset in ns statefulset-2408
    May  1 22:43:47.708: INFO: Scaling statefulset ss to 0
    May  1 22:43:48.021: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 22:43:48.125: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  1 22:43:48.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2408" for this suite. 05/01/23 22:43:48.543
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:43:48.649
May  1 22:43:48.649: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook 05/01/23 22:43:48.651
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:43:48.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:43:49.169
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 05/01/23 22:43:49.481
May  1 22:43:49.589: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9487" to be "running and ready"
May  1 22:43:49.693: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 104.02343ms
May  1 22:43:49.693: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  1 22:43:51.798: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.208778403s
May  1 22:43:51.798: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
May  1 22:43:51.798: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 05/01/23 22:43:51.902
May  1 22:43:52.007: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9487" to be "running and ready"
May  1 22:43:52.112: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 104.164619ms
May  1 22:43:52.112: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May  1 22:43:54.216: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.208313261s
May  1 22:43:54.216: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
May  1 22:43:54.216: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 05/01/23 22:43:54.32
May  1 22:43:54.426: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  1 22:43:54.530: INFO: Pod pod-with-prestop-exec-hook still exists
May  1 22:43:56.530: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  1 22:43:56.635: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 05/01/23 22:43:56.635
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
May  1 22:43:56.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9487" for this suite. 05/01/23 22:43:56.846
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":18,"skipped":302,"failed":0}
------------------------------
• [SLOW TEST] [8.302 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:43:48.649
    May  1 22:43:48.649: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-lifecycle-hook 05/01/23 22:43:48.651
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:43:48.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:43:49.169
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 05/01/23 22:43:49.481
    May  1 22:43:49.589: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9487" to be "running and ready"
    May  1 22:43:49.693: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 104.02343ms
    May  1 22:43:49.693: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:43:51.798: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.208778403s
    May  1 22:43:51.798: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    May  1 22:43:51.798: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 05/01/23 22:43:51.902
    May  1 22:43:52.007: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9487" to be "running and ready"
    May  1 22:43:52.112: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 104.164619ms
    May  1 22:43:52.112: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:43:54.216: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.208313261s
    May  1 22:43:54.216: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    May  1 22:43:54.216: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 05/01/23 22:43:54.32
    May  1 22:43:54.426: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    May  1 22:43:54.530: INFO: Pod pod-with-prestop-exec-hook still exists
    May  1 22:43:56.530: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    May  1 22:43:56.635: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 05/01/23 22:43:56.635
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    May  1 22:43:56.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9487" for this suite. 05/01/23 22:43:56.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:43:56.953
May  1 22:43:56.953: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/01/23 22:43:56.954
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:43:57.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:43:57.476
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 05/01/23 22:43:57.683
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local;sleep 1; done
 05/01/23 22:43:57.789
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local;sleep 1; done
 05/01/23 22:43:57.79
STEP: creating a pod to probe DNS 05/01/23 22:43:57.79
STEP: submitting the pod to kubernetes 05/01/23 22:43:57.79
May  1 22:43:57.899: INFO: Waiting up to 15m0s for pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784" in namespace "dns-4658" to be "running"
May  1 22:43:58.002: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Pending", Reason="", readiness=false. Elapsed: 103.592793ms
May  1 22:44:00.107: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208603691s
May  1 22:44:02.109: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210369731s
May  1 22:44:04.107: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Running", Reason="", readiness=true. Elapsed: 6.208034289s
May  1 22:44:04.107: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784" satisfied condition "running"
STEP: retrieving the pod 05/01/23 22:44:04.107
STEP: looking for the results for each expected name from probers 05/01/23 22:44:04.211
May  1 22:44:04.316: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:04.421: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:04.525: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:04.629: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:04.734: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:04.839: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:04.943: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:05.048: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:05.048: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

May  1 22:44:10.153: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.362: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.466: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.571: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.677: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.781: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.886: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:10.886: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

May  1 22:44:15.154: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.363: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.467: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.572: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.677: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.781: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.886: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:15.886: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

May  1 22:44:20.153: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.257: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.362: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.466: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.571: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.675: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.779: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.884: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:20.884: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

May  1 22:44:25.154: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.362: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.467: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.572: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.676: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.781: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.886: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:25.887: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

May  1 22:44:30.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:30.468: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:30.678: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
May  1 22:44:30.887: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local]

May  1 22:44:35.892: INFO: DNS probes using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 succeeded

STEP: deleting the pod 05/01/23 22:44:35.892
STEP: deleting the test headless service 05/01/23 22:44:36.015
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  1 22:44:36.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4658" for this suite. 05/01/23 22:44:36.24
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":19,"skipped":319,"failed":0}
------------------------------
• [SLOW TEST] [39.393 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:43:56.953
    May  1 22:43:56.953: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/01/23 22:43:56.954
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:43:57.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:43:57.476
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 05/01/23 22:43:57.683
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local;sleep 1; done
     05/01/23 22:43:57.789
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4658.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local;sleep 1; done
     05/01/23 22:43:57.79
    STEP: creating a pod to probe DNS 05/01/23 22:43:57.79
    STEP: submitting the pod to kubernetes 05/01/23 22:43:57.79
    May  1 22:43:57.899: INFO: Waiting up to 15m0s for pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784" in namespace "dns-4658" to be "running"
    May  1 22:43:58.002: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Pending", Reason="", readiness=false. Elapsed: 103.592793ms
    May  1 22:44:00.107: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208603691s
    May  1 22:44:02.109: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210369731s
    May  1 22:44:04.107: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784": Phase="Running", Reason="", readiness=true. Elapsed: 6.208034289s
    May  1 22:44:04.107: INFO: Pod "dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 22:44:04.107
    STEP: looking for the results for each expected name from probers 05/01/23 22:44:04.211
    May  1 22:44:04.316: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:04.421: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:04.525: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:04.629: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:04.734: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:04.839: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:04.943: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:05.048: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:05.048: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

    May  1 22:44:10.153: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.362: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.466: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.571: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.677: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.781: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.886: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:10.886: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

    May  1 22:44:15.154: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.363: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.467: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.572: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.677: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.781: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.886: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:15.886: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

    May  1 22:44:20.153: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.257: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.362: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.466: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.571: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.675: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.779: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.884: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:20.884: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

    May  1 22:44:25.154: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.362: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.467: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.572: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.676: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.781: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.886: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:25.887: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local jessie_udp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4658.svc.cluster.local]

    May  1 22:44:30.258: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:30.468: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:30.678: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local from pod dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784: the server could not find the requested resource (get pods dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784)
    May  1 22:44:30.887: INFO: Lookups using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4658.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4658.svc.cluster.local]

    May  1 22:44:35.892: INFO: DNS probes using dns-4658/dns-test-f152990f-3eae-43b6-a6a7-a31cc6093784 succeeded

    STEP: deleting the pod 05/01/23 22:44:35.892
    STEP: deleting the test headless service 05/01/23 22:44:36.015
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  1 22:44:36.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4658" for this suite. 05/01/23 22:44:36.24
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:44:36.347
May  1 22:44:36.347: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/01/23 22:44:36.348
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:44:36.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:44:36.869
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59 in namespace container-probe-7199 05/01/23 22:44:37.076
May  1 22:44:37.185: INFO: Waiting up to 5m0s for pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59" in namespace "container-probe-7199" to be "not pending"
May  1 22:44:37.290: INFO: Pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59": Phase="Pending", Reason="", readiness=false. Elapsed: 104.371522ms
May  1 22:44:39.394: INFO: Pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59": Phase="Running", Reason="", readiness=true. Elapsed: 2.208955271s
May  1 22:44:39.394: INFO: Pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59" satisfied condition "not pending"
May  1 22:44:39.394: INFO: Started pod liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59 in namespace container-probe-7199
STEP: checking the pod's current state and verifying that restartCount is present 05/01/23 22:44:39.394
May  1 22:44:39.499: INFO: Initial restart count of pod liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59 is 0
STEP: deleting the pod 05/01/23 22:48:41.603
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  1 22:48:41.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7199" for this suite. 05/01/23 22:48:41.822
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":20,"skipped":320,"failed":0}
------------------------------
• [SLOW TEST] [245.583 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:44:36.347
    May  1 22:44:36.347: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/01/23 22:44:36.348
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:44:36.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:44:36.869
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59 in namespace container-probe-7199 05/01/23 22:44:37.076
    May  1 22:44:37.185: INFO: Waiting up to 5m0s for pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59" in namespace "container-probe-7199" to be "not pending"
    May  1 22:44:37.290: INFO: Pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59": Phase="Pending", Reason="", readiness=false. Elapsed: 104.371522ms
    May  1 22:44:39.394: INFO: Pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59": Phase="Running", Reason="", readiness=true. Elapsed: 2.208955271s
    May  1 22:44:39.394: INFO: Pod "liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59" satisfied condition "not pending"
    May  1 22:44:39.394: INFO: Started pod liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59 in namespace container-probe-7199
    STEP: checking the pod's current state and verifying that restartCount is present 05/01/23 22:44:39.394
    May  1 22:44:39.499: INFO: Initial restart count of pod liveness-678d4759-d8a4-4b1d-b015-ab267c0efe59 is 0
    STEP: deleting the pod 05/01/23 22:48:41.603
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  1 22:48:41.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7199" for this suite. 05/01/23 22:48:41.822
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:48:41.931
May  1 22:48:41.931: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename hostport 05/01/23 22:48:41.933
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:48:42.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:48:42.454
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 05/01/23 22:48:42.766
May  1 22:48:42.875: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8297" to be "running and ready"
May  1 22:48:42.980: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 104.422596ms
May  1 22:48:42.980: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:48:45.086: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.21009306s
May  1 22:48:45.086: INFO: The phase of Pod pod1 is Running (Ready = true)
May  1 22:48:45.086: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.20.48.211 on the node which pod1 resides and expect scheduled 05/01/23 22:48:45.086
May  1 22:48:45.192: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8297" to be "running and ready"
May  1 22:48:45.296: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.333948ms
May  1 22:48:45.296: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:48:47.402: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.209451093s
May  1 22:48:47.402: INFO: The phase of Pod pod2 is Running (Ready = false)
May  1 22:48:49.402: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.209519369s
May  1 22:48:49.402: INFO: The phase of Pod pod2 is Running (Ready = true)
May  1 22:48:49.402: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.20.48.211 but use UDP protocol on the node which pod2 resides 05/01/23 22:48:49.402
May  1 22:48:49.507: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8297" to be "running and ready"
May  1 22:48:49.612: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 104.435179ms
May  1 22:48:49.612: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:48:51.718: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.211085696s
May  1 22:48:51.719: INFO: The phase of Pod pod3 is Running (Ready = true)
May  1 22:48:51.719: INFO: Pod "pod3" satisfied condition "running and ready"
May  1 22:48:51.828: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8297" to be "running and ready"
May  1 22:48:51.932: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 104.393331ms
May  1 22:48:51.932: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
May  1 22:48:54.037: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.209295587s
May  1 22:48:54.037: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
May  1 22:48:54.037: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 05/01/23 22:48:54.142
May  1 22:48:54.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.20.48.211 http://127.0.0.1:54323/hostname] Namespace:hostport-8297 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:48:54.142: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:48:54.143: INFO: ExecWithOptions: Clientset creation
May  1 22:48:54.143: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/hostport-8297/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.20.48.211+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.20.48.211, port: 54323 05/01/23 22:48:54.878
May  1 22:48:54.878: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.20.48.211:54323/hostname] Namespace:hostport-8297 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:48:54.878: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:48:54.879: INFO: ExecWithOptions: Clientset creation
May  1 22:48:54.879: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/hostport-8297/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.20.48.211%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.20.48.211, port: 54323 UDP 05/01/23 22:48:55.589
May  1 22:48:55.589: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.20.48.211 54323] Namespace:hostport-8297 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 22:48:55.589: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:48:55.590: INFO: ExecWithOptions: Clientset creation
May  1 22:48:55.590: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/hostport-8297/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.20.48.211+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
May  1 22:49:01.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8297" for this suite. 05/01/23 22:49:01.389
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":21,"skipped":333,"failed":0}
------------------------------
• [SLOW TEST] [19.564 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:48:41.931
    May  1 22:48:41.931: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename hostport 05/01/23 22:48:41.933
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:48:42.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:48:42.454
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 05/01/23 22:48:42.766
    May  1 22:48:42.875: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8297" to be "running and ready"
    May  1 22:48:42.980: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 104.422596ms
    May  1 22:48:42.980: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:48:45.086: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.21009306s
    May  1 22:48:45.086: INFO: The phase of Pod pod1 is Running (Ready = true)
    May  1 22:48:45.086: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.20.48.211 on the node which pod1 resides and expect scheduled 05/01/23 22:48:45.086
    May  1 22:48:45.192: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8297" to be "running and ready"
    May  1 22:48:45.296: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.333948ms
    May  1 22:48:45.296: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:48:47.402: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.209451093s
    May  1 22:48:47.402: INFO: The phase of Pod pod2 is Running (Ready = false)
    May  1 22:48:49.402: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.209519369s
    May  1 22:48:49.402: INFO: The phase of Pod pod2 is Running (Ready = true)
    May  1 22:48:49.402: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.20.48.211 but use UDP protocol on the node which pod2 resides 05/01/23 22:48:49.402
    May  1 22:48:49.507: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8297" to be "running and ready"
    May  1 22:48:49.612: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 104.435179ms
    May  1 22:48:49.612: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:48:51.718: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.211085696s
    May  1 22:48:51.719: INFO: The phase of Pod pod3 is Running (Ready = true)
    May  1 22:48:51.719: INFO: Pod "pod3" satisfied condition "running and ready"
    May  1 22:48:51.828: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8297" to be "running and ready"
    May  1 22:48:51.932: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 104.393331ms
    May  1 22:48:51.932: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:48:54.037: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.209295587s
    May  1 22:48:54.037: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    May  1 22:48:54.037: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 05/01/23 22:48:54.142
    May  1 22:48:54.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.20.48.211 http://127.0.0.1:54323/hostname] Namespace:hostport-8297 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:48:54.142: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:48:54.143: INFO: ExecWithOptions: Clientset creation
    May  1 22:48:54.143: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/hostport-8297/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.20.48.211+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.20.48.211, port: 54323 05/01/23 22:48:54.878
    May  1 22:48:54.878: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.20.48.211:54323/hostname] Namespace:hostport-8297 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:48:54.878: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:48:54.879: INFO: ExecWithOptions: Clientset creation
    May  1 22:48:54.879: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/hostport-8297/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.20.48.211%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.20.48.211, port: 54323 UDP 05/01/23 22:48:55.589
    May  1 22:48:55.589: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.20.48.211 54323] Namespace:hostport-8297 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 22:48:55.589: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:48:55.590: INFO: ExecWithOptions: Clientset creation
    May  1 22:48:55.590: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/hostport-8297/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.20.48.211+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    May  1 22:49:01.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-8297" for this suite. 05/01/23 22:49:01.389
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:01.496
May  1 22:49:01.496: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 22:49:01.497
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:01.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:02.022
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 05/01/23 22:49:02.229
May  1 22:49:02.338: INFO: Waiting up to 5m0s for pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39" in namespace "downward-api-5395" to be "Succeeded or Failed"
May  1 22:49:02.443: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39": Phase="Pending", Reason="", readiness=false. Elapsed: 104.381815ms
May  1 22:49:04.548: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209316037s
May  1 22:49:06.550: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211271981s
STEP: Saw pod success 05/01/23 22:49:06.55
May  1 22:49:06.550: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39" satisfied condition "Succeeded or Failed"
May  1 22:49:06.654: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39 container dapi-container: <nil>
STEP: delete the pod 05/01/23 22:49:06.769
May  1 22:49:06.881: INFO: Waiting for pod downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39 to disappear
May  1 22:49:06.985: INFO: Pod downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
May  1 22:49:06.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5395" for this suite. 05/01/23 22:49:07.091
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":22,"skipped":337,"failed":0}
------------------------------
• [SLOW TEST] [5.701 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:01.496
    May  1 22:49:01.496: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 22:49:01.497
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:01.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:02.022
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 05/01/23 22:49:02.229
    May  1 22:49:02.338: INFO: Waiting up to 5m0s for pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39" in namespace "downward-api-5395" to be "Succeeded or Failed"
    May  1 22:49:02.443: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39": Phase="Pending", Reason="", readiness=false. Elapsed: 104.381815ms
    May  1 22:49:04.548: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209316037s
    May  1 22:49:06.550: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211271981s
    STEP: Saw pod success 05/01/23 22:49:06.55
    May  1 22:49:06.550: INFO: Pod "downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39" satisfied condition "Succeeded or Failed"
    May  1 22:49:06.654: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39 container dapi-container: <nil>
    STEP: delete the pod 05/01/23 22:49:06.769
    May  1 22:49:06.881: INFO: Waiting for pod downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39 to disappear
    May  1 22:49:06.985: INFO: Pod downward-api-d75007fd-429b-4ccd-98b1-1cde45a2ee39 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    May  1 22:49:06.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5395" for this suite. 05/01/23 22:49:07.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:07.197
May  1 22:49:07.198: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred 05/01/23 22:49:07.199
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:07.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:07.723
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May  1 22:49:07.930: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  1 22:49:08.141: INFO: Waiting for terminating namespaces to be deleted...
May  1 22:49:08.245: INFO: 
Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
May  1 22:49:08.353: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.353: INFO: 	Container calico-node ready: true, restart count 0
May  1 22:49:08.353: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.353: INFO: 	Container coredns ready: true, restart count 0
May  1 22:49:08.353: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.353: INFO: 	Container autoscaler ready: true, restart count 0
May  1 22:49:08.353: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
May  1 22:49:08.353: INFO: 	Container csi-attacher ready: true, restart count 0
May  1 22:49:08.353: INFO: 	Container csi-provisioner ready: true, restart count 0
May  1 22:49:08.353: INFO: 	Container csi-resizer ready: true, restart count 0
May  1 22:49:08.353: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 22:49:08.353: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 22:49:08.353: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
May  1 22:49:08.353: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 22:49:08.353: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 22:49:08.353: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 22:49:08.353: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.353: INFO: 	Container kube-proxy ready: true, restart count 0
May  1 22:49:08.353: INFO: 
Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
May  1 22:49:08.461: INFO: pod2 from hostport-8297 started at 2023-05-01 22:48:45 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.461: INFO: 	Container agnhost ready: false, restart count 0
May  1 22:49:08.461: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.461: INFO: 	Container calico-node ready: true, restart count 0
May  1 22:49:08.461: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
May  1 22:49:08.461: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 22:49:08.461: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 22:49:08.461: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 22:49:08.461: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.461: INFO: 	Container kube-proxy ready: true, restart count 0
May  1 22:49:08.461: INFO: 
Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
May  1 22:49:08.569: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.569: INFO: 	Container calico-node ready: true, restart count 0
May  1 22:49:08.569: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
May  1 22:49:08.569: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 22:49:08.569: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 22:49:08.569: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 22:49:08.569: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.569: INFO: 	Container kube-proxy ready: true, restart count 0
May  1 22:49:08.569: INFO: 
Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
May  1 22:49:08.676: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.676: INFO: 	Container calico-node ready: true, restart count 0
May  1 22:49:08.676: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.676: INFO: 	Container coredns ready: true, restart count 0
May  1 22:49:08.676: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
May  1 22:49:08.676: INFO: 	Container csi-attacher ready: true, restart count 0
May  1 22:49:08.676: INFO: 	Container csi-provisioner ready: true, restart count 0
May  1 22:49:08.676: INFO: 	Container csi-resizer ready: true, restart count 0
May  1 22:49:08.676: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 22:49:08.676: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 22:49:08.676: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
May  1 22:49:08.676: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 22:49:08.676: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 22:49:08.676: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 22:49:08.676: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
May  1 22:49:08.676: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node i-00fed7c0a42791aae 05/01/23 22:49:08.903
STEP: verifying the node has the label node i-02d061b30635c230c 05/01/23 22:49:09.118
STEP: verifying the node has the label node i-0627b78ff917cf2ae 05/01/23 22:49:09.332
STEP: verifying the node has the label node i-0aa263047c51ef669 05/01/23 22:49:09.548
May  1 22:49:09.765: INFO: Pod calico-node-lr44d requesting resource cpu=100m on Node i-02d061b30635c230c
May  1 22:49:09.765: INFO: Pod calico-node-phdpj requesting resource cpu=100m on Node i-0aa263047c51ef669
May  1 22:49:09.765: INFO: Pod calico-node-vtrp8 requesting resource cpu=100m on Node i-0627b78ff917cf2ae
May  1 22:49:09.765: INFO: Pod calico-node-zd6l4 requesting resource cpu=100m on Node i-00fed7c0a42791aae
May  1 22:49:09.765: INFO: Pod coredns-6c7bddbb75-7b4g9 requesting resource cpu=100m on Node i-00fed7c0a42791aae
May  1 22:49:09.765: INFO: Pod coredns-6c7bddbb75-zv7nq requesting resource cpu=100m on Node i-0aa263047c51ef669
May  1 22:49:09.765: INFO: Pod coredns-autoscaler-db7b97744-xpnj5 requesting resource cpu=20m on Node i-00fed7c0a42791aae
May  1 22:49:09.765: INFO: Pod ebs-csi-controller-f987fd46-c4wk5 requesting resource cpu=0m on Node i-00fed7c0a42791aae
May  1 22:49:09.765: INFO: Pod ebs-csi-controller-f987fd46-vlkj2 requesting resource cpu=0m on Node i-0aa263047c51ef669
May  1 22:49:09.765: INFO: Pod ebs-csi-node-4hblj requesting resource cpu=0m on Node i-00fed7c0a42791aae
May  1 22:49:09.765: INFO: Pod ebs-csi-node-9zhf8 requesting resource cpu=0m on Node i-0627b78ff917cf2ae
May  1 22:49:09.765: INFO: Pod ebs-csi-node-hvkck requesting resource cpu=0m on Node i-0aa263047c51ef669
May  1 22:49:09.765: INFO: Pod ebs-csi-node-s46d6 requesting resource cpu=0m on Node i-02d061b30635c230c
May  1 22:49:09.765: INFO: Pod kube-proxy-i-00fed7c0a42791aae requesting resource cpu=100m on Node i-00fed7c0a42791aae
May  1 22:49:09.765: INFO: Pod kube-proxy-i-02d061b30635c230c requesting resource cpu=100m on Node i-02d061b30635c230c
May  1 22:49:09.765: INFO: Pod kube-proxy-i-0627b78ff917cf2ae requesting resource cpu=100m on Node i-0627b78ff917cf2ae
May  1 22:49:09.765: INFO: Pod kube-proxy-i-0aa263047c51ef669 requesting resource cpu=100m on Node i-0aa263047c51ef669
STEP: Starting Pods to consume most of the cluster CPU. 05/01/23 22:49:09.765
May  1 22:49:09.765: INFO: Creating a pod which consumes cpu=1176m on Node i-00fed7c0a42791aae
May  1 22:49:09.874: INFO: Creating a pod which consumes cpu=1260m on Node i-02d061b30635c230c
May  1 22:49:09.980: INFO: Creating a pod which consumes cpu=1260m on Node i-0627b78ff917cf2ae
May  1 22:49:10.086: INFO: Creating a pod which consumes cpu=1190m on Node i-0aa263047c51ef669
May  1 22:49:10.207: INFO: Waiting up to 5m0s for pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3" in namespace "sched-pred-3464" to be "running"
May  1 22:49:10.316: INFO: Pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 108.887457ms
May  1 22:49:12.421: INFO: Pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3": Phase="Running", Reason="", readiness=true. Elapsed: 2.213728019s
May  1 22:49:12.421: INFO: Pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3" satisfied condition "running"
May  1 22:49:12.421: INFO: Waiting up to 5m0s for pod "filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8" in namespace "sched-pred-3464" to be "running"
May  1 22:49:12.526: INFO: Pod "filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8": Phase="Running", Reason="", readiness=true. Elapsed: 104.500433ms
May  1 22:49:12.526: INFO: Pod "filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8" satisfied condition "running"
May  1 22:49:12.526: INFO: Waiting up to 5m0s for pod "filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324" in namespace "sched-pred-3464" to be "running"
May  1 22:49:12.630: INFO: Pod "filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324": Phase="Running", Reason="", readiness=true. Elapsed: 104.364332ms
May  1 22:49:12.630: INFO: Pod "filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324" satisfied condition "running"
May  1 22:49:12.630: INFO: Waiting up to 5m0s for pod "filler-pod-353f5d62-a27e-4690-b057-b55c76fab728" in namespace "sched-pred-3464" to be "running"
May  1 22:49:12.735: INFO: Pod "filler-pod-353f5d62-a27e-4690-b057-b55c76fab728": Phase="Running", Reason="", readiness=true. Elapsed: 104.539184ms
May  1 22:49:12.735: INFO: Pod "filler-pod-353f5d62-a27e-4690-b057-b55c76fab728" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 05/01/23 22:49:12.735
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f043ea35c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-353f5d62-a27e-4690-b057-b55c76fab728 to i-0aa263047c51ef669] 05/01/23 22:49:12.84
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f28e0a8b4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f29d7482d], Reason = [Created], Message = [Created container filler-pod-353f5d62-a27e-4690-b057-b55c76fab728] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f2e82a08f], Reason = [Started], Message = [Started container filler-pod-353f5d62-a27e-4690-b057-b55c76fab728] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269efceb8fd9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324 to i-0627b78ff917cf2ae] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269f232f2528], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269f242e4965], Reason = [Created], Message = [Created container filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269f2b9df649], Reason = [Started], Message = [Started container filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269ef689c4f0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8 to i-02d061b30635c230c] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f209657fb], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.8"] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f40bd2e17], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.8" in 539.378816ms (539.400343ms including waiting)] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f420f7074], Reason = [Created], Message = [Created container filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8] 05/01/23 22:49:12.841
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f46dcb0dd], Reason = [Started], Message = [Started container filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8] 05/01/23 22:49:12.842
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269ef01da864], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3 to i-00fed7c0a42791aae] 05/01/23 22:49:12.842
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269f1a1aa613], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 05/01/23 22:49:12.842
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269f1b5ca80e], Reason = [Created], Message = [Created container filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3] 05/01/23 22:49:12.842
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269f21b20e79], Reason = [Started], Message = [Started container filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3] 05/01/23 22:49:12.842
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.175b269fad312c72], Reason = [FailedScheduling], Message = [0/5 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 4 Insufficient cpu. preemption: 0/5 nodes are available: 1 Preemption is not helpful for scheduling, 4 No preemption victims found for incoming pod.] 05/01/23 22:49:13.055
STEP: removing the label node off the node i-0aa263047c51ef669 05/01/23 22:49:14.156
STEP: verifying the node doesn't have the label node 05/01/23 22:49:14.371
STEP: removing the label node off the node i-00fed7c0a42791aae 05/01/23 22:49:14.476
STEP: verifying the node doesn't have the label node 05/01/23 22:49:14.69
STEP: removing the label node off the node i-02d061b30635c230c 05/01/23 22:49:14.799
STEP: verifying the node doesn't have the label node 05/01/23 22:49:15.013
STEP: removing the label node off the node i-0627b78ff917cf2ae 05/01/23 22:49:15.118
STEP: verifying the node doesn't have the label node 05/01/23 22:49:15.333
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
May  1 22:49:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3464" for this suite. 05/01/23 22:49:15.544
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":23,"skipped":346,"failed":0}
------------------------------
• [SLOW TEST] [8.455 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:07.197
    May  1 22:49:07.198: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-pred 05/01/23 22:49:07.199
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:07.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:07.723
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    May  1 22:49:07.930: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    May  1 22:49:08.141: INFO: Waiting for terminating namespaces to be deleted...
    May  1 22:49:08.245: INFO: 
    Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
    May  1 22:49:08.353: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.353: INFO: 	Container calico-node ready: true, restart count 0
    May  1 22:49:08.353: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.353: INFO: 	Container coredns ready: true, restart count 0
    May  1 22:49:08.353: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.353: INFO: 	Container autoscaler ready: true, restart count 0
    May  1 22:49:08.353: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
    May  1 22:49:08.353: INFO: 	Container csi-attacher ready: true, restart count 0
    May  1 22:49:08.353: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  1 22:49:08.353: INFO: 	Container csi-resizer ready: true, restart count 0
    May  1 22:49:08.353: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 22:49:08.353: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 22:49:08.353: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
    May  1 22:49:08.353: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 22:49:08.353: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 22:49:08.353: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 22:49:08.353: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.353: INFO: 	Container kube-proxy ready: true, restart count 0
    May  1 22:49:08.353: INFO: 
    Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
    May  1 22:49:08.461: INFO: pod2 from hostport-8297 started at 2023-05-01 22:48:45 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.461: INFO: 	Container agnhost ready: false, restart count 0
    May  1 22:49:08.461: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.461: INFO: 	Container calico-node ready: true, restart count 0
    May  1 22:49:08.461: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
    May  1 22:49:08.461: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 22:49:08.461: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 22:49:08.461: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 22:49:08.461: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.461: INFO: 	Container kube-proxy ready: true, restart count 0
    May  1 22:49:08.461: INFO: 
    Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
    May  1 22:49:08.569: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.569: INFO: 	Container calico-node ready: true, restart count 0
    May  1 22:49:08.569: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
    May  1 22:49:08.569: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 22:49:08.569: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 22:49:08.569: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 22:49:08.569: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.569: INFO: 	Container kube-proxy ready: true, restart count 0
    May  1 22:49:08.569: INFO: 
    Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
    May  1 22:49:08.676: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.676: INFO: 	Container calico-node ready: true, restart count 0
    May  1 22:49:08.676: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.676: INFO: 	Container coredns ready: true, restart count 0
    May  1 22:49:08.676: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
    May  1 22:49:08.676: INFO: 	Container csi-attacher ready: true, restart count 0
    May  1 22:49:08.676: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  1 22:49:08.676: INFO: 	Container csi-resizer ready: true, restart count 0
    May  1 22:49:08.676: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 22:49:08.676: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 22:49:08.676: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
    May  1 22:49:08.676: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 22:49:08.676: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 22:49:08.676: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 22:49:08.676: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
    May  1 22:49:08.676: INFO: 	Container kube-proxy ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node i-00fed7c0a42791aae 05/01/23 22:49:08.903
    STEP: verifying the node has the label node i-02d061b30635c230c 05/01/23 22:49:09.118
    STEP: verifying the node has the label node i-0627b78ff917cf2ae 05/01/23 22:49:09.332
    STEP: verifying the node has the label node i-0aa263047c51ef669 05/01/23 22:49:09.548
    May  1 22:49:09.765: INFO: Pod calico-node-lr44d requesting resource cpu=100m on Node i-02d061b30635c230c
    May  1 22:49:09.765: INFO: Pod calico-node-phdpj requesting resource cpu=100m on Node i-0aa263047c51ef669
    May  1 22:49:09.765: INFO: Pod calico-node-vtrp8 requesting resource cpu=100m on Node i-0627b78ff917cf2ae
    May  1 22:49:09.765: INFO: Pod calico-node-zd6l4 requesting resource cpu=100m on Node i-00fed7c0a42791aae
    May  1 22:49:09.765: INFO: Pod coredns-6c7bddbb75-7b4g9 requesting resource cpu=100m on Node i-00fed7c0a42791aae
    May  1 22:49:09.765: INFO: Pod coredns-6c7bddbb75-zv7nq requesting resource cpu=100m on Node i-0aa263047c51ef669
    May  1 22:49:09.765: INFO: Pod coredns-autoscaler-db7b97744-xpnj5 requesting resource cpu=20m on Node i-00fed7c0a42791aae
    May  1 22:49:09.765: INFO: Pod ebs-csi-controller-f987fd46-c4wk5 requesting resource cpu=0m on Node i-00fed7c0a42791aae
    May  1 22:49:09.765: INFO: Pod ebs-csi-controller-f987fd46-vlkj2 requesting resource cpu=0m on Node i-0aa263047c51ef669
    May  1 22:49:09.765: INFO: Pod ebs-csi-node-4hblj requesting resource cpu=0m on Node i-00fed7c0a42791aae
    May  1 22:49:09.765: INFO: Pod ebs-csi-node-9zhf8 requesting resource cpu=0m on Node i-0627b78ff917cf2ae
    May  1 22:49:09.765: INFO: Pod ebs-csi-node-hvkck requesting resource cpu=0m on Node i-0aa263047c51ef669
    May  1 22:49:09.765: INFO: Pod ebs-csi-node-s46d6 requesting resource cpu=0m on Node i-02d061b30635c230c
    May  1 22:49:09.765: INFO: Pod kube-proxy-i-00fed7c0a42791aae requesting resource cpu=100m on Node i-00fed7c0a42791aae
    May  1 22:49:09.765: INFO: Pod kube-proxy-i-02d061b30635c230c requesting resource cpu=100m on Node i-02d061b30635c230c
    May  1 22:49:09.765: INFO: Pod kube-proxy-i-0627b78ff917cf2ae requesting resource cpu=100m on Node i-0627b78ff917cf2ae
    May  1 22:49:09.765: INFO: Pod kube-proxy-i-0aa263047c51ef669 requesting resource cpu=100m on Node i-0aa263047c51ef669
    STEP: Starting Pods to consume most of the cluster CPU. 05/01/23 22:49:09.765
    May  1 22:49:09.765: INFO: Creating a pod which consumes cpu=1176m on Node i-00fed7c0a42791aae
    May  1 22:49:09.874: INFO: Creating a pod which consumes cpu=1260m on Node i-02d061b30635c230c
    May  1 22:49:09.980: INFO: Creating a pod which consumes cpu=1260m on Node i-0627b78ff917cf2ae
    May  1 22:49:10.086: INFO: Creating a pod which consumes cpu=1190m on Node i-0aa263047c51ef669
    May  1 22:49:10.207: INFO: Waiting up to 5m0s for pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3" in namespace "sched-pred-3464" to be "running"
    May  1 22:49:10.316: INFO: Pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 108.887457ms
    May  1 22:49:12.421: INFO: Pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3": Phase="Running", Reason="", readiness=true. Elapsed: 2.213728019s
    May  1 22:49:12.421: INFO: Pod "filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3" satisfied condition "running"
    May  1 22:49:12.421: INFO: Waiting up to 5m0s for pod "filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8" in namespace "sched-pred-3464" to be "running"
    May  1 22:49:12.526: INFO: Pod "filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8": Phase="Running", Reason="", readiness=true. Elapsed: 104.500433ms
    May  1 22:49:12.526: INFO: Pod "filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8" satisfied condition "running"
    May  1 22:49:12.526: INFO: Waiting up to 5m0s for pod "filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324" in namespace "sched-pred-3464" to be "running"
    May  1 22:49:12.630: INFO: Pod "filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324": Phase="Running", Reason="", readiness=true. Elapsed: 104.364332ms
    May  1 22:49:12.630: INFO: Pod "filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324" satisfied condition "running"
    May  1 22:49:12.630: INFO: Waiting up to 5m0s for pod "filler-pod-353f5d62-a27e-4690-b057-b55c76fab728" in namespace "sched-pred-3464" to be "running"
    May  1 22:49:12.735: INFO: Pod "filler-pod-353f5d62-a27e-4690-b057-b55c76fab728": Phase="Running", Reason="", readiness=true. Elapsed: 104.539184ms
    May  1 22:49:12.735: INFO: Pod "filler-pod-353f5d62-a27e-4690-b057-b55c76fab728" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 05/01/23 22:49:12.735
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f043ea35c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-353f5d62-a27e-4690-b057-b55c76fab728 to i-0aa263047c51ef669] 05/01/23 22:49:12.84
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f28e0a8b4], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f29d7482d], Reason = [Created], Message = [Created container filler-pod-353f5d62-a27e-4690-b057-b55c76fab728] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-353f5d62-a27e-4690-b057-b55c76fab728.175b269f2e82a08f], Reason = [Started], Message = [Started container filler-pod-353f5d62-a27e-4690-b057-b55c76fab728] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269efceb8fd9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324 to i-0627b78ff917cf2ae] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269f232f2528], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269f242e4965], Reason = [Created], Message = [Created container filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324.175b269f2b9df649], Reason = [Started], Message = [Started container filler-pod-7b6cbd05-0c28-495b-abbe-c99de10f0324] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269ef689c4f0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8 to i-02d061b30635c230c] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f209657fb], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.8"] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f40bd2e17], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.8" in 539.378816ms (539.400343ms including waiting)] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f420f7074], Reason = [Created], Message = [Created container filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8] 05/01/23 22:49:12.841
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8.175b269f46dcb0dd], Reason = [Started], Message = [Started container filler-pod-c0c06074-85bc-4c18-a33d-34885c32dff8] 05/01/23 22:49:12.842
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269ef01da864], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3464/filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3 to i-00fed7c0a42791aae] 05/01/23 22:49:12.842
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269f1a1aa613], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 05/01/23 22:49:12.842
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269f1b5ca80e], Reason = [Created], Message = [Created container filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3] 05/01/23 22:49:12.842
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3.175b269f21b20e79], Reason = [Started], Message = [Started container filler-pod-e6767f44-d5e0-49ad-905f-1927a93f7ca3] 05/01/23 22:49:12.842
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.175b269fad312c72], Reason = [FailedScheduling], Message = [0/5 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 4 Insufficient cpu. preemption: 0/5 nodes are available: 1 Preemption is not helpful for scheduling, 4 No preemption victims found for incoming pod.] 05/01/23 22:49:13.055
    STEP: removing the label node off the node i-0aa263047c51ef669 05/01/23 22:49:14.156
    STEP: verifying the node doesn't have the label node 05/01/23 22:49:14.371
    STEP: removing the label node off the node i-00fed7c0a42791aae 05/01/23 22:49:14.476
    STEP: verifying the node doesn't have the label node 05/01/23 22:49:14.69
    STEP: removing the label node off the node i-02d061b30635c230c 05/01/23 22:49:14.799
    STEP: verifying the node doesn't have the label node 05/01/23 22:49:15.013
    STEP: removing the label node off the node i-0627b78ff917cf2ae 05/01/23 22:49:15.118
    STEP: verifying the node doesn't have the label node 05/01/23 22:49:15.333
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    May  1 22:49:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3464" for this suite. 05/01/23 22:49:15.544
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:15.655
May  1 22:49:15.655: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller 05/01/23 22:49:15.657
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:15.972
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:16.18
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 05/01/23 22:49:16.387
STEP: When the matched label of one of its pods change 05/01/23 22:49:16.493
May  1 22:49:16.598: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 05/01/23 22:49:16.811
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
May  1 22:49:16.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8742" for this suite. 05/01/23 22:49:17.021
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":24,"skipped":379,"failed":0}
------------------------------
• [1.474 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:15.655
    May  1 22:49:15.655: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replication-controller 05/01/23 22:49:15.657
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:15.972
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:16.18
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 05/01/23 22:49:16.387
    STEP: When the matched label of one of its pods change 05/01/23 22:49:16.493
    May  1 22:49:16.598: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 05/01/23 22:49:16.811
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    May  1 22:49:16.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8742" for this suite. 05/01/23 22:49:17.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:17.133
May  1 22:49:17.133: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 22:49:17.135
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:17.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:17.657
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 05/01/23 22:49:17.969
May  1 22:49:17.969: INFO: Creating simple deployment test-deployment-wjkmj
May  1 22:49:18.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wjkmj-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 05/01/23 22:49:20.6
May  1 22:49:20.709: INFO: Deployment test-deployment-wjkmj has Conditions: [{Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 05/01/23 22:49:20.709
May  1 22:49:20.923: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wjkmj-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 05/01/23 22:49:20.923
May  1 22:49:21.027: INFO: Observed &Deployment event: ADDED
May  1 22:49:21.027: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wjkmj-777898ffcc" is progressing.}
May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
May  1 22:49:21.028: INFO: Found Deployment test-deployment-wjkmj in namespace deployment-9879 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  1 22:49:21.028: INFO: Deployment test-deployment-wjkmj has an updated status
STEP: patching the Statefulset Status 05/01/23 22:49:21.028
May  1 22:49:21.029: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May  1 22:49:21.138: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 05/01/23 22:49:21.138
May  1 22:49:21.243: INFO: Observed &Deployment event: ADDED
May  1 22:49:21.243: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
May  1 22:49:21.243: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.243: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
May  1 22:49:21.243: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  1 22:49:21.243: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wjkmj-777898ffcc" is progressing.}
May  1 22:49:21.244: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
May  1 22:49:21.245: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.245: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
May  1 22:49:21.245: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
May  1 22:49:21.245: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  1 22:49:21.245: INFO: Observed &Deployment event: MODIFIED
May  1 22:49:21.245: INFO: Found deployment test-deployment-wjkmj in namespace deployment-9879 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
May  1 22:49:21.245: INFO: Deployment test-deployment-wjkmj has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 22:49:21.351: INFO: Deployment "test-deployment-wjkmj":
&Deployment{ObjectMeta:{test-deployment-wjkmj  deployment-9879  7388eb0a-f307-4105-9175-539fb8e2a4a1 5395 1 2023-05-01 22:49:18 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-05-01 22:49:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-05-01 22:49:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003834528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 22:49:21 +0000 UTC,LastTransitionTime:2023-05-01 22:49:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.,LastUpdateTime:2023-05-01 22:49:21 +0000 UTC,LastTransitionTime:2023-05-01 22:49:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  1 22:49:21.455: INFO: New ReplicaSet "test-deployment-wjkmj-777898ffcc" of Deployment "test-deployment-wjkmj":
&ReplicaSet{ObjectMeta:{test-deployment-wjkmj-777898ffcc  deployment-9879  7e59d0c9-560b-4c63-9cf0-f6d421c41df8 5368 1 2023-05-01 22:49:18 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-wjkmj 7388eb0a-f307-4105-9175-539fb8e2a4a1 0xc003834917 0xc003834918}] [] [{kube-controller-manager Update apps/v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7388eb0a-f307-4105-9175-539fb8e2a4a1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038349c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  1 22:49:21.560: INFO: Pod "test-deployment-wjkmj-777898ffcc-xl4st" is available:
&Pod{ObjectMeta:{test-deployment-wjkmj-777898ffcc-xl4st test-deployment-wjkmj-777898ffcc- deployment-9879  f8cffb25-606f-4cc4-9173-5c05e11e39fe 5367 0 2023-05-01 22:49:18 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:5668723d8d49028c667451c896d8e6ffd5538b02c16695f2e827b0fdcc1951eb cni.projectcalico.org/podIP:100.96.36.18/32 cni.projectcalico.org/podIPs:100.96.36.18/32] [{apps/v1 ReplicaSet test-deployment-wjkmj-777898ffcc 7e59d0c9-560b-4c63-9cf0-f6d421c41df8 0xc003834d77 0xc003834d78}] [] [{calico Update v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e59d0c9-560b-4c63-9cf0-f6d421c41df8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 22:49:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pjsm7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pjsm7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.18,StartTime:2023-05-01 22:49:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 22:49:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://aa4de4fd7ddfc9996a8e20f4626e7aeb0628e876f0d700a924d11bf7d6530902,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 22:49:21.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9879" for this suite. 05/01/23 22:49:21.665
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":25,"skipped":430,"failed":0}
------------------------------
• [4.639 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:17.133
    May  1 22:49:17.133: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 22:49:17.135
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:17.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:17.657
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 05/01/23 22:49:17.969
    May  1 22:49:17.969: INFO: Creating simple deployment test-deployment-wjkmj
    May  1 22:49:18.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wjkmj-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 05/01/23 22:49:20.6
    May  1 22:49:20.709: INFO: Deployment test-deployment-wjkmj has Conditions: [{Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 05/01/23 22:49:20.709
    May  1 22:49:20.923: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 19, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 18, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wjkmj-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 05/01/23 22:49:20.923
    May  1 22:49:21.027: INFO: Observed &Deployment event: ADDED
    May  1 22:49:21.027: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
    May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wjkmj-777898ffcc" is progressing.}
    May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
    May  1 22:49:21.028: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    May  1 22:49:21.028: INFO: Observed Deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
    May  1 22:49:21.028: INFO: Found Deployment test-deployment-wjkmj in namespace deployment-9879 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    May  1 22:49:21.028: INFO: Deployment test-deployment-wjkmj has an updated status
    STEP: patching the Statefulset Status 05/01/23 22:49:21.028
    May  1 22:49:21.029: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    May  1 22:49:21.138: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 05/01/23 22:49:21.138
    May  1 22:49:21.243: INFO: Observed &Deployment event: ADDED
    May  1 22:49:21.243: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
    May  1 22:49:21.243: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.243: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wjkmj-777898ffcc"}
    May  1 22:49:21.243: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    May  1 22:49:21.243: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:18 +0000 UTC 2023-05-01 22:49:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wjkmj-777898ffcc" is progressing.}
    May  1 22:49:21.244: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    May  1 22:49:21.244: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
    May  1 22:49:21.245: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.245: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    May  1 22:49:21.245: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-05-01 22:49:19 +0000 UTC 2023-05-01 22:49:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.}
    May  1 22:49:21.245: INFO: Observed deployment test-deployment-wjkmj in namespace deployment-9879 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    May  1 22:49:21.245: INFO: Observed &Deployment event: MODIFIED
    May  1 22:49:21.245: INFO: Found deployment test-deployment-wjkmj in namespace deployment-9879 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    May  1 22:49:21.245: INFO: Deployment test-deployment-wjkmj has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 22:49:21.351: INFO: Deployment "test-deployment-wjkmj":
    &Deployment{ObjectMeta:{test-deployment-wjkmj  deployment-9879  7388eb0a-f307-4105-9175-539fb8e2a4a1 5395 1 2023-05-01 22:49:18 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-05-01 22:49:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-05-01 22:49:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003834528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 22:49:21 +0000 UTC,LastTransitionTime:2023-05-01 22:49:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-deployment-wjkmj-777898ffcc" has successfully progressed.,LastUpdateTime:2023-05-01 22:49:21 +0000 UTC,LastTransitionTime:2023-05-01 22:49:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    May  1 22:49:21.455: INFO: New ReplicaSet "test-deployment-wjkmj-777898ffcc" of Deployment "test-deployment-wjkmj":
    &ReplicaSet{ObjectMeta:{test-deployment-wjkmj-777898ffcc  deployment-9879  7e59d0c9-560b-4c63-9cf0-f6d421c41df8 5368 1 2023-05-01 22:49:18 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-wjkmj 7388eb0a-f307-4105-9175-539fb8e2a4a1 0xc003834917 0xc003834918}] [] [{kube-controller-manager Update apps/v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7388eb0a-f307-4105-9175-539fb8e2a4a1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038349c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    May  1 22:49:21.560: INFO: Pod "test-deployment-wjkmj-777898ffcc-xl4st" is available:
    &Pod{ObjectMeta:{test-deployment-wjkmj-777898ffcc-xl4st test-deployment-wjkmj-777898ffcc- deployment-9879  f8cffb25-606f-4cc4-9173-5c05e11e39fe 5367 0 2023-05-01 22:49:18 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:5668723d8d49028c667451c896d8e6ffd5538b02c16695f2e827b0fdcc1951eb cni.projectcalico.org/podIP:100.96.36.18/32 cni.projectcalico.org/podIPs:100.96.36.18/32] [{apps/v1 ReplicaSet test-deployment-wjkmj-777898ffcc 7e59d0c9-560b-4c63-9cf0-f6d421c41df8 0xc003834d77 0xc003834d78}] [] [{calico Update v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 22:49:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e59d0c9-560b-4c63-9cf0-f6d421c41df8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 22:49:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pjsm7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pjsm7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.18,StartTime:2023-05-01 22:49:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 22:49:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://aa4de4fd7ddfc9996a8e20f4626e7aeb0628e876f0d700a924d11bf7d6530902,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 22:49:21.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9879" for this suite. 05/01/23 22:49:21.665
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:21.774
May  1 22:49:21.774: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 22:49:21.776
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:22.09
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:22.297
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
May  1 22:49:22.718: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 05/01/23 22:49:22.718
May  1 22:49:22.718: INFO: Waiting up to 5m0s for pod "test-rollover-controller-62ff4" in namespace "deployment-9801" to be "running"
May  1 22:49:22.823: INFO: Pod "test-rollover-controller-62ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 104.390071ms
May  1 22:49:24.929: INFO: Pod "test-rollover-controller-62ff4": Phase="Running", Reason="", readiness=true. Elapsed: 2.210208501s
May  1 22:49:24.929: INFO: Pod "test-rollover-controller-62ff4" satisfied condition "running"
May  1 22:49:24.929: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May  1 22:49:27.034: INFO: Creating deployment "test-rollover-deployment"
May  1 22:49:27.243: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May  1 22:49:27.348: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May  1 22:49:27.557: INFO: Ensure that both replica sets have 1 created replica
May  1 22:49:27.765: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May  1 22:49:27.976: INFO: Updating deployment test-rollover-deployment
May  1 22:49:27.976: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May  1 22:49:28.080: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May  1 22:49:28.289: INFO: Make sure deployment "test-rollover-deployment" is complete
May  1 22:49:28.499: INFO: all replica sets need to contain the pod-template-hash label
May  1 22:49:28.499: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:49:30.709: INFO: all replica sets need to contain the pod-template-hash label
May  1 22:49:30.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:49:32.708: INFO: all replica sets need to contain the pod-template-hash label
May  1 22:49:32.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:49:34.708: INFO: all replica sets need to contain the pod-template-hash label
May  1 22:49:34.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:49:36.709: INFO: all replica sets need to contain the pod-template-hash label
May  1 22:49:36.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:49:38.709: INFO: all replica sets need to contain the pod-template-hash label
May  1 22:49:38.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:49:40.708: INFO: 
May  1 22:49:40.708: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 22:49:41.022: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9801  ce81f82b-481d-46ab-9ddd-99b0ac285e12 5568 2 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004048378 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 22:49:27 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-05-01 22:49:39 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  1 22:49:41.127: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-9801  caac09a9-f5e2-49b2-9a4f-6475e27a14f0 5560 2 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ce81f82b-481d-46ab-9ddd-99b0ac285e12 0xc003ebd2d7 0xc003ebd2d8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce81f82b-481d-46ab-9ddd-99b0ac285e12\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ebd388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  1 22:49:41.127: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May  1 22:49:41.128: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9801  f557136d-c489-4351-91af-37b3d2c035ad 5567 2 2023-05-01 22:49:22 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ce81f82b-481d-46ab-9ddd-99b0ac285e12 0xc003ebd09f 0xc003ebd0b0}] [] [{e2e.test Update apps/v1 2023-05-01 22:49:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce81f82b-481d-46ab-9ddd-99b0ac285e12\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ebd168 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  1 22:49:41.128: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-9801  05295472-5eab-46a8-bfa6-fe1672f889f5 5507 2 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ce81f82b-481d-46ab-9ddd-99b0ac285e12 0xc003ebd1c7 0xc003ebd1c8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce81f82b-481d-46ab-9ddd-99b0ac285e12\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ebd278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  1 22:49:41.233: INFO: Pod "test-rollover-deployment-6d45fd857b-hgkpb" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-hgkpb test-rollover-deployment-6d45fd857b- deployment-9801  ee2f704b-5032-45f7-8ae0-6db7e45eac91 5527 0 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:d946ccf2ba80db96bf2bb588ca93c111cb8ce98217cff8befbfec7adaabfe84f cni.projectcalico.org/podIP:100.96.36.20/32 cni.projectcalico.org/podIPs:100.96.36.20/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b caac09a9-f5e2-49b2-9a4f-6475e27a14f0 0xc003ebd8d7 0xc003ebd8d8}] [] [{kube-controller-manager Update v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caac09a9-f5e2-49b2-9a4f-6475e27a14f0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-01 22:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-01 22:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p7mwh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p7mwh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.20,StartTime:2023-05-01 22:49:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 22:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c4265ac99b3627ca23f3433e7cb0a17a2eb333adb35714dc8cdf823dcd453554,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 22:49:41.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9801" for this suite. 05/01/23 22:49:41.338
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":26,"skipped":442,"failed":0}
------------------------------
• [SLOW TEST] [19.672 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:21.774
    May  1 22:49:21.774: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 22:49:21.776
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:22.09
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:22.297
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    May  1 22:49:22.718: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 05/01/23 22:49:22.718
    May  1 22:49:22.718: INFO: Waiting up to 5m0s for pod "test-rollover-controller-62ff4" in namespace "deployment-9801" to be "running"
    May  1 22:49:22.823: INFO: Pod "test-rollover-controller-62ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 104.390071ms
    May  1 22:49:24.929: INFO: Pod "test-rollover-controller-62ff4": Phase="Running", Reason="", readiness=true. Elapsed: 2.210208501s
    May  1 22:49:24.929: INFO: Pod "test-rollover-controller-62ff4" satisfied condition "running"
    May  1 22:49:24.929: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    May  1 22:49:27.034: INFO: Creating deployment "test-rollover-deployment"
    May  1 22:49:27.243: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    May  1 22:49:27.348: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    May  1 22:49:27.557: INFO: Ensure that both replica sets have 1 created replica
    May  1 22:49:27.765: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    May  1 22:49:27.976: INFO: Updating deployment test-rollover-deployment
    May  1 22:49:27.976: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    May  1 22:49:28.080: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    May  1 22:49:28.289: INFO: Make sure deployment "test-rollover-deployment" is complete
    May  1 22:49:28.499: INFO: all replica sets need to contain the pod-template-hash label
    May  1 22:49:28.499: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:49:30.709: INFO: all replica sets need to contain the pod-template-hash label
    May  1 22:49:30.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:49:32.708: INFO: all replica sets need to contain the pod-template-hash label
    May  1 22:49:32.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:49:34.708: INFO: all replica sets need to contain the pod-template-hash label
    May  1 22:49:34.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:49:36.709: INFO: all replica sets need to contain the pod-template-hash label
    May  1 22:49:36.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:49:38.709: INFO: all replica sets need to contain the pod-template-hash label
    May  1 22:49:38.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:49:40.708: INFO: 
    May  1 22:49:40.708: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 22:49:41.022: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-9801  ce81f82b-481d-46ab-9ddd-99b0ac285e12 5568 2 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004048378 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 22:49:27 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-05-01 22:49:39 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    May  1 22:49:41.127: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-9801  caac09a9-f5e2-49b2-9a4f-6475e27a14f0 5560 2 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ce81f82b-481d-46ab-9ddd-99b0ac285e12 0xc003ebd2d7 0xc003ebd2d8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce81f82b-481d-46ab-9ddd-99b0ac285e12\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ebd388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    May  1 22:49:41.127: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    May  1 22:49:41.128: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9801  f557136d-c489-4351-91af-37b3d2c035ad 5567 2 2023-05-01 22:49:22 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ce81f82b-481d-46ab-9ddd-99b0ac285e12 0xc003ebd09f 0xc003ebd0b0}] [] [{e2e.test Update apps/v1 2023-05-01 22:49:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce81f82b-481d-46ab-9ddd-99b0ac285e12\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:39 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ebd168 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    May  1 22:49:41.128: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-9801  05295472-5eab-46a8-bfa6-fe1672f889f5 5507 2 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ce81f82b-481d-46ab-9ddd-99b0ac285e12 0xc003ebd1c7 0xc003ebd1c8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce81f82b-481d-46ab-9ddd-99b0ac285e12\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ebd278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    May  1 22:49:41.233: INFO: Pod "test-rollover-deployment-6d45fd857b-hgkpb" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-hgkpb test-rollover-deployment-6d45fd857b- deployment-9801  ee2f704b-5032-45f7-8ae0-6db7e45eac91 5527 0 2023-05-01 22:49:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:d946ccf2ba80db96bf2bb588ca93c111cb8ce98217cff8befbfec7adaabfe84f cni.projectcalico.org/podIP:100.96.36.20/32 cni.projectcalico.org/podIPs:100.96.36.20/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b caac09a9-f5e2-49b2-9a4f-6475e27a14f0 0xc003ebd8d7 0xc003ebd8d8}] [] [{kube-controller-manager Update v1 2023-05-01 22:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caac09a9-f5e2-49b2-9a4f-6475e27a14f0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-01 22:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-01 22:49:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p7mwh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p7mwh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 22:49:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.20,StartTime:2023-05-01 22:49:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 22:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c4265ac99b3627ca23f3433e7cb0a17a2eb333adb35714dc8cdf823dcd453554,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 22:49:41.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9801" for this suite. 05/01/23 22:49:41.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:41.447
May  1 22:49:41.447: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 22:49:41.45
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:41.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:41.972
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-2628 05/01/23 22:49:42.179
STEP: creating service affinity-clusterip in namespace services-2628 05/01/23 22:49:42.179
STEP: creating replication controller affinity-clusterip in namespace services-2628 05/01/23 22:49:42.292
I0501 22:49:42.398160    6969 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2628, replica count: 3
I0501 22:49:45.549460    6969 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  1 22:49:45.759: INFO: Creating new exec pod
May  1 22:49:45.866: INFO: Waiting up to 5m0s for pod "execpod-affinitydrgvf" in namespace "services-2628" to be "running"
May  1 22:49:45.970: INFO: Pod "execpod-affinitydrgvf": Phase="Pending", Reason="", readiness=false. Elapsed: 104.693856ms
May  1 22:49:48.076: INFO: Pod "execpod-affinitydrgvf": Phase="Running", Reason="", readiness=true. Elapsed: 2.2106212s
May  1 22:49:48.076: INFO: Pod "execpod-affinitydrgvf" satisfied condition "running"
May  1 22:49:49.077: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2628 exec execpod-affinitydrgvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
May  1 22:49:50.221: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
May  1 22:49:50.221: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 22:49:50.221: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2628 exec execpod-affinitydrgvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.252.12 80'
May  1 22:49:51.338: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.252.12 80\nConnection to 100.69.252.12 80 port [tcp/http] succeeded!\n"
May  1 22:49:51.338: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 22:49:51.338: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2628 exec execpod-affinitydrgvf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.69.252.12:80/ ; done'
May  1 22:49:52.586: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n"
May  1 22:49:52.586: INFO: stdout: "\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9"
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
May  1 22:49:52.586: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-2628, will wait for the garbage collector to delete the pods 05/01/23 22:49:52.699
May  1 22:49:53.063: INFO: Deleting ReplicationController affinity-clusterip took: 108.859074ms
May  1 22:49:53.163: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.472661ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 22:49:55.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2628" for this suite. 05/01/23 22:49:55.487
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":27,"skipped":449,"failed":0}
------------------------------
• [SLOW TEST] [14.150 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:41.447
    May  1 22:49:41.447: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 22:49:41.45
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:41.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:41.972
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-2628 05/01/23 22:49:42.179
    STEP: creating service affinity-clusterip in namespace services-2628 05/01/23 22:49:42.179
    STEP: creating replication controller affinity-clusterip in namespace services-2628 05/01/23 22:49:42.292
    I0501 22:49:42.398160    6969 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2628, replica count: 3
    I0501 22:49:45.549460    6969 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  1 22:49:45.759: INFO: Creating new exec pod
    May  1 22:49:45.866: INFO: Waiting up to 5m0s for pod "execpod-affinitydrgvf" in namespace "services-2628" to be "running"
    May  1 22:49:45.970: INFO: Pod "execpod-affinitydrgvf": Phase="Pending", Reason="", readiness=false. Elapsed: 104.693856ms
    May  1 22:49:48.076: INFO: Pod "execpod-affinitydrgvf": Phase="Running", Reason="", readiness=true. Elapsed: 2.2106212s
    May  1 22:49:48.076: INFO: Pod "execpod-affinitydrgvf" satisfied condition "running"
    May  1 22:49:49.077: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2628 exec execpod-affinitydrgvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    May  1 22:49:50.221: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    May  1 22:49:50.221: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 22:49:50.221: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2628 exec execpod-affinitydrgvf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.252.12 80'
    May  1 22:49:51.338: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.252.12 80\nConnection to 100.69.252.12 80 port [tcp/http] succeeded!\n"
    May  1 22:49:51.338: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 22:49:51.338: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2628 exec execpod-affinitydrgvf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.69.252.12:80/ ; done'
    May  1 22:49:52.586: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.69.252.12:80/\n"
    May  1 22:49:52.586: INFO: stdout: "\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9\naffinity-clusterip-phlp9"
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Received response from host: affinity-clusterip-phlp9
    May  1 22:49:52.586: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-2628, will wait for the garbage collector to delete the pods 05/01/23 22:49:52.699
    May  1 22:49:53.063: INFO: Deleting ReplicationController affinity-clusterip took: 108.859074ms
    May  1 22:49:53.163: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.472661ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 22:49:55.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2628" for this suite. 05/01/23 22:49:55.487
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:55.602
May  1 22:49:55.603: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 22:49:55.604
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:55.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:56.129
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 05/01/23 22:49:56.337
STEP: listing secrets in all namespaces to ensure that there are more than zero 05/01/23 22:49:56.443
STEP: patching the secret 05/01/23 22:49:56.547
STEP: deleting the secret using a LabelSelector 05/01/23 22:49:56.759
STEP: listing secrets in all namespaces, searching for label name and value in patch 05/01/23 22:49:56.866
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
May  1 22:49:56.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6349" for this suite. 05/01/23 22:49:57.075
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":28,"skipped":541,"failed":0}
------------------------------
• [1.579 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:55.602
    May  1 22:49:55.603: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 22:49:55.604
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:55.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:56.129
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 05/01/23 22:49:56.337
    STEP: listing secrets in all namespaces to ensure that there are more than zero 05/01/23 22:49:56.443
    STEP: patching the secret 05/01/23 22:49:56.547
    STEP: deleting the secret using a LabelSelector 05/01/23 22:49:56.759
    STEP: listing secrets in all namespaces, searching for label name and value in patch 05/01/23 22:49:56.866
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    May  1 22:49:56.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6349" for this suite. 05/01/23 22:49:57.075
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:49:57.182
May  1 22:49:57.182: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 22:49:57.183
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:57.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:57.705
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 22:49:58.128
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 22:49:58.939
STEP: Deploying the webhook pod 05/01/23 22:49:59.048
STEP: Wait for the deployment to be ready 05/01/23 22:49:59.262
May  1 22:49:59.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 22:50:01.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 22:50:03.681
STEP: Verifying the service has paired with the endpoint 05/01/23 22:50:03.792
May  1 22:50:04.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
May  1 22:50:04.897: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the custom resource webhook via the AdmissionRegistration API 05/01/23 22:50:05.111
STEP: Creating a custom resource that should be denied by the webhook 05/01/23 22:50:05.331
STEP: Creating a custom resource whose deletion would be denied by the webhook 05/01/23 22:50:07.505
STEP: Updating the custom resource with disallowed data should be denied 05/01/23 22:50:07.613
STEP: Deleting the custom resource should be denied 05/01/23 22:50:07.825
STEP: Remove the offending key and value from the custom resource data 05/01/23 22:50:07.933
STEP: Deleting the updated custom resource should be successful 05/01/23 22:50:08.149
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 22:50:08.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-955" for this suite. 05/01/23 22:50:08.68
STEP: Destroying namespace "webhook-955-markers" for this suite. 05/01/23 22:50:08.787
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":29,"skipped":544,"failed":0}
------------------------------
• [SLOW TEST] [12.151 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:49:57.182
    May  1 22:49:57.182: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 22:49:57.183
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:49:57.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:49:57.705
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 22:49:58.128
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 22:49:58.939
    STEP: Deploying the webhook pod 05/01/23 22:49:59.048
    STEP: Wait for the deployment to be ready 05/01/23 22:49:59.262
    May  1 22:49:59.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 22:50:01.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 49, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 22:50:03.681
    STEP: Verifying the service has paired with the endpoint 05/01/23 22:50:03.792
    May  1 22:50:04.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    May  1 22:50:04.897: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 05/01/23 22:50:05.111
    STEP: Creating a custom resource that should be denied by the webhook 05/01/23 22:50:05.331
    STEP: Creating a custom resource whose deletion would be denied by the webhook 05/01/23 22:50:07.505
    STEP: Updating the custom resource with disallowed data should be denied 05/01/23 22:50:07.613
    STEP: Deleting the custom resource should be denied 05/01/23 22:50:07.825
    STEP: Remove the offending key and value from the custom resource data 05/01/23 22:50:07.933
    STEP: Deleting the updated custom resource should be successful 05/01/23 22:50:08.149
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 22:50:08.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-955" for this suite. 05/01/23 22:50:08.68
    STEP: Destroying namespace "webhook-955-markers" for this suite. 05/01/23 22:50:08.787
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:50:09.334
May  1 22:50:09.334: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 22:50:09.335
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:50:09.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:50:09.861
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
May  1 22:50:10.068: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-9820 version'
May  1 22:50:10.488: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
May  1 22:50:10.488: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:08:36Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 22:50:10.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9820" for this suite. 05/01/23 22:50:10.593
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":30,"skipped":547,"failed":0}
------------------------------
• [1.365 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:50:09.334
    May  1 22:50:09.334: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 22:50:09.335
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:50:09.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:50:09.861
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    May  1 22:50:10.068: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-9820 version'
    May  1 22:50:10.488: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    May  1 22:50:10.488: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:16:51Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.9\", GitCommit:\"a1a87a0a2bcd605820920c6b0e618a8ab7d117d4\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:08:36Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 22:50:10.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9820" for this suite. 05/01/23 22:50:10.593
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:50:10.699
May  1 22:50:10.700: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-preemption 05/01/23 22:50:10.7
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:50:11.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:50:11.222
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May  1 22:50:11.747: INFO: Waiting up to 1m0s for all nodes to be ready
May  1 22:51:12.493: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 05/01/23 22:51:12.598
May  1 22:51:12.819: INFO: Created pod: pod0-0-sched-preemption-low-priority
May  1 22:51:12.928: INFO: Created pod: pod0-1-sched-preemption-medium-priority
May  1 22:51:13.147: INFO: Created pod: pod1-0-sched-preemption-medium-priority
May  1 22:51:13.255: INFO: Created pod: pod1-1-sched-preemption-medium-priority
May  1 22:51:13.477: INFO: Created pod: pod2-0-sched-preemption-medium-priority
May  1 22:51:13.583: INFO: Created pod: pod2-1-sched-preemption-medium-priority
May  1 22:51:13.802: INFO: Created pod: pod3-0-sched-preemption-medium-priority
May  1 22:51:13.908: INFO: Created pod: pod3-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 05/01/23 22:51:13.908
May  1 22:51:13.909: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:14.013: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 104.391447ms
May  1 22:51:16.119: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209858538s
May  1 22:51:18.118: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209230168s
May  1 22:51:20.119: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210158643s
May  1 22:51:22.118: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.20927578s
May  1 22:51:22.118: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
May  1 22:51:22.118: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:22.222: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.229156ms
May  1 22:51:22.223: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
May  1 22:51:22.223: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:22.327: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 104.118702ms
May  1 22:51:24.433: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.210114997s
May  1 22:51:24.433: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
May  1 22:51:24.433: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:24.537: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.527114ms
May  1 22:51:24.537: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
May  1 22:51:24.537: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:24.642: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.39803ms
May  1 22:51:24.642: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
May  1 22:51:24.642: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:24.746: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.411395ms
May  1 22:51:24.746: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
May  1 22:51:24.746: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:24.851: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.50809ms
May  1 22:51:24.851: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
May  1 22:51:24.851: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
May  1 22:51:24.956: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.548421ms
May  1 22:51:24.956: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 05/01/23 22:51:24.956
May  1 22:51:25.065: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
May  1 22:51:25.170: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.292475ms
May  1 22:51:27.275: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20999135s
May  1 22:51:29.276: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.21033099s
May  1 22:51:29.276: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
May  1 22:51:30.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6397" for this suite. 05/01/23 22:51:30.538
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":31,"skipped":547,"failed":0}
------------------------------
• [SLOW TEST] [80.699 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:50:10.699
    May  1 22:50:10.700: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-preemption 05/01/23 22:50:10.7
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:50:11.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:50:11.222
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    May  1 22:50:11.747: INFO: Waiting up to 1m0s for all nodes to be ready
    May  1 22:51:12.493: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 05/01/23 22:51:12.598
    May  1 22:51:12.819: INFO: Created pod: pod0-0-sched-preemption-low-priority
    May  1 22:51:12.928: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    May  1 22:51:13.147: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    May  1 22:51:13.255: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    May  1 22:51:13.477: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    May  1 22:51:13.583: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    May  1 22:51:13.802: INFO: Created pod: pod3-0-sched-preemption-medium-priority
    May  1 22:51:13.908: INFO: Created pod: pod3-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 05/01/23 22:51:13.908
    May  1 22:51:13.909: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:14.013: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 104.391447ms
    May  1 22:51:16.119: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209858538s
    May  1 22:51:18.118: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209230168s
    May  1 22:51:20.119: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.210158643s
    May  1 22:51:22.118: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.20927578s
    May  1 22:51:22.118: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    May  1 22:51:22.118: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:22.222: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.229156ms
    May  1 22:51:22.223: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    May  1 22:51:22.223: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:22.327: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 104.118702ms
    May  1 22:51:24.433: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.210114997s
    May  1 22:51:24.433: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    May  1 22:51:24.433: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:24.537: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.527114ms
    May  1 22:51:24.537: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    May  1 22:51:24.537: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:24.642: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.39803ms
    May  1 22:51:24.642: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    May  1 22:51:24.642: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:24.746: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.411395ms
    May  1 22:51:24.746: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    May  1 22:51:24.746: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:24.851: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.50809ms
    May  1 22:51:24.851: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
    May  1 22:51:24.851: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-6397" to be "running"
    May  1 22:51:24.956: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 104.548421ms
    May  1 22:51:24.956: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 05/01/23 22:51:24.956
    May  1 22:51:25.065: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    May  1 22:51:25.170: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.292475ms
    May  1 22:51:27.275: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20999135s
    May  1 22:51:29.276: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.21033099s
    May  1 22:51:29.276: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    May  1 22:51:30.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-6397" for this suite. 05/01/23 22:51:30.538
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:51:31.403
May  1 22:51:31.403: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context 05/01/23 22:51:31.404
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:51:31.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:51:31.926
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 05/01/23 22:51:32.134
May  1 22:51:32.242: INFO: Waiting up to 5m0s for pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d" in namespace "security-context-5970" to be "Succeeded or Failed"
May  1 22:51:32.346: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d": Phase="Pending", Reason="", readiness=false. Elapsed: 104.413776ms
May  1 22:51:34.451: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209159696s
May  1 22:51:36.452: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210331111s
STEP: Saw pod success 05/01/23 22:51:36.452
May  1 22:51:36.452: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d" satisfied condition "Succeeded or Failed"
May  1 22:51:36.557: INFO: Trying to get logs from node i-02d061b30635c230c pod security-context-32344d2b-b7a2-4936-87d4-0793d0de066d container test-container: <nil>
STEP: delete the pod 05/01/23 22:51:36.67
May  1 22:51:36.782: INFO: Waiting for pod security-context-32344d2b-b7a2-4936-87d4-0793d0de066d to disappear
May  1 22:51:36.886: INFO: Pod security-context-32344d2b-b7a2-4936-87d4-0793d0de066d no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
May  1 22:51:36.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5970" for this suite. 05/01/23 22:51:36.991
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":32,"skipped":612,"failed":0}
------------------------------
• [SLOW TEST] [5.696 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:51:31.403
    May  1 22:51:31.403: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename security-context 05/01/23 22:51:31.404
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:51:31.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:51:31.926
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 05/01/23 22:51:32.134
    May  1 22:51:32.242: INFO: Waiting up to 5m0s for pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d" in namespace "security-context-5970" to be "Succeeded or Failed"
    May  1 22:51:32.346: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d": Phase="Pending", Reason="", readiness=false. Elapsed: 104.413776ms
    May  1 22:51:34.451: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209159696s
    May  1 22:51:36.452: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210331111s
    STEP: Saw pod success 05/01/23 22:51:36.452
    May  1 22:51:36.452: INFO: Pod "security-context-32344d2b-b7a2-4936-87d4-0793d0de066d" satisfied condition "Succeeded or Failed"
    May  1 22:51:36.557: INFO: Trying to get logs from node i-02d061b30635c230c pod security-context-32344d2b-b7a2-4936-87d4-0793d0de066d container test-container: <nil>
    STEP: delete the pod 05/01/23 22:51:36.67
    May  1 22:51:36.782: INFO: Waiting for pod security-context-32344d2b-b7a2-4936-87d4-0793d0de066d to disappear
    May  1 22:51:36.886: INFO: Pod security-context-32344d2b-b7a2-4936-87d4-0793d0de066d no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    May  1 22:51:36.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5970" for this suite. 05/01/23 22:51:36.991
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:51:37.099
May  1 22:51:37.099: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath 05/01/23 22:51:37.1
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:51:37.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:51:37.621
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 05/01/23 22:51:37.828
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-2648 05/01/23 22:51:38.041
STEP: Creating a pod to test atomic-volume-subpath 05/01/23 22:51:38.041
May  1 22:51:38.166: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2648" in namespace "subpath-2546" to be "Succeeded or Failed"
May  1 22:51:38.270: INFO: Pod "pod-subpath-test-secret-2648": Phase="Pending", Reason="", readiness=false. Elapsed: 104.176524ms
May  1 22:51:40.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 2.210159486s
May  1 22:51:42.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 4.210685941s
May  1 22:51:44.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 6.210066143s
May  1 22:51:46.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 8.209042867s
May  1 22:51:48.377: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 10.210862225s
May  1 22:51:50.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 12.209850858s
May  1 22:51:52.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 14.208986596s
May  1 22:51:54.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 16.209101978s
May  1 22:51:56.377: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 18.211003666s
May  1 22:51:58.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 20.210699193s
May  1 22:52:00.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=false. Elapsed: 22.209434949s
May  1 22:52:02.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.20902839s
STEP: Saw pod success 05/01/23 22:52:02.375
May  1 22:52:02.375: INFO: Pod "pod-subpath-test-secret-2648" satisfied condition "Succeeded or Failed"
May  1 22:52:02.479: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-secret-2648 container test-container-subpath-secret-2648: <nil>
STEP: delete the pod 05/01/23 22:52:02.595
May  1 22:52:02.708: INFO: Waiting for pod pod-subpath-test-secret-2648 to disappear
May  1 22:52:02.812: INFO: Pod pod-subpath-test-secret-2648 no longer exists
STEP: Deleting pod pod-subpath-test-secret-2648 05/01/23 22:52:02.812
May  1 22:52:02.812: INFO: Deleting pod "pod-subpath-test-secret-2648" in namespace "subpath-2546"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
May  1 22:52:02.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2546" for this suite. 05/01/23 22:52:03.021
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":33,"skipped":612,"failed":0}
------------------------------
• [SLOW TEST] [26.028 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:51:37.099
    May  1 22:51:37.099: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename subpath 05/01/23 22:51:37.1
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:51:37.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:51:37.621
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 05/01/23 22:51:37.828
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-2648 05/01/23 22:51:38.041
    STEP: Creating a pod to test atomic-volume-subpath 05/01/23 22:51:38.041
    May  1 22:51:38.166: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2648" in namespace "subpath-2546" to be "Succeeded or Failed"
    May  1 22:51:38.270: INFO: Pod "pod-subpath-test-secret-2648": Phase="Pending", Reason="", readiness=false. Elapsed: 104.176524ms
    May  1 22:51:40.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 2.210159486s
    May  1 22:51:42.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 4.210685941s
    May  1 22:51:44.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 6.210066143s
    May  1 22:51:46.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 8.209042867s
    May  1 22:51:48.377: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 10.210862225s
    May  1 22:51:50.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 12.209850858s
    May  1 22:51:52.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 14.208986596s
    May  1 22:51:54.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 16.209101978s
    May  1 22:51:56.377: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 18.211003666s
    May  1 22:51:58.376: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=true. Elapsed: 20.210699193s
    May  1 22:52:00.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Running", Reason="", readiness=false. Elapsed: 22.209434949s
    May  1 22:52:02.375: INFO: Pod "pod-subpath-test-secret-2648": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.20902839s
    STEP: Saw pod success 05/01/23 22:52:02.375
    May  1 22:52:02.375: INFO: Pod "pod-subpath-test-secret-2648" satisfied condition "Succeeded or Failed"
    May  1 22:52:02.479: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-secret-2648 container test-container-subpath-secret-2648: <nil>
    STEP: delete the pod 05/01/23 22:52:02.595
    May  1 22:52:02.708: INFO: Waiting for pod pod-subpath-test-secret-2648 to disappear
    May  1 22:52:02.812: INFO: Pod pod-subpath-test-secret-2648 no longer exists
    STEP: Deleting pod pod-subpath-test-secret-2648 05/01/23 22:52:02.812
    May  1 22:52:02.812: INFO: Deleting pod "pod-subpath-test-secret-2648" in namespace "subpath-2546"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    May  1 22:52:02.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2546" for this suite. 05/01/23 22:52:03.021
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:52:03.128
May  1 22:52:03.129: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container 05/01/23 22:52:03.129
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:03.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:03.657
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 05/01/23 22:52:03.864
May  1 22:52:03.864: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
May  1 22:52:08.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7852" for this suite. 05/01/23 22:52:09.027
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":34,"skipped":615,"failed":0}
------------------------------
• [SLOW TEST] [6.004 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:52:03.128
    May  1 22:52:03.129: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename init-container 05/01/23 22:52:03.129
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:03.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:03.657
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 05/01/23 22:52:03.864
    May  1 22:52:03.864: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    May  1 22:52:08.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7852" for this suite. 05/01/23 22:52:09.027
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:52:09.133
May  1 22:52:09.133: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 22:52:09.134
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:09.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:09.657
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1a02bfdf-db6f-46bb-9582-d4e89a329d70 05/01/23 22:52:09.969
STEP: Creating the pod 05/01/23 22:52:10.076
May  1 22:52:10.185: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b" in namespace "projected-6769" to be "running and ready"
May  1 22:52:10.289: INFO: Pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.245852ms
May  1 22:52:10.289: INFO: The phase of Pod pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b is Pending, waiting for it to be Running (with Ready = true)
May  1 22:52:12.398: INFO: Pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b": Phase="Running", Reason="", readiness=true. Elapsed: 2.21385126s
May  1 22:52:12.398: INFO: The phase of Pod pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b is Running (Ready = true)
May  1 22:52:12.398: INFO: Pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-1a02bfdf-db6f-46bb-9582-d4e89a329d70 05/01/23 22:52:12.609
STEP: waiting to observe update in volume 05/01/23 22:52:12.715
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  1 22:52:14.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6769" for this suite. 05/01/23 22:52:15.042
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":35,"skipped":625,"failed":0}
------------------------------
• [SLOW TEST] [6.015 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:52:09.133
    May  1 22:52:09.133: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 22:52:09.134
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:09.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:09.657
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-1a02bfdf-db6f-46bb-9582-d4e89a329d70 05/01/23 22:52:09.969
    STEP: Creating the pod 05/01/23 22:52:10.076
    May  1 22:52:10.185: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b" in namespace "projected-6769" to be "running and ready"
    May  1 22:52:10.289: INFO: Pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.245852ms
    May  1 22:52:10.289: INFO: The phase of Pod pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:52:12.398: INFO: Pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b": Phase="Running", Reason="", readiness=true. Elapsed: 2.21385126s
    May  1 22:52:12.398: INFO: The phase of Pod pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b is Running (Ready = true)
    May  1 22:52:12.398: INFO: Pod "pod-projected-configmaps-b2952b63-3fe0-46dc-af89-622f4d9c078b" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-1a02bfdf-db6f-46bb-9582-d4e89a329d70 05/01/23 22:52:12.609
    STEP: waiting to observe update in volume 05/01/23 22:52:12.715
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  1 22:52:14.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6769" for this suite. 05/01/23 22:52:15.042
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:52:15.15
May  1 22:52:15.150: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 22:52:15.152
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:15.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:15.674
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 05/01/23 22:52:15.881
May  1 22:52:15.989: INFO: Waiting up to 5m0s for pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c" in namespace "emptydir-5134" to be "Succeeded or Failed"
May  1 22:52:16.094: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c": Phase="Pending", Reason="", readiness=false. Elapsed: 104.855849ms
May  1 22:52:18.199: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209855802s
May  1 22:52:20.199: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210185815s
STEP: Saw pod success 05/01/23 22:52:20.199
May  1 22:52:20.199: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c" satisfied condition "Succeeded or Failed"
May  1 22:52:20.303: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c container test-container: <nil>
STEP: delete the pod 05/01/23 22:52:20.412
May  1 22:52:20.525: INFO: Waiting for pod pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c to disappear
May  1 22:52:20.629: INFO: Pod pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 22:52:20.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5134" for this suite. 05/01/23 22:52:20.735
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":36,"skipped":640,"failed":0}
------------------------------
• [SLOW TEST] [5.793 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:52:15.15
    May  1 22:52:15.150: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 22:52:15.152
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:15.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:15.674
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 05/01/23 22:52:15.881
    May  1 22:52:15.989: INFO: Waiting up to 5m0s for pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c" in namespace "emptydir-5134" to be "Succeeded or Failed"
    May  1 22:52:16.094: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c": Phase="Pending", Reason="", readiness=false. Elapsed: 104.855849ms
    May  1 22:52:18.199: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209855802s
    May  1 22:52:20.199: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210185815s
    STEP: Saw pod success 05/01/23 22:52:20.199
    May  1 22:52:20.199: INFO: Pod "pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c" satisfied condition "Succeeded or Failed"
    May  1 22:52:20.303: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c container test-container: <nil>
    STEP: delete the pod 05/01/23 22:52:20.412
    May  1 22:52:20.525: INFO: Waiting for pod pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c to disappear
    May  1 22:52:20.629: INFO: Pod pod-ad346b2b-d4b2-460d-b782-d3d86caaf27c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 22:52:20.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5134" for this suite. 05/01/23 22:52:20.735
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:52:20.944
May  1 22:52:20.945: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 22:52:20.946
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:21.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:21.468
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 05/01/23 22:52:21.675
May  1 22:52:21.784: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d" in namespace "projected-9609" to be "Succeeded or Failed"
May  1 22:52:21.889: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d": Phase="Pending", Reason="", readiness=false. Elapsed: 104.789288ms
May  1 22:52:23.994: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210008194s
May  1 22:52:25.994: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209958631s
STEP: Saw pod success 05/01/23 22:52:25.994
May  1 22:52:25.994: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d" satisfied condition "Succeeded or Failed"
May  1 22:52:26.098: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d container client-container: <nil>
STEP: delete the pod 05/01/23 22:52:26.205
May  1 22:52:26.319: INFO: Waiting for pod downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d to disappear
May  1 22:52:26.423: INFO: Pod downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  1 22:52:26.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9609" for this suite. 05/01/23 22:52:26.529
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":37,"skipped":653,"failed":0}
------------------------------
• [SLOW TEST] [5.692 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:52:20.944
    May  1 22:52:20.945: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 22:52:20.946
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:21.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:21.468
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 05/01/23 22:52:21.675
    May  1 22:52:21.784: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d" in namespace "projected-9609" to be "Succeeded or Failed"
    May  1 22:52:21.889: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d": Phase="Pending", Reason="", readiness=false. Elapsed: 104.789288ms
    May  1 22:52:23.994: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210008194s
    May  1 22:52:25.994: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209958631s
    STEP: Saw pod success 05/01/23 22:52:25.994
    May  1 22:52:25.994: INFO: Pod "downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d" satisfied condition "Succeeded or Failed"
    May  1 22:52:26.098: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d container client-container: <nil>
    STEP: delete the pod 05/01/23 22:52:26.205
    May  1 22:52:26.319: INFO: Waiting for pod downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d to disappear
    May  1 22:52:26.423: INFO: Pod downwardapi-volume-8f2d5f32-a255-4a4e-b148-3956d46d163d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  1 22:52:26.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9609" for this suite. 05/01/23 22:52:26.529
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:52:26.638
May  1 22:52:26.638: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/01/23 22:52:26.639
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:26.953
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:27.161
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
May  1 22:52:27.475: INFO: Waiting up to 2m0s for pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" in namespace "var-expansion-6047" to be "container 0 failed with reason CreateContainerConfigError"
May  1 22:52:27.579: INFO: Pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda": Phase="Pending", Reason="", readiness=false. Elapsed: 104.510256ms
May  1 22:52:29.684: INFO: Pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20945242s
May  1 22:52:29.684: INFO: Pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" satisfied condition "container 0 failed with reason CreateContainerConfigError"
May  1 22:52:29.684: INFO: Deleting pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" in namespace "var-expansion-6047"
May  1 22:52:29.792: INFO: Wait up to 5m0s for pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  1 22:52:32.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6047" for this suite. 05/01/23 22:52:32.107
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":38,"skipped":685,"failed":0}
------------------------------
• [SLOW TEST] [5.576 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:52:26.638
    May  1 22:52:26.638: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/01/23 22:52:26.639
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:26.953
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:27.161
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    May  1 22:52:27.475: INFO: Waiting up to 2m0s for pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" in namespace "var-expansion-6047" to be "container 0 failed with reason CreateContainerConfigError"
    May  1 22:52:27.579: INFO: Pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda": Phase="Pending", Reason="", readiness=false. Elapsed: 104.510256ms
    May  1 22:52:29.684: INFO: Pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20945242s
    May  1 22:52:29.684: INFO: Pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    May  1 22:52:29.684: INFO: Deleting pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" in namespace "var-expansion-6047"
    May  1 22:52:29.792: INFO: Wait up to 5m0s for pod "var-expansion-90837353-c639-4f2d-99f9-b81f9fb9dbda" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  1 22:52:32.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6047" for this suite. 05/01/23 22:52:32.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:52:32.214
May  1 22:52:32.215: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 22:52:32.216
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:32.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:32.736
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 05/01/23 22:52:32.943
May  1 22:52:32.944: INFO: >>> kubeConfig: /root/.kube/config
STEP: mark a version not serverd 05/01/23 22:52:55.31
STEP: check the unserved version gets removed 05/01/23 22:52:55.748
STEP: check the other version is not changed 05/01/23 22:53:02.428
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 22:53:19.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9484" for this suite. 05/01/23 22:53:20.168
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":39,"skipped":696,"failed":0}
------------------------------
• [SLOW TEST] [48.059 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:52:32.214
    May  1 22:52:32.215: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 22:52:32.216
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:52:32.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:52:32.736
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 05/01/23 22:52:32.943
    May  1 22:52:32.944: INFO: >>> kubeConfig: /root/.kube/config
    STEP: mark a version not serverd 05/01/23 22:52:55.31
    STEP: check the unserved version gets removed 05/01/23 22:52:55.748
    STEP: check the other version is not changed 05/01/23 22:53:02.428
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 22:53:19.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9484" for this suite. 05/01/23 22:53:20.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:53:20.276
May  1 22:53:20.276: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller 05/01/23 22:53:20.277
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:53:20.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:53:20.792
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 05/01/23 22:53:20.996
May  1 22:53:21.103: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-1149" to be "running and ready"
May  1 22:53:21.206: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 103.133849ms
May  1 22:53:21.206: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
May  1 22:53:23.311: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.207447105s
May  1 22:53:23.311: INFO: The phase of Pod pod-adoption is Running (Ready = true)
May  1 22:53:23.311: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 05/01/23 22:53:23.413
STEP: Then the orphan pod is adopted 05/01/23 22:53:23.52
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
May  1 22:53:23.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1149" for this suite. 05/01/23 22:53:23.727
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":40,"skipped":721,"failed":0}
------------------------------
• [3.656 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:53:20.276
    May  1 22:53:20.276: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replication-controller 05/01/23 22:53:20.277
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:53:20.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:53:20.792
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 05/01/23 22:53:20.996
    May  1 22:53:21.103: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-1149" to be "running and ready"
    May  1 22:53:21.206: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 103.133849ms
    May  1 22:53:21.206: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:53:23.311: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.207447105s
    May  1 22:53:23.311: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    May  1 22:53:23.311: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 05/01/23 22:53:23.413
    STEP: Then the orphan pod is adopted 05/01/23 22:53:23.52
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    May  1 22:53:23.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1149" for this suite. 05/01/23 22:53:23.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:53:23.933
May  1 22:53:23.933: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 22:53:23.934
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:53:24.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:53:24.448
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 05/01/23 22:53:24.653
May  1 22:53:24.654: INFO: >>> kubeConfig: /root/.kube/config
May  1 22:53:31.646: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 22:54:03.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8578" for this suite. 05/01/23 22:54:03.774
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":41,"skipped":731,"failed":0}
------------------------------
• [SLOW TEST] [39.948 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:53:23.933
    May  1 22:53:23.933: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 22:53:23.934
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:53:24.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:53:24.448
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 05/01/23 22:53:24.653
    May  1 22:53:24.654: INFO: >>> kubeConfig: /root/.kube/config
    May  1 22:53:31.646: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 22:54:03.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8578" for this suite. 05/01/23 22:54:03.774
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:03.883
May  1 22:54:03.883: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 22:54:03.884
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:04.196
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:04.402
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 05/01/23 22:54:04.608
May  1 22:54:04.715: INFO: Waiting up to 5m0s for pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e" in namespace "downward-api-3632" to be "Succeeded or Failed"
May  1 22:54:04.818: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 103.769986ms
May  1 22:54:06.923: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208741365s
May  1 22:54:08.924: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209044584s
STEP: Saw pod success 05/01/23 22:54:08.924
May  1 22:54:08.924: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e" satisfied condition "Succeeded or Failed"
May  1 22:54:09.028: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e container dapi-container: <nil>
STEP: delete the pod 05/01/23 22:54:09.14
May  1 22:54:09.252: INFO: Waiting for pod downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e to disappear
May  1 22:54:09.355: INFO: Pod downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
May  1 22:54:09.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3632" for this suite. 05/01/23 22:54:09.46
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":42,"skipped":779,"failed":0}
------------------------------
• [SLOW TEST] [5.682 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:03.883
    May  1 22:54:03.883: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 22:54:03.884
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:04.196
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:04.402
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 05/01/23 22:54:04.608
    May  1 22:54:04.715: INFO: Waiting up to 5m0s for pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e" in namespace "downward-api-3632" to be "Succeeded or Failed"
    May  1 22:54:04.818: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 103.769986ms
    May  1 22:54:06.923: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208741365s
    May  1 22:54:08.924: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209044584s
    STEP: Saw pod success 05/01/23 22:54:08.924
    May  1 22:54:08.924: INFO: Pod "downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e" satisfied condition "Succeeded or Failed"
    May  1 22:54:09.028: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e container dapi-container: <nil>
    STEP: delete the pod 05/01/23 22:54:09.14
    May  1 22:54:09.252: INFO: Waiting for pod downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e to disappear
    May  1 22:54:09.355: INFO: Pod downward-api-3b0953a7-6e76-467e-a0e9-3bdec8f26f2e no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    May  1 22:54:09.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3632" for this suite. 05/01/23 22:54:09.46
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:09.566
May  1 22:54:09.567: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 22:54:09.568
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:09.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:10.085
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 05/01/23 22:54:10.29
May  1 22:54:10.398: INFO: Waiting up to 5m0s for pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae" in namespace "emptydir-3269" to be "Succeeded or Failed"
May  1 22:54:10.502: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae": Phase="Pending", Reason="", readiness=false. Elapsed: 103.716337ms
May  1 22:54:12.606: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207405193s
May  1 22:54:14.606: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207749345s
STEP: Saw pod success 05/01/23 22:54:14.606
May  1 22:54:14.606: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae" satisfied condition "Succeeded or Failed"
May  1 22:54:14.710: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-bc263c72-a579-4059-ad89-63d44bc15dae container test-container: <nil>
STEP: delete the pod 05/01/23 22:54:14.816
May  1 22:54:14.928: INFO: Waiting for pod pod-bc263c72-a579-4059-ad89-63d44bc15dae to disappear
May  1 22:54:15.032: INFO: Pod pod-bc263c72-a579-4059-ad89-63d44bc15dae no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 22:54:15.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3269" for this suite. 05/01/23 22:54:15.137
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":43,"skipped":795,"failed":0}
------------------------------
• [SLOW TEST] [5.776 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:09.566
    May  1 22:54:09.567: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 22:54:09.568
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:09.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:10.085
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 05/01/23 22:54:10.29
    May  1 22:54:10.398: INFO: Waiting up to 5m0s for pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae" in namespace "emptydir-3269" to be "Succeeded or Failed"
    May  1 22:54:10.502: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae": Phase="Pending", Reason="", readiness=false. Elapsed: 103.716337ms
    May  1 22:54:12.606: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207405193s
    May  1 22:54:14.606: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207749345s
    STEP: Saw pod success 05/01/23 22:54:14.606
    May  1 22:54:14.606: INFO: Pod "pod-bc263c72-a579-4059-ad89-63d44bc15dae" satisfied condition "Succeeded or Failed"
    May  1 22:54:14.710: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-bc263c72-a579-4059-ad89-63d44bc15dae container test-container: <nil>
    STEP: delete the pod 05/01/23 22:54:14.816
    May  1 22:54:14.928: INFO: Waiting for pod pod-bc263c72-a579-4059-ad89-63d44bc15dae to disappear
    May  1 22:54:15.032: INFO: Pod pod-bc263c72-a579-4059-ad89-63d44bc15dae no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 22:54:15.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3269" for this suite. 05/01/23 22:54:15.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:15.345
May  1 22:54:15.345: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 22:54:15.346
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:15.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:15.863
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/01/23 22:54:16.068
May  1 22:54:16.068: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-789 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
May  1 22:54:16.488: INFO: stderr: ""
May  1 22:54:16.488: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 05/01/23 22:54:16.488
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
May  1 22:54:16.592: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-789 delete pods e2e-test-httpd-pod'
May  1 22:54:18.354: INFO: stderr: ""
May  1 22:54:18.354: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 22:54:18.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-789" for this suite. 05/01/23 22:54:18.459
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":44,"skipped":829,"failed":0}
------------------------------
• [3.220 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:15.345
    May  1 22:54:15.345: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 22:54:15.346
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:15.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:15.863
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/01/23 22:54:16.068
    May  1 22:54:16.068: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-789 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    May  1 22:54:16.488: INFO: stderr: ""
    May  1 22:54:16.488: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 05/01/23 22:54:16.488
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    May  1 22:54:16.592: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-789 delete pods e2e-test-httpd-pod'
    May  1 22:54:18.354: INFO: stderr: ""
    May  1 22:54:18.354: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 22:54:18.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-789" for this suite. 05/01/23 22:54:18.459
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:18.566
May  1 22:54:18.566: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 22:54:18.568
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:18.883
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:19.088
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 05/01/23 22:54:19.294
May  1 22:54:19.400: INFO: Waiting up to 5m0s for pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa" in namespace "emptydir-2528" to be "Succeeded or Failed"
May  1 22:54:19.504: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa": Phase="Pending", Reason="", readiness=false. Elapsed: 103.569816ms
May  1 22:54:21.609: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208432343s
May  1 22:54:23.610: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209215905s
STEP: Saw pod success 05/01/23 22:54:23.61
May  1 22:54:23.610: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa" satisfied condition "Succeeded or Failed"
May  1 22:54:23.717: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa container test-container: <nil>
STEP: delete the pod 05/01/23 22:54:23.83
May  1 22:54:23.942: INFO: Waiting for pod pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa to disappear
May  1 22:54:24.046: INFO: Pod pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 22:54:24.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2528" for this suite. 05/01/23 22:54:24.151
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":45,"skipped":840,"failed":0}
------------------------------
• [SLOW TEST] [5.791 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:18.566
    May  1 22:54:18.566: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 22:54:18.568
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:18.883
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:19.088
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 05/01/23 22:54:19.294
    May  1 22:54:19.400: INFO: Waiting up to 5m0s for pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa" in namespace "emptydir-2528" to be "Succeeded or Failed"
    May  1 22:54:19.504: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa": Phase="Pending", Reason="", readiness=false. Elapsed: 103.569816ms
    May  1 22:54:21.609: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208432343s
    May  1 22:54:23.610: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209215905s
    STEP: Saw pod success 05/01/23 22:54:23.61
    May  1 22:54:23.610: INFO: Pod "pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa" satisfied condition "Succeeded or Failed"
    May  1 22:54:23.717: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa container test-container: <nil>
    STEP: delete the pod 05/01/23 22:54:23.83
    May  1 22:54:23.942: INFO: Waiting for pod pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa to disappear
    May  1 22:54:24.046: INFO: Pod pod-4b2dd6ab-6534-4a5e-afe6-ad59f58f98aa no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 22:54:24.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2528" for this suite. 05/01/23 22:54:24.151
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:24.358
May  1 22:54:24.358: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/01/23 22:54:24.36
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:24.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:24.877
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 05/01/23 22:54:25.082
STEP: setting up watch 05/01/23 22:54:25.082
STEP: submitting the pod to kubernetes 05/01/23 22:54:25.387
STEP: verifying the pod is in kubernetes 05/01/23 22:54:25.495
STEP: verifying pod creation was observed 05/01/23 22:54:25.601
May  1 22:54:25.601: INFO: Waiting up to 5m0s for pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a" in namespace "pods-409" to be "running"
May  1 22:54:25.705: INFO: Pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a": Phase="Pending", Reason="", readiness=false. Elapsed: 103.693438ms
May  1 22:54:27.809: INFO: Pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a": Phase="Running", Reason="", readiness=true. Elapsed: 2.20856996s
May  1 22:54:27.809: INFO: Pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a" satisfied condition "running"
STEP: deleting the pod gracefully 05/01/23 22:54:27.913
STEP: verifying pod deletion was observed 05/01/23 22:54:28.022
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  1 22:54:30.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-409" for this suite. 05/01/23 22:54:30.462
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":46,"skipped":843,"failed":0}
------------------------------
• [SLOW TEST] [6.310 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:24.358
    May  1 22:54:24.358: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/01/23 22:54:24.36
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:24.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:24.877
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 05/01/23 22:54:25.082
    STEP: setting up watch 05/01/23 22:54:25.082
    STEP: submitting the pod to kubernetes 05/01/23 22:54:25.387
    STEP: verifying the pod is in kubernetes 05/01/23 22:54:25.495
    STEP: verifying pod creation was observed 05/01/23 22:54:25.601
    May  1 22:54:25.601: INFO: Waiting up to 5m0s for pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a" in namespace "pods-409" to be "running"
    May  1 22:54:25.705: INFO: Pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a": Phase="Pending", Reason="", readiness=false. Elapsed: 103.693438ms
    May  1 22:54:27.809: INFO: Pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a": Phase="Running", Reason="", readiness=true. Elapsed: 2.20856996s
    May  1 22:54:27.809: INFO: Pod "pod-submit-remove-b7b08f82-24ee-430d-9bd2-3dfb5ee6d03a" satisfied condition "running"
    STEP: deleting the pod gracefully 05/01/23 22:54:27.913
    STEP: verifying pod deletion was observed 05/01/23 22:54:28.022
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  1 22:54:30.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-409" for this suite. 05/01/23 22:54:30.462
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:30.669
May  1 22:54:30.669: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 22:54:30.67
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:30.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:31.188
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 05/01/23 22:54:31.394
STEP: Creating a ResourceQuota 05/01/23 22:54:36.498
STEP: Ensuring resource quota status is calculated 05/01/23 22:54:36.605
STEP: Creating a ReplicationController 05/01/23 22:54:38.71
STEP: Ensuring resource quota status captures replication controller creation 05/01/23 22:54:38.82
STEP: Deleting a ReplicationController 05/01/23 22:54:40.924
STEP: Ensuring resource quota status released usage 05/01/23 22:54:41.029
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 22:54:43.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2958" for this suite. 05/01/23 22:54:43.239
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":47,"skipped":862,"failed":0}
------------------------------
• [SLOW TEST] [12.776 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:30.669
    May  1 22:54:30.669: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 22:54:30.67
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:30.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:31.188
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 05/01/23 22:54:31.394
    STEP: Creating a ResourceQuota 05/01/23 22:54:36.498
    STEP: Ensuring resource quota status is calculated 05/01/23 22:54:36.605
    STEP: Creating a ReplicationController 05/01/23 22:54:38.71
    STEP: Ensuring resource quota status captures replication controller creation 05/01/23 22:54:38.82
    STEP: Deleting a ReplicationController 05/01/23 22:54:40.924
    STEP: Ensuring resource quota status released usage 05/01/23 22:54:41.029
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 22:54:43.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2958" for this suite. 05/01/23 22:54:43.239
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:43.446
May  1 22:54:43.446: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 22:54:43.447
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:43.759
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:43.964
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-fcf4bc66-2470-4672-b56f-2f69e3760bba 05/01/23 22:54:44.17
STEP: Creating a pod to test consume secrets 05/01/23 22:54:44.274
May  1 22:54:44.381: INFO: Waiting up to 5m0s for pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869" in namespace "secrets-8363" to be "Succeeded or Failed"
May  1 22:54:44.485: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869": Phase="Pending", Reason="", readiness=false. Elapsed: 103.831844ms
May  1 22:54:46.589: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207998129s
May  1 22:54:48.592: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.21097194s
STEP: Saw pod success 05/01/23 22:54:48.592
May  1 22:54:48.593: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869" satisfied condition "Succeeded or Failed"
May  1 22:54:48.696: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869 container secret-volume-test: <nil>
STEP: delete the pod 05/01/23 22:54:48.802
May  1 22:54:48.913: INFO: Waiting for pod pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869 to disappear
May  1 22:54:49.016: INFO: Pod pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  1 22:54:49.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8363" for this suite. 05/01/23 22:54:49.121
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":48,"skipped":897,"failed":0}
------------------------------
• [SLOW TEST] [5.780 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:43.446
    May  1 22:54:43.446: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 22:54:43.447
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:43.759
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:43.964
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-fcf4bc66-2470-4672-b56f-2f69e3760bba 05/01/23 22:54:44.17
    STEP: Creating a pod to test consume secrets 05/01/23 22:54:44.274
    May  1 22:54:44.381: INFO: Waiting up to 5m0s for pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869" in namespace "secrets-8363" to be "Succeeded or Failed"
    May  1 22:54:44.485: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869": Phase="Pending", Reason="", readiness=false. Elapsed: 103.831844ms
    May  1 22:54:46.589: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207998129s
    May  1 22:54:48.592: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.21097194s
    STEP: Saw pod success 05/01/23 22:54:48.592
    May  1 22:54:48.593: INFO: Pod "pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869" satisfied condition "Succeeded or Failed"
    May  1 22:54:48.696: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869 container secret-volume-test: <nil>
    STEP: delete the pod 05/01/23 22:54:48.802
    May  1 22:54:48.913: INFO: Waiting for pod pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869 to disappear
    May  1 22:54:49.016: INFO: Pod pod-secrets-ec6d09db-eae9-4f14-8126-3db00caab869 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  1 22:54:49.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8363" for this suite. 05/01/23 22:54:49.121
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:49.23
May  1 22:54:49.230: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 22:54:49.232
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:49.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:49.749
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 05/01/23 22:54:49.955
May  1 22:54:49.955: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
May  1 22:54:50.365: INFO: stderr: ""
May  1 22:54:50.365: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 05/01/23 22:54:50.365
May  1 22:54:50.365: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
May  1 22:54:50.365: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2711" to be "running and ready, or succeeded"
May  1 22:54:50.469: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 103.770097ms
May  1 22:54:50.469: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'i-02d061b30635c230c' to be 'Running' but was 'Pending'
May  1 22:54:52.573: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.207699464s
May  1 22:54:52.573: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
May  1 22:54:52.573: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 05/01/23 22:54:52.573
May  1 22:54:52.573: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator'
May  1 22:54:53.082: INFO: stderr: ""
May  1 22:54:53.082: INFO: stdout: "I0501 22:54:51.143027       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/88g 219\nI0501 22:54:51.343153       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/xl4 234\nI0501 22:54:51.543536       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hkw 410\nI0501 22:54:51.743876       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/rch 256\nI0501 22:54:51.943131       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/pjt 401\nI0501 22:54:52.143431       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/9ss 429\nI0501 22:54:52.343744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/w6q 258\nI0501 22:54:52.544065       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/8r2n 586\nI0501 22:54:52.743377       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/lsx 440\nI0501 22:54:52.943691       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/xbnh 580\n"
STEP: limiting log lines 05/01/23 22:54:53.082
May  1 22:54:53.083: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --tail=1'
May  1 22:54:53.596: INFO: stderr: ""
May  1 22:54:53.596: INFO: stdout: "I0501 22:54:53.343245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/d84v 483\n"
May  1 22:54:53.596: INFO: got output "I0501 22:54:53.343245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/d84v 483\n"
STEP: limiting log bytes 05/01/23 22:54:53.596
May  1 22:54:53.597: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --limit-bytes=1'
May  1 22:54:54.124: INFO: stderr: ""
May  1 22:54:54.124: INFO: stdout: "I"
May  1 22:54:54.124: INFO: got output "I"
STEP: exposing timestamps 05/01/23 22:54:54.124
May  1 22:54:54.124: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --tail=1 --timestamps'
May  1 22:54:54.634: INFO: stderr: ""
May  1 22:54:54.634: INFO: stdout: "2023-05-01T22:54:54.544579749Z I0501 22:54:54.544461       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/r2p 342\n"
May  1 22:54:54.634: INFO: got output "2023-05-01T22:54:54.544579749Z I0501 22:54:54.544461       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/r2p 342\n"
STEP: restricting to a time range 05/01/23 22:54:54.634
May  1 22:54:57.136: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --since=1s'
May  1 22:54:57.656: INFO: stderr: ""
May  1 22:54:57.656: INFO: stdout: "I0501 22:54:56.744066       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/jqhs 519\nI0501 22:54:56.943391       1 logs_generator.go:76] 29 POST /api/v1/namespaces/ns/pods/gc4b 297\nI0501 22:54:57.143713       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/k7wc 464\nI0501 22:54:57.344027       1 logs_generator.go:76] 31 POST /api/v1/namespaces/ns/pods/xzxl 573\nI0501 22:54:57.543279       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/cbjk 332\n"
May  1 22:54:57.656: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --since=24h'
May  1 22:54:58.165: INFO: stderr: ""
May  1 22:54:58.165: INFO: stdout: "I0501 22:54:51.143027       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/88g 219\nI0501 22:54:51.343153       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/xl4 234\nI0501 22:54:51.543536       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hkw 410\nI0501 22:54:51.743876       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/rch 256\nI0501 22:54:51.943131       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/pjt 401\nI0501 22:54:52.143431       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/9ss 429\nI0501 22:54:52.343744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/w6q 258\nI0501 22:54:52.544065       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/8r2n 586\nI0501 22:54:52.743377       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/lsx 440\nI0501 22:54:52.943691       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/xbnh 580\nI0501 22:54:53.144004       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/l8zt 430\nI0501 22:54:53.343245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/d84v 483\nI0501 22:54:53.543723       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/6qf 564\nI0501 22:54:53.744112       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/b88 313\nI0501 22:54:53.944893       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/kj2 511\nI0501 22:54:54.143175       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/rx9v 292\nI0501 22:54:54.343467       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/qgh 256\nI0501 22:54:54.544461       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/r2p 342\nI0501 22:54:54.743761       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/9bz 489\nI0501 22:54:54.944071       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kzd 423\nI0501 22:54:55.143402       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lvk 362\nI0501 22:54:55.343726       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/jhwr 343\nI0501 22:54:55.544048       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/7n2 573\nI0501 22:54:55.743370       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/jmd 305\nI0501 22:54:55.943682       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/qdhx 321\nI0501 22:54:56.144031       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/tdq 375\nI0501 22:54:56.343413       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/w6z 258\nI0501 22:54:56.543721       1 logs_generator.go:76] 27 POST /api/v1/namespaces/default/pods/q2np 476\nI0501 22:54:56.744066       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/jqhs 519\nI0501 22:54:56.943391       1 logs_generator.go:76] 29 POST /api/v1/namespaces/ns/pods/gc4b 297\nI0501 22:54:57.143713       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/k7wc 464\nI0501 22:54:57.344027       1 logs_generator.go:76] 31 POST /api/v1/namespaces/ns/pods/xzxl 573\nI0501 22:54:57.543279       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/cbjk 332\nI0501 22:54:57.743581       1 logs_generator.go:76] 33 GET /api/v1/namespaces/default/pods/4pg 372\nI0501 22:54:57.943915       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/kube-system/pods/9vfh 548\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
May  1 22:54:58.165: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 delete pod logs-generator'
May  1 22:54:59.411: INFO: stderr: ""
May  1 22:54:59.411: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 22:54:59.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2711" for this suite. 05/01/23 22:54:59.515
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":49,"skipped":953,"failed":0}
------------------------------
• [SLOW TEST] [10.391 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:49.23
    May  1 22:54:49.230: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 22:54:49.232
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:49.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:54:49.749
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 05/01/23 22:54:49.955
    May  1 22:54:49.955: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    May  1 22:54:50.365: INFO: stderr: ""
    May  1 22:54:50.365: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 05/01/23 22:54:50.365
    May  1 22:54:50.365: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    May  1 22:54:50.365: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2711" to be "running and ready, or succeeded"
    May  1 22:54:50.469: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 103.770097ms
    May  1 22:54:50.469: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'i-02d061b30635c230c' to be 'Running' but was 'Pending'
    May  1 22:54:52.573: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.207699464s
    May  1 22:54:52.573: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    May  1 22:54:52.573: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 05/01/23 22:54:52.573
    May  1 22:54:52.573: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator'
    May  1 22:54:53.082: INFO: stderr: ""
    May  1 22:54:53.082: INFO: stdout: "I0501 22:54:51.143027       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/88g 219\nI0501 22:54:51.343153       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/xl4 234\nI0501 22:54:51.543536       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hkw 410\nI0501 22:54:51.743876       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/rch 256\nI0501 22:54:51.943131       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/pjt 401\nI0501 22:54:52.143431       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/9ss 429\nI0501 22:54:52.343744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/w6q 258\nI0501 22:54:52.544065       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/8r2n 586\nI0501 22:54:52.743377       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/lsx 440\nI0501 22:54:52.943691       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/xbnh 580\n"
    STEP: limiting log lines 05/01/23 22:54:53.082
    May  1 22:54:53.083: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --tail=1'
    May  1 22:54:53.596: INFO: stderr: ""
    May  1 22:54:53.596: INFO: stdout: "I0501 22:54:53.343245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/d84v 483\n"
    May  1 22:54:53.596: INFO: got output "I0501 22:54:53.343245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/d84v 483\n"
    STEP: limiting log bytes 05/01/23 22:54:53.596
    May  1 22:54:53.597: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --limit-bytes=1'
    May  1 22:54:54.124: INFO: stderr: ""
    May  1 22:54:54.124: INFO: stdout: "I"
    May  1 22:54:54.124: INFO: got output "I"
    STEP: exposing timestamps 05/01/23 22:54:54.124
    May  1 22:54:54.124: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --tail=1 --timestamps'
    May  1 22:54:54.634: INFO: stderr: ""
    May  1 22:54:54.634: INFO: stdout: "2023-05-01T22:54:54.544579749Z I0501 22:54:54.544461       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/r2p 342\n"
    May  1 22:54:54.634: INFO: got output "2023-05-01T22:54:54.544579749Z I0501 22:54:54.544461       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/r2p 342\n"
    STEP: restricting to a time range 05/01/23 22:54:54.634
    May  1 22:54:57.136: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --since=1s'
    May  1 22:54:57.656: INFO: stderr: ""
    May  1 22:54:57.656: INFO: stdout: "I0501 22:54:56.744066       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/jqhs 519\nI0501 22:54:56.943391       1 logs_generator.go:76] 29 POST /api/v1/namespaces/ns/pods/gc4b 297\nI0501 22:54:57.143713       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/k7wc 464\nI0501 22:54:57.344027       1 logs_generator.go:76] 31 POST /api/v1/namespaces/ns/pods/xzxl 573\nI0501 22:54:57.543279       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/cbjk 332\n"
    May  1 22:54:57.656: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 logs logs-generator logs-generator --since=24h'
    May  1 22:54:58.165: INFO: stderr: ""
    May  1 22:54:58.165: INFO: stdout: "I0501 22:54:51.143027       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/88g 219\nI0501 22:54:51.343153       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/xl4 234\nI0501 22:54:51.543536       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/hkw 410\nI0501 22:54:51.743876       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/rch 256\nI0501 22:54:51.943131       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/pjt 401\nI0501 22:54:52.143431       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/9ss 429\nI0501 22:54:52.343744       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/w6q 258\nI0501 22:54:52.544065       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/8r2n 586\nI0501 22:54:52.743377       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/lsx 440\nI0501 22:54:52.943691       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/xbnh 580\nI0501 22:54:53.144004       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/l8zt 430\nI0501 22:54:53.343245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/d84v 483\nI0501 22:54:53.543723       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/6qf 564\nI0501 22:54:53.744112       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/b88 313\nI0501 22:54:53.944893       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/kj2 511\nI0501 22:54:54.143175       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/rx9v 292\nI0501 22:54:54.343467       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/qgh 256\nI0501 22:54:54.544461       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/r2p 342\nI0501 22:54:54.743761       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/9bz 489\nI0501 22:54:54.944071       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kzd 423\nI0501 22:54:55.143402       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lvk 362\nI0501 22:54:55.343726       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/jhwr 343\nI0501 22:54:55.544048       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/7n2 573\nI0501 22:54:55.743370       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/jmd 305\nI0501 22:54:55.943682       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/qdhx 321\nI0501 22:54:56.144031       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/tdq 375\nI0501 22:54:56.343413       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/w6z 258\nI0501 22:54:56.543721       1 logs_generator.go:76] 27 POST /api/v1/namespaces/default/pods/q2np 476\nI0501 22:54:56.744066       1 logs_generator.go:76] 28 POST /api/v1/namespaces/default/pods/jqhs 519\nI0501 22:54:56.943391       1 logs_generator.go:76] 29 POST /api/v1/namespaces/ns/pods/gc4b 297\nI0501 22:54:57.143713       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/k7wc 464\nI0501 22:54:57.344027       1 logs_generator.go:76] 31 POST /api/v1/namespaces/ns/pods/xzxl 573\nI0501 22:54:57.543279       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/cbjk 332\nI0501 22:54:57.743581       1 logs_generator.go:76] 33 GET /api/v1/namespaces/default/pods/4pg 372\nI0501 22:54:57.943915       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/kube-system/pods/9vfh 548\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    May  1 22:54:58.165: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-2711 delete pod logs-generator'
    May  1 22:54:59.411: INFO: stderr: ""
    May  1 22:54:59.411: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 22:54:59.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2711" for this suite. 05/01/23 22:54:59.515
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:54:59.622
May  1 22:54:59.622: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename cronjob 05/01/23 22:54:59.623
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:59.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:55:00.14
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 05/01/23 22:55:00.345
STEP: Ensuring a job is scheduled 05/01/23 22:55:00.453
STEP: Ensuring exactly one is scheduled 05/01/23 22:56:00.561
STEP: Ensuring exactly one running job exists by listing jobs explicitly 05/01/23 22:56:00.665
STEP: Ensuring the job is replaced with a new one 05/01/23 22:56:00.769
STEP: Removing cronjob 05/01/23 22:57:00.873
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
May  1 22:57:00.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6496" for this suite. 05/01/23 22:57:01.084
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":50,"skipped":969,"failed":0}
------------------------------
• [SLOW TEST] [121.568 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:54:59.622
    May  1 22:54:59.622: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename cronjob 05/01/23 22:54:59.623
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:54:59.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:55:00.14
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 05/01/23 22:55:00.345
    STEP: Ensuring a job is scheduled 05/01/23 22:55:00.453
    STEP: Ensuring exactly one is scheduled 05/01/23 22:56:00.561
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 05/01/23 22:56:00.665
    STEP: Ensuring the job is replaced with a new one 05/01/23 22:56:00.769
    STEP: Removing cronjob 05/01/23 22:57:00.873
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    May  1 22:57:00.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6496" for this suite. 05/01/23 22:57:01.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:01.191
May  1 22:57:01.192: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-webhook 05/01/23 22:57:01.193
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:01.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:01.711
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 05/01/23 22:57:01.917
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 05/01/23 22:57:02.421
STEP: Deploying the custom resource conversion webhook pod 05/01/23 22:57:02.528
STEP: Wait for the deployment to be ready 05/01/23 22:57:02.74
May  1 22:57:03.051: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 22:57:05.156
STEP: Verifying the service has paired with the endpoint 05/01/23 22:57:05.267
May  1 22:57:06.267: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
May  1 22:57:06.372: INFO: >>> kubeConfig: /root/.kube/config
STEP: Creating a v1 custom resource 05/01/23 22:57:08.979
STEP: Create a v2 custom resource 05/01/23 22:57:09.296
STEP: List CRs in v1 05/01/23 22:57:09.444
STEP: List CRs in v2 05/01/23 22:57:09.549
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 22:57:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4502" for this suite. 05/01/23 22:57:10.074
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":51,"skipped":984,"failed":0}
------------------------------
• [SLOW TEST] [9.436 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:01.191
    May  1 22:57:01.192: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-webhook 05/01/23 22:57:01.193
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:01.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:01.711
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 05/01/23 22:57:01.917
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 05/01/23 22:57:02.421
    STEP: Deploying the custom resource conversion webhook pod 05/01/23 22:57:02.528
    STEP: Wait for the deployment to be ready 05/01/23 22:57:02.74
    May  1 22:57:03.051: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 57, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 22:57:05.156
    STEP: Verifying the service has paired with the endpoint 05/01/23 22:57:05.267
    May  1 22:57:06.267: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    May  1 22:57:06.372: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Creating a v1 custom resource 05/01/23 22:57:08.979
    STEP: Create a v2 custom resource 05/01/23 22:57:09.296
    STEP: List CRs in v1 05/01/23 22:57:09.444
    STEP: List CRs in v2 05/01/23 22:57:09.549
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 22:57:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-4502" for this suite. 05/01/23 22:57:10.074
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:10.628
May  1 22:57:10.628: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 22:57:10.629
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:10.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:11.146
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 05/01/23 22:57:11.351
May  1 22:57:11.352: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 create -f -'
May  1 22:57:12.980: INFO: stderr: ""
May  1 22:57:12.980: INFO: stdout: "pod/pause created\n"
May  1 22:57:12.980: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May  1 22:57:12.980: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6461" to be "running and ready"
May  1 22:57:13.084: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 103.644947ms
May  1 22:57:13.084: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'i-0627b78ff917cf2ae' to be 'Running' but was 'Pending'
May  1 22:57:15.192: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.211774925s
May  1 22:57:15.192: INFO: Pod "pause" satisfied condition "running and ready"
May  1 22:57:15.192: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 05/01/23 22:57:15.192
May  1 22:57:15.192: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 label pods pause testing-label=testing-label-value'
May  1 22:57:15.734: INFO: stderr: ""
May  1 22:57:15.734: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 05/01/23 22:57:15.734
May  1 22:57:15.734: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get pod pause -L testing-label'
May  1 22:57:16.151: INFO: stderr: ""
May  1 22:57:16.151: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod 05/01/23 22:57:16.151
May  1 22:57:16.152: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 label pods pause testing-label-'
May  1 22:57:16.676: INFO: stderr: ""
May  1 22:57:16.676: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 05/01/23 22:57:16.676
May  1 22:57:16.676: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get pod pause -L testing-label'
May  1 22:57:17.101: INFO: stderr: ""
May  1 22:57:17.101: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 05/01/23 22:57:17.101
May  1 22:57:17.102: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 delete --grace-period=0 --force -f -'
May  1 22:57:17.616: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  1 22:57:17.616: INFO: stdout: "pod \"pause\" force deleted\n"
May  1 22:57:17.616: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get rc,svc -l name=pause --no-headers'
May  1 22:57:18.124: INFO: stderr: "No resources found in kubectl-6461 namespace.\n"
May  1 22:57:18.124: INFO: stdout: ""
May  1 22:57:18.124: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  1 22:57:18.564: INFO: stderr: ""
May  1 22:57:18.564: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 22:57:18.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6461" for this suite. 05/01/23 22:57:18.668
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":52,"skipped":985,"failed":0}
------------------------------
• [SLOW TEST] [8.146 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:10.628
    May  1 22:57:10.628: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 22:57:10.629
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:10.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:11.146
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 05/01/23 22:57:11.351
    May  1 22:57:11.352: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 create -f -'
    May  1 22:57:12.980: INFO: stderr: ""
    May  1 22:57:12.980: INFO: stdout: "pod/pause created\n"
    May  1 22:57:12.980: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    May  1 22:57:12.980: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6461" to be "running and ready"
    May  1 22:57:13.084: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 103.644947ms
    May  1 22:57:13.084: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'i-0627b78ff917cf2ae' to be 'Running' but was 'Pending'
    May  1 22:57:15.192: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.211774925s
    May  1 22:57:15.192: INFO: Pod "pause" satisfied condition "running and ready"
    May  1 22:57:15.192: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 05/01/23 22:57:15.192
    May  1 22:57:15.192: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 label pods pause testing-label=testing-label-value'
    May  1 22:57:15.734: INFO: stderr: ""
    May  1 22:57:15.734: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 05/01/23 22:57:15.734
    May  1 22:57:15.734: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get pod pause -L testing-label'
    May  1 22:57:16.151: INFO: stderr: ""
    May  1 22:57:16.151: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 05/01/23 22:57:16.151
    May  1 22:57:16.152: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 label pods pause testing-label-'
    May  1 22:57:16.676: INFO: stderr: ""
    May  1 22:57:16.676: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 05/01/23 22:57:16.676
    May  1 22:57:16.676: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get pod pause -L testing-label'
    May  1 22:57:17.101: INFO: stderr: ""
    May  1 22:57:17.101: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 05/01/23 22:57:17.101
    May  1 22:57:17.102: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 delete --grace-period=0 --force -f -'
    May  1 22:57:17.616: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  1 22:57:17.616: INFO: stdout: "pod \"pause\" force deleted\n"
    May  1 22:57:17.616: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get rc,svc -l name=pause --no-headers'
    May  1 22:57:18.124: INFO: stderr: "No resources found in kubectl-6461 namespace.\n"
    May  1 22:57:18.124: INFO: stdout: ""
    May  1 22:57:18.124: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6461 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    May  1 22:57:18.564: INFO: stderr: ""
    May  1 22:57:18.564: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 22:57:18.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6461" for this suite. 05/01/23 22:57:18.668
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:18.774
May  1 22:57:18.774: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch 05/01/23 22:57:18.775
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:19.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:19.296
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 05/01/23 22:57:19.502
STEP: creating a new configmap 05/01/23 22:57:19.604
STEP: modifying the configmap once 05/01/23 22:57:19.709
STEP: closing the watch once it receives two notifications 05/01/23 22:57:19.918
May  1 22:57:19.918: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7844 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 22:57:19.918: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7845 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 05/01/23 22:57:19.918
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 05/01/23 22:57:20.127
STEP: deleting the configmap 05/01/23 22:57:20.229
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 05/01/23 22:57:20.334
May  1 22:57:20.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7846 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 22:57:20.335: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7848 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
May  1 22:57:20.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1231" for this suite. 05/01/23 22:57:20.439
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":53,"skipped":985,"failed":0}
------------------------------
• [1.772 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:18.774
    May  1 22:57:18.774: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename watch 05/01/23 22:57:18.775
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:19.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:19.296
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 05/01/23 22:57:19.502
    STEP: creating a new configmap 05/01/23 22:57:19.604
    STEP: modifying the configmap once 05/01/23 22:57:19.709
    STEP: closing the watch once it receives two notifications 05/01/23 22:57:19.918
    May  1 22:57:19.918: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7844 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 22:57:19.918: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7845 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:19 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 05/01/23 22:57:19.918
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 05/01/23 22:57:20.127
    STEP: deleting the configmap 05/01/23 22:57:20.229
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 05/01/23 22:57:20.334
    May  1 22:57:20.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7846 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 22:57:20.335: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1231  a2b15833-b531-46da-994e-4e310034b6bc 7848 0 2023-05-01 22:57:19 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-05-01 22:57:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    May  1 22:57:20.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1231" for this suite. 05/01/23 22:57:20.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:20.547
May  1 22:57:20.547: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename proxy 05/01/23 22:57:20.548
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:20.86
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:21.065
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 05/01/23 22:57:21.381
STEP: creating replication controller proxy-service-8ksx7 in namespace proxy-3254 05/01/23 22:57:21.381
I0501 22:57:21.488645    6969 runners.go:193] Created replication controller with name: proxy-service-8ksx7, namespace: proxy-3254, replica count: 1
I0501 22:57:22.639662    6969 runners.go:193] proxy-service-8ksx7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0501 22:57:23.640133    6969 runners.go:193] proxy-service-8ksx7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  1 22:57:23.744: INFO: setup took 2.47266917s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 05/01/23 22:57:23.744
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 117.547712ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 117.559443ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 117.490658ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 117.399306ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 117.226188ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 117.31574ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 117.378447ms)
May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 117.424724ms)
May  1 22:57:23.865: INFO: (0) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 120.21547ms)
May  1 22:57:23.865: INFO: (0) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 120.164034ms)
May  1 22:57:23.954: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 209.921736ms)
May  1 22:57:23.954: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 209.443613ms)
May  1 22:57:23.954: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 209.514972ms)
May  1 22:57:23.963: INFO: (0) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 218.634318ms)
May  1 22:57:23.963: INFO: (0) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 218.79591ms)
May  1 22:57:23.963: INFO: (0) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 218.526049ms)
May  1 22:57:24.074: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.537263ms)
May  1 22:57:24.074: INFO: (1) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.759874ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 111.62906ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 111.177892ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.167986ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.149803ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 111.414824ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.296557ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 111.147127ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.529731ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.348086ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 111.39995ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.822746ms)
May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.637219ms)
May  1 22:57:24.076: INFO: (1) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 112.330533ms)
May  1 22:57:24.076: INFO: (1) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.35865ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.496614ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.855143ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.521677ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.631357ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.624107ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.686529ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.779575ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.592322ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.506336ms)
May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.577765ms)
May  1 22:57:24.188: INFO: (2) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.215269ms)
May  1 22:57:24.188: INFO: (2) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.961598ms)
May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.819948ms)
May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.13276ms)
May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.257498ms)
May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.132257ms)
May  1 22:57:24.294: INFO: (3) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 105.418128ms)
May  1 22:57:24.294: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 105.182245ms)
May  1 22:57:24.294: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 105.284469ms)
May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.430639ms)
May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.470796ms)
May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.665109ms)
May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.634253ms)
May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.659529ms)
May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.58973ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.247599ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.367536ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.278254ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 112.116467ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.020083ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.129307ms)
May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.097912ms)
May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.610411ms)
May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.878325ms)
May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.676887ms)
May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.771561ms)
May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.009359ms)
May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.725332ms)
May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.945595ms)
May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.985747ms)
May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.169712ms)
May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.90532ms)
May  1 22:57:24.413: INFO: (4) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.222276ms)
May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.891765ms)
May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.034313ms)
May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.484353ms)
May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.532487ms)
May  1 22:57:24.415: INFO: (4) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 113.008296ms)
May  1 22:57:24.525: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.599079ms)
May  1 22:57:24.525: INFO: (5) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.220492ms)
May  1 22:57:24.525: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.97078ms)
May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.904648ms)
May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.545875ms)
May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.828227ms)
May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.820578ms)
May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.204095ms)
May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.847653ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 114.318864ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 113.275431ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 114.038598ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 114.134014ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 114.325957ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 114.230911ms)
May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 114.383742ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.962871ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.769942ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.568124ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.554611ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.753313ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.425434ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.386732ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 110.881311ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.019002ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.31891ms)
May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.947652ms)
May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.109654ms)
May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.81419ms)
May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.078226ms)
May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.814386ms)
May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.65191ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.604995ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.370924ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.792051ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.81119ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.825055ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.810076ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.028373ms)
May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.817935ms)
May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 111.254726ms)
May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 111.194299ms)
May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.314445ms)
May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.28067ms)
May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.29964ms)
May  1 22:57:24.756: INFO: (7) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.603548ms)
May  1 22:57:24.756: INFO: (7) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.552093ms)
May  1 22:57:24.756: INFO: (7) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.750789ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.794543ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.678689ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 108.725075ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.915237ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 108.862341ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 108.935648ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.006377ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.870222ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 108.865238ms)
May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.922241ms)
May  1 22:57:24.867: INFO: (8) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.027409ms)
May  1 22:57:24.867: INFO: (8) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 110.832641ms)
May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.095317ms)
May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.16854ms)
May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.261292ms)
May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.227507ms)
May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.393434ms)
May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.692327ms)
May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 111.390636ms)
May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.162102ms)
May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.241824ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.150455ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.564036ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 111.33492ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.082425ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.126126ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.941792ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.920719ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.890782ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.961702ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 112.264201ms)
May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 112.395721ms)
May  1 22:57:25.089: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.61453ms)
May  1 22:57:25.089: INFO: (10) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 108.555056ms)
May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.045588ms)
May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.581768ms)
May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.620241ms)
May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.735629ms)
May  1 22:57:25.091: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.955075ms)
May  1 22:57:25.091: INFO: (10) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.252321ms)
May  1 22:57:25.091: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.493152ms)
May  1 22:57:25.092: INFO: (10) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.706839ms)
May  1 22:57:25.092: INFO: (10) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.811905ms)
May  1 22:57:25.092: INFO: (10) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.805542ms)
May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.419934ms)
May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 112.33061ms)
May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.304916ms)
May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.854804ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.581294ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.515042ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.677936ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.685217ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.649307ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.611107ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.748122ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.951394ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.743711ms)
May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.736928ms)
May  1 22:57:25.205: INFO: (11) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.758892ms)
May  1 22:57:25.205: INFO: (11) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.580096ms)
May  1 22:57:25.205: INFO: (11) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.715637ms)
May  1 22:57:25.206: INFO: (11) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.111848ms)
May  1 22:57:25.206: INFO: (11) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.373633ms)
May  1 22:57:25.206: INFO: (11) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.633383ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.023779ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.206176ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 108.847994ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.788202ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.122779ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.864543ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.045201ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 108.994977ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.815181ms)
May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.026163ms)
May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 110.899904ms)
May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 110.906882ms)
May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.036096ms)
May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.327986ms)
May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 110.993478ms)
May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.104967ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.705194ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.750055ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.817859ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.97691ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.955695ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.920197ms)
May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.913884ms)
May  1 22:57:25.429: INFO: (13) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 110.995158ms)
May  1 22:57:25.429: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.432179ms)
May  1 22:57:25.430: INFO: (13) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.658132ms)
May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 112.679213ms)
May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.904946ms)
May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.806966ms)
May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.892283ms)
May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 112.715711ms)
May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.893434ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 125.63749ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 126.024333ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 125.749982ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 125.46485ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 125.805857ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 125.776207ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 125.848683ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 126.263357ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 125.882199ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 125.908571ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 125.960004ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 125.994215ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 125.791137ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 125.877016ms)
May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 126.013171ms)
May  1 22:57:25.558: INFO: (14) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 126.271117ms)
May  1 22:57:25.668: INFO: (15) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.33843ms)
May  1 22:57:25.669: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.87656ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 118.171857ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 118.157174ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 117.961126ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 118.251752ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 118.295351ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 118.38316ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 118.274084ms)
May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 118.601169ms)
May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 118.558241ms)
May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 118.557331ms)
May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 118.669652ms)
May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 118.738814ms)
May  1 22:57:25.678: INFO: (15) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 119.930807ms)
May  1 22:57:25.678: INFO: (15) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 120.304428ms)
May  1 22:57:25.787: INFO: (16) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.617024ms)
May  1 22:57:25.788: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.988748ms)
May  1 22:57:25.789: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.851912ms)
May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.27702ms)
May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 110.849196ms)
May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 111.065306ms)
May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.602982ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.982311ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 112.218625ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.427643ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.529335ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.770034ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 112.709034ms)
May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 112.746214ms)
May  1 22:57:25.792: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 112.786713ms)
May  1 22:57:25.792: INFO: (16) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 112.717833ms)
May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.930916ms)
May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.042402ms)
May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.137575ms)
May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.121845ms)
May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.301696ms)
May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.351131ms)
May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.520303ms)
May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.511262ms)
May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 111.282871ms)
May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.365056ms)
May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.41078ms)
May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.38135ms)
May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.333569ms)
May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.438905ms)
May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.484416ms)
May  1 22:57:25.905: INFO: (17) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 112.660946ms)
May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 108.924933ms)
May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.095001ms)
May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.598185ms)
May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.438002ms)
May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.937481ms)
May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.540238ms)
May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.580062ms)
May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.76937ms)
May  1 22:57:26.016: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.190693ms)
May  1 22:57:26.016: INFO: (18) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 111.132447ms)
May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.438462ms)
May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.494071ms)
May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.126593ms)
May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.435992ms)
May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.996015ms)
May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.228895ms)
May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.367417ms)
May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.649471ms)
May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 108.47215ms)
May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.824757ms)
May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.734736ms)
May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.481991ms)
May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.561861ms)
May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.595673ms)
May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.59853ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.012434ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.139496ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 111.21631ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.481584ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.551884ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.728658ms)
May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.590402ms)
STEP: deleting ReplicationController proxy-service-8ksx7 in namespace proxy-3254, will wait for the garbage collector to delete the pods 05/01/23 22:57:26.129
May  1 22:57:26.490: INFO: Deleting ReplicationController proxy-service-8ksx7 took: 105.595544ms
May  1 22:57:26.591: INFO: Terminating ReplicationController proxy-service-8ksx7 pods took: 101.20047ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
May  1 22:57:27.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3254" for this suite. 05/01/23 22:57:27.797
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":54,"skipped":990,"failed":0}
------------------------------
• [SLOW TEST] [7.355 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:20.547
    May  1 22:57:20.547: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename proxy 05/01/23 22:57:20.548
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:20.86
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:21.065
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 05/01/23 22:57:21.381
    STEP: creating replication controller proxy-service-8ksx7 in namespace proxy-3254 05/01/23 22:57:21.381
    I0501 22:57:21.488645    6969 runners.go:193] Created replication controller with name: proxy-service-8ksx7, namespace: proxy-3254, replica count: 1
    I0501 22:57:22.639662    6969 runners.go:193] proxy-service-8ksx7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0501 22:57:23.640133    6969 runners.go:193] proxy-service-8ksx7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  1 22:57:23.744: INFO: setup took 2.47266917s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 05/01/23 22:57:23.744
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 117.547712ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 117.559443ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 117.490658ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 117.399306ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 117.226188ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 117.31574ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 117.378447ms)
    May  1 22:57:23.862: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 117.424724ms)
    May  1 22:57:23.865: INFO: (0) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 120.21547ms)
    May  1 22:57:23.865: INFO: (0) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 120.164034ms)
    May  1 22:57:23.954: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 209.921736ms)
    May  1 22:57:23.954: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 209.443613ms)
    May  1 22:57:23.954: INFO: (0) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 209.514972ms)
    May  1 22:57:23.963: INFO: (0) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 218.634318ms)
    May  1 22:57:23.963: INFO: (0) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 218.79591ms)
    May  1 22:57:23.963: INFO: (0) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 218.526049ms)
    May  1 22:57:24.074: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.537263ms)
    May  1 22:57:24.074: INFO: (1) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.759874ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 111.62906ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 111.177892ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.167986ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.149803ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 111.414824ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.296557ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 111.147127ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.529731ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.348086ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 111.39995ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.822746ms)
    May  1 22:57:24.075: INFO: (1) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.637219ms)
    May  1 22:57:24.076: INFO: (1) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 112.330533ms)
    May  1 22:57:24.076: INFO: (1) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.35865ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.496614ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.855143ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.521677ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.631357ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.624107ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.686529ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.779575ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.592322ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.506336ms)
    May  1 22:57:24.186: INFO: (2) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.577765ms)
    May  1 22:57:24.188: INFO: (2) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.215269ms)
    May  1 22:57:24.188: INFO: (2) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.961598ms)
    May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.819948ms)
    May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.13276ms)
    May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.257498ms)
    May  1 22:57:24.189: INFO: (2) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.132257ms)
    May  1 22:57:24.294: INFO: (3) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 105.418128ms)
    May  1 22:57:24.294: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 105.182245ms)
    May  1 22:57:24.294: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 105.284469ms)
    May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.430639ms)
    May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.470796ms)
    May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.665109ms)
    May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.634253ms)
    May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.659529ms)
    May  1 22:57:24.299: INFO: (3) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.58973ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.247599ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.367536ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.278254ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 112.116467ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.020083ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.129307ms)
    May  1 22:57:24.301: INFO: (3) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.097912ms)
    May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.610411ms)
    May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.878325ms)
    May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.676887ms)
    May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.771561ms)
    May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.009359ms)
    May  1 22:57:24.411: INFO: (4) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.725332ms)
    May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.945595ms)
    May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.985747ms)
    May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.169712ms)
    May  1 22:57:24.412: INFO: (4) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.90532ms)
    May  1 22:57:24.413: INFO: (4) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.222276ms)
    May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.891765ms)
    May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.034313ms)
    May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.484353ms)
    May  1 22:57:24.414: INFO: (4) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.532487ms)
    May  1 22:57:24.415: INFO: (4) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 113.008296ms)
    May  1 22:57:24.525: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.599079ms)
    May  1 22:57:24.525: INFO: (5) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.220492ms)
    May  1 22:57:24.525: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.97078ms)
    May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.904648ms)
    May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.545875ms)
    May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.828227ms)
    May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.820578ms)
    May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.204095ms)
    May  1 22:57:24.526: INFO: (5) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.847653ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 114.318864ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 113.275431ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 114.038598ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 114.134014ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 114.325957ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 114.230911ms)
    May  1 22:57:24.530: INFO: (5) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 114.383742ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.962871ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.769942ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.568124ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.554611ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.753313ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.425434ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.386732ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 110.881311ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.019002ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.31891ms)
    May  1 22:57:24.641: INFO: (6) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.947652ms)
    May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.109654ms)
    May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.81419ms)
    May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.078226ms)
    May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.814386ms)
    May  1 22:57:24.643: INFO: (6) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.65191ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.604995ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.370924ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.792051ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.81119ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.825055ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.810076ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.028373ms)
    May  1 22:57:24.754: INFO: (7) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.817935ms)
    May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 111.254726ms)
    May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 111.194299ms)
    May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.314445ms)
    May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.28067ms)
    May  1 22:57:24.755: INFO: (7) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.29964ms)
    May  1 22:57:24.756: INFO: (7) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.603548ms)
    May  1 22:57:24.756: INFO: (7) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.552093ms)
    May  1 22:57:24.756: INFO: (7) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.750789ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.794543ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.678689ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 108.725075ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.915237ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 108.862341ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 108.935648ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.006377ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.870222ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 108.865238ms)
    May  1 22:57:24.865: INFO: (8) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.922241ms)
    May  1 22:57:24.867: INFO: (8) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.027409ms)
    May  1 22:57:24.867: INFO: (8) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 110.832641ms)
    May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.095317ms)
    May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.16854ms)
    May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.261292ms)
    May  1 22:57:24.868: INFO: (8) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.227507ms)
    May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.393434ms)
    May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.692327ms)
    May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 111.390636ms)
    May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.162102ms)
    May  1 22:57:24.979: INFO: (9) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.241824ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.150455ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 111.564036ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 111.33492ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.082425ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.126126ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.941792ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.920719ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.890782ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.961702ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 112.264201ms)
    May  1 22:57:24.980: INFO: (9) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 112.395721ms)
    May  1 22:57:25.089: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.61453ms)
    May  1 22:57:25.089: INFO: (10) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 108.555056ms)
    May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.045588ms)
    May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.581768ms)
    May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.620241ms)
    May  1 22:57:25.090: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.735629ms)
    May  1 22:57:25.091: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.955075ms)
    May  1 22:57:25.091: INFO: (10) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.252321ms)
    May  1 22:57:25.091: INFO: (10) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.493152ms)
    May  1 22:57:25.092: INFO: (10) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.706839ms)
    May  1 22:57:25.092: INFO: (10) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.811905ms)
    May  1 22:57:25.092: INFO: (10) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.805542ms)
    May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.419934ms)
    May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 112.33061ms)
    May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.304916ms)
    May  1 22:57:25.093: INFO: (10) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.854804ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.581294ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 110.515042ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 110.677936ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.685217ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.649307ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.611107ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.748122ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.951394ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.743711ms)
    May  1 22:57:25.204: INFO: (11) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.736928ms)
    May  1 22:57:25.205: INFO: (11) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.758892ms)
    May  1 22:57:25.205: INFO: (11) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.580096ms)
    May  1 22:57:25.205: INFO: (11) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.715637ms)
    May  1 22:57:25.206: INFO: (11) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.111848ms)
    May  1 22:57:25.206: INFO: (11) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.373633ms)
    May  1 22:57:25.206: INFO: (11) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.633383ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.023779ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.206176ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 108.847994ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.788202ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.122779ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.864543ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.045201ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 108.994977ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.815181ms)
    May  1 22:57:25.316: INFO: (12) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.026163ms)
    May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 110.899904ms)
    May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 110.906882ms)
    May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.036096ms)
    May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.327986ms)
    May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 110.993478ms)
    May  1 22:57:25.318: INFO: (12) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.104967ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.705194ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.750055ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 109.817859ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.97691ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.955695ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.920197ms)
    May  1 22:57:25.428: INFO: (13) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 109.913884ms)
    May  1 22:57:25.429: INFO: (13) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 110.995158ms)
    May  1 22:57:25.429: INFO: (13) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.432179ms)
    May  1 22:57:25.430: INFO: (13) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.658132ms)
    May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 112.679213ms)
    May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.904946ms)
    May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.806966ms)
    May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.892283ms)
    May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 112.715711ms)
    May  1 22:57:25.431: INFO: (13) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.893434ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 125.63749ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 126.024333ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 125.749982ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 125.46485ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 125.805857ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 125.776207ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 125.848683ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 126.263357ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 125.882199ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 125.908571ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 125.960004ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 125.994215ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 125.791137ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 125.877016ms)
    May  1 22:57:25.557: INFO: (14) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 126.013171ms)
    May  1 22:57:25.558: INFO: (14) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 126.271117ms)
    May  1 22:57:25.668: INFO: (15) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.33843ms)
    May  1 22:57:25.669: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.87656ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 118.171857ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 118.157174ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 117.961126ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 118.251752ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 118.295351ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 118.38316ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 118.274084ms)
    May  1 22:57:25.676: INFO: (15) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 118.601169ms)
    May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 118.558241ms)
    May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 118.557331ms)
    May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 118.669652ms)
    May  1 22:57:25.677: INFO: (15) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 118.738814ms)
    May  1 22:57:25.678: INFO: (15) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 119.930807ms)
    May  1 22:57:25.678: INFO: (15) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 120.304428ms)
    May  1 22:57:25.787: INFO: (16) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.617024ms)
    May  1 22:57:25.788: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.988748ms)
    May  1 22:57:25.789: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.851912ms)
    May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.27702ms)
    May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 110.849196ms)
    May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 111.065306ms)
    May  1 22:57:25.790: INFO: (16) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.602982ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.982311ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 112.218625ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.427643ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.529335ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 112.770034ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 112.709034ms)
    May  1 22:57:25.791: INFO: (16) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 112.746214ms)
    May  1 22:57:25.792: INFO: (16) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 112.786713ms)
    May  1 22:57:25.792: INFO: (16) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 112.717833ms)
    May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.930916ms)
    May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.042402ms)
    May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.137575ms)
    May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 110.121845ms)
    May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.301696ms)
    May  1 22:57:25.902: INFO: (17) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.351131ms)
    May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 110.520303ms)
    May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.511262ms)
    May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 111.282871ms)
    May  1 22:57:25.903: INFO: (17) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.365056ms)
    May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.41078ms)
    May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.38135ms)
    May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 112.333569ms)
    May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 112.438905ms)
    May  1 22:57:25.904: INFO: (17) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.484416ms)
    May  1 22:57:25.905: INFO: (17) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 112.660946ms)
    May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 108.924933ms)
    May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 109.095001ms)
    May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 109.598185ms)
    May  1 22:57:26.014: INFO: (18) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 109.438002ms)
    May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.937481ms)
    May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 109.540238ms)
    May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 109.580062ms)
    May  1 22:57:26.015: INFO: (18) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 109.76937ms)
    May  1 22:57:26.016: INFO: (18) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 111.190693ms)
    May  1 22:57:26.016: INFO: (18) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 111.132447ms)
    May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.438462ms)
    May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.494071ms)
    May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 112.126593ms)
    May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 112.435992ms)
    May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.996015ms)
    May  1 22:57:26.017: INFO: (18) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 112.228895ms)
    May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 108.367417ms)
    May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.649471ms)
    May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">... (200; 108.47215ms)
    May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:462/proxy/: tls qux (200; 108.824757ms)
    May  1 22:57:26.126: INFO: (19) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:162/proxy/: bar (200; 108.734736ms)
    May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/http:proxy-service-8ksx7-9t6hj:160/proxy/: foo (200; 110.481991ms)
    May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj:1080/proxy/rewriteme">test<... (200; 110.561861ms)
    May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/proxy-service-8ksx7-9t6hj/proxy/rewriteme">test</a> (200; 110.595673ms)
    May  1 22:57:26.128: INFO: (19) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/: <a href="/api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:443/proxy/tlsrewritem... (200; 110.59853ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname1/proxy/: foo (200; 111.012434ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/http:proxy-service-8ksx7:portname2/proxy/: bar (200; 111.139496ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/pods/https:proxy-service-8ksx7-9t6hj:460/proxy/: tls baz (200; 111.21631ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname1/proxy/: foo (200; 111.481584ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname2/proxy/: tls qux (200; 111.551884ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/https:proxy-service-8ksx7:tlsportname1/proxy/: tls baz (200; 111.728658ms)
    May  1 22:57:26.129: INFO: (19) /api/v1/namespaces/proxy-3254/services/proxy-service-8ksx7:portname2/proxy/: bar (200; 111.590402ms)
    STEP: deleting ReplicationController proxy-service-8ksx7 in namespace proxy-3254, will wait for the garbage collector to delete the pods 05/01/23 22:57:26.129
    May  1 22:57:26.490: INFO: Deleting ReplicationController proxy-service-8ksx7 took: 105.595544ms
    May  1 22:57:26.591: INFO: Terminating ReplicationController proxy-service-8ksx7 pods took: 101.20047ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    May  1 22:57:27.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3254" for this suite. 05/01/23 22:57:27.797
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:27.903
May  1 22:57:27.903: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 22:57:27.904
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:28.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:28.423
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-badb9023-c632-4032-ba81-e366160ad4b3 05/01/23 22:57:28.628
STEP: Creating a pod to test consume configMaps 05/01/23 22:57:28.733
May  1 22:57:28.841: INFO: Waiting up to 5m0s for pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237" in namespace "configmap-8068" to be "Succeeded or Failed"
May  1 22:57:28.945: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237": Phase="Pending", Reason="", readiness=false. Elapsed: 103.770358ms
May  1 22:57:31.050: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237": Phase="Running", Reason="", readiness=false. Elapsed: 2.208542685s
May  1 22:57:33.053: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211649515s
STEP: Saw pod success 05/01/23 22:57:33.053
May  1 22:57:33.053: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237" satisfied condition "Succeeded or Failed"
May  1 22:57:33.157: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-configmaps-da83d793-99d0-4408-9667-b86dce051237 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 22:57:33.268
May  1 22:57:33.379: INFO: Waiting for pod pod-configmaps-da83d793-99d0-4408-9667-b86dce051237 to disappear
May  1 22:57:33.483: INFO: Pod pod-configmaps-da83d793-99d0-4408-9667-b86dce051237 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 22:57:33.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8068" for this suite. 05/01/23 22:57:33.588
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":55,"skipped":990,"failed":0}
------------------------------
• [SLOW TEST] [5.791 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:27.903
    May  1 22:57:27.903: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 22:57:27.904
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:28.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:28.423
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-badb9023-c632-4032-ba81-e366160ad4b3 05/01/23 22:57:28.628
    STEP: Creating a pod to test consume configMaps 05/01/23 22:57:28.733
    May  1 22:57:28.841: INFO: Waiting up to 5m0s for pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237" in namespace "configmap-8068" to be "Succeeded or Failed"
    May  1 22:57:28.945: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237": Phase="Pending", Reason="", readiness=false. Elapsed: 103.770358ms
    May  1 22:57:31.050: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237": Phase="Running", Reason="", readiness=false. Elapsed: 2.208542685s
    May  1 22:57:33.053: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211649515s
    STEP: Saw pod success 05/01/23 22:57:33.053
    May  1 22:57:33.053: INFO: Pod "pod-configmaps-da83d793-99d0-4408-9667-b86dce051237" satisfied condition "Succeeded or Failed"
    May  1 22:57:33.157: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-configmaps-da83d793-99d0-4408-9667-b86dce051237 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 22:57:33.268
    May  1 22:57:33.379: INFO: Waiting for pod pod-configmaps-da83d793-99d0-4408-9667-b86dce051237 to disappear
    May  1 22:57:33.483: INFO: Pod pod-configmaps-da83d793-99d0-4408-9667-b86dce051237 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 22:57:33.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8068" for this suite. 05/01/23 22:57:33.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:33.695
May  1 22:57:33.695: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts 05/01/23 22:57:33.696
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:34.009
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:34.215
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  05/01/23 22:57:34.421
May  1 22:57:34.528: INFO: Waiting up to 5m0s for pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d" in namespace "svcaccounts-2506" to be "Succeeded or Failed"
May  1 22:57:34.633: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d": Phase="Pending", Reason="", readiness=false. Elapsed: 104.045338ms
May  1 22:57:36.737: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208470351s
May  1 22:57:38.741: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212976925s
STEP: Saw pod success 05/01/23 22:57:38.741
May  1 22:57:38.742: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d" satisfied condition "Succeeded or Failed"
May  1 22:57:38.845: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod test-pod-26a32f27-612e-47ad-ae73-4003876b565d container agnhost-container: <nil>
STEP: delete the pod 05/01/23 22:57:38.954
May  1 22:57:39.069: INFO: Waiting for pod test-pod-26a32f27-612e-47ad-ae73-4003876b565d to disappear
May  1 22:57:39.172: INFO: Pod test-pod-26a32f27-612e-47ad-ae73-4003876b565d no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
May  1 22:57:39.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2506" for this suite. 05/01/23 22:57:39.277
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":56,"skipped":996,"failed":0}
------------------------------
• [SLOW TEST] [5.688 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:33.695
    May  1 22:57:33.695: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svcaccounts 05/01/23 22:57:33.696
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:34.009
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:34.215
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  05/01/23 22:57:34.421
    May  1 22:57:34.528: INFO: Waiting up to 5m0s for pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d" in namespace "svcaccounts-2506" to be "Succeeded or Failed"
    May  1 22:57:34.633: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d": Phase="Pending", Reason="", readiness=false. Elapsed: 104.045338ms
    May  1 22:57:36.737: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208470351s
    May  1 22:57:38.741: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212976925s
    STEP: Saw pod success 05/01/23 22:57:38.741
    May  1 22:57:38.742: INFO: Pod "test-pod-26a32f27-612e-47ad-ae73-4003876b565d" satisfied condition "Succeeded or Failed"
    May  1 22:57:38.845: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod test-pod-26a32f27-612e-47ad-ae73-4003876b565d container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 22:57:38.954
    May  1 22:57:39.069: INFO: Waiting for pod test-pod-26a32f27-612e-47ad-ae73-4003876b565d to disappear
    May  1 22:57:39.172: INFO: Pod test-pod-26a32f27-612e-47ad-ae73-4003876b565d no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    May  1 22:57:39.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2506" for this suite. 05/01/23 22:57:39.277
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:57:39.384
May  1 22:57:39.385: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 22:57:39.386
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:39.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:39.903
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-32db43a1-24cf-45e3-8a98-37f16dddaea9 05/01/23 22:57:40.214
STEP: Creating configMap with name cm-test-opt-upd-8d15b0ab-bb0f-432a-b28b-93b7f8c077f2 05/01/23 22:57:40.318
STEP: Creating the pod 05/01/23 22:57:40.423
May  1 22:57:40.532: INFO: Waiting up to 5m0s for pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32" in namespace "configmap-5710" to be "running and ready"
May  1 22:57:40.635: INFO: Pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32": Phase="Pending", Reason="", readiness=false. Elapsed: 103.813014ms
May  1 22:57:40.636: INFO: The phase of Pod pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:57:42.741: INFO: Pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32": Phase="Running", Reason="", readiness=true. Elapsed: 2.209295883s
May  1 22:57:42.741: INFO: The phase of Pod pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32 is Running (Ready = true)
May  1 22:57:42.741: INFO: Pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-32db43a1-24cf-45e3-8a98-37f16dddaea9 05/01/23 22:57:43.168
STEP: Updating configmap cm-test-opt-upd-8d15b0ab-bb0f-432a-b28b-93b7f8c077f2 05/01/23 22:57:43.273
STEP: Creating configMap with name cm-test-opt-create-9ebfc90d-1420-4595-9726-f28034d2bd6b 05/01/23 22:57:43.378
STEP: waiting to observe update in volume 05/01/23 22:57:43.484
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 22:58:55.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5710" for this suite. 05/01/23 22:58:55.559
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":57,"skipped":1037,"failed":0}
------------------------------
• [SLOW TEST] [76.280 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:57:39.384
    May  1 22:57:39.385: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 22:57:39.386
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:57:39.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:57:39.903
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-32db43a1-24cf-45e3-8a98-37f16dddaea9 05/01/23 22:57:40.214
    STEP: Creating configMap with name cm-test-opt-upd-8d15b0ab-bb0f-432a-b28b-93b7f8c077f2 05/01/23 22:57:40.318
    STEP: Creating the pod 05/01/23 22:57:40.423
    May  1 22:57:40.532: INFO: Waiting up to 5m0s for pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32" in namespace "configmap-5710" to be "running and ready"
    May  1 22:57:40.635: INFO: Pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32": Phase="Pending", Reason="", readiness=false. Elapsed: 103.813014ms
    May  1 22:57:40.636: INFO: The phase of Pod pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:57:42.741: INFO: Pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32": Phase="Running", Reason="", readiness=true. Elapsed: 2.209295883s
    May  1 22:57:42.741: INFO: The phase of Pod pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32 is Running (Ready = true)
    May  1 22:57:42.741: INFO: Pod "pod-configmaps-e7058fc6-09ad-4435-9379-344766072e32" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-32db43a1-24cf-45e3-8a98-37f16dddaea9 05/01/23 22:57:43.168
    STEP: Updating configmap cm-test-opt-upd-8d15b0ab-bb0f-432a-b28b-93b7f8c077f2 05/01/23 22:57:43.273
    STEP: Creating configMap with name cm-test-opt-create-9ebfc90d-1420-4595-9726-f28034d2bd6b 05/01/23 22:57:43.378
    STEP: waiting to observe update in volume 05/01/23 22:57:43.484
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 22:58:55.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5710" for this suite. 05/01/23 22:58:55.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:58:55.665
May  1 22:58:55.665: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename server-version 05/01/23 22:58:55.666
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:58:55.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:58:56.183
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 05/01/23 22:58:56.389
STEP: Confirm major version 05/01/23 22:58:56.491
May  1 22:58:56.491: INFO: Major version: 1
STEP: Confirm minor version 05/01/23 22:58:56.491
May  1 22:58:56.491: INFO: cleanMinorVersion: 25
May  1 22:58:56.491: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
May  1 22:58:56.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-470" for this suite. 05/01/23 22:58:56.596
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":58,"skipped":1050,"failed":0}
------------------------------
• [1.038 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:58:55.665
    May  1 22:58:55.665: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename server-version 05/01/23 22:58:55.666
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:58:55.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:58:56.183
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 05/01/23 22:58:56.389
    STEP: Confirm major version 05/01/23 22:58:56.491
    May  1 22:58:56.491: INFO: Major version: 1
    STEP: Confirm minor version 05/01/23 22:58:56.491
    May  1 22:58:56.491: INFO: cleanMinorVersion: 25
    May  1 22:58:56.491: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    May  1 22:58:56.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-470" for this suite. 05/01/23 22:58:56.596
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:58:56.703
May  1 22:58:56.703: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/01/23 22:58:56.704
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:58:57.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:58:57.22
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 05/01/23 22:58:58.152
STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 22:58:58.259
May  1 22:58:58.363: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 22:58:58.467: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 22:58:58.467: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  1 22:58:59.571: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 22:58:59.675: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May  1 22:58:59.675: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 22:59:00.576: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 22:59:00.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 22:59:00.680: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
May  1 22:59:01.572: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 22:59:01.676: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 22:59:01.676: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
May  1 22:59:02.571: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 22:59:02.675: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  1 22:59:02.675: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Getting /status 05/01/23 22:59:02.779
May  1 22:59:02.883: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 05/01/23 22:59:02.883
May  1 22:59:03.093: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 05/01/23 22:59:03.093
May  1 22:59:03.196: INFO: Observed &DaemonSet event: ADDED
May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.198: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.198: INFO: Found daemon set daemon-set in namespace daemonsets-3924 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May  1 22:59:03.198: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 05/01/23 22:59:03.198
STEP: watching for the daemon set status to be patched 05/01/23 22:59:03.304
May  1 22:59:03.408: INFO: Observed &DaemonSet event: ADDED
May  1 22:59:03.408: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.408: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.409: INFO: Observed daemon set daemon-set in namespace daemonsets-3924 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May  1 22:59:03.410: INFO: Observed &DaemonSet event: MODIFIED
May  1 22:59:03.410: INFO: Found daemon set daemon-set in namespace daemonsets-3924 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
May  1 22:59:03.410: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 05/01/23 22:59:03.514
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3924, will wait for the garbage collector to delete the pods 05/01/23 22:59:03.514
May  1 22:59:03.874: INFO: Deleting DaemonSet.extensions daemon-set took: 105.305559ms
May  1 22:59:03.974: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.142359ms
May  1 22:59:05.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 22:59:05.478: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May  1 22:59:05.593: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8393"},"items":null}

May  1 22:59:05.697: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8393"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  1 22:59:06.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3924" for this suite. 05/01/23 22:59:06.32
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":59,"skipped":1062,"failed":0}
------------------------------
• [SLOW TEST] [9.722 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:58:56.703
    May  1 22:58:56.703: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/01/23 22:58:56.704
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:58:57.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:58:57.22
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 05/01/23 22:58:58.152
    STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 22:58:58.259
    May  1 22:58:58.363: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 22:58:58.467: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 22:58:58.467: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  1 22:58:59.571: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 22:58:59.675: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    May  1 22:58:59.675: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 22:59:00.576: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 22:59:00.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 22:59:00.680: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
    May  1 22:59:01.572: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 22:59:01.676: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 22:59:01.676: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
    May  1 22:59:02.571: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 22:59:02.675: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  1 22:59:02.675: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Getting /status 05/01/23 22:59:02.779
    May  1 22:59:02.883: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 05/01/23 22:59:02.883
    May  1 22:59:03.093: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 05/01/23 22:59:03.093
    May  1 22:59:03.196: INFO: Observed &DaemonSet event: ADDED
    May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.197: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.198: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.198: INFO: Found daemon set daemon-set in namespace daemonsets-3924 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    May  1 22:59:03.198: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 05/01/23 22:59:03.198
    STEP: watching for the daemon set status to be patched 05/01/23 22:59:03.304
    May  1 22:59:03.408: INFO: Observed &DaemonSet event: ADDED
    May  1 22:59:03.408: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.408: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.409: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.409: INFO: Observed daemon set daemon-set in namespace daemonsets-3924 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    May  1 22:59:03.410: INFO: Observed &DaemonSet event: MODIFIED
    May  1 22:59:03.410: INFO: Found daemon set daemon-set in namespace daemonsets-3924 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    May  1 22:59:03.410: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 05/01/23 22:59:03.514
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3924, will wait for the garbage collector to delete the pods 05/01/23 22:59:03.514
    May  1 22:59:03.874: INFO: Deleting DaemonSet.extensions daemon-set took: 105.305559ms
    May  1 22:59:03.974: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.142359ms
    May  1 22:59:05.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 22:59:05.478: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    May  1 22:59:05.593: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8393"},"items":null}

    May  1 22:59:05.697: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8393"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  1 22:59:06.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3924" for this suite. 05/01/23 22:59:06.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:59:06.426
May  1 22:59:06.426: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sysctl 05/01/23 22:59:06.428
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:06.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:06.947
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 05/01/23 22:59:07.152
STEP: Watching for error events or started pod 05/01/23 22:59:07.259
STEP: Waiting for pod completion 05/01/23 22:59:09.363
May  1 22:59:09.363: INFO: Waiting up to 3m0s for pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332" in namespace "sysctl-4937" to be "completed"
May  1 22:59:09.467: INFO: Pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332": Phase="Pending", Reason="", readiness=false. Elapsed: 103.684288ms
May  1 22:59:11.573: INFO: Pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.210083567s
May  1 22:59:11.573: INFO: Pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332" satisfied condition "completed"
STEP: Checking that the pod succeeded 05/01/23 22:59:11.677
STEP: Getting logs from the pod 05/01/23 22:59:11.677
STEP: Checking that the sysctl is actually updated 05/01/23 22:59:11.783
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
May  1 22:59:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4937" for this suite. 05/01/23 22:59:11.888
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":60,"skipped":1067,"failed":0}
------------------------------
• [SLOW TEST] [5.668 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:59:06.426
    May  1 22:59:06.426: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sysctl 05/01/23 22:59:06.428
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:06.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:06.947
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 05/01/23 22:59:07.152
    STEP: Watching for error events or started pod 05/01/23 22:59:07.259
    STEP: Waiting for pod completion 05/01/23 22:59:09.363
    May  1 22:59:09.363: INFO: Waiting up to 3m0s for pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332" in namespace "sysctl-4937" to be "completed"
    May  1 22:59:09.467: INFO: Pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332": Phase="Pending", Reason="", readiness=false. Elapsed: 103.684288ms
    May  1 22:59:11.573: INFO: Pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.210083567s
    May  1 22:59:11.573: INFO: Pod "sysctl-78613f6c-6add-48ce-a76a-13d38351d332" satisfied condition "completed"
    STEP: Checking that the pod succeeded 05/01/23 22:59:11.677
    STEP: Getting logs from the pod 05/01/23 22:59:11.677
    STEP: Checking that the sysctl is actually updated 05/01/23 22:59:11.783
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    May  1 22:59:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-4937" for this suite. 05/01/23 22:59:11.888
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:59:12.095
May  1 22:59:12.095: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 22:59:12.097
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:12.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:12.613
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 22:59:13.03
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 22:59:13.463
STEP: Deploying the webhook pod 05/01/23 22:59:13.571
STEP: Wait for the deployment to be ready 05/01/23 22:59:13.782
May  1 22:59:14.092: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 22:59:16.197
STEP: Verifying the service has paired with the endpoint 05/01/23 22:59:16.304
May  1 22:59:17.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 05/01/23 22:59:17.408
STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:17.408
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 05/01/23 22:59:17.622
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 05/01/23 22:59:18.832
STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:18.833
STEP: Having no error when timeout is longer than webhook latency 05/01/23 22:59:20.359
STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:20.359
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 05/01/23 22:59:25.891
STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:25.891
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 22:59:31.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7060" for this suite. 05/01/23 22:59:31.528
STEP: Destroying namespace "webhook-7060-markers" for this suite. 05/01/23 22:59:31.633
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":61,"skipped":1093,"failed":0}
------------------------------
• [SLOW TEST] [20.078 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:59:12.095
    May  1 22:59:12.095: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 22:59:12.097
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:12.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:12.613
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 22:59:13.03
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 22:59:13.463
    STEP: Deploying the webhook pod 05/01/23 22:59:13.571
    STEP: Wait for the deployment to be ready 05/01/23 22:59:13.782
    May  1 22:59:14.092: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 22, 59, 13, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 22:59:16.197
    STEP: Verifying the service has paired with the endpoint 05/01/23 22:59:16.304
    May  1 22:59:17.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 05/01/23 22:59:17.408
    STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:17.408
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 05/01/23 22:59:17.622
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 05/01/23 22:59:18.832
    STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:18.833
    STEP: Having no error when timeout is longer than webhook latency 05/01/23 22:59:20.359
    STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:20.359
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 05/01/23 22:59:25.891
    STEP: Registering slow webhook via the AdmissionRegistration API 05/01/23 22:59:25.891
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 22:59:31.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7060" for this suite. 05/01/23 22:59:31.528
    STEP: Destroying namespace "webhook-7060-markers" for this suite. 05/01/23 22:59:31.633
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:59:32.174
May  1 22:59:32.174: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 22:59:32.175
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:32.489
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:32.694
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-b2d316f3-f9a9-42ed-a64c-0ac4d9f35279 05/01/23 22:59:32.899
STEP: Creating a pod to test consume configMaps 05/01/23 22:59:33.003
May  1 22:59:33.112: INFO: Waiting up to 5m0s for pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b" in namespace "configmap-7147" to be "Succeeded or Failed"
May  1 22:59:33.215: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 103.594679ms
May  1 22:59:35.319: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207531855s
May  1 22:59:37.319: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207641748s
STEP: Saw pod success 05/01/23 22:59:37.319
May  1 22:59:37.320: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b" satisfied condition "Succeeded or Failed"
May  1 22:59:37.423: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b container agnhost-container: <nil>
STEP: delete the pod 05/01/23 22:59:37.529
May  1 22:59:37.638: INFO: Waiting for pod pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b to disappear
May  1 22:59:37.741: INFO: Pod pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 22:59:37.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7147" for this suite. 05/01/23 22:59:37.846
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":62,"skipped":1094,"failed":0}
------------------------------
• [SLOW TEST] [5.777 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:59:32.174
    May  1 22:59:32.174: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 22:59:32.175
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:32.489
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:32.694
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-b2d316f3-f9a9-42ed-a64c-0ac4d9f35279 05/01/23 22:59:32.899
    STEP: Creating a pod to test consume configMaps 05/01/23 22:59:33.003
    May  1 22:59:33.112: INFO: Waiting up to 5m0s for pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b" in namespace "configmap-7147" to be "Succeeded or Failed"
    May  1 22:59:33.215: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 103.594679ms
    May  1 22:59:35.319: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207531855s
    May  1 22:59:37.319: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207641748s
    STEP: Saw pod success 05/01/23 22:59:37.319
    May  1 22:59:37.320: INFO: Pod "pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b" satisfied condition "Succeeded or Failed"
    May  1 22:59:37.423: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 22:59:37.529
    May  1 22:59:37.638: INFO: Waiting for pod pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b to disappear
    May  1 22:59:37.741: INFO: Pod pod-configmaps-0bed597e-0e79-4c8c-9fde-3079b5544e2b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 22:59:37.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7147" for this suite. 05/01/23 22:59:37.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 22:59:37.954
May  1 22:59:37.954: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pod-network-test 05/01/23 22:59:37.956
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:38.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:38.472
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-925 05/01/23 22:59:38.677
STEP: creating a selector 05/01/23 22:59:38.678
STEP: Creating the service pods in kubernetes 05/01/23 22:59:38.678
May  1 22:59:38.678: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  1 22:59:39.313: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-925" to be "running and ready"
May  1 22:59:39.416: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 103.414285ms
May  1 22:59:39.416: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  1 22:59:41.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.208024659s
May  1 22:59:41.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:59:43.520: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.207563891s
May  1 22:59:43.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:59:45.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.208026197s
May  1 22:59:45.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:59:47.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.207884133s
May  1 22:59:47.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  1 22:59:49.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 10.20804264s
May  1 22:59:49.521: INFO: The phase of Pod netserver-0 is Running (Ready = true)
May  1 22:59:49.521: INFO: Pod "netserver-0" satisfied condition "running and ready"
May  1 22:59:49.625: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-925" to be "running and ready"
May  1 22:59:49.728: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 103.189685ms
May  1 22:59:49.728: INFO: The phase of Pod netserver-1 is Running (Ready = true)
May  1 22:59:49.728: INFO: Pod "netserver-1" satisfied condition "running and ready"
May  1 22:59:49.831: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-925" to be "running and ready"
May  1 22:59:49.935: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 103.499991ms
May  1 22:59:49.935: INFO: The phase of Pod netserver-2 is Running (Ready = true)
May  1 22:59:49.935: INFO: Pod "netserver-2" satisfied condition "running and ready"
May  1 22:59:50.039: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-925" to be "running and ready"
May  1 22:59:50.142: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 103.597352ms
May  1 22:59:50.142: INFO: The phase of Pod netserver-3 is Running (Ready = false)
May  1 22:59:52.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 2.207152825s
May  1 22:59:52.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
May  1 22:59:54.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 4.20729736s
May  1 22:59:54.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
May  1 22:59:56.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 6.207323146s
May  1 22:59:56.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
May  1 22:59:58.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 8.207457603s
May  1 22:59:58.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
May  1 23:00:00.247: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 10.208142228s
May  1 23:00:00.247: INFO: The phase of Pod netserver-3 is Running (Ready = true)
May  1 23:00:00.247: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 05/01/23 23:00:00.35
May  1 23:00:00.564: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-925" to be "running"
May  1 23:00:00.667: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.744469ms
May  1 23:00:02.773: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209303168s
May  1 23:00:02.773: INFO: Pod "test-container-pod" satisfied condition "running"
May  1 23:00:02.877: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-925" to be "running"
May  1 23:00:02.980: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 103.440381ms
May  1 23:00:02.980: INFO: Pod "host-test-container-pod" satisfied condition "running"
May  1 23:00:03.084: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
May  1 23:00:03.084: INFO: Going to poll 100.123.145.210 on port 8081 at least 0 times, with a maximum of 46 tries before failing
May  1 23:00:03.188: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.123.145.210 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:00:03.188: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:00:03.189: INFO: ExecWithOptions: Clientset creation
May  1 23:00:03.189: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.123.145.210+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  1 23:00:04.893: INFO: Found all 1 expected endpoints: [netserver-0]
May  1 23:00:04.893: INFO: Going to poll 100.96.36.36 on port 8081 at least 0 times, with a maximum of 46 tries before failing
May  1 23:00:04.997: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.36.36 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:00:04.997: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:00:04.997: INFO: ExecWithOptions: Clientset creation
May  1 23:00:04.998: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.36.36+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  1 23:00:06.721: INFO: Found all 1 expected endpoints: [netserver-1]
May  1 23:00:06.721: INFO: Going to poll 100.105.72.170 on port 8081 at least 0 times, with a maximum of 46 tries before failing
May  1 23:00:06.824: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.105.72.170 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:00:06.824: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:00:06.825: INFO: ExecWithOptions: Clientset creation
May  1 23:00:06.825: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.105.72.170+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  1 23:00:08.541: INFO: Found all 1 expected endpoints: [netserver-2]
May  1 23:00:08.541: INFO: Going to poll 100.101.231.143 on port 8081 at least 0 times, with a maximum of 46 tries before failing
May  1 23:00:08.646: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.101.231.143 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:00:08.646: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:00:08.647: INFO: ExecWithOptions: Clientset creation
May  1 23:00:08.647: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.101.231.143+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  1 23:00:10.354: INFO: Found all 1 expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
May  1 23:00:10.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-925" for this suite. 05/01/23 23:00:10.458
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":63,"skipped":1137,"failed":0}
------------------------------
• [SLOW TEST] [32.609 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 22:59:37.954
    May  1 22:59:37.954: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pod-network-test 05/01/23 22:59:37.956
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 22:59:38.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 22:59:38.472
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-925 05/01/23 22:59:38.677
    STEP: creating a selector 05/01/23 22:59:38.678
    STEP: Creating the service pods in kubernetes 05/01/23 22:59:38.678
    May  1 22:59:38.678: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    May  1 22:59:39.313: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-925" to be "running and ready"
    May  1 22:59:39.416: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 103.414285ms
    May  1 22:59:39.416: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    May  1 22:59:41.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.208024659s
    May  1 22:59:41.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:59:43.520: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.207563891s
    May  1 22:59:43.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:59:45.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.208026197s
    May  1 22:59:45.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:59:47.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.207884133s
    May  1 22:59:47.521: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  1 22:59:49.521: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 10.20804264s
    May  1 22:59:49.521: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    May  1 22:59:49.521: INFO: Pod "netserver-0" satisfied condition "running and ready"
    May  1 22:59:49.625: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-925" to be "running and ready"
    May  1 22:59:49.728: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 103.189685ms
    May  1 22:59:49.728: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    May  1 22:59:49.728: INFO: Pod "netserver-1" satisfied condition "running and ready"
    May  1 22:59:49.831: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-925" to be "running and ready"
    May  1 22:59:49.935: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 103.499991ms
    May  1 22:59:49.935: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    May  1 22:59:49.935: INFO: Pod "netserver-2" satisfied condition "running and ready"
    May  1 22:59:50.039: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-925" to be "running and ready"
    May  1 22:59:50.142: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 103.597352ms
    May  1 22:59:50.142: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    May  1 22:59:52.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 2.207152825s
    May  1 22:59:52.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    May  1 22:59:54.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 4.20729736s
    May  1 22:59:54.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    May  1 22:59:56.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 6.207323146s
    May  1 22:59:56.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    May  1 22:59:58.246: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=false. Elapsed: 8.207457603s
    May  1 22:59:58.246: INFO: The phase of Pod netserver-3 is Running (Ready = false)
    May  1 23:00:00.247: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 10.208142228s
    May  1 23:00:00.247: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    May  1 23:00:00.247: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 05/01/23 23:00:00.35
    May  1 23:00:00.564: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-925" to be "running"
    May  1 23:00:00.667: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.744469ms
    May  1 23:00:02.773: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209303168s
    May  1 23:00:02.773: INFO: Pod "test-container-pod" satisfied condition "running"
    May  1 23:00:02.877: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-925" to be "running"
    May  1 23:00:02.980: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 103.440381ms
    May  1 23:00:02.980: INFO: Pod "host-test-container-pod" satisfied condition "running"
    May  1 23:00:03.084: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    May  1 23:00:03.084: INFO: Going to poll 100.123.145.210 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    May  1 23:00:03.188: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.123.145.210 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:00:03.188: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:00:03.189: INFO: ExecWithOptions: Clientset creation
    May  1 23:00:03.189: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.123.145.210+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  1 23:00:04.893: INFO: Found all 1 expected endpoints: [netserver-0]
    May  1 23:00:04.893: INFO: Going to poll 100.96.36.36 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    May  1 23:00:04.997: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.36.36 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:00:04.997: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:00:04.997: INFO: ExecWithOptions: Clientset creation
    May  1 23:00:04.998: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.36.36+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  1 23:00:06.721: INFO: Found all 1 expected endpoints: [netserver-1]
    May  1 23:00:06.721: INFO: Going to poll 100.105.72.170 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    May  1 23:00:06.824: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.105.72.170 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:00:06.824: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:00:06.825: INFO: ExecWithOptions: Clientset creation
    May  1 23:00:06.825: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.105.72.170+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  1 23:00:08.541: INFO: Found all 1 expected endpoints: [netserver-2]
    May  1 23:00:08.541: INFO: Going to poll 100.101.231.143 on port 8081 at least 0 times, with a maximum of 46 tries before failing
    May  1 23:00:08.646: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.101.231.143 8081 | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:00:08.646: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:00:08.647: INFO: ExecWithOptions: Clientset creation
    May  1 23:00:08.647: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-925/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.101.231.143+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  1 23:00:10.354: INFO: Found all 1 expected endpoints: [netserver-3]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    May  1 23:00:10.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-925" for this suite. 05/01/23 23:00:10.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:10.565
May  1 23:00:10.565: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:00:10.566
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:10.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:11.081
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:00:11.499
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:00:12.01
STEP: Deploying the webhook pod 05/01/23 23:00:12.117
STEP: Wait for the deployment to be ready 05/01/23 23:00:12.33
May  1 23:00:12.640: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:00:14.745
STEP: Verifying the service has paired with the endpoint 05/01/23 23:00:14.857
May  1 23:00:15.857: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 05/01/23 23:00:15.962
STEP: create a pod 05/01/23 23:00:16.192
May  1 23:00:16.297: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4141" to be "running"
May  1 23:00:16.401: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.431422ms
May  1 23:00:18.506: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208494071s
May  1 23:00:18.506: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 05/01/23 23:00:18.506
May  1 23:00:18.506: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=webhook-4141 attach --namespace=webhook-4141 to-be-attached-pod -i -c=container1'
May  1 23:00:19.303: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:00:19.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4141" for this suite. 05/01/23 23:00:19.513
STEP: Destroying namespace "webhook-4141-markers" for this suite. 05/01/23 23:00:19.618
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":64,"skipped":1152,"failed":0}
------------------------------
• [SLOW TEST] [9.595 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:10.565
    May  1 23:00:10.565: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:00:10.566
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:10.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:11.081
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:00:11.499
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:00:12.01
    STEP: Deploying the webhook pod 05/01/23 23:00:12.117
    STEP: Wait for the deployment to be ready 05/01/23 23:00:12.33
    May  1 23:00:12.640: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 0, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:00:14.745
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:00:14.857
    May  1 23:00:15.857: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 05/01/23 23:00:15.962
    STEP: create a pod 05/01/23 23:00:16.192
    May  1 23:00:16.297: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4141" to be "running"
    May  1 23:00:16.401: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.431422ms
    May  1 23:00:18.506: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208494071s
    May  1 23:00:18.506: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 05/01/23 23:00:18.506
    May  1 23:00:18.506: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=webhook-4141 attach --namespace=webhook-4141 to-be-attached-pod -i -c=container1'
    May  1 23:00:19.303: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:00:19.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4141" for this suite. 05/01/23 23:00:19.513
    STEP: Destroying namespace "webhook-4141-markers" for this suite. 05/01/23 23:00:19.618
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:20.16
May  1 23:00:20.160: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/01/23 23:00:20.162
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:20.475
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:20.681
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 05/01/23 23:00:20.885
May  1 23:00:20.993: INFO: Waiting up to 5m0s for pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9" in namespace "var-expansion-2763" to be "Succeeded or Failed"
May  1 23:00:21.097: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9": Phase="Pending", Reason="", readiness=false. Elapsed: 103.409619ms
May  1 23:00:23.200: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207327238s
May  1 23:00:25.201: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207585218s
STEP: Saw pod success 05/01/23 23:00:25.201
May  1 23:00:25.201: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9" satisfied condition "Succeeded or Failed"
May  1 23:00:25.304: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9 container dapi-container: <nil>
STEP: delete the pod 05/01/23 23:00:25.423
May  1 23:00:25.534: INFO: Waiting for pod var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9 to disappear
May  1 23:00:25.639: INFO: Pod var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  1 23:00:25.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2763" for this suite. 05/01/23 23:00:25.743
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":65,"skipped":1157,"failed":0}
------------------------------
• [SLOW TEST] [5.789 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:20.16
    May  1 23:00:20.160: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/01/23 23:00:20.162
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:20.475
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:20.681
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 05/01/23 23:00:20.885
    May  1 23:00:20.993: INFO: Waiting up to 5m0s for pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9" in namespace "var-expansion-2763" to be "Succeeded or Failed"
    May  1 23:00:21.097: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9": Phase="Pending", Reason="", readiness=false. Elapsed: 103.409619ms
    May  1 23:00:23.200: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207327238s
    May  1 23:00:25.201: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207585218s
    STEP: Saw pod success 05/01/23 23:00:25.201
    May  1 23:00:25.201: INFO: Pod "var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9" satisfied condition "Succeeded or Failed"
    May  1 23:00:25.304: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9 container dapi-container: <nil>
    STEP: delete the pod 05/01/23 23:00:25.423
    May  1 23:00:25.534: INFO: Waiting for pod var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9 to disappear
    May  1 23:00:25.639: INFO: Pod var-expansion-eaedb2dc-3296-4105-99eb-aa03ecf4c7b9 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  1 23:00:25.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2763" for this suite. 05/01/23 23:00:25.743
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:25.951
May  1 23:00:25.951: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/01/23 23:00:25.953
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:26.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:26.47
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 05/01/23 23:00:26.675
May  1 23:00:26.783: INFO: Waiting up to 5m0s for pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7" in namespace "var-expansion-8859" to be "Succeeded or Failed"
May  1 23:00:26.886: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.370762ms
May  1 23:00:28.991: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20782473s
May  1 23:00:30.991: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20787251s
STEP: Saw pod success 05/01/23 23:00:30.991
May  1 23:00:30.991: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7" satisfied condition "Succeeded or Failed"
May  1 23:00:31.094: INFO: Trying to get logs from node i-02d061b30635c230c pod var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7 container dapi-container: <nil>
STEP: delete the pod 05/01/23 23:00:31.2
May  1 23:00:31.311: INFO: Waiting for pod var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7 to disappear
May  1 23:00:31.415: INFO: Pod var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  1 23:00:31.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8859" for this suite. 05/01/23 23:00:31.519
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":66,"skipped":1186,"failed":0}
------------------------------
• [SLOW TEST] [5.673 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:25.951
    May  1 23:00:25.951: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/01/23 23:00:25.953
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:26.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:26.47
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 05/01/23 23:00:26.675
    May  1 23:00:26.783: INFO: Waiting up to 5m0s for pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7" in namespace "var-expansion-8859" to be "Succeeded or Failed"
    May  1 23:00:26.886: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.370762ms
    May  1 23:00:28.991: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20782473s
    May  1 23:00:30.991: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20787251s
    STEP: Saw pod success 05/01/23 23:00:30.991
    May  1 23:00:30.991: INFO: Pod "var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7" satisfied condition "Succeeded or Failed"
    May  1 23:00:31.094: INFO: Trying to get logs from node i-02d061b30635c230c pod var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7 container dapi-container: <nil>
    STEP: delete the pod 05/01/23 23:00:31.2
    May  1 23:00:31.311: INFO: Waiting for pod var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7 to disappear
    May  1 23:00:31.415: INFO: Pod var-expansion-08de0cdf-ce27-4b56-9fb9-a40b37f756d7 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  1 23:00:31.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8859" for this suite. 05/01/23 23:00:31.519
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:31.625
May  1 23:00:31.625: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:00:31.626
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:31.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:32.142
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:00:33.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2240" for this suite. 05/01/23 23:00:33.392
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":67,"skipped":1215,"failed":0}
------------------------------
• [1.873 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:31.625
    May  1 23:00:31.625: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:00:31.626
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:31.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:32.142
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:00:33.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2240" for this suite. 05/01/23 23:00:33.392
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:33.502
May  1 23:00:33.502: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:00:33.503
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:33.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:34.02
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 05/01/23 23:00:34.225
STEP: getting /apis/node.k8s.io 05/01/23 23:00:34.429
STEP: getting /apis/node.k8s.io/v1 05/01/23 23:00:34.532
STEP: creating 05/01/23 23:00:34.634
STEP: watching 05/01/23 23:00:34.948
May  1 23:00:34.948: INFO: starting watch
STEP: getting 05/01/23 23:00:35.156
STEP: listing 05/01/23 23:00:35.259
STEP: patching 05/01/23 23:00:35.362
STEP: updating 05/01/23 23:00:35.467
May  1 23:00:35.580: INFO: waiting for watch events with expected annotations
STEP: deleting 05/01/23 23:00:35.58
STEP: deleting a collection 05/01/23 23:00:35.891
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
May  1 23:00:36.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2147" for this suite. 05/01/23 23:00:36.208
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":68,"skipped":1291,"failed":0}
------------------------------
• [2.812 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:33.502
    May  1 23:00:33.502: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:00:33.503
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:33.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:34.02
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 05/01/23 23:00:34.225
    STEP: getting /apis/node.k8s.io 05/01/23 23:00:34.429
    STEP: getting /apis/node.k8s.io/v1 05/01/23 23:00:34.532
    STEP: creating 05/01/23 23:00:34.634
    STEP: watching 05/01/23 23:00:34.948
    May  1 23:00:34.948: INFO: starting watch
    STEP: getting 05/01/23 23:00:35.156
    STEP: listing 05/01/23 23:00:35.259
    STEP: patching 05/01/23 23:00:35.362
    STEP: updating 05/01/23 23:00:35.467
    May  1 23:00:35.580: INFO: waiting for watch events with expected annotations
    STEP: deleting 05/01/23 23:00:35.58
    STEP: deleting a collection 05/01/23 23:00:35.891
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    May  1 23:00:36.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2147" for this suite. 05/01/23 23:00:36.208
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:36.315
May  1 23:00:36.315: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:00:36.316
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:36.627
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:36.832
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:00:37.038
May  1 23:00:37.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384" in namespace "downward-api-4025" to be "Succeeded or Failed"
May  1 23:00:37.247: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384": Phase="Pending", Reason="", readiness=false. Elapsed: 103.54272ms
May  1 23:00:39.351: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20760101s
May  1 23:00:41.351: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207265086s
STEP: Saw pod success 05/01/23 23:00:41.351
May  1 23:00:41.351: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384" satisfied condition "Succeeded or Failed"
May  1 23:00:41.455: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384 container client-container: <nil>
STEP: delete the pod 05/01/23 23:00:41.56
May  1 23:00:41.670: INFO: Waiting for pod downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384 to disappear
May  1 23:00:41.774: INFO: Pod downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:00:41.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4025" for this suite. 05/01/23 23:00:41.879
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":69,"skipped":1295,"failed":0}
------------------------------
• [SLOW TEST] [5.670 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:36.315
    May  1 23:00:36.315: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:00:36.316
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:36.627
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:36.832
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:00:37.038
    May  1 23:00:37.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384" in namespace "downward-api-4025" to be "Succeeded or Failed"
    May  1 23:00:37.247: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384": Phase="Pending", Reason="", readiness=false. Elapsed: 103.54272ms
    May  1 23:00:39.351: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20760101s
    May  1 23:00:41.351: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207265086s
    STEP: Saw pod success 05/01/23 23:00:41.351
    May  1 23:00:41.351: INFO: Pod "downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384" satisfied condition "Succeeded or Failed"
    May  1 23:00:41.455: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:00:41.56
    May  1 23:00:41.670: INFO: Waiting for pod downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384 to disappear
    May  1 23:00:41.774: INFO: Pod downwardapi-volume-caf468d5-2fbc-4a70-9fab-4140488c3384 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:00:41.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4025" for this suite. 05/01/23 23:00:41.879
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:00:41.985
May  1 23:00:41.985: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath 05/01/23 23:00:41.986
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:42.298
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:42.503
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 05/01/23 23:00:42.708
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-dfrx 05/01/23 23:00:42.917
STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:00:42.917
May  1 23:00:43.024: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dfrx" in namespace "subpath-6446" to be "Succeeded or Failed"
May  1 23:00:43.128: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Pending", Reason="", readiness=false. Elapsed: 103.431743ms
May  1 23:00:45.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 2.207751394s
May  1 23:00:47.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 4.208284582s
May  1 23:00:49.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 6.207665822s
May  1 23:00:51.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 8.208461162s
May  1 23:00:53.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 10.209228444s
May  1 23:00:55.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 12.207524055s
May  1 23:00:57.234: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 14.209692631s
May  1 23:00:59.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 16.208968957s
May  1 23:01:01.231: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 18.207352679s
May  1 23:01:03.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 20.208879174s
May  1 23:01:05.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=false. Elapsed: 22.207876883s
May  1 23:01:07.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.208527337s
STEP: Saw pod success 05/01/23 23:01:07.233
May  1 23:01:07.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx" satisfied condition "Succeeded or Failed"
May  1 23:01:07.336: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-subpath-test-downwardapi-dfrx container test-container-subpath-downwardapi-dfrx: <nil>
STEP: delete the pod 05/01/23 23:01:07.444
May  1 23:01:07.554: INFO: Waiting for pod pod-subpath-test-downwardapi-dfrx to disappear
May  1 23:01:07.657: INFO: Pod pod-subpath-test-downwardapi-dfrx no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dfrx 05/01/23 23:01:07.657
May  1 23:01:07.657: INFO: Deleting pod "pod-subpath-test-downwardapi-dfrx" in namespace "subpath-6446"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
May  1 23:01:07.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6446" for this suite. 05/01/23 23:01:07.867
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":70,"skipped":1296,"failed":0}
------------------------------
• [SLOW TEST] [26.089 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:00:41.985
    May  1 23:00:41.985: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename subpath 05/01/23 23:00:41.986
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:00:42.298
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:00:42.503
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 05/01/23 23:00:42.708
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-dfrx 05/01/23 23:00:42.917
    STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:00:42.917
    May  1 23:00:43.024: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dfrx" in namespace "subpath-6446" to be "Succeeded or Failed"
    May  1 23:00:43.128: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Pending", Reason="", readiness=false. Elapsed: 103.431743ms
    May  1 23:00:45.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 2.207751394s
    May  1 23:00:47.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 4.208284582s
    May  1 23:00:49.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 6.207665822s
    May  1 23:00:51.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 8.208461162s
    May  1 23:00:53.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 10.209228444s
    May  1 23:00:55.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 12.207524055s
    May  1 23:00:57.234: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 14.209692631s
    May  1 23:00:59.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 16.208968957s
    May  1 23:01:01.231: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 18.207352679s
    May  1 23:01:03.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=true. Elapsed: 20.208879174s
    May  1 23:01:05.232: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Running", Reason="", readiness=false. Elapsed: 22.207876883s
    May  1 23:01:07.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.208527337s
    STEP: Saw pod success 05/01/23 23:01:07.233
    May  1 23:01:07.233: INFO: Pod "pod-subpath-test-downwardapi-dfrx" satisfied condition "Succeeded or Failed"
    May  1 23:01:07.336: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-subpath-test-downwardapi-dfrx container test-container-subpath-downwardapi-dfrx: <nil>
    STEP: delete the pod 05/01/23 23:01:07.444
    May  1 23:01:07.554: INFO: Waiting for pod pod-subpath-test-downwardapi-dfrx to disappear
    May  1 23:01:07.657: INFO: Pod pod-subpath-test-downwardapi-dfrx no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-dfrx 05/01/23 23:01:07.657
    May  1 23:01:07.657: INFO: Deleting pod "pod-subpath-test-downwardapi-dfrx" in namespace "subpath-6446"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    May  1 23:01:07.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6446" for this suite. 05/01/23 23:01:07.867
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:01:08.075
May  1 23:01:08.075: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces 05/01/23 23:01:08.077
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:08.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:01:08.596
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 05/01/23 23:01:08.802
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:09.113
STEP: Creating a pod in the namespace 05/01/23 23:01:09.318
STEP: Waiting for the pod to have running status 05/01/23 23:01:09.426
May  1 23:01:09.426: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-9831" to be "running"
May  1 23:01:09.529: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.678709ms
May  1 23:01:11.634: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208359984s
May  1 23:01:11.634: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 05/01/23 23:01:11.634
STEP: Waiting for the namespace to be removed. 05/01/23 23:01:11.739
STEP: Recreating the namespace 05/01/23 23:01:22.843
STEP: Verifying there are no pods in the namespace 05/01/23 23:01:23.154
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
May  1 23:01:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4292" for this suite. 05/01/23 23:01:23.362
STEP: Destroying namespace "nsdeletetest-9831" for this suite. 05/01/23 23:01:23.467
May  1 23:01:23.571: INFO: Namespace nsdeletetest-9831 was already deleted
STEP: Destroying namespace "nsdeletetest-3745" for this suite. 05/01/23 23:01:23.571
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":71,"skipped":1314,"failed":0}
------------------------------
• [SLOW TEST] [15.601 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:01:08.075
    May  1 23:01:08.075: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename namespaces 05/01/23 23:01:08.077
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:08.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:01:08.596
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 05/01/23 23:01:08.802
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:09.113
    STEP: Creating a pod in the namespace 05/01/23 23:01:09.318
    STEP: Waiting for the pod to have running status 05/01/23 23:01:09.426
    May  1 23:01:09.426: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-9831" to be "running"
    May  1 23:01:09.529: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.678709ms
    May  1 23:01:11.634: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208359984s
    May  1 23:01:11.634: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 05/01/23 23:01:11.634
    STEP: Waiting for the namespace to be removed. 05/01/23 23:01:11.739
    STEP: Recreating the namespace 05/01/23 23:01:22.843
    STEP: Verifying there are no pods in the namespace 05/01/23 23:01:23.154
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:01:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4292" for this suite. 05/01/23 23:01:23.362
    STEP: Destroying namespace "nsdeletetest-9831" for this suite. 05/01/23 23:01:23.467
    May  1 23:01:23.571: INFO: Namespace nsdeletetest-9831 was already deleted
    STEP: Destroying namespace "nsdeletetest-3745" for this suite. 05/01/23 23:01:23.571
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:01:23.677
May  1 23:01:23.677: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename disruption 05/01/23 23:01:23.678
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:23.991
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:01:24.197
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 05/01/23 23:01:24.402
STEP: Waiting for the pdb to be processed 05/01/23 23:01:24.507
STEP: First trying to evict a pod which shouldn't be evictable 05/01/23 23:01:24.716
STEP: Waiting for all pods to be running 05/01/23 23:01:24.716
May  1 23:01:24.820: INFO: running pods: 0 < 3
STEP: locating a running pod 05/01/23 23:01:26.925
STEP: Updating the pdb to allow a pod to be evicted 05/01/23 23:01:27.135
STEP: Waiting for the pdb to be processed 05/01/23 23:01:27.345
STEP: Trying to evict the same pod we tried earlier which should now be evictable 05/01/23 23:01:27.448
STEP: Waiting for all pods to be running 05/01/23 23:01:27.448
STEP: Waiting for the pdb to observed all healthy pods 05/01/23 23:01:27.552
STEP: Patching the pdb to disallow a pod to be evicted 05/01/23 23:01:27.77
STEP: Waiting for the pdb to be processed 05/01/23 23:01:27.981
STEP: Waiting for all pods to be running 05/01/23 23:01:28.084
May  1 23:01:28.188: INFO: running pods: 2 < 3
STEP: locating a running pod 05/01/23 23:01:30.293
STEP: Deleting the pdb to allow a pod to be evicted 05/01/23 23:01:30.502
STEP: Waiting for the pdb to be deleted 05/01/23 23:01:30.607
STEP: Trying to evict the same pod we tried earlier which should now be evictable 05/01/23 23:01:30.71
STEP: Waiting for all pods to be running 05/01/23 23:01:30.71
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
May  1 23:01:30.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5363" for this suite. 05/01/23 23:01:31.028
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":72,"skipped":1317,"failed":0}
------------------------------
• [SLOW TEST] [7.456 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:01:23.677
    May  1 23:01:23.677: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename disruption 05/01/23 23:01:23.678
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:23.991
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:01:24.197
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 05/01/23 23:01:24.402
    STEP: Waiting for the pdb to be processed 05/01/23 23:01:24.507
    STEP: First trying to evict a pod which shouldn't be evictable 05/01/23 23:01:24.716
    STEP: Waiting for all pods to be running 05/01/23 23:01:24.716
    May  1 23:01:24.820: INFO: running pods: 0 < 3
    STEP: locating a running pod 05/01/23 23:01:26.925
    STEP: Updating the pdb to allow a pod to be evicted 05/01/23 23:01:27.135
    STEP: Waiting for the pdb to be processed 05/01/23 23:01:27.345
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 05/01/23 23:01:27.448
    STEP: Waiting for all pods to be running 05/01/23 23:01:27.448
    STEP: Waiting for the pdb to observed all healthy pods 05/01/23 23:01:27.552
    STEP: Patching the pdb to disallow a pod to be evicted 05/01/23 23:01:27.77
    STEP: Waiting for the pdb to be processed 05/01/23 23:01:27.981
    STEP: Waiting for all pods to be running 05/01/23 23:01:28.084
    May  1 23:01:28.188: INFO: running pods: 2 < 3
    STEP: locating a running pod 05/01/23 23:01:30.293
    STEP: Deleting the pdb to allow a pod to be evicted 05/01/23 23:01:30.502
    STEP: Waiting for the pdb to be deleted 05/01/23 23:01:30.607
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 05/01/23 23:01:30.71
    STEP: Waiting for all pods to be running 05/01/23 23:01:30.71
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    May  1 23:01:30.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5363" for this suite. 05/01/23 23:01:31.028
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:01:31.134
May  1 23:01:31.134: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/01/23 23:01:31.136
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:31.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:01:31.652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8502 05/01/23 23:01:31.858
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 05/01/23 23:01:31.966
STEP: Creating stateful set ss in namespace statefulset-8502 05/01/23 23:01:32.07
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8502 05/01/23 23:01:32.175
May  1 23:01:32.288: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May  1 23:01:42.395: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 05/01/23 23:01:42.395
May  1 23:01:42.499: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 23:01:43.649: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 23:01:43.649: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 23:01:43.649: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 23:01:43.753: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  1 23:01:53.861: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  1 23:01:53.861: INFO: Waiting for statefulset status.replicas updated to 0
May  1 23:01:54.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999957s
May  1 23:01:55.384: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.895432137s
May  1 23:01:56.488: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.791731567s
May  1 23:01:57.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.687772747s
May  1 23:01:58.696: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.583319975s
May  1 23:01:59.800: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.479469488s
May  1 23:02:00.904: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.375194755s
May  1 23:02:02.008: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.271448634s
May  1 23:02:03.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.167178536s
May  1 23:02:04.216: INFO: Verifying statefulset ss doesn't scale past 1 for another 63.278141ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8502 05/01/23 23:02:05.216
May  1 23:02:05.321: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:02:06.492: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  1 23:02:06.492: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  1 23:02:06.492: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  1 23:02:06.596: INFO: Found 2 stateful pods, waiting for 3
May  1 23:02:16.701: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  1 23:02:16.701: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  1 23:02:16.701: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 05/01/23 23:02:16.701
STEP: Scale down will halt with unhealthy stateful pod 05/01/23 23:02:16.701
May  1 23:02:16.909: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 23:02:18.059: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 23:02:18.060: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 23:02:18.060: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 23:02:18.060: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 23:02:19.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 23:02:19.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 23:02:19.196: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 23:02:19.196: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  1 23:02:20.315: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  1 23:02:20.316: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  1 23:02:20.316: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  1 23:02:20.316: INFO: Waiting for statefulset status.replicas updated to 0
May  1 23:02:20.419: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May  1 23:02:30.627: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  1 23:02:30.627: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  1 23:02:30.627: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  1 23:02:30.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999548s
May  1 23:02:32.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.896132946s
May  1 23:02:33.149: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.791731053s
May  1 23:02:34.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.687558727s
May  1 23:02:35.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.583459222s
May  1 23:02:36.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.478648308s
May  1 23:02:37.567: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.374464933s
May  1 23:02:38.672: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.269527817s
May  1 23:02:39.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.164770441s
May  1 23:02:40.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 60.588474ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8502 05/01/23 23:02:41.88
May  1 23:02:41.985: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:02:43.153: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  1 23:02:43.153: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  1 23:02:43.153: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  1 23:02:43.153: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:02:44.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  1 23:02:44.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  1 23:02:44.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  1 23:02:44.239: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:02:45.296: INFO: rc: 1
May  1 23:02:45.296: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: container is in CONTAINER_EXITED state

error:
exit status 1
May  1 23:02:55.297: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:02:55.852: INFO: rc: 1
May  1 23:02:55.852: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:03:05.852: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:03:06.405: INFO: rc: 1
May  1 23:03:06.405: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:03:16.407: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:03:16.934: INFO: rc: 1
May  1 23:03:16.934: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:03:26.936: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:03:27.467: INFO: rc: 1
May  1 23:03:27.467: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:03:37.467: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:03:38.010: INFO: rc: 1
May  1 23:03:38.010: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:03:48.010: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:03:48.539: INFO: rc: 1
May  1 23:03:48.539: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:03:58.542: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:03:59.069: INFO: rc: 1
May  1 23:03:59.069: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:04:09.073: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:04:09.579: INFO: rc: 1
May  1 23:04:09.580: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:04:19.581: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:04:20.109: INFO: rc: 1
May  1 23:04:20.109: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:04:30.110: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:04:30.628: INFO: rc: 1
May  1 23:04:30.628: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:04:40.629: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:04:41.165: INFO: rc: 1
May  1 23:04:41.165: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:04:51.166: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:04:51.706: INFO: rc: 1
May  1 23:04:51.706: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:05:01.708: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:05:02.246: INFO: rc: 1
May  1 23:05:02.246: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:05:12.246: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:05:12.776: INFO: rc: 1
May  1 23:05:12.776: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:05:22.778: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:05:23.306: INFO: rc: 1
May  1 23:05:23.306: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:05:33.309: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:05:33.841: INFO: rc: 1
May  1 23:05:33.841: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:05:43.845: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:05:44.387: INFO: rc: 1
May  1 23:05:44.387: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:05:54.387: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:05:54.898: INFO: rc: 1
May  1 23:05:54.898: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:06:04.898: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:06:05.432: INFO: rc: 1
May  1 23:06:05.432: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:06:15.432: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:06:15.967: INFO: rc: 1
May  1 23:06:15.967: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:06:25.968: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:06:26.490: INFO: rc: 1
May  1 23:06:26.490: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:06:36.490: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:06:37.024: INFO: rc: 1
May  1 23:06:37.024: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:06:47.025: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:06:47.550: INFO: rc: 1
May  1 23:06:47.550: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:06:57.551: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:06:58.066: INFO: rc: 1
May  1 23:06:58.066: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:07:08.069: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:07:08.586: INFO: rc: 1
May  1 23:07:08.586: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:07:18.586: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:07:19.121: INFO: rc: 1
May  1 23:07:19.121: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:07:29.125: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:07:29.664: INFO: rc: 1
May  1 23:07:29.664: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:07:39.664: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:07:40.196: INFO: rc: 1
May  1 23:07:40.196: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May  1 23:07:50.197: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  1 23:07:50.715: INFO: rc: 1
May  1 23:07:50.715: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
May  1 23:07:50.715: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 05/01/23 23:07:51.027
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  1 23:07:51.027: INFO: Deleting all statefulset in ns statefulset-8502
May  1 23:07:51.130: INFO: Scaling statefulset ss to 0
May  1 23:07:51.442: INFO: Waiting for statefulset status.replicas updated to 0
May  1 23:07:51.546: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  1 23:07:51.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8502" for this suite. 05/01/23 23:07:51.963
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":73,"skipped":1337,"failed":0}
------------------------------
• [SLOW TEST] [380.934 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:01:31.134
    May  1 23:01:31.134: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/01/23 23:01:31.136
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:01:31.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:01:31.652
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8502 05/01/23 23:01:31.858
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 05/01/23 23:01:31.966
    STEP: Creating stateful set ss in namespace statefulset-8502 05/01/23 23:01:32.07
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8502 05/01/23 23:01:32.175
    May  1 23:01:32.288: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    May  1 23:01:42.395: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 05/01/23 23:01:42.395
    May  1 23:01:42.499: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 23:01:43.649: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 23:01:43.649: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 23:01:43.649: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 23:01:43.753: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    May  1 23:01:53.861: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    May  1 23:01:53.861: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 23:01:54.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999957s
    May  1 23:01:55.384: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.895432137s
    May  1 23:01:56.488: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.791731567s
    May  1 23:01:57.592: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.687772747s
    May  1 23:01:58.696: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.583319975s
    May  1 23:01:59.800: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.479469488s
    May  1 23:02:00.904: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.375194755s
    May  1 23:02:02.008: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.271448634s
    May  1 23:02:03.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.167178536s
    May  1 23:02:04.216: INFO: Verifying statefulset ss doesn't scale past 1 for another 63.278141ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8502 05/01/23 23:02:05.216
    May  1 23:02:05.321: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:02:06.492: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    May  1 23:02:06.492: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  1 23:02:06.492: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  1 23:02:06.596: INFO: Found 2 stateful pods, waiting for 3
    May  1 23:02:16.701: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    May  1 23:02:16.701: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    May  1 23:02:16.701: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 05/01/23 23:02:16.701
    STEP: Scale down will halt with unhealthy stateful pod 05/01/23 23:02:16.701
    May  1 23:02:16.909: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 23:02:18.059: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 23:02:18.060: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 23:02:18.060: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 23:02:18.060: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 23:02:19.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 23:02:19.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 23:02:19.196: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 23:02:19.196: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  1 23:02:20.315: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  1 23:02:20.316: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  1 23:02:20.316: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  1 23:02:20.316: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 23:02:20.419: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    May  1 23:02:30.627: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    May  1 23:02:30.627: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    May  1 23:02:30.627: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    May  1 23:02:30.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999548s
    May  1 23:02:32.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.896132946s
    May  1 23:02:33.149: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.791731053s
    May  1 23:02:34.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.687558727s
    May  1 23:02:35.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.583459222s
    May  1 23:02:36.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.478648308s
    May  1 23:02:37.567: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.374464933s
    May  1 23:02:38.672: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.269527817s
    May  1 23:02:39.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.164770441s
    May  1 23:02:40.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 60.588474ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8502 05/01/23 23:02:41.88
    May  1 23:02:41.985: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:02:43.153: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    May  1 23:02:43.153: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  1 23:02:43.153: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  1 23:02:43.153: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:02:44.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    May  1 23:02:44.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  1 23:02:44.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  1 23:02:44.239: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:02:45.296: INFO: rc: 1
    May  1 23:02:45.296: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    error: Internal error occurred: error executing command in container: failed to exec in container: container is in CONTAINER_EXITED state

    error:
    exit status 1
    May  1 23:02:55.297: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:02:55.852: INFO: rc: 1
    May  1 23:02:55.852: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:03:05.852: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:03:06.405: INFO: rc: 1
    May  1 23:03:06.405: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:03:16.407: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:03:16.934: INFO: rc: 1
    May  1 23:03:16.934: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:03:26.936: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:03:27.467: INFO: rc: 1
    May  1 23:03:27.467: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:03:37.467: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:03:38.010: INFO: rc: 1
    May  1 23:03:38.010: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:03:48.010: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:03:48.539: INFO: rc: 1
    May  1 23:03:48.539: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:03:58.542: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:03:59.069: INFO: rc: 1
    May  1 23:03:59.069: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:04:09.073: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:04:09.579: INFO: rc: 1
    May  1 23:04:09.580: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:04:19.581: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:04:20.109: INFO: rc: 1
    May  1 23:04:20.109: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:04:30.110: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:04:30.628: INFO: rc: 1
    May  1 23:04:30.628: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:04:40.629: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:04:41.165: INFO: rc: 1
    May  1 23:04:41.165: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:04:51.166: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:04:51.706: INFO: rc: 1
    May  1 23:04:51.706: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:05:01.708: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:05:02.246: INFO: rc: 1
    May  1 23:05:02.246: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:05:12.246: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:05:12.776: INFO: rc: 1
    May  1 23:05:12.776: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:05:22.778: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:05:23.306: INFO: rc: 1
    May  1 23:05:23.306: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:05:33.309: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:05:33.841: INFO: rc: 1
    May  1 23:05:33.841: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:05:43.845: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:05:44.387: INFO: rc: 1
    May  1 23:05:44.387: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:05:54.387: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:05:54.898: INFO: rc: 1
    May  1 23:05:54.898: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:06:04.898: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:06:05.432: INFO: rc: 1
    May  1 23:06:05.432: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:06:15.432: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:06:15.967: INFO: rc: 1
    May  1 23:06:15.967: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:06:25.968: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:06:26.490: INFO: rc: 1
    May  1 23:06:26.490: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:06:36.490: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:06:37.024: INFO: rc: 1
    May  1 23:06:37.024: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:06:47.025: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:06:47.550: INFO: rc: 1
    May  1 23:06:47.550: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:06:57.551: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:06:58.066: INFO: rc: 1
    May  1 23:06:58.066: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:07:08.069: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:07:08.586: INFO: rc: 1
    May  1 23:07:08.586: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:07:18.586: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:07:19.121: INFO: rc: 1
    May  1 23:07:19.121: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:07:29.125: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:07:29.664: INFO: rc: 1
    May  1 23:07:29.664: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:07:39.664: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:07:40.196: INFO: rc: 1
    May  1 23:07:40.196: INFO: Waiting 10s to retry failed RunHostCmd: error running /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
    Command stdout:

    stderr:
    Error from server (NotFound): pods "ss-2" not found

    error:
    exit status 1
    May  1 23:07:50.197: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-8502 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  1 23:07:50.715: INFO: rc: 1
    May  1 23:07:50.715: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
    May  1 23:07:50.715: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 05/01/23 23:07:51.027
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  1 23:07:51.027: INFO: Deleting all statefulset in ns statefulset-8502
    May  1 23:07:51.130: INFO: Scaling statefulset ss to 0
    May  1 23:07:51.442: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 23:07:51.546: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  1 23:07:51.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8502" for this suite. 05/01/23 23:07:51.963
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:07:52.069
May  1 23:07:52.069: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/01/23 23:07:52.071
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:07:52.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:07:52.59
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3825 05/01/23 23:07:52.796
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 05/01/23 23:07:52.901
STEP: Creating pod with conflicting port in namespace statefulset-3825 05/01/23 23:07:53.006
STEP: Waiting until pod test-pod will start running in namespace statefulset-3825 05/01/23 23:07:53.114
May  1 23:07:53.114: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3825" to be "running"
May  1 23:07:53.218: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.748792ms
May  1 23:07:55.322: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208075872s
May  1 23:07:55.322: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-3825 05/01/23 23:07:55.322
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3825 05/01/23 23:07:55.429
May  1 23:07:55.533: INFO: Observed stateful pod in namespace: statefulset-3825, name: ss-0, uid: 5033ae18-7d10-4ebc-8722-02800fecee12, status phase: Pending. Waiting for statefulset controller to delete.
May  1 23:07:55.636: INFO: Observed stateful pod in namespace: statefulset-3825, name: ss-0, uid: 5033ae18-7d10-4ebc-8722-02800fecee12, status phase: Failed. Waiting for statefulset controller to delete.
May  1 23:07:55.636: INFO: Observed stateful pod in namespace: statefulset-3825, name: ss-0, uid: 5033ae18-7d10-4ebc-8722-02800fecee12, status phase: Failed. Waiting for statefulset controller to delete.
May  1 23:07:55.636: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3825
STEP: Removing pod with conflicting port in namespace statefulset-3825 05/01/23 23:07:55.636
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3825 and will be in running state 05/01/23 23:07:55.749
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  1 23:07:57.960: INFO: Deleting all statefulset in ns statefulset-3825
May  1 23:07:58.063: INFO: Scaling statefulset ss to 0
May  1 23:08:08.483: INFO: Waiting for statefulset status.replicas updated to 0
May  1 23:08:08.587: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  1 23:08:08.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3825" for this suite. 05/01/23 23:08:09.004
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":74,"skipped":1345,"failed":0}
------------------------------
• [SLOW TEST] [17.141 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:07:52.069
    May  1 23:07:52.069: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/01/23 23:07:52.071
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:07:52.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:07:52.59
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3825 05/01/23 23:07:52.796
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 05/01/23 23:07:52.901
    STEP: Creating pod with conflicting port in namespace statefulset-3825 05/01/23 23:07:53.006
    STEP: Waiting until pod test-pod will start running in namespace statefulset-3825 05/01/23 23:07:53.114
    May  1 23:07:53.114: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3825" to be "running"
    May  1 23:07:53.218: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.748792ms
    May  1 23:07:55.322: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.208075872s
    May  1 23:07:55.322: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-3825 05/01/23 23:07:55.322
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3825 05/01/23 23:07:55.429
    May  1 23:07:55.533: INFO: Observed stateful pod in namespace: statefulset-3825, name: ss-0, uid: 5033ae18-7d10-4ebc-8722-02800fecee12, status phase: Pending. Waiting for statefulset controller to delete.
    May  1 23:07:55.636: INFO: Observed stateful pod in namespace: statefulset-3825, name: ss-0, uid: 5033ae18-7d10-4ebc-8722-02800fecee12, status phase: Failed. Waiting for statefulset controller to delete.
    May  1 23:07:55.636: INFO: Observed stateful pod in namespace: statefulset-3825, name: ss-0, uid: 5033ae18-7d10-4ebc-8722-02800fecee12, status phase: Failed. Waiting for statefulset controller to delete.
    May  1 23:07:55.636: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3825
    STEP: Removing pod with conflicting port in namespace statefulset-3825 05/01/23 23:07:55.636
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3825 and will be in running state 05/01/23 23:07:55.749
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  1 23:07:57.960: INFO: Deleting all statefulset in ns statefulset-3825
    May  1 23:07:58.063: INFO: Scaling statefulset ss to 0
    May  1 23:08:08.483: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 23:08:08.587: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  1 23:08:08.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3825" for this suite. 05/01/23 23:08:09.004
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:08:09.21
May  1 23:08:09.211: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:08:09.212
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:09.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:09.73
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:08:10.148
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:08:10.8
STEP: Deploying the webhook pod 05/01/23 23:08:10.915
STEP: Wait for the deployment to be ready 05/01/23 23:08:11.128
May  1 23:08:11.439: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:08:13.545
STEP: Verifying the service has paired with the endpoint 05/01/23 23:08:13.654
May  1 23:08:14.654: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
May  1 23:08:14.759: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6978-crds.webhook.example.com via the AdmissionRegistration API 05/01/23 23:08:15.07
STEP: Creating a custom resource while v1 is storage version 05/01/23 23:08:15.288
STEP: Patching Custom Resource Definition to set v2 as storage 05/01/23 23:08:17.402
STEP: Patching the custom resource while v2 is storage version 05/01/23 23:08:17.51
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:08:18.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7790" for this suite. 05/01/23 23:08:18.171
STEP: Destroying namespace "webhook-7790-markers" for this suite. 05/01/23 23:08:18.277
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":75,"skipped":1352,"failed":0}
------------------------------
• [SLOW TEST] [9.610 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:08:09.21
    May  1 23:08:09.211: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:08:09.212
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:09.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:09.73
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:08:10.148
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:08:10.8
    STEP: Deploying the webhook pod 05/01/23 23:08:10.915
    STEP: Wait for the deployment to be ready 05/01/23 23:08:11.128
    May  1 23:08:11.439: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 8, 11, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:08:13.545
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:08:13.654
    May  1 23:08:14.654: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    May  1 23:08:14.759: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6978-crds.webhook.example.com via the AdmissionRegistration API 05/01/23 23:08:15.07
    STEP: Creating a custom resource while v1 is storage version 05/01/23 23:08:15.288
    STEP: Patching Custom Resource Definition to set v2 as storage 05/01/23 23:08:17.402
    STEP: Patching the custom resource while v2 is storage version 05/01/23 23:08:17.51
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:08:18.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7790" for this suite. 05/01/23 23:08:18.171
    STEP: Destroying namespace "webhook-7790-markers" for this suite. 05/01/23 23:08:18.277
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:08:18.824
May  1 23:08:18.824: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/01/23 23:08:18.826
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:19.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:19.357
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 05/01/23 23:08:19.562
May  1 23:08:19.670: INFO: Waiting up to 5m0s for pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da" in namespace "var-expansion-8246" to be "Succeeded or Failed"
May  1 23:08:19.774: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da": Phase="Pending", Reason="", readiness=false. Elapsed: 104.221528ms
May  1 23:08:21.878: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208348069s
May  1 23:08:23.879: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208456918s
STEP: Saw pod success 05/01/23 23:08:23.879
May  1 23:08:23.879: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da" satisfied condition "Succeeded or Failed"
May  1 23:08:23.983: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod var-expansion-de216e42-8964-4132-826f-d3bc463be2da container dapi-container: <nil>
STEP: delete the pod 05/01/23 23:08:24.1
May  1 23:08:24.212: INFO: Waiting for pod var-expansion-de216e42-8964-4132-826f-d3bc463be2da to disappear
May  1 23:08:24.315: INFO: Pod var-expansion-de216e42-8964-4132-826f-d3bc463be2da no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  1 23:08:24.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8246" for this suite. 05/01/23 23:08:24.42
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":76,"skipped":1406,"failed":0}
------------------------------
• [SLOW TEST] [5.701 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:08:18.824
    May  1 23:08:18.824: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/01/23 23:08:18.826
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:19.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:19.357
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 05/01/23 23:08:19.562
    May  1 23:08:19.670: INFO: Waiting up to 5m0s for pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da" in namespace "var-expansion-8246" to be "Succeeded or Failed"
    May  1 23:08:19.774: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da": Phase="Pending", Reason="", readiness=false. Elapsed: 104.221528ms
    May  1 23:08:21.878: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208348069s
    May  1 23:08:23.879: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208456918s
    STEP: Saw pod success 05/01/23 23:08:23.879
    May  1 23:08:23.879: INFO: Pod "var-expansion-de216e42-8964-4132-826f-d3bc463be2da" satisfied condition "Succeeded or Failed"
    May  1 23:08:23.983: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod var-expansion-de216e42-8964-4132-826f-d3bc463be2da container dapi-container: <nil>
    STEP: delete the pod 05/01/23 23:08:24.1
    May  1 23:08:24.212: INFO: Waiting for pod var-expansion-de216e42-8964-4132-826f-d3bc463be2da to disappear
    May  1 23:08:24.315: INFO: Pod var-expansion-de216e42-8964-4132-826f-d3bc463be2da no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  1 23:08:24.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8246" for this suite. 05/01/23 23:08:24.42
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:08:24.526
May  1 23:08:24.526: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/01/23 23:08:24.527
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:24.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:25.044
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 05/01/23 23:08:25.356
STEP: delete the rc 05/01/23 23:08:30.565
STEP: wait for the rc to be deleted 05/01/23 23:08:30.672
May  1 23:08:31.893: INFO: 80 pods remaining
May  1 23:08:31.893: INFO: 80 pods has nil DeletionTimestamp
May  1 23:08:31.893: INFO: 
May  1 23:08:32.888: INFO: 68 pods remaining
May  1 23:08:32.888: INFO: 67 pods has nil DeletionTimestamp
May  1 23:08:32.888: INFO: 
May  1 23:08:33.985: INFO: 55 pods remaining
May  1 23:08:33.986: INFO: 55 pods has nil DeletionTimestamp
May  1 23:08:33.986: INFO: 
May  1 23:08:34.915: INFO: 40 pods remaining
May  1 23:08:34.915: INFO: 40 pods has nil DeletionTimestamp
May  1 23:08:34.915: INFO: 
May  1 23:08:35.890: INFO: 27 pods remaining
May  1 23:08:35.890: INFO: 27 pods has nil DeletionTimestamp
May  1 23:08:35.890: INFO: 
May  1 23:08:36.886: INFO: 15 pods remaining
May  1 23:08:36.886: INFO: 15 pods has nil DeletionTimestamp
May  1 23:08:36.886: INFO: 
STEP: Gathering metrics 05/01/23 23:08:37.881
May  1 23:08:38.157: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
May  1 23:08:38.261: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 103.744752ms
May  1 23:08:38.261: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
May  1 23:08:38.261: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
May  1 23:08:39.205: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  1 23:08:39.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7422" for this suite. 05/01/23 23:08:39.31
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":77,"skipped":1420,"failed":0}
------------------------------
• [SLOW TEST] [14.889 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:08:24.526
    May  1 23:08:24.526: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/01/23 23:08:24.527
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:24.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:25.044
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 05/01/23 23:08:25.356
    STEP: delete the rc 05/01/23 23:08:30.565
    STEP: wait for the rc to be deleted 05/01/23 23:08:30.672
    May  1 23:08:31.893: INFO: 80 pods remaining
    May  1 23:08:31.893: INFO: 80 pods has nil DeletionTimestamp
    May  1 23:08:31.893: INFO: 
    May  1 23:08:32.888: INFO: 68 pods remaining
    May  1 23:08:32.888: INFO: 67 pods has nil DeletionTimestamp
    May  1 23:08:32.888: INFO: 
    May  1 23:08:33.985: INFO: 55 pods remaining
    May  1 23:08:33.986: INFO: 55 pods has nil DeletionTimestamp
    May  1 23:08:33.986: INFO: 
    May  1 23:08:34.915: INFO: 40 pods remaining
    May  1 23:08:34.915: INFO: 40 pods has nil DeletionTimestamp
    May  1 23:08:34.915: INFO: 
    May  1 23:08:35.890: INFO: 27 pods remaining
    May  1 23:08:35.890: INFO: 27 pods has nil DeletionTimestamp
    May  1 23:08:35.890: INFO: 
    May  1 23:08:36.886: INFO: 15 pods remaining
    May  1 23:08:36.886: INFO: 15 pods has nil DeletionTimestamp
    May  1 23:08:36.886: INFO: 
    STEP: Gathering metrics 05/01/23 23:08:37.881
    May  1 23:08:38.157: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
    May  1 23:08:38.261: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 103.744752ms
    May  1 23:08:38.261: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
    May  1 23:08:38.261: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
    May  1 23:08:39.205: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  1 23:08:39.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7422" for this suite. 05/01/23 23:08:39.31
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:08:39.416
May  1 23:08:39.416: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename disruption 05/01/23 23:08:39.417
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:39.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:39.938
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 05/01/23 23:08:40.248
STEP: Updating PodDisruptionBudget status 05/01/23 23:08:40.354
STEP: Waiting for all pods to be running 05/01/23 23:08:40.463
May  1 23:08:40.567: INFO: running pods: 0 < 1
May  1 23:08:42.671: INFO: running pods: 0 < 1
May  1 23:08:44.671: INFO: running pods: 0 < 1
May  1 23:08:46.671: INFO: running pods: 0 < 1
STEP: locating a running pod 05/01/23 23:08:48.674
STEP: Waiting for the pdb to be processed 05/01/23 23:08:48.987
STEP: Patching PodDisruptionBudget status 05/01/23 23:08:49.195
STEP: Waiting for the pdb to be processed 05/01/23 23:08:49.405
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
May  1 23:08:49.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6705" for this suite. 05/01/23 23:08:49.614
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":78,"skipped":1432,"failed":0}
------------------------------
• [SLOW TEST] [10.403 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:08:39.416
    May  1 23:08:39.416: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename disruption 05/01/23 23:08:39.417
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:39.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:39.938
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 05/01/23 23:08:40.248
    STEP: Updating PodDisruptionBudget status 05/01/23 23:08:40.354
    STEP: Waiting for all pods to be running 05/01/23 23:08:40.463
    May  1 23:08:40.567: INFO: running pods: 0 < 1
    May  1 23:08:42.671: INFO: running pods: 0 < 1
    May  1 23:08:44.671: INFO: running pods: 0 < 1
    May  1 23:08:46.671: INFO: running pods: 0 < 1
    STEP: locating a running pod 05/01/23 23:08:48.674
    STEP: Waiting for the pdb to be processed 05/01/23 23:08:48.987
    STEP: Patching PodDisruptionBudget status 05/01/23 23:08:49.195
    STEP: Waiting for the pdb to be processed 05/01/23 23:08:49.405
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    May  1 23:08:49.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6705" for this suite. 05/01/23 23:08:49.614
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:08:49.821
May  1 23:08:49.822: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 23:08:49.823
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:50.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:50.341
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 05/01/23 23:08:50.547
STEP: Creating a ResourceQuota 05/01/23 23:08:55.651
STEP: Ensuring resource quota status is calculated 05/01/23 23:08:55.757
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 23:08:57.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9452" for this suite. 05/01/23 23:08:57.967
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":79,"skipped":1485,"failed":0}
------------------------------
• [SLOW TEST] [8.251 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:08:49.821
    May  1 23:08:49.822: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 23:08:49.823
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:50.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:50.341
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 05/01/23 23:08:50.547
    STEP: Creating a ResourceQuota 05/01/23 23:08:55.651
    STEP: Ensuring resource quota status is calculated 05/01/23 23:08:55.757
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 23:08:57.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9452" for this suite. 05/01/23 23:08:57.967
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:08:58.073
May  1 23:08:58.073: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test 05/01/23 23:08:58.075
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:58.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:58.592
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
May  1 23:08:58.906: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7" in namespace "security-context-test-9797" to be "Succeeded or Failed"
May  1 23:08:59.009: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.767621ms
May  1 23:09:01.114: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208124732s
May  1 23:09:03.113: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20761869s
May  1 23:09:03.113: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
May  1 23:09:03.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9797" for this suite. 05/01/23 23:09:03.324
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":80,"skipped":1486,"failed":0}
------------------------------
• [SLOW TEST] [5.357 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:08:58.073
    May  1 23:08:58.073: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename security-context-test 05/01/23 23:08:58.075
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:08:58.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:08:58.592
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    May  1 23:08:58.906: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7" in namespace "security-context-test-9797" to be "Succeeded or Failed"
    May  1 23:08:59.009: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.767621ms
    May  1 23:09:01.114: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208124732s
    May  1 23:09:03.113: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20761869s
    May  1 23:09:03.113: INFO: Pod "alpine-nnp-false-8cfd6003-fa5b-41f1-87e9-8d6d1d2470d7" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    May  1 23:09:03.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9797" for this suite. 05/01/23 23:09:03.324
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:09:03.43
May  1 23:09:03.431: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:09:03.431
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:03.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:03.95
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7758 05/01/23 23:09:04.156
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 05/01/23 23:09:04.265
STEP: creating service externalsvc in namespace services-7758 05/01/23 23:09:04.265
STEP: creating replication controller externalsvc in namespace services-7758 05/01/23 23:09:04.392
I0501 23:09:04.499626    6969 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7758, replica count: 2
I0501 23:09:07.651016    6969 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 05/01/23 23:09:07.754
May  1 23:09:07.967: INFO: Creating new exec pod
May  1 23:09:08.081: INFO: Waiting up to 5m0s for pod "execpod44jq5" in namespace "services-7758" to be "running"
May  1 23:09:08.185: INFO: Pod "execpod44jq5": Phase="Pending", Reason="", readiness=false. Elapsed: 103.658645ms
May  1 23:09:10.290: INFO: Pod "execpod44jq5": Phase="Running", Reason="", readiness=true. Elapsed: 2.209058251s
May  1 23:09:10.290: INFO: Pod "execpod44jq5" satisfied condition "running"
May  1 23:09:10.290: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-7758 exec execpod44jq5 -- /bin/sh -x -c nslookup clusterip-service.services-7758.svc.cluster.local'
May  1 23:09:11.455: INFO: stderr: "+ nslookup clusterip-service.services-7758.svc.cluster.local\n"
May  1 23:09:11.455: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-7758.svc.cluster.local\tcanonical name = externalsvc.services-7758.svc.cluster.local.\nName:\texternalsvc.services-7758.svc.cluster.local\nAddress: 100.71.44.71\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7758, will wait for the garbage collector to delete the pods 05/01/23 23:09:11.455
May  1 23:09:11.814: INFO: Deleting ReplicationController externalsvc took: 105.175721ms
May  1 23:09:11.915: INFO: Terminating ReplicationController externalsvc pods took: 100.289962ms
May  1 23:09:14.430: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:09:14.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7758" for this suite. 05/01/23 23:09:14.648
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":81,"skipped":1501,"failed":0}
------------------------------
• [SLOW TEST] [11.324 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:09:03.43
    May  1 23:09:03.431: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:09:03.431
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:03.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:03.95
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7758 05/01/23 23:09:04.156
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 05/01/23 23:09:04.265
    STEP: creating service externalsvc in namespace services-7758 05/01/23 23:09:04.265
    STEP: creating replication controller externalsvc in namespace services-7758 05/01/23 23:09:04.392
    I0501 23:09:04.499626    6969 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7758, replica count: 2
    I0501 23:09:07.651016    6969 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 05/01/23 23:09:07.754
    May  1 23:09:07.967: INFO: Creating new exec pod
    May  1 23:09:08.081: INFO: Waiting up to 5m0s for pod "execpod44jq5" in namespace "services-7758" to be "running"
    May  1 23:09:08.185: INFO: Pod "execpod44jq5": Phase="Pending", Reason="", readiness=false. Elapsed: 103.658645ms
    May  1 23:09:10.290: INFO: Pod "execpod44jq5": Phase="Running", Reason="", readiness=true. Elapsed: 2.209058251s
    May  1 23:09:10.290: INFO: Pod "execpod44jq5" satisfied condition "running"
    May  1 23:09:10.290: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-7758 exec execpod44jq5 -- /bin/sh -x -c nslookup clusterip-service.services-7758.svc.cluster.local'
    May  1 23:09:11.455: INFO: stderr: "+ nslookup clusterip-service.services-7758.svc.cluster.local\n"
    May  1 23:09:11.455: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-7758.svc.cluster.local\tcanonical name = externalsvc.services-7758.svc.cluster.local.\nName:\texternalsvc.services-7758.svc.cluster.local\nAddress: 100.71.44.71\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7758, will wait for the garbage collector to delete the pods 05/01/23 23:09:11.455
    May  1 23:09:11.814: INFO: Deleting ReplicationController externalsvc took: 105.175721ms
    May  1 23:09:11.915: INFO: Terminating ReplicationController externalsvc pods took: 100.289962ms
    May  1 23:09:14.430: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:09:14.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7758" for this suite. 05/01/23 23:09:14.648
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:09:14.755
May  1 23:09:14.755: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename podtemplate 05/01/23 23:09:14.756
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:15.069
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:15.274
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 05/01/23 23:09:15.48
May  1 23:09:15.587: INFO: created test-podtemplate-1
May  1 23:09:15.693: INFO: created test-podtemplate-2
May  1 23:09:15.799: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 05/01/23 23:09:15.799
STEP: delete collection of pod templates 05/01/23 23:09:15.902
May  1 23:09:15.903: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 05/01/23 23:09:16.013
May  1 23:09:16.013: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
May  1 23:09:16.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6709" for this suite. 05/01/23 23:09:16.221
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":82,"skipped":1506,"failed":0}
------------------------------
• [1.572 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:09:14.755
    May  1 23:09:14.755: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename podtemplate 05/01/23 23:09:14.756
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:15.069
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:15.274
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 05/01/23 23:09:15.48
    May  1 23:09:15.587: INFO: created test-podtemplate-1
    May  1 23:09:15.693: INFO: created test-podtemplate-2
    May  1 23:09:15.799: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 05/01/23 23:09:15.799
    STEP: delete collection of pod templates 05/01/23 23:09:15.902
    May  1 23:09:15.903: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 05/01/23 23:09:16.013
    May  1 23:09:16.013: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    May  1 23:09:16.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6709" for this suite. 05/01/23 23:09:16.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:09:16.329
May  1 23:09:16.329: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename events 05/01/23 23:09:16.33
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:16.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:16.848
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 05/01/23 23:09:17.054
May  1 23:09:17.159: INFO: created test-event-1
May  1 23:09:17.264: INFO: created test-event-2
May  1 23:09:17.369: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 05/01/23 23:09:17.369
STEP: delete collection of events 05/01/23 23:09:17.473
May  1 23:09:17.473: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 05/01/23 23:09:17.585
May  1 23:09:17.586: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
May  1 23:09:17.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4333" for this suite. 05/01/23 23:09:17.794
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":83,"skipped":1578,"failed":0}
------------------------------
• [1.570 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:09:16.329
    May  1 23:09:16.329: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename events 05/01/23 23:09:16.33
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:16.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:16.848
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 05/01/23 23:09:17.054
    May  1 23:09:17.159: INFO: created test-event-1
    May  1 23:09:17.264: INFO: created test-event-2
    May  1 23:09:17.369: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 05/01/23 23:09:17.369
    STEP: delete collection of events 05/01/23 23:09:17.473
    May  1 23:09:17.473: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 05/01/23 23:09:17.585
    May  1 23:09:17.586: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    May  1 23:09:17.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4333" for this suite. 05/01/23 23:09:17.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:09:17.901
May  1 23:09:17.901: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/01/23 23:09:17.902
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:18.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:18.422
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 05/01/23 23:09:19.254
STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:09:19.359
May  1 23:09:19.464: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:09:19.568: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:09:19.568: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  1 23:09:20.673: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:09:20.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May  1 23:09:20.777: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:09:21.674: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:09:21.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  1 23:09:21.778: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 05/01/23 23:09:21.881
May  1 23:09:22.199: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:09:22.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 23:09:22.304: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:09:23.409: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:09:23.513: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  1 23:09:23.513: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 05/01/23 23:09:23.513
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 05/01/23 23:09:23.72
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4515, will wait for the garbage collector to delete the pods 05/01/23 23:09:23.721
May  1 23:09:24.081: INFO: Deleting DaemonSet.extensions daemon-set took: 105.338966ms
May  1 23:09:24.182: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.037362ms
May  1 23:09:26.486: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:09:26.486: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May  1 23:09:26.590: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12521"},"items":null}

May  1 23:09:26.693: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12522"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  1 23:09:27.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4515" for this suite. 05/01/23 23:09:27.317
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":84,"skipped":1611,"failed":0}
------------------------------
• [SLOW TEST] [9.523 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:09:17.901
    May  1 23:09:17.901: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/01/23 23:09:17.902
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:18.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:18.422
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 05/01/23 23:09:19.254
    STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:09:19.359
    May  1 23:09:19.464: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:09:19.568: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:09:19.568: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  1 23:09:20.673: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:09:20.777: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    May  1 23:09:20.777: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:09:21.674: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:09:21.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  1 23:09:21.778: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 05/01/23 23:09:21.881
    May  1 23:09:22.199: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:09:22.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 23:09:22.304: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:09:23.409: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:09:23.513: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  1 23:09:23.513: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 05/01/23 23:09:23.513
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 05/01/23 23:09:23.72
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4515, will wait for the garbage collector to delete the pods 05/01/23 23:09:23.721
    May  1 23:09:24.081: INFO: Deleting DaemonSet.extensions daemon-set took: 105.338966ms
    May  1 23:09:24.182: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.037362ms
    May  1 23:09:26.486: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:09:26.486: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    May  1 23:09:26.590: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12521"},"items":null}

    May  1 23:09:26.693: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12522"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:09:27.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4515" for this suite. 05/01/23 23:09:27.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:09:27.425
May  1 23:09:27.425: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath 05/01/23 23:09:27.426
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:27.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:27.944
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 05/01/23 23:09:28.149
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-x8m8 05/01/23 23:09:28.36
STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:09:28.36
May  1 23:09:28.467: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x8m8" in namespace "subpath-7349" to be "Succeeded or Failed"
May  1 23:09:28.571: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Pending", Reason="", readiness=false. Elapsed: 103.550266ms
May  1 23:09:30.676: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 2.208868368s
May  1 23:09:32.676: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 4.208898261s
May  1 23:09:34.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 6.207598596s
May  1 23:09:36.674: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 8.207218074s
May  1 23:09:38.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 10.207627325s
May  1 23:09:40.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 12.207960034s
May  1 23:09:42.677: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 14.209512254s
May  1 23:09:44.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 16.208305154s
May  1 23:09:46.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 18.20775426s
May  1 23:09:48.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 20.208448318s
May  1 23:09:50.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=false. Elapsed: 22.207662615s
May  1 23:09:52.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.207844116s
STEP: Saw pod success 05/01/23 23:09:52.675
May  1 23:09:52.675: INFO: Pod "pod-subpath-test-configmap-x8m8" satisfied condition "Succeeded or Failed"
May  1 23:09:52.779: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-configmap-x8m8 container test-container-subpath-configmap-x8m8: <nil>
STEP: delete the pod 05/01/23 23:09:52.885
May  1 23:09:52.997: INFO: Waiting for pod pod-subpath-test-configmap-x8m8 to disappear
May  1 23:09:53.100: INFO: Pod pod-subpath-test-configmap-x8m8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x8m8 05/01/23 23:09:53.1
May  1 23:09:53.100: INFO: Deleting pod "pod-subpath-test-configmap-x8m8" in namespace "subpath-7349"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
May  1 23:09:53.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7349" for this suite. 05/01/23 23:09:53.309
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":85,"skipped":1620,"failed":0}
------------------------------
• [SLOW TEST] [25.989 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:09:27.425
    May  1 23:09:27.425: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename subpath 05/01/23 23:09:27.426
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:27.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:27.944
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 05/01/23 23:09:28.149
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-x8m8 05/01/23 23:09:28.36
    STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:09:28.36
    May  1 23:09:28.467: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x8m8" in namespace "subpath-7349" to be "Succeeded or Failed"
    May  1 23:09:28.571: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Pending", Reason="", readiness=false. Elapsed: 103.550266ms
    May  1 23:09:30.676: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 2.208868368s
    May  1 23:09:32.676: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 4.208898261s
    May  1 23:09:34.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 6.207598596s
    May  1 23:09:36.674: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 8.207218074s
    May  1 23:09:38.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 10.207627325s
    May  1 23:09:40.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 12.207960034s
    May  1 23:09:42.677: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 14.209512254s
    May  1 23:09:44.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 16.208305154s
    May  1 23:09:46.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 18.20775426s
    May  1 23:09:48.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=true. Elapsed: 20.208448318s
    May  1 23:09:50.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Running", Reason="", readiness=false. Elapsed: 22.207662615s
    May  1 23:09:52.675: INFO: Pod "pod-subpath-test-configmap-x8m8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.207844116s
    STEP: Saw pod success 05/01/23 23:09:52.675
    May  1 23:09:52.675: INFO: Pod "pod-subpath-test-configmap-x8m8" satisfied condition "Succeeded or Failed"
    May  1 23:09:52.779: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-configmap-x8m8 container test-container-subpath-configmap-x8m8: <nil>
    STEP: delete the pod 05/01/23 23:09:52.885
    May  1 23:09:52.997: INFO: Waiting for pod pod-subpath-test-configmap-x8m8 to disappear
    May  1 23:09:53.100: INFO: Pod pod-subpath-test-configmap-x8m8 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-x8m8 05/01/23 23:09:53.1
    May  1 23:09:53.100: INFO: Deleting pod "pod-subpath-test-configmap-x8m8" in namespace "subpath-7349"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    May  1 23:09:53.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7349" for this suite. 05/01/23 23:09:53.309
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:09:53.415
May  1 23:09:53.415: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename taint-single-pod 05/01/23 23:09:53.416
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:53.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:53.934
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
May  1 23:09:54.139: INFO: Waiting up to 1m0s for all nodes to be ready
May  1 23:10:54.775: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
May  1 23:10:54.879: INFO: Starting informer...
STEP: Starting pod... 05/01/23 23:10:54.879
May  1 23:10:55.089: INFO: Pod is running on i-0627b78ff917cf2ae. Tainting Node
STEP: Trying to apply a taint on the Node 05/01/23 23:10:55.089
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:10:55.303
STEP: Waiting short time to make sure Pod is queued for deletion 05/01/23 23:10:55.406
May  1 23:10:55.407: INFO: Pod wasn't evicted. Proceeding
May  1 23:10:55.407: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:10:55.631
STEP: Waiting some time to make sure that toleration time passed. 05/01/23 23:10:55.735
May  1 23:12:10.736: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
May  1 23:12:10.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4039" for this suite. 05/01/23 23:12:10.842
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":86,"skipped":1624,"failed":0}
------------------------------
• [SLOW TEST] [137.634 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:09:53.415
    May  1 23:09:53.415: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename taint-single-pod 05/01/23 23:09:53.416
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:09:53.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:09:53.934
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    May  1 23:09:54.139: INFO: Waiting up to 1m0s for all nodes to be ready
    May  1 23:10:54.775: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    May  1 23:10:54.879: INFO: Starting informer...
    STEP: Starting pod... 05/01/23 23:10:54.879
    May  1 23:10:55.089: INFO: Pod is running on i-0627b78ff917cf2ae. Tainting Node
    STEP: Trying to apply a taint on the Node 05/01/23 23:10:55.089
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:10:55.303
    STEP: Waiting short time to make sure Pod is queued for deletion 05/01/23 23:10:55.406
    May  1 23:10:55.407: INFO: Pod wasn't evicted. Proceeding
    May  1 23:10:55.407: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:10:55.631
    STEP: Waiting some time to make sure that toleration time passed. 05/01/23 23:10:55.735
    May  1 23:12:10.736: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:12:10.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-4039" for this suite. 05/01/23 23:12:10.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:11.05
May  1 23:12:11.050: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 23:12:11.051
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:11.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:11.569
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-fc69c89e-e35b-4af4-9777-30b7d8aaa43c 05/01/23 23:12:11.775
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
May  1 23:12:11.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9243" for this suite. 05/01/23 23:12:11.982
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":87,"skipped":1649,"failed":0}
------------------------------
• [1.038 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:11.05
    May  1 23:12:11.050: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 23:12:11.051
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:11.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:11.569
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-fc69c89e-e35b-4af4-9777-30b7d8aaa43c 05/01/23 23:12:11.775
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    May  1 23:12:11.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9243" for this suite. 05/01/23 23:12:11.982
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:12.088
May  1 23:12:12.088: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:12:12.089
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:12.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:12.607
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-76d149d7-bc2f-4528-8f8a-49ca6eed6ea0 05/01/23 23:12:12.813
STEP: Creating a pod to test consume secrets 05/01/23 23:12:12.918
May  1 23:12:13.024: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54" in namespace "projected-4585" to be "Succeeded or Failed"
May  1 23:12:13.128: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54": Phase="Pending", Reason="", readiness=false. Elapsed: 103.676242ms
May  1 23:12:15.233: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208651581s
May  1 23:12:17.233: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208195193s
STEP: Saw pod success 05/01/23 23:12:17.233
May  1 23:12:17.233: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54" satisfied condition "Succeeded or Failed"
May  1 23:12:17.337: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54 container projected-secret-volume-test: <nil>
STEP: delete the pod 05/01/23 23:12:17.449
May  1 23:12:17.561: INFO: Waiting for pod pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54 to disappear
May  1 23:12:17.664: INFO: Pod pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  1 23:12:17.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4585" for this suite. 05/01/23 23:12:17.769
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":88,"skipped":1649,"failed":0}
------------------------------
• [SLOW TEST] [5.786 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:12.088
    May  1 23:12:12.088: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:12:12.089
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:12.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:12.607
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-76d149d7-bc2f-4528-8f8a-49ca6eed6ea0 05/01/23 23:12:12.813
    STEP: Creating a pod to test consume secrets 05/01/23 23:12:12.918
    May  1 23:12:13.024: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54" in namespace "projected-4585" to be "Succeeded or Failed"
    May  1 23:12:13.128: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54": Phase="Pending", Reason="", readiness=false. Elapsed: 103.676242ms
    May  1 23:12:15.233: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208651581s
    May  1 23:12:17.233: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208195193s
    STEP: Saw pod success 05/01/23 23:12:17.233
    May  1 23:12:17.233: INFO: Pod "pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54" satisfied condition "Succeeded or Failed"
    May  1 23:12:17.337: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54 container projected-secret-volume-test: <nil>
    STEP: delete the pod 05/01/23 23:12:17.449
    May  1 23:12:17.561: INFO: Waiting for pod pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54 to disappear
    May  1 23:12:17.664: INFO: Pod pod-projected-secrets-8282ebd3-67d6-4b7a-841e-c0d56d19ac54 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  1 23:12:17.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4585" for this suite. 05/01/23 23:12:17.769
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:17.875
May  1 23:12:17.876: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:12:17.876
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:18.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:18.394
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-2814 05/01/23 23:12:18.6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[] 05/01/23 23:12:18.709
May  1 23:12:19.021: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2814 05/01/23 23:12:19.021
May  1 23:12:19.130: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2814" to be "running and ready"
May  1 23:12:19.234: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.731872ms
May  1 23:12:19.234: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:12:21.338: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.207844803s
May  1 23:12:21.338: INFO: The phase of Pod pod1 is Running (Ready = true)
May  1 23:12:21.338: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[pod1:[80]] 05/01/23 23:12:21.441
May  1 23:12:21.855: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 05/01/23 23:12:21.855
May  1 23:12:21.856: INFO: Creating new exec pod
May  1 23:12:21.962: INFO: Waiting up to 5m0s for pod "execpod4v27l" in namespace "services-2814" to be "running"
May  1 23:12:22.066: INFO: Pod "execpod4v27l": Phase="Pending", Reason="", readiness=false. Elapsed: 103.675769ms
May  1 23:12:24.171: INFO: Pod "execpod4v27l": Phase="Running", Reason="", readiness=true. Elapsed: 2.208756262s
May  1 23:12:24.171: INFO: Pod "execpod4v27l" satisfied condition "running"
May  1 23:12:25.171: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May  1 23:12:26.298: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May  1 23:12:26.298: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:12:26.299: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.243.98 80'
May  1 23:12:27.461: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.243.98 80\nConnection to 100.70.243.98 80 port [tcp/http] succeeded!\n"
May  1 23:12:27.461: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2814 05/01/23 23:12:27.461
May  1 23:12:27.567: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2814" to be "running and ready"
May  1 23:12:27.672: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.403797ms
May  1 23:12:27.672: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:12:29.776: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.208456821s
May  1 23:12:29.776: INFO: The phase of Pod pod2 is Running (Ready = true)
May  1 23:12:29.776: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[pod1:[80] pod2:[80]] 05/01/23 23:12:29.879
May  1 23:12:30.396: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 05/01/23 23:12:30.396
May  1 23:12:31.397: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May  1 23:12:32.512: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May  1 23:12:32.512: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:12:32.513: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.243.98 80'
May  1 23:12:33.636: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.243.98 80\nConnection to 100.70.243.98 80 port [tcp/http] succeeded!\n"
May  1 23:12:33.636: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2814 05/01/23 23:12:33.636
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[pod2:[80]] 05/01/23 23:12:33.754
May  1 23:12:34.173: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 05/01/23 23:12:34.173
May  1 23:12:35.174: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
May  1 23:12:36.300: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
May  1 23:12:36.300: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:12:36.300: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.243.98 80'
May  1 23:12:37.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.243.98 80\nConnection to 100.70.243.98 80 port [tcp/http] succeeded!\n"
May  1 23:12:37.425: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2814 05/01/23 23:12:37.425
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[] 05/01/23 23:12:37.539
May  1 23:12:37.858: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:12:37.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2814" for this suite. 05/01/23 23:12:38.084
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":89,"skipped":1664,"failed":0}
------------------------------
• [SLOW TEST] [20.315 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:17.875
    May  1 23:12:17.876: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:12:17.876
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:18.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:18.394
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-2814 05/01/23 23:12:18.6
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[] 05/01/23 23:12:18.709
    May  1 23:12:19.021: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-2814 05/01/23 23:12:19.021
    May  1 23:12:19.130: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2814" to be "running and ready"
    May  1 23:12:19.234: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.731872ms
    May  1 23:12:19.234: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:12:21.338: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.207844803s
    May  1 23:12:21.338: INFO: The phase of Pod pod1 is Running (Ready = true)
    May  1 23:12:21.338: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[pod1:[80]] 05/01/23 23:12:21.441
    May  1 23:12:21.855: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 05/01/23 23:12:21.855
    May  1 23:12:21.856: INFO: Creating new exec pod
    May  1 23:12:21.962: INFO: Waiting up to 5m0s for pod "execpod4v27l" in namespace "services-2814" to be "running"
    May  1 23:12:22.066: INFO: Pod "execpod4v27l": Phase="Pending", Reason="", readiness=false. Elapsed: 103.675769ms
    May  1 23:12:24.171: INFO: Pod "execpod4v27l": Phase="Running", Reason="", readiness=true. Elapsed: 2.208756262s
    May  1 23:12:24.171: INFO: Pod "execpod4v27l" satisfied condition "running"
    May  1 23:12:25.171: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    May  1 23:12:26.298: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    May  1 23:12:26.298: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:12:26.299: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.243.98 80'
    May  1 23:12:27.461: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.243.98 80\nConnection to 100.70.243.98 80 port [tcp/http] succeeded!\n"
    May  1 23:12:27.461: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-2814 05/01/23 23:12:27.461
    May  1 23:12:27.567: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2814" to be "running and ready"
    May  1 23:12:27.672: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.403797ms
    May  1 23:12:27.672: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:12:29.776: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.208456821s
    May  1 23:12:29.776: INFO: The phase of Pod pod2 is Running (Ready = true)
    May  1 23:12:29.776: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[pod1:[80] pod2:[80]] 05/01/23 23:12:29.879
    May  1 23:12:30.396: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 05/01/23 23:12:30.396
    May  1 23:12:31.397: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    May  1 23:12:32.512: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    May  1 23:12:32.512: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:12:32.513: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.243.98 80'
    May  1 23:12:33.636: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.243.98 80\nConnection to 100.70.243.98 80 port [tcp/http] succeeded!\n"
    May  1 23:12:33.636: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-2814 05/01/23 23:12:33.636
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[pod2:[80]] 05/01/23 23:12:33.754
    May  1 23:12:34.173: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 05/01/23 23:12:34.173
    May  1 23:12:35.174: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    May  1 23:12:36.300: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    May  1 23:12:36.300: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:12:36.300: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2814 exec execpod4v27l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.243.98 80'
    May  1 23:12:37.425: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.243.98 80\nConnection to 100.70.243.98 80 port [tcp/http] succeeded!\n"
    May  1 23:12:37.425: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-2814 05/01/23 23:12:37.425
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2814 to expose endpoints map[] 05/01/23 23:12:37.539
    May  1 23:12:37.858: INFO: successfully validated that service endpoint-test2 in namespace services-2814 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:12:37.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2814" for this suite. 05/01/23 23:12:38.084
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:38.191
May  1 23:12:38.191: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 23:12:38.192
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:38.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:38.71
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
May  1 23:12:38.916: INFO: Creating deployment "test-recreate-deployment"
May  1 23:12:39.022: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May  1 23:12:39.229: INFO: Waiting deployment "test-recreate-deployment" to complete
May  1 23:12:39.333: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 12, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 12, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 12, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 12, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:12:41.437: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May  1 23:12:41.648: INFO: Updating deployment test-recreate-deployment
May  1 23:12:41.648: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 23:12:41.855: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1140  7e0a0d75-3611-4fce-8215-3589ddd370fc 13284 2 2023-05-01 23:12:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00326d6c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-05-01 23:12:41 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-05-01 23:12:41 +0000 UTC,LastTransitionTime:2023-05-01 23:12:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

May  1 23:12:41.959: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1140  73937c9b-5940-4c78-b892-97b4a7b24a96 13283 1 2023-05-01 23:12:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7e0a0d75-3611-4fce-8215-3589ddd370fc 0xc001cc9da0 0xc001cc9da1}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e0a0d75-3611-4fce-8215-3589ddd370fc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  1 23:12:41.959: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May  1 23:12:41.960: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1140  a36a5ce0-0b2a-430e-b1fc-72f0b6458656 13275 2 2023-05-01 23:12:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7e0a0d75-3611-4fce-8215-3589ddd370fc 0xc001cc9c87 0xc001cc9c88}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e0a0d75-3611-4fce-8215-3589ddd370fc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  1 23:12:42.064: INFO: Pod "test-recreate-deployment-9d58999df-wldhq" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-wldhq test-recreate-deployment-9d58999df- deployment-1140  7e6c9666-f7ef-4ff5-bc2f-b9f540e702dd 13282 0 2023-05-01 23:12:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 73937c9b-5940-4c78-b892-97b4a7b24a96 0xc003f2a2a0 0xc003f2a2a1}] [] [{kube-controller-manager Update v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"73937c9b-5940-4c78-b892-97b4a7b24a96\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2snl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2snl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-01 23:12:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 23:12:42.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1140" for this suite. 05/01/23 23:12:42.169
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":90,"skipped":1667,"failed":0}
------------------------------
• [4.184 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:38.191
    May  1 23:12:38.191: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 23:12:38.192
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:38.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:38.71
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    May  1 23:12:38.916: INFO: Creating deployment "test-recreate-deployment"
    May  1 23:12:39.022: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    May  1 23:12:39.229: INFO: Waiting deployment "test-recreate-deployment" to complete
    May  1 23:12:39.333: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 12, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 12, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 12, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 12, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:12:41.437: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    May  1 23:12:41.648: INFO: Updating deployment test-recreate-deployment
    May  1 23:12:41.648: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 23:12:41.855: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-1140  7e0a0d75-3611-4fce-8215-3589ddd370fc 13284 2 2023-05-01 23:12:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00326d6c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-05-01 23:12:41 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-05-01 23:12:41 +0000 UTC,LastTransitionTime:2023-05-01 23:12:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    May  1 23:12:41.959: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1140  73937c9b-5940-4c78-b892-97b4a7b24a96 13283 1 2023-05-01 23:12:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7e0a0d75-3611-4fce-8215-3589ddd370fc 0xc001cc9da0 0xc001cc9da1}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e0a0d75-3611-4fce-8215-3589ddd370fc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    May  1 23:12:41.959: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    May  1 23:12:41.960: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1140  a36a5ce0-0b2a-430e-b1fc-72f0b6458656 13275 2 2023-05-01 23:12:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7e0a0d75-3611-4fce-8215-3589ddd370fc 0xc001cc9c87 0xc001cc9c88}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e0a0d75-3611-4fce-8215-3589ddd370fc\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    May  1 23:12:42.064: INFO: Pod "test-recreate-deployment-9d58999df-wldhq" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-wldhq test-recreate-deployment-9d58999df- deployment-1140  7e6c9666-f7ef-4ff5-bc2f-b9f540e702dd 13282 0 2023-05-01 23:12:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 73937c9b-5940-4c78-b892-97b4a7b24a96 0xc003f2a2a0 0xc003f2a2a1}] [] [{kube-controller-manager Update v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"73937c9b-5940-4c78-b892-97b4a7b24a96\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:12:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2snl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2snl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:12:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-01 23:12:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 23:12:42.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1140" for this suite. 05/01/23 23:12:42.169
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:42.376
May  1 23:12:42.376: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename tables 05/01/23 23:12:42.378
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:42.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:42.895
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
May  1 23:12:43.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4026" for this suite. 05/01/23 23:12:43.41
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":91,"skipped":1667,"failed":0}
------------------------------
• [1.140 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:42.376
    May  1 23:12:42.376: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename tables 05/01/23 23:12:42.378
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:42.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:42.895
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    May  1 23:12:43.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-4026" for this suite. 05/01/23 23:12:43.41
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:43.517
May  1 23:12:43.517: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:12:43.518
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:43.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:44.035
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-30fb380f-c300-4043-90ce-180f5b00243e 05/01/23 23:12:44.241
STEP: Creating a pod to test consume configMaps 05/01/23 23:12:44.346
May  1 23:12:44.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7" in namespace "configmap-8869" to be "Succeeded or Failed"
May  1 23:12:44.557: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.675544ms
May  1 23:12:46.662: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208352795s
May  1 23:12:48.662: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208428665s
STEP: Saw pod success 05/01/23 23:12:48.662
May  1 23:12:48.662: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7" satisfied condition "Succeeded or Failed"
May  1 23:12:48.766: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 23:12:48.872
May  1 23:12:48.985: INFO: Waiting for pod pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7 to disappear
May  1 23:12:49.089: INFO: Pod pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:12:49.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8869" for this suite. 05/01/23 23:12:49.194
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":92,"skipped":1669,"failed":0}
------------------------------
• [SLOW TEST] [5.782 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:43.517
    May  1 23:12:43.517: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:12:43.518
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:43.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:44.035
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-30fb380f-c300-4043-90ce-180f5b00243e 05/01/23 23:12:44.241
    STEP: Creating a pod to test consume configMaps 05/01/23 23:12:44.346
    May  1 23:12:44.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7" in namespace "configmap-8869" to be "Succeeded or Failed"
    May  1 23:12:44.557: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.675544ms
    May  1 23:12:46.662: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208352795s
    May  1 23:12:48.662: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208428665s
    STEP: Saw pod success 05/01/23 23:12:48.662
    May  1 23:12:48.662: INFO: Pod "pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7" satisfied condition "Succeeded or Failed"
    May  1 23:12:48.766: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 23:12:48.872
    May  1 23:12:48.985: INFO: Waiting for pod pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7 to disappear
    May  1 23:12:49.089: INFO: Pod pod-configmaps-2019bf33-7855-4536-a43b-222686407ac7 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:12:49.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8869" for this suite. 05/01/23 23:12:49.194
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:49.299
May  1 23:12:49.300: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:12:49.3
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:49.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:49.817
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:12:50.023
May  1 23:12:50.131: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89" in namespace "projected-5801" to be "Succeeded or Failed"
May  1 23:12:50.234: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89": Phase="Pending", Reason="", readiness=false. Elapsed: 103.654504ms
May  1 23:12:52.339: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20786456s
May  1 23:12:54.339: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207725077s
STEP: Saw pod success 05/01/23 23:12:54.339
May  1 23:12:54.339: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89" satisfied condition "Succeeded or Failed"
May  1 23:12:54.442: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89 container client-container: <nil>
STEP: delete the pod 05/01/23 23:12:54.556
May  1 23:12:54.666: INFO: Waiting for pod downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89 to disappear
May  1 23:12:54.770: INFO: Pod downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  1 23:12:54.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5801" for this suite. 05/01/23 23:12:54.875
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":93,"skipped":1673,"failed":0}
------------------------------
• [SLOW TEST] [5.781 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:49.299
    May  1 23:12:49.300: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:12:49.3
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:49.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:49.817
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:12:50.023
    May  1 23:12:50.131: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89" in namespace "projected-5801" to be "Succeeded or Failed"
    May  1 23:12:50.234: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89": Phase="Pending", Reason="", readiness=false. Elapsed: 103.654504ms
    May  1 23:12:52.339: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20786456s
    May  1 23:12:54.339: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207725077s
    STEP: Saw pod success 05/01/23 23:12:54.339
    May  1 23:12:54.339: INFO: Pod "downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89" satisfied condition "Succeeded or Failed"
    May  1 23:12:54.442: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:12:54.556
    May  1 23:12:54.666: INFO: Waiting for pod downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89 to disappear
    May  1 23:12:54.770: INFO: Pod downwardapi-volume-0bf023b7-2321-4e0c-9851-2002cfe39c89 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  1 23:12:54.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5801" for this suite. 05/01/23 23:12:54.875
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:12:55.084
May  1 23:12:55.084: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/01/23 23:12:55.085
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:55.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:55.603
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 05/01/23 23:12:55.808
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6633;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6633;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +notcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_tcp@PTR;sleep 1; done
 05/01/23 23:12:56.023
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6633;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6633;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +notcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_tcp@PTR;sleep 1; done
 05/01/23 23:12:56.023
STEP: creating a pod to probe DNS 05/01/23 23:12:56.023
STEP: submitting the pod to kubernetes 05/01/23 23:12:56.023
May  1 23:12:56.132: INFO: Waiting up to 15m0s for pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb" in namespace "dns-6633" to be "running"
May  1 23:12:56.236: INFO: Pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb": Phase="Pending", Reason="", readiness=false. Elapsed: 103.904105ms
May  1 23:12:58.342: INFO: Pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.209302162s
May  1 23:12:58.342: INFO: Pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb" satisfied condition "running"
STEP: retrieving the pod 05/01/23 23:12:58.342
STEP: looking for the results for each expected name from probers 05/01/23 23:12:58.445
May  1 23:12:58.550: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:58.654: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:58.760: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:58.864: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:58.969: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:59.073: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:59.177: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:59.282: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:59.803: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:12:59.907: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.011: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.115: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.220: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.324: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.428: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.533: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:00.950: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

May  1 23:13:06.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.160: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.264: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.474: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.578: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.682: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:06.787: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.308: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.414: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.518: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.622: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.727: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.831: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:07.935: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:08.040: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:08.460: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

May  1 23:13:11.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.471: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:11.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.306: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.410: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.514: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.723: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.828: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:12.932: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:13.036: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:13.455: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

May  1 23:13:16.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.471: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.575: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.679: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:16.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.306: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.410: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.514: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.723: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.827: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:17.937: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:18.041: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:18.462: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

May  1 23:13:21.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.471: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.575: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.679: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:21.783: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.304: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.409: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.513: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.617: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.721: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.826: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:22.930: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:23.034: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:23.451: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

May  1 23:13:26.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.160: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.264: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.472: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:26.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.305: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.409: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.513: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.617: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.721: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.825: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:27.930: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:28.034: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
May  1 23:13:28.454: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

May  1 23:13:33.452: INFO: DNS probes using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb succeeded

STEP: deleting the pod 05/01/23 23:13:33.452
STEP: deleting the test service 05/01/23 23:13:33.573
STEP: deleting the test headless service 05/01/23 23:13:33.692
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  1 23:13:33.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6633" for this suite. 05/01/23 23:13:33.912
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":94,"skipped":1726,"failed":0}
------------------------------
• [SLOW TEST] [38.934 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:12:55.084
    May  1 23:12:55.084: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/01/23 23:12:55.085
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:12:55.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:12:55.603
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 05/01/23 23:12:55.808
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6633;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6633;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +notcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_tcp@PTR;sleep 1; done
     05/01/23 23:12:56.023
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6633;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6633;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6633.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6633.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6633.svc;check="$$(dig +notcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_udp@PTR;check="$$(dig +tcp +noall +answer +search 23.22.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.22.23_tcp@PTR;sleep 1; done
     05/01/23 23:12:56.023
    STEP: creating a pod to probe DNS 05/01/23 23:12:56.023
    STEP: submitting the pod to kubernetes 05/01/23 23:12:56.023
    May  1 23:12:56.132: INFO: Waiting up to 15m0s for pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb" in namespace "dns-6633" to be "running"
    May  1 23:12:56.236: INFO: Pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb": Phase="Pending", Reason="", readiness=false. Elapsed: 103.904105ms
    May  1 23:12:58.342: INFO: Pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.209302162s
    May  1 23:12:58.342: INFO: Pod "dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 23:12:58.342
    STEP: looking for the results for each expected name from probers 05/01/23 23:12:58.445
    May  1 23:12:58.550: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:58.654: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:58.760: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:58.864: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:58.969: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:59.073: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:59.177: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:59.282: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:59.803: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:12:59.907: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.011: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.115: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.220: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.324: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.428: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.533: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:00.950: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

    May  1 23:13:06.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.160: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.264: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.474: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.578: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.682: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:06.787: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.308: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.414: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.518: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.622: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.727: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.831: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:07.935: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:08.040: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:08.460: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

    May  1 23:13:11.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.471: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:11.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.306: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.410: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.514: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.723: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.828: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:12.932: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:13.036: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:13.455: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

    May  1 23:13:16.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.471: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.575: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.679: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:16.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.306: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.410: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.514: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.723: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.827: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:17.937: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:18.041: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:18.462: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

    May  1 23:13:21.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.159: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.471: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.575: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.679: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:21.783: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.304: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.409: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.513: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.617: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.721: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.826: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:22.930: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:23.034: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:23.451: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

    May  1 23:13:26.055: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.160: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.264: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.472: INFO: Unable to read wheezy_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.576: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.680: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:26.784: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.305: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.409: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.513: INFO: Unable to read jessie_udp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.617: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633 from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.721: INFO: Unable to read jessie_udp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.825: INFO: Unable to read jessie_tcp@dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:27.930: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:28.034: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc from pod dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb: the server could not find the requested resource (get pods dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb)
    May  1 23:13:28.454: INFO: Lookups using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6633 wheezy_tcp@dns-test-service.dns-6633 wheezy_udp@dns-test-service.dns-6633.svc wheezy_tcp@dns-test-service.dns-6633.svc wheezy_udp@_http._tcp.dns-test-service.dns-6633.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6633.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6633 jessie_tcp@dns-test-service.dns-6633 jessie_udp@dns-test-service.dns-6633.svc jessie_tcp@dns-test-service.dns-6633.svc jessie_udp@_http._tcp.dns-test-service.dns-6633.svc jessie_tcp@_http._tcp.dns-test-service.dns-6633.svc]

    May  1 23:13:33.452: INFO: DNS probes using dns-6633/dns-test-0ebb6549-0e1d-4870-b9e2-6c868dbca3bb succeeded

    STEP: deleting the pod 05/01/23 23:13:33.452
    STEP: deleting the test service 05/01/23 23:13:33.573
    STEP: deleting the test headless service 05/01/23 23:13:33.692
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  1 23:13:33.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6633" for this suite. 05/01/23 23:13:33.912
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:13:34.021
May  1 23:13:34.021: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/01/23 23:13:34.022
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:13:34.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:13:34.539
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 05/01/23 23:13:34.746
May  1 23:13:34.854: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7944  0337391e-9a15-4e00-8108-d3c5b0f222fc 13571 0 2023-05-01 23:13:34 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-05-01 23:13:34 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-grxdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-grxdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  1 23:13:34.855: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-7944" to be "running and ready"
May  1 23:13:34.958: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 103.722526ms
May  1 23:13:34.958: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
May  1 23:13:37.063: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.208309148s
May  1 23:13:37.063: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
May  1 23:13:37.063: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 05/01/23 23:13:37.063
May  1 23:13:37.063: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7944 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:13:37.063: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:13:37.065: INFO: ExecWithOptions: Clientset creation
May  1 23:13:37.065: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/dns-7944/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 05/01/23 23:13:37.817
May  1 23:13:37.817: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7944 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:13:37.817: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:13:37.818: INFO: ExecWithOptions: Clientset creation
May  1 23:13:37.818: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/dns-7944/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  1 23:13:38.541: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  1 23:13:38.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7944" for this suite. 05/01/23 23:13:38.76
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":95,"skipped":1786,"failed":0}
------------------------------
• [4.846 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:13:34.021
    May  1 23:13:34.021: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/01/23 23:13:34.022
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:13:34.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:13:34.539
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 05/01/23 23:13:34.746
    May  1 23:13:34.854: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7944  0337391e-9a15-4e00-8108-d3c5b0f222fc 13571 0 2023-05-01 23:13:34 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-05-01 23:13:34 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-grxdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-grxdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  1 23:13:34.855: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-7944" to be "running and ready"
    May  1 23:13:34.958: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 103.722526ms
    May  1 23:13:34.958: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:13:37.063: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.208309148s
    May  1 23:13:37.063: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    May  1 23:13:37.063: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 05/01/23 23:13:37.063
    May  1 23:13:37.063: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7944 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:13:37.063: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:13:37.065: INFO: ExecWithOptions: Clientset creation
    May  1 23:13:37.065: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/dns-7944/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 05/01/23 23:13:37.817
    May  1 23:13:37.817: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7944 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:13:37.817: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:13:37.818: INFO: ExecWithOptions: Clientset creation
    May  1 23:13:37.818: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/dns-7944/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  1 23:13:38.541: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  1 23:13:38.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7944" for this suite. 05/01/23 23:13:38.76
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:13:38.867
May  1 23:13:38.867: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:13:38.868
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:13:39.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:13:39.385
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
STEP: creating service in namespace services-918 05/01/23 23:13:39.591
STEP: creating service affinity-nodeport-transition in namespace services-918 05/01/23 23:13:39.591
STEP: creating replication controller affinity-nodeport-transition in namespace services-918 05/01/23 23:13:39.704
I0501 23:13:39.810307    6969 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-918, replica count: 3
I0501 23:13:42.961667    6969 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  1 23:13:43.273: INFO: Creating new exec pod
May  1 23:13:43.380: INFO: Waiting up to 5m0s for pod "execpod-affinity84kmq" in namespace "services-918" to be "running"
May  1 23:13:43.483: INFO: Pod "execpod-affinity84kmq": Phase="Pending", Reason="", readiness=false. Elapsed: 103.673177ms
May  1 23:13:45.596: INFO: Pod "execpod-affinity84kmq": Phase="Running", Reason="", readiness=true. Elapsed: 2.216537499s
May  1 23:13:45.596: INFO: Pod "execpod-affinity84kmq" satisfied condition "running"
May  1 23:13:46.701: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
May  1 23:13:47.821: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
May  1 23:13:47.821: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:13:47.821: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.54.149 80'
May  1 23:13:48.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.54.149 80\nConnection to 100.65.54.149 80 port [tcp/http] succeeded!\n"
May  1 23:13:48.927: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:13:48.927: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.48.211 31138'
May  1 23:13:50.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.48.211 31138\nConnection to 172.20.48.211 31138 port [tcp/*] succeeded!\n"
May  1 23:13:50.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:13:50.013: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 31138'
May  1 23:13:51.107: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.39.145 31138\nConnection to 172.20.39.145 31138 port [tcp/*] succeeded!\n"
May  1 23:13:51.107: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:13:51.315: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.44.200:31138/ ; done'
May  1 23:13:52.532: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n"
May  1 23:13:52.532: INFO: stdout: "\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-r8klb"
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
May  1 23:13:52.746: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.44.200:31138/ ; done'
May  1 23:13:53.961: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n"
May  1 23:13:53.961: INFO: stdout: "\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg"
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
May  1 23:13:53.961: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-918, will wait for the garbage collector to delete the pods 05/01/23 23:13:54.073
May  1 23:13:54.434: INFO: Deleting ReplicationController affinity-nodeport-transition took: 106.040735ms
May  1 23:13:54.535: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.484755ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:13:57.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-918" for this suite. 05/01/23 23:13:57.358
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":96,"skipped":1810,"failed":0}
------------------------------
• [SLOW TEST] [18.596 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:13:38.867
    May  1 23:13:38.867: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:13:38.868
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:13:39.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:13:39.385
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2216
    STEP: creating service in namespace services-918 05/01/23 23:13:39.591
    STEP: creating service affinity-nodeport-transition in namespace services-918 05/01/23 23:13:39.591
    STEP: creating replication controller affinity-nodeport-transition in namespace services-918 05/01/23 23:13:39.704
    I0501 23:13:39.810307    6969 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-918, replica count: 3
    I0501 23:13:42.961667    6969 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  1 23:13:43.273: INFO: Creating new exec pod
    May  1 23:13:43.380: INFO: Waiting up to 5m0s for pod "execpod-affinity84kmq" in namespace "services-918" to be "running"
    May  1 23:13:43.483: INFO: Pod "execpod-affinity84kmq": Phase="Pending", Reason="", readiness=false. Elapsed: 103.673177ms
    May  1 23:13:45.596: INFO: Pod "execpod-affinity84kmq": Phase="Running", Reason="", readiness=true. Elapsed: 2.216537499s
    May  1 23:13:45.596: INFO: Pod "execpod-affinity84kmq" satisfied condition "running"
    May  1 23:13:46.701: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    May  1 23:13:47.821: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    May  1 23:13:47.821: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:13:47.821: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.54.149 80'
    May  1 23:13:48.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.54.149 80\nConnection to 100.65.54.149 80 port [tcp/http] succeeded!\n"
    May  1 23:13:48.927: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:13:48.927: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.48.211 31138'
    May  1 23:13:50.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.48.211 31138\nConnection to 172.20.48.211 31138 port [tcp/*] succeeded!\n"
    May  1 23:13:50.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:13:50.013: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 31138'
    May  1 23:13:51.107: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.39.145 31138\nConnection to 172.20.39.145 31138 port [tcp/*] succeeded!\n"
    May  1 23:13:51.107: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:13:51.315: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.44.200:31138/ ; done'
    May  1 23:13:52.532: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n"
    May  1 23:13:52.532: INFO: stdout: "\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-hgrp6\naffinity-nodeport-transition-r8klb\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-r8klb"
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-hgrp6
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:52.532: INFO: Received response from host: affinity-nodeport-transition-r8klb
    May  1 23:13:52.746: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-918 exec execpod-affinity84kmq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.44.200:31138/ ; done'
    May  1 23:13:53.961: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31138/\n"
    May  1 23:13:53.961: INFO: stdout: "\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg\naffinity-nodeport-transition-h4nfg"
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Received response from host: affinity-nodeport-transition-h4nfg
    May  1 23:13:53.961: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-918, will wait for the garbage collector to delete the pods 05/01/23 23:13:54.073
    May  1 23:13:54.434: INFO: Deleting ReplicationController affinity-nodeport-transition took: 106.040735ms
    May  1 23:13:54.535: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.484755ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:13:57.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-918" for this suite. 05/01/23 23:13:57.358
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:13:57.465
May  1 23:13:57.465: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename limitrange 05/01/23 23:13:57.466
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:13:57.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:13:57.983
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 05/01/23 23:13:58.188
STEP: Setting up watch 05/01/23 23:13:58.188
STEP: Submitting a LimitRange 05/01/23 23:13:58.492
STEP: Verifying LimitRange creation was observed 05/01/23 23:13:58.598
STEP: Fetching the LimitRange to ensure it has proper values 05/01/23 23:13:58.598
May  1 23:13:58.702: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May  1 23:13:58.702: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 05/01/23 23:13:58.702
STEP: Ensuring Pod has resource requirements applied from LimitRange 05/01/23 23:13:58.809
May  1 23:13:58.912: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
May  1 23:13:58.913: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 05/01/23 23:13:58.913
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 05/01/23 23:13:59.018
May  1 23:13:59.122: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
May  1 23:13:59.122: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 05/01/23 23:13:59.122
STEP: Failing to create a Pod with more than max resources 05/01/23 23:13:59.226
STEP: Updating a LimitRange 05/01/23 23:13:59.329
STEP: Verifying LimitRange updating is effective 05/01/23 23:13:59.434
STEP: Creating a Pod with less than former min resources 05/01/23 23:14:01.539
STEP: Failing to create a Pod with more than max resources 05/01/23 23:14:01.645
STEP: Deleting a LimitRange 05/01/23 23:14:01.749
STEP: Verifying the LimitRange was deleted 05/01/23 23:14:01.854
May  1 23:14:06.961: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 05/01/23 23:14:06.961
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
May  1 23:14:07.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-6296" for this suite. 05/01/23 23:14:07.174
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":97,"skipped":1846,"failed":0}
------------------------------
• [SLOW TEST] [9.815 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:13:57.465
    May  1 23:13:57.465: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename limitrange 05/01/23 23:13:57.466
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:13:57.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:13:57.983
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 05/01/23 23:13:58.188
    STEP: Setting up watch 05/01/23 23:13:58.188
    STEP: Submitting a LimitRange 05/01/23 23:13:58.492
    STEP: Verifying LimitRange creation was observed 05/01/23 23:13:58.598
    STEP: Fetching the LimitRange to ensure it has proper values 05/01/23 23:13:58.598
    May  1 23:13:58.702: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    May  1 23:13:58.702: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 05/01/23 23:13:58.702
    STEP: Ensuring Pod has resource requirements applied from LimitRange 05/01/23 23:13:58.809
    May  1 23:13:58.912: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    May  1 23:13:58.913: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 05/01/23 23:13:58.913
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 05/01/23 23:13:59.018
    May  1 23:13:59.122: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    May  1 23:13:59.122: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 05/01/23 23:13:59.122
    STEP: Failing to create a Pod with more than max resources 05/01/23 23:13:59.226
    STEP: Updating a LimitRange 05/01/23 23:13:59.329
    STEP: Verifying LimitRange updating is effective 05/01/23 23:13:59.434
    STEP: Creating a Pod with less than former min resources 05/01/23 23:14:01.539
    STEP: Failing to create a Pod with more than max resources 05/01/23 23:14:01.645
    STEP: Deleting a LimitRange 05/01/23 23:14:01.749
    STEP: Verifying the LimitRange was deleted 05/01/23 23:14:01.854
    May  1 23:14:06.961: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 05/01/23 23:14:06.961
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    May  1 23:14:07.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-6296" for this suite. 05/01/23 23:14:07.174
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:14:07.281
May  1 23:14:07.282: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename disruption 05/01/23 23:14:07.283
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:07.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:07.802
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:14:08.007
May  1 23:14:08.007: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename disruption-2 05/01/23 23:14:08.009
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:08.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:08.526
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 05/01/23 23:14:08.838
STEP: Waiting for the pdb to be processed 05/01/23 23:14:09.046
STEP: Waiting for the pdb to be processed 05/01/23 23:14:09.255
STEP: listing a collection of PDBs across all namespaces 05/01/23 23:14:09.359
STEP: listing a collection of PDBs in namespace disruption-3 05/01/23 23:14:09.463
STEP: deleting a collection of PDBs 05/01/23 23:14:09.567
STEP: Waiting for the PDB collection to be deleted 05/01/23 23:14:09.675
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
May  1 23:14:09.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1562" for this suite. 05/01/23 23:14:09.883
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
May  1 23:14:09.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3" for this suite. 05/01/23 23:14:10.094
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":98,"skipped":1862,"failed":0}
------------------------------
• [2.918 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:14:07.281
    May  1 23:14:07.282: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename disruption 05/01/23 23:14:07.283
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:07.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:07.802
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:14:08.007
    May  1 23:14:08.007: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename disruption-2 05/01/23 23:14:08.009
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:08.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:08.526
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 05/01/23 23:14:08.838
    STEP: Waiting for the pdb to be processed 05/01/23 23:14:09.046
    STEP: Waiting for the pdb to be processed 05/01/23 23:14:09.255
    STEP: listing a collection of PDBs across all namespaces 05/01/23 23:14:09.359
    STEP: listing a collection of PDBs in namespace disruption-3 05/01/23 23:14:09.463
    STEP: deleting a collection of PDBs 05/01/23 23:14:09.567
    STEP: Waiting for the PDB collection to be deleted 05/01/23 23:14:09.675
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    May  1 23:14:09.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-1562" for this suite. 05/01/23 23:14:09.883
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    May  1 23:14:09.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3" for this suite. 05/01/23 23:14:10.094
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:14:10.202
May  1 23:14:10.202: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch 05/01/23 23:14:10.203
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:10.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:10.721
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 05/01/23 23:14:10.926
STEP: creating a watch on configmaps with label B 05/01/23 23:14:11.029
STEP: creating a watch on configmaps with label A or B 05/01/23 23:14:11.132
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 05/01/23 23:14:11.235
May  1 23:14:11.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13840 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:14:11.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13840 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 05/01/23 23:14:11.34
May  1 23:14:11.548: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13842 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:14:11.548: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13842 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 05/01/23 23:14:11.549
May  1 23:14:11.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13844 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:14:11.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13844 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 05/01/23 23:14:11.757
May  1 23:14:11.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13845 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:14:11.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13845 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 05/01/23 23:14:11.862
May  1 23:14:11.967: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13847 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:14:11.967: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13847 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 05/01/23 23:14:21.967
May  1 23:14:22.073: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13899 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:14:22.074: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13899 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
May  1 23:14:32.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9734" for this suite. 05/01/23 23:14:32.18
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":99,"skipped":1891,"failed":0}
------------------------------
• [SLOW TEST] [22.083 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:14:10.202
    May  1 23:14:10.202: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename watch 05/01/23 23:14:10.203
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:10.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:10.721
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 05/01/23 23:14:10.926
    STEP: creating a watch on configmaps with label B 05/01/23 23:14:11.029
    STEP: creating a watch on configmaps with label A or B 05/01/23 23:14:11.132
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 05/01/23 23:14:11.235
    May  1 23:14:11.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13840 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:14:11.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13840 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 05/01/23 23:14:11.34
    May  1 23:14:11.548: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13842 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:14:11.548: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13842 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 05/01/23 23:14:11.549
    May  1 23:14:11.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13844 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:14:11.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13844 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 05/01/23 23:14:11.757
    May  1 23:14:11.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13845 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:14:11.862: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9734  0698c0ec-1f2b-49a9-9637-b29db844dc80 13845 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 05/01/23 23:14:11.862
    May  1 23:14:11.967: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13847 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:14:11.967: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13847 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 05/01/23 23:14:21.967
    May  1 23:14:22.073: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13899 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:14:22.074: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9734  cd3b850f-2c6d-4355-bfc0-53dbbeae690b 13899 0 2023-05-01 23:14:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-05-01 23:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    May  1 23:14:32.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9734" for this suite. 05/01/23 23:14:32.18
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:14:32.287
May  1 23:14:32.287: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/01/23 23:14:32.288
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:32.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:32.807
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 05/01/23 23:14:33.012
May  1 23:14:33.120: INFO: Waiting up to 5m0s for pod "pod-ktgs9" in namespace "pods-7047" to be "running"
May  1 23:14:33.224: INFO: Pod "pod-ktgs9": Phase="Pending", Reason="", readiness=false. Elapsed: 103.784081ms
May  1 23:14:35.328: INFO: Pod "pod-ktgs9": Phase="Running", Reason="", readiness=true. Elapsed: 2.207747068s
May  1 23:14:35.328: INFO: Pod "pod-ktgs9" satisfied condition "running"
STEP: patching /status 05/01/23 23:14:35.328
May  1 23:14:35.435: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  1 23:14:35.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7047" for this suite. 05/01/23 23:14:35.542
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":100,"skipped":1902,"failed":0}
------------------------------
• [3.364 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:14:32.287
    May  1 23:14:32.287: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/01/23 23:14:32.288
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:32.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:32.807
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 05/01/23 23:14:33.012
    May  1 23:14:33.120: INFO: Waiting up to 5m0s for pod "pod-ktgs9" in namespace "pods-7047" to be "running"
    May  1 23:14:33.224: INFO: Pod "pod-ktgs9": Phase="Pending", Reason="", readiness=false. Elapsed: 103.784081ms
    May  1 23:14:35.328: INFO: Pod "pod-ktgs9": Phase="Running", Reason="", readiness=true. Elapsed: 2.207747068s
    May  1 23:14:35.328: INFO: Pod "pod-ktgs9" satisfied condition "running"
    STEP: patching /status 05/01/23 23:14:35.328
    May  1 23:14:35.435: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  1 23:14:35.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7047" for this suite. 05/01/23 23:14:35.542
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:14:35.651
May  1 23:14:35.651: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename taint-multiple-pods 05/01/23 23:14:35.652
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:35.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:36.168
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
May  1 23:14:36.374: INFO: Waiting up to 1m0s for all nodes to be ready
May  1 23:15:37.007: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
May  1 23:15:37.111: INFO: Starting informer...
STEP: Starting pods... 05/01/23 23:15:37.111
May  1 23:15:37.426: INFO: Pod1 is running on i-02d061b30635c230c. Tainting Node
May  1 23:15:37.633: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-3676" to be "running"
May  1 23:15:37.737: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.412583ms
May  1 23:15:39.841: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.207972093s
May  1 23:15:39.841: INFO: Pod "taint-eviction-b1" satisfied condition "running"
May  1 23:15:39.841: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-3676" to be "running"
May  1 23:15:39.945: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 103.899188ms
May  1 23:15:39.945: INFO: Pod "taint-eviction-b2" satisfied condition "running"
May  1 23:15:39.945: INFO: Pod2 is running on i-02d061b30635c230c. Tainting Node
STEP: Trying to apply a taint on the Node 05/01/23 23:15:39.945
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:15:40.159
STEP: Waiting for Pod1 and Pod2 to be deleted 05/01/23 23:15:40.263
May  1 23:15:46.169: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
May  1 23:16:06.212: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:16:06.426
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
May  1 23:16:06.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-3676" for this suite. 05/01/23 23:16:06.634
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":101,"skipped":1907,"failed":0}
------------------------------
• [SLOW TEST] [91.089 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:14:35.651
    May  1 23:14:35.651: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename taint-multiple-pods 05/01/23 23:14:35.652
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:14:35.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:14:36.168
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    May  1 23:14:36.374: INFO: Waiting up to 1m0s for all nodes to be ready
    May  1 23:15:37.007: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    May  1 23:15:37.111: INFO: Starting informer...
    STEP: Starting pods... 05/01/23 23:15:37.111
    May  1 23:15:37.426: INFO: Pod1 is running on i-02d061b30635c230c. Tainting Node
    May  1 23:15:37.633: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-3676" to be "running"
    May  1 23:15:37.737: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.412583ms
    May  1 23:15:39.841: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.207972093s
    May  1 23:15:39.841: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    May  1 23:15:39.841: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-3676" to be "running"
    May  1 23:15:39.945: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 103.899188ms
    May  1 23:15:39.945: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    May  1 23:15:39.945: INFO: Pod2 is running on i-02d061b30635c230c. Tainting Node
    STEP: Trying to apply a taint on the Node 05/01/23 23:15:39.945
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:15:40.159
    STEP: Waiting for Pod1 and Pod2 to be deleted 05/01/23 23:15:40.263
    May  1 23:15:46.169: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    May  1 23:16:06.212: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 05/01/23 23:16:06.426
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:16:06.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-3676" for this suite. 05/01/23 23:16:06.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:16:06.74
May  1 23:16:06.740: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename disruption 05/01/23 23:16:06.741
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:07.053
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:07.259
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 05/01/23 23:16:07.569
STEP: Waiting for all pods to be running 05/01/23 23:16:07.996
May  1 23:16:08.100: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
May  1 23:16:10.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3407" for this suite. 05/01/23 23:16:10.414
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":102,"skipped":1915,"failed":0}
------------------------------
• [3.778 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:16:06.74
    May  1 23:16:06.740: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename disruption 05/01/23 23:16:06.741
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:07.053
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:07.259
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 05/01/23 23:16:07.569
    STEP: Waiting for all pods to be running 05/01/23 23:16:07.996
    May  1 23:16:08.100: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    May  1 23:16:10.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3407" for this suite. 05/01/23 23:16:10.414
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:16:10.522
May  1 23:16:10.522: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:16:10.524
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:10.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:11.042
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:16:11.458
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:16:12.204
STEP: Deploying the webhook pod 05/01/23 23:16:12.311
STEP: Wait for the deployment to be ready 05/01/23 23:16:12.524
May  1 23:16:12.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:16:14.942
STEP: Verifying the service has paired with the endpoint 05/01/23 23:16:15.054
May  1 23:16:16.055: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 05/01/23 23:16:16.159
STEP: create a pod that should be denied by the webhook 05/01/23 23:16:16.374
STEP: create a pod that causes the webhook to hang 05/01/23 23:16:16.487
STEP: create a configmap that should be denied by the webhook 05/01/23 23:16:26.697
STEP: create a configmap that should be admitted by the webhook 05/01/23 23:16:26.824
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 05/01/23 23:16:26.934
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 05/01/23 23:16:27.143
STEP: create a namespace that bypass the webhook 05/01/23 23:16:27.252
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 05/01/23 23:16:27.359
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:16:27.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9282" for this suite. 05/01/23 23:16:27.784
STEP: Destroying namespace "webhook-9282-markers" for this suite. 05/01/23 23:16:27.889
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":103,"skipped":1973,"failed":0}
------------------------------
• [SLOW TEST] [17.914 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:16:10.522
    May  1 23:16:10.522: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:16:10.524
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:10.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:11.042
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:16:11.458
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:16:12.204
    STEP: Deploying the webhook pod 05/01/23 23:16:12.311
    STEP: Wait for the deployment to be ready 05/01/23 23:16:12.524
    May  1 23:16:12.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:16:14.942
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:16:15.054
    May  1 23:16:16.055: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 05/01/23 23:16:16.159
    STEP: create a pod that should be denied by the webhook 05/01/23 23:16:16.374
    STEP: create a pod that causes the webhook to hang 05/01/23 23:16:16.487
    STEP: create a configmap that should be denied by the webhook 05/01/23 23:16:26.697
    STEP: create a configmap that should be admitted by the webhook 05/01/23 23:16:26.824
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 05/01/23 23:16:26.934
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 05/01/23 23:16:27.143
    STEP: create a namespace that bypass the webhook 05/01/23 23:16:27.252
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 05/01/23 23:16:27.359
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:16:27.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9282" for this suite. 05/01/23 23:16:27.784
    STEP: Destroying namespace "webhook-9282-markers" for this suite. 05/01/23 23:16:27.889
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:16:28.436
May  1 23:16:28.437: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 23:16:28.438
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:28.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:28.956
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
May  1 23:16:29.161: INFO: Creating simple deployment test-new-deployment
May  1 23:16:29.579: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 05/01/23 23:16:31.787
STEP: updating a scale subresource 05/01/23 23:16:31.891
STEP: verifying the deployment Spec.Replicas was modified 05/01/23 23:16:31.996
STEP: Patch a scale subresource 05/01/23 23:16:32.099
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 23:16:32.415: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-8231  0f2c19b0-67df-4177-9778-b5eda0d56aad 14521 3 2023-05-01 23:16:29 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-05-01 23:16:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:4,UpdatedReplicas:4,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-05-01 23:16:30 +0000 UTC,LastTransitionTime:2023-05-01 23:16:29 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-05-01 23:16:31 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  1 23:16:32.519: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8231  017ba412-26c3-4a72-a84e-99237515bb0b 14518 3 2023-05-01 23:16:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 0f2c19b0-67df-4177-9778-b5eda0d56aad 0xc001cc96a7 0xc001cc96a8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f2c19b0-67df-4177-9778-b5eda0d56aad\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:4,FullyLabeledReplicas:4,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-7z5rd" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-7z5rd test-new-deployment-845c8977d9- deployment-8231  576057f9-9b75-46e3-8581-93290b2dc556 14520 0 2023-05-01 23:16:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc001cc9ad7 0xc001cc9ad8}] [] [{kube-controller-manager Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hw5nx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hw5nx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-01 23:16:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-9gl8w" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-9gl8w test-new-deployment-845c8977d9- deployment-8231  b0175765-270c-4551-b850-3cd4909b9730 14525 0 2023-05-01 23:16:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:bb0ce9074c2015309bd42f58c42600e516ad3589b0da9a8ee9c03f6281d1fc8f cni.projectcalico.org/podIP:100.105.72.154/32 cni.projectcalico.org/podIPs:100.105.72.154/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc001cc9c97 0xc001cc9c98}] [] [{kube-controller-manager Update v1 2023-05-01 23:16:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9xkt8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9xkt8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-01 23:16:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-rzc4k" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-rzc4k test-new-deployment-845c8977d9- deployment-8231  0254c0ed-3581-4c6b-9623-b2fe883ef70e 14519 0 2023-05-01 23:16:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc001cc9e77 0xc001cc9e78}] [] [{kube-controller-manager Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jx6zr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jx6zr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-01 23:16:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-srcb9" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-srcb9 test-new-deployment-845c8977d9- deployment-8231  7ac7685b-b4e9-4ab5-bb33-bea8b984ec4c 14489 0 2023-05-01 23:16:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ee0b5dc6e59eb12d5b54ed7ec831a3f54c80f3ade84eb280e834a526732eb74b cni.projectcalico.org/podIP:100.96.36.23/32 cni.projectcalico.org/podIPs:100.96.36.23/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc002898057 0xc002898058}] [] [{calico Update v1 2023-05-01 23:16:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 23:16:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5jpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5jpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.23,StartTime:2023-05-01 23:16:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 23:16:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6add143c84c8fae5fe684b2feb9e2de619c4e0499b59713103e819f73985ef3d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 23:16:32.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8231" for this suite. 05/01/23 23:16:32.729
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":104,"skipped":1976,"failed":0}
------------------------------
• [4.408 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:16:28.436
    May  1 23:16:28.437: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 23:16:28.438
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:28.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:28.956
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    May  1 23:16:29.161: INFO: Creating simple deployment test-new-deployment
    May  1 23:16:29.579: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 16, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 05/01/23 23:16:31.787
    STEP: updating a scale subresource 05/01/23 23:16:31.891
    STEP: verifying the deployment Spec.Replicas was modified 05/01/23 23:16:31.996
    STEP: Patch a scale subresource 05/01/23 23:16:32.099
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 23:16:32.415: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-8231  0f2c19b0-67df-4177-9778-b5eda0d56aad 14521 3 2023-05-01 23:16:29 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-05-01 23:16:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:4,UpdatedReplicas:4,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-05-01 23:16:30 +0000 UTC,LastTransitionTime:2023-05-01 23:16:29 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-05-01 23:16:31 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    May  1 23:16:32.519: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8231  017ba412-26c3-4a72-a84e-99237515bb0b 14518 3 2023-05-01 23:16:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 0f2c19b0-67df-4177-9778-b5eda0d56aad 0xc001cc96a7 0xc001cc96a8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0f2c19b0-67df-4177-9778-b5eda0d56aad\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001cc9748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:4,FullyLabeledReplicas:4,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-7z5rd" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-7z5rd test-new-deployment-845c8977d9- deployment-8231  576057f9-9b75-46e3-8581-93290b2dc556 14520 0 2023-05-01 23:16:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc001cc9ad7 0xc001cc9ad8}] [] [{kube-controller-manager Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hw5nx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hw5nx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-01 23:16:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-9gl8w" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-9gl8w test-new-deployment-845c8977d9- deployment-8231  b0175765-270c-4551-b850-3cd4909b9730 14525 0 2023-05-01 23:16:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:bb0ce9074c2015309bd42f58c42600e516ad3589b0da9a8ee9c03f6281d1fc8f cni.projectcalico.org/podIP:100.105.72.154/32 cni.projectcalico.org/podIPs:100.105.72.154/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc001cc9c97 0xc001cc9c98}] [] [{kube-controller-manager Update v1 2023-05-01 23:16:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9xkt8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9xkt8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-01 23:16:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-rzc4k" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-rzc4k test-new-deployment-845c8977d9- deployment-8231  0254c0ed-3581-4c6b-9623-b2fe883ef70e 14519 0 2023-05-01 23:16:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc001cc9e77 0xc001cc9e78}] [] [{kube-controller-manager Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jx6zr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jx6zr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-01 23:16:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  1 23:16:32.624: INFO: Pod "test-new-deployment-845c8977d9-srcb9" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-srcb9 test-new-deployment-845c8977d9- deployment-8231  7ac7685b-b4e9-4ab5-bb33-bea8b984ec4c 14489 0 2023-05-01 23:16:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ee0b5dc6e59eb12d5b54ed7ec831a3f54c80f3ade84eb280e834a526732eb74b cni.projectcalico.org/podIP:100.96.36.23/32 cni.projectcalico.org/podIPs:100.96.36.23/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 017ba412-26c3-4a72-a84e-99237515bb0b 0xc002898057 0xc002898058}] [] [{calico Update v1 2023-05-01 23:16:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 23:16:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"017ba412-26c3-4a72-a84e-99237515bb0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:16:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5jpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5jpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:16:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.23,StartTime:2023-05-01 23:16:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 23:16:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6add143c84c8fae5fe684b2feb9e2de619c4e0499b59713103e819f73985ef3d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 23:16:32.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8231" for this suite. 05/01/23 23:16:32.729
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:16:32.846
May  1 23:16:32.847: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:16:32.848
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:33.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:33.371
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:16:33.578
May  1 23:16:33.686: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f" in namespace "projected-8404" to be "Succeeded or Failed"
May  1 23:16:33.790: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f": Phase="Pending", Reason="", readiness=false. Elapsed: 103.488482ms
May  1 23:16:35.894: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207818658s
May  1 23:16:37.895: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208592188s
STEP: Saw pod success 05/01/23 23:16:37.895
May  1 23:16:37.895: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f" satisfied condition "Succeeded or Failed"
May  1 23:16:38.010: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f container client-container: <nil>
STEP: delete the pod 05/01/23 23:16:38.121
May  1 23:16:38.233: INFO: Waiting for pod downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f to disappear
May  1 23:16:38.336: INFO: Pod downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  1 23:16:38.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8404" for this suite. 05/01/23 23:16:38.441
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":105,"skipped":2000,"failed":0}
------------------------------
• [SLOW TEST] [5.700 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:16:32.846
    May  1 23:16:32.847: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:16:32.848
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:33.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:33.371
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:16:33.578
    May  1 23:16:33.686: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f" in namespace "projected-8404" to be "Succeeded or Failed"
    May  1 23:16:33.790: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f": Phase="Pending", Reason="", readiness=false. Elapsed: 103.488482ms
    May  1 23:16:35.894: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207818658s
    May  1 23:16:37.895: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208592188s
    STEP: Saw pod success 05/01/23 23:16:37.895
    May  1 23:16:37.895: INFO: Pod "downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f" satisfied condition "Succeeded or Failed"
    May  1 23:16:38.010: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f container client-container: <nil>
    STEP: delete the pod 05/01/23 23:16:38.121
    May  1 23:16:38.233: INFO: Waiting for pod downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f to disappear
    May  1 23:16:38.336: INFO: Pod downwardapi-volume-fa14ec73-4493-442b-bc94-db6fb752977f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  1 23:16:38.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8404" for this suite. 05/01/23 23:16:38.441
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:16:38.547
May  1 23:16:38.548: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/01/23 23:16:38.549
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:38.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:39.068
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 05/01/23 23:16:39.273
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_tcp@PTR;sleep 1; done
 05/01/23 23:16:39.488
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_tcp@PTR;sleep 1; done
 05/01/23 23:16:39.488
STEP: creating a pod to probe DNS 05/01/23 23:16:39.488
STEP: submitting the pod to kubernetes 05/01/23 23:16:39.489
May  1 23:16:39.598: INFO: Waiting up to 15m0s for pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304" in namespace "dns-9900" to be "running"
May  1 23:16:39.702: INFO: Pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304": Phase="Pending", Reason="", readiness=false. Elapsed: 103.658413ms
May  1 23:16:41.806: INFO: Pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304": Phase="Running", Reason="", readiness=true. Elapsed: 2.207547145s
May  1 23:16:41.806: INFO: Pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304" satisfied condition "running"
STEP: retrieving the pod 05/01/23 23:16:41.806
STEP: looking for the results for each expected name from probers 05/01/23 23:16:41.91
May  1 23:16:42.227: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:42.331: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:43.061: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:43.165: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:43.584: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

May  1 23:16:48.899: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:49.003: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:49.732: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:49.836: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:50.253: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

May  1 23:16:53.898: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:54.002: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:54.740: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:54.844: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:55.261: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

May  1 23:16:58.899: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:59.003: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:59.746: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:16:59.850: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:00.268: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

May  1 23:17:03.897: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:04.003: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:04.733: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:04.838: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:05.255: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

May  1 23:17:08.898: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:09.002: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:09.731: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:09.835: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
May  1 23:17:10.251: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

May  1 23:17:15.254: INFO: DNS probes using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 succeeded

STEP: deleting the pod 05/01/23 23:17:15.254
STEP: deleting the test service 05/01/23 23:17:15.378
STEP: deleting the test headless service 05/01/23 23:17:15.504
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  1 23:17:15.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9900" for this suite. 05/01/23 23:17:15.727
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":106,"skipped":2013,"failed":0}
------------------------------
• [SLOW TEST] [37.285 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:16:38.547
    May  1 23:16:38.548: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/01/23 23:16:38.549
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:16:38.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:16:39.068
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 05/01/23 23:16:39.273
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_tcp@PTR;sleep 1; done
     05/01/23 23:16:39.488
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9900.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9900.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9900.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.149.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.149.202_tcp@PTR;sleep 1; done
     05/01/23 23:16:39.488
    STEP: creating a pod to probe DNS 05/01/23 23:16:39.488
    STEP: submitting the pod to kubernetes 05/01/23 23:16:39.489
    May  1 23:16:39.598: INFO: Waiting up to 15m0s for pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304" in namespace "dns-9900" to be "running"
    May  1 23:16:39.702: INFO: Pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304": Phase="Pending", Reason="", readiness=false. Elapsed: 103.658413ms
    May  1 23:16:41.806: INFO: Pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304": Phase="Running", Reason="", readiness=true. Elapsed: 2.207547145s
    May  1 23:16:41.806: INFO: Pod "dns-test-2fe00923-2749-44ac-9057-fa953b911304" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 23:16:41.806
    STEP: looking for the results for each expected name from probers 05/01/23 23:16:41.91
    May  1 23:16:42.227: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:42.331: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:43.061: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:43.165: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:43.584: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

    May  1 23:16:48.899: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:49.003: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:49.732: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:49.836: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:50.253: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

    May  1 23:16:53.898: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:54.002: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:54.740: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:54.844: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:55.261: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

    May  1 23:16:58.899: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:59.003: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:59.746: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:16:59.850: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:00.268: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

    May  1 23:17:03.897: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:04.003: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:04.733: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:04.838: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:05.255: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

    May  1 23:17:08.898: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:09.002: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:09.731: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:09.835: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local from pod dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304: the server could not find the requested resource (get pods dns-test-2fe00923-2749-44ac-9057-fa953b911304)
    May  1 23:17:10.251: INFO: Lookups using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9900.svc.cluster.local]

    May  1 23:17:15.254: INFO: DNS probes using dns-9900/dns-test-2fe00923-2749-44ac-9057-fa953b911304 succeeded

    STEP: deleting the pod 05/01/23 23:17:15.254
    STEP: deleting the test service 05/01/23 23:17:15.378
    STEP: deleting the test headless service 05/01/23 23:17:15.504
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  1 23:17:15.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9900" for this suite. 05/01/23 23:17:15.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:17:15.833
May  1 23:17:15.834: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename endpointslice 05/01/23 23:17:15.834
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:16.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:16.352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 05/01/23 23:17:22.31
STEP: referencing matching pods with named port 05/01/23 23:17:27.518
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 05/01/23 23:17:32.728
STEP: recreating EndpointSlices after they've been deleted 05/01/23 23:17:37.936
May  1 23:17:38.354: INFO: EndpointSlice for Service endpointslice-4555/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
May  1 23:17:48.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4555" for this suite. 05/01/23 23:17:48.674
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":107,"skipped":2032,"failed":0}
------------------------------
• [SLOW TEST] [32.948 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:17:15.833
    May  1 23:17:15.834: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename endpointslice 05/01/23 23:17:15.834
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:16.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:16.352
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 05/01/23 23:17:22.31
    STEP: referencing matching pods with named port 05/01/23 23:17:27.518
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 05/01/23 23:17:32.728
    STEP: recreating EndpointSlices after they've been deleted 05/01/23 23:17:37.936
    May  1 23:17:38.354: INFO: EndpointSlice for Service endpointslice-4555/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    May  1 23:17:48.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4555" for this suite. 05/01/23 23:17:48.674
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:17:48.782
May  1 23:17:48.782: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 23:17:48.783
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:49.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:49.3
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 05/01/23 23:17:49.506
May  1 23:17:49.613: INFO: Waiting up to 5m0s for pod "pod-738c16ec-edc3-4266-a76d-d927be33f838" in namespace "emptydir-1449" to be "Succeeded or Failed"
May  1 23:17:49.717: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838": Phase="Pending", Reason="", readiness=false. Elapsed: 103.694665ms
May  1 23:17:51.821: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208266839s
May  1 23:17:53.824: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211033603s
STEP: Saw pod success 05/01/23 23:17:53.824
May  1 23:17:53.824: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838" satisfied condition "Succeeded or Failed"
May  1 23:17:53.933: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-738c16ec-edc3-4266-a76d-d927be33f838 container test-container: <nil>
STEP: delete the pod 05/01/23 23:17:54.051
May  1 23:17:54.161: INFO: Waiting for pod pod-738c16ec-edc3-4266-a76d-d927be33f838 to disappear
May  1 23:17:54.268: INFO: Pod pod-738c16ec-edc3-4266-a76d-d927be33f838 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 23:17:54.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1449" for this suite. 05/01/23 23:17:54.373
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":108,"skipped":2052,"failed":0}
------------------------------
• [SLOW TEST] [5.803 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:17:48.782
    May  1 23:17:48.782: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 23:17:48.783
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:49.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:49.3
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 05/01/23 23:17:49.506
    May  1 23:17:49.613: INFO: Waiting up to 5m0s for pod "pod-738c16ec-edc3-4266-a76d-d927be33f838" in namespace "emptydir-1449" to be "Succeeded or Failed"
    May  1 23:17:49.717: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838": Phase="Pending", Reason="", readiness=false. Elapsed: 103.694665ms
    May  1 23:17:51.821: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208266839s
    May  1 23:17:53.824: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211033603s
    STEP: Saw pod success 05/01/23 23:17:53.824
    May  1 23:17:53.824: INFO: Pod "pod-738c16ec-edc3-4266-a76d-d927be33f838" satisfied condition "Succeeded or Failed"
    May  1 23:17:53.933: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-738c16ec-edc3-4266-a76d-d927be33f838 container test-container: <nil>
    STEP: delete the pod 05/01/23 23:17:54.051
    May  1 23:17:54.161: INFO: Waiting for pod pod-738c16ec-edc3-4266-a76d-d927be33f838 to disappear
    May  1 23:17:54.268: INFO: Pod pod-738c16ec-edc3-4266-a76d-d927be33f838 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 23:17:54.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1449" for this suite. 05/01/23 23:17:54.373
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:17:54.585
May  1 23:17:54.586: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename certificates 05/01/23 23:17:54.587
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:54.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:55.104
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 05/01/23 23:17:56.017
STEP: getting /apis/certificates.k8s.io 05/01/23 23:17:56.222
STEP: getting /apis/certificates.k8s.io/v1 05/01/23 23:17:56.325
STEP: creating 05/01/23 23:17:56.428
STEP: getting 05/01/23 23:17:56.746
STEP: listing 05/01/23 23:17:56.85
STEP: watching 05/01/23 23:17:56.954
May  1 23:17:56.954: INFO: starting watch
STEP: patching 05/01/23 23:17:57.056
STEP: updating 05/01/23 23:17:57.162
May  1 23:17:57.270: INFO: waiting for watch events with expected annotations
May  1 23:17:57.270: INFO: saw patched and updated annotations
STEP: getting /approval 05/01/23 23:17:57.27
STEP: patching /approval 05/01/23 23:17:57.374
STEP: updating /approval 05/01/23 23:17:57.481
STEP: getting /status 05/01/23 23:17:57.588
STEP: patching /status 05/01/23 23:17:57.691
STEP: updating /status 05/01/23 23:17:57.8
STEP: deleting 05/01/23 23:17:57.908
STEP: deleting a collection 05/01/23 23:17:58.221
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:17:58.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-2394" for this suite. 05/01/23 23:17:58.537
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":109,"skipped":2062,"failed":0}
------------------------------
• [4.057 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:17:54.585
    May  1 23:17:54.586: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename certificates 05/01/23 23:17:54.587
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:54.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:55.104
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 05/01/23 23:17:56.017
    STEP: getting /apis/certificates.k8s.io 05/01/23 23:17:56.222
    STEP: getting /apis/certificates.k8s.io/v1 05/01/23 23:17:56.325
    STEP: creating 05/01/23 23:17:56.428
    STEP: getting 05/01/23 23:17:56.746
    STEP: listing 05/01/23 23:17:56.85
    STEP: watching 05/01/23 23:17:56.954
    May  1 23:17:56.954: INFO: starting watch
    STEP: patching 05/01/23 23:17:57.056
    STEP: updating 05/01/23 23:17:57.162
    May  1 23:17:57.270: INFO: waiting for watch events with expected annotations
    May  1 23:17:57.270: INFO: saw patched and updated annotations
    STEP: getting /approval 05/01/23 23:17:57.27
    STEP: patching /approval 05/01/23 23:17:57.374
    STEP: updating /approval 05/01/23 23:17:57.481
    STEP: getting /status 05/01/23 23:17:57.588
    STEP: patching /status 05/01/23 23:17:57.691
    STEP: updating /status 05/01/23 23:17:57.8
    STEP: deleting 05/01/23 23:17:57.908
    STEP: deleting a collection 05/01/23 23:17:58.221
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:17:58.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-2394" for this suite. 05/01/23 23:17:58.537
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:17:58.643
May  1 23:17:58.643: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/01/23 23:17:58.644
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:58.97
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:59.175
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
May  1 23:18:00.006: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 05/01/23 23:18:00.112
May  1 23:18:00.216: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:00.216: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 05/01/23 23:18:00.216
May  1 23:18:00.638: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:00.638: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:18:01.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May  1 23:18:01.743: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 05/01/23 23:18:01.846
May  1 23:18:02.164: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:02.164: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 05/01/23 23:18:02.164
May  1 23:18:02.375: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:02.375: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:18:03.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:03.480: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:18:04.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:04.479: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:18:05.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:05.479: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:18:06.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May  1 23:18:06.480: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 05/01/23 23:18:06.687
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-929, will wait for the garbage collector to delete the pods 05/01/23 23:18:06.687
May  1 23:18:07.047: INFO: Deleting DaemonSet.extensions daemon-set took: 105.399836ms
May  1 23:18:07.147: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.28567ms
May  1 23:18:08.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:18:08.752: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May  1 23:18:08.855: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15108"},"items":null}

May  1 23:18:08.959: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15108"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  1 23:18:09.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-929" for this suite. 05/01/23 23:18:09.692
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":110,"skipped":2067,"failed":0}
------------------------------
• [SLOW TEST] [11.156 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:17:58.643
    May  1 23:17:58.643: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/01/23 23:17:58.644
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:17:58.97
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:17:59.175
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    May  1 23:18:00.006: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 05/01/23 23:18:00.112
    May  1 23:18:00.216: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:00.216: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 05/01/23 23:18:00.216
    May  1 23:18:00.638: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:00.638: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:18:01.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    May  1 23:18:01.743: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 05/01/23 23:18:01.846
    May  1 23:18:02.164: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:02.164: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 05/01/23 23:18:02.164
    May  1 23:18:02.375: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:02.375: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:18:03.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:03.480: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:18:04.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:04.479: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:18:05.479: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:05.479: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:18:06.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    May  1 23:18:06.480: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 05/01/23 23:18:06.687
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-929, will wait for the garbage collector to delete the pods 05/01/23 23:18:06.687
    May  1 23:18:07.047: INFO: Deleting DaemonSet.extensions daemon-set took: 105.399836ms
    May  1 23:18:07.147: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.28567ms
    May  1 23:18:08.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:18:08.752: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    May  1 23:18:08.855: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15108"},"items":null}

    May  1 23:18:08.959: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15108"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:18:09.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-929" for this suite. 05/01/23 23:18:09.692
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:18:09.8
May  1 23:18:09.800: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container 05/01/23 23:18:09.801
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:10.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:10.32
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 05/01/23 23:18:10.526
May  1 23:18:10.527: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
May  1 23:18:15.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1577" for this suite. 05/01/23 23:18:15.738
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":111,"skipped":2077,"failed":0}
------------------------------
• [SLOW TEST] [6.044 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:18:09.8
    May  1 23:18:09.800: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename init-container 05/01/23 23:18:09.801
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:10.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:10.32
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 05/01/23 23:18:10.526
    May  1 23:18:10.527: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    May  1 23:18:15.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1577" for this suite. 05/01/23 23:18:15.738
  << End Captured GinkgoWriter Output
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:18:15.844
May  1 23:18:15.844: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename events 05/01/23 23:18:15.845
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:16.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:16.363
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 05/01/23 23:18:16.568
STEP: listing all events in all namespaces 05/01/23 23:18:16.673
STEP: patching the test event 05/01/23 23:18:16.785
STEP: fetching the test event 05/01/23 23:18:16.891
STEP: updating the test event 05/01/23 23:18:16.995
STEP: getting the test event 05/01/23 23:18:17.204
STEP: deleting the test event 05/01/23 23:18:17.308
STEP: listing all events in all namespaces 05/01/23 23:18:17.414
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
May  1 23:18:17.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9921" for this suite. 05/01/23 23:18:17.627
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":112,"skipped":2077,"failed":0}
------------------------------
• [1.888 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:18:15.844
    May  1 23:18:15.844: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename events 05/01/23 23:18:15.845
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:16.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:16.363
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 05/01/23 23:18:16.568
    STEP: listing all events in all namespaces 05/01/23 23:18:16.673
    STEP: patching the test event 05/01/23 23:18:16.785
    STEP: fetching the test event 05/01/23 23:18:16.891
    STEP: updating the test event 05/01/23 23:18:16.995
    STEP: getting the test event 05/01/23 23:18:17.204
    STEP: deleting the test event 05/01/23 23:18:17.308
    STEP: listing all events in all namespaces 05/01/23 23:18:17.414
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    May  1 23:18:17.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9921" for this suite. 05/01/23 23:18:17.627
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:18:17.733
May  1 23:18:17.733: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 23:18:17.734
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:18.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:18.252
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
May  1 23:18:18.668: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 05/01/23 23:18:18.668
May  1 23:18:18.668: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-z2gjt" in namespace "deployment-7073" to be "running"
May  1 23:18:18.772: INFO: Pod "test-cleanup-controller-z2gjt": Phase="Pending", Reason="", readiness=false. Elapsed: 103.723552ms
May  1 23:18:20.875: INFO: Pod "test-cleanup-controller-z2gjt": Phase="Running", Reason="", readiness=true. Elapsed: 2.207575864s
May  1 23:18:20.875: INFO: Pod "test-cleanup-controller-z2gjt" satisfied condition "running"
May  1 23:18:20.875: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 05/01/23 23:18:21.188
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 23:18:23.707: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7073  83a1ac50-44c5-4e7c-aba7-2072095701e1 15219 1 2023-05-01 23:18:21 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:18:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002aba1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 23:18:21 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2023-05-01 23:18:22 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  1 23:18:23.811: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-7073  030d2621-86e9-47c3-8e8d-559b824a1a25 15212 1 2023-05-01 23:18:21 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 83a1ac50-44c5-4e7c-aba7-2072095701e1 0xc003eed637 0xc003eed638}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83a1ac50-44c5-4e7c-aba7-2072095701e1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:18:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003eed6e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  1 23:18:23.915: INFO: Pod "test-cleanup-deployment-69cb9c5497-fswp5" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-fswp5 test-cleanup-deployment-69cb9c5497- deployment-7073  259a7a31-4fdf-4968-bf4b-bcd6c6867a01 15211 0 2023-05-01 23:18:21 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:39e5de187b7e3330d3068f04405c1a46118f63c368a55c828692df8d0c0a558d cni.projectcalico.org/podIP:100.96.36.30/32 cni.projectcalico.org/podIPs:100.96.36.30/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 030d2621-86e9-47c3-8e8d-559b824a1a25 0xc003eeda97 0xc003eeda98}] [] [{calico Update v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"030d2621-86e9-47c3-8e8d-559b824a1a25\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:18:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.30\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kch8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kch8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.30,StartTime:2023-05-01 23:18:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 23:18:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://2a17561a803a85551819f10c7c1cca1553cfba8b3dbe415e55332830acf5822b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 23:18:23.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7073" for this suite. 05/01/23 23:18:24.021
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":113,"skipped":2099,"failed":0}
------------------------------
• [SLOW TEST] [6.393 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:18:17.733
    May  1 23:18:17.733: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 23:18:17.734
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:18.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:18.252
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    May  1 23:18:18.668: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 05/01/23 23:18:18.668
    May  1 23:18:18.668: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-z2gjt" in namespace "deployment-7073" to be "running"
    May  1 23:18:18.772: INFO: Pod "test-cleanup-controller-z2gjt": Phase="Pending", Reason="", readiness=false. Elapsed: 103.723552ms
    May  1 23:18:20.875: INFO: Pod "test-cleanup-controller-z2gjt": Phase="Running", Reason="", readiness=true. Elapsed: 2.207575864s
    May  1 23:18:20.875: INFO: Pod "test-cleanup-controller-z2gjt" satisfied condition "running"
    May  1 23:18:20.875: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 05/01/23 23:18:21.188
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 23:18:23.707: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7073  83a1ac50-44c5-4e7c-aba7-2072095701e1 15219 1 2023-05-01 23:18:21 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:18:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002aba1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 23:18:21 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2023-05-01 23:18:22 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    May  1 23:18:23.811: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-7073  030d2621-86e9-47c3-8e8d-559b824a1a25 15212 1 2023-05-01 23:18:21 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 83a1ac50-44c5-4e7c-aba7-2072095701e1 0xc003eed637 0xc003eed638}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83a1ac50-44c5-4e7c-aba7-2072095701e1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:18:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003eed6e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    May  1 23:18:23.915: INFO: Pod "test-cleanup-deployment-69cb9c5497-fswp5" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-fswp5 test-cleanup-deployment-69cb9c5497- deployment-7073  259a7a31-4fdf-4968-bf4b-bcd6c6867a01 15211 0 2023-05-01 23:18:21 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:39e5de187b7e3330d3068f04405c1a46118f63c368a55c828692df8d0c0a558d cni.projectcalico.org/podIP:100.96.36.30/32 cni.projectcalico.org/podIPs:100.96.36.30/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 030d2621-86e9-47c3-8e8d-559b824a1a25 0xc003eeda97 0xc003eeda98}] [] [{calico Update v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 23:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"030d2621-86e9-47c3-8e8d-559b824a1a25\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:18:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.30\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kch8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kch8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:18:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.30,StartTime:2023-05-01 23:18:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 23:18:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://2a17561a803a85551819f10c7c1cca1553cfba8b3dbe415e55332830acf5822b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 23:18:23.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7073" for this suite. 05/01/23 23:18:24.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:18:24.126
May  1 23:18:24.127: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename cronjob 05/01/23 23:18:24.127
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:24.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:24.646
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 05/01/23 23:18:24.852
STEP: Ensuring no jobs are scheduled 05/01/23 23:18:24.957
STEP: Ensuring no job exists by listing jobs explicitly 05/01/23 23:23:25.163
STEP: Removing cronjob 05/01/23 23:23:25.265
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
May  1 23:23:25.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2935" for this suite. 05/01/23 23:23:25.474
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":114,"skipped":2104,"failed":0}
------------------------------
• [SLOW TEST] [301.552 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:18:24.126
    May  1 23:18:24.127: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename cronjob 05/01/23 23:18:24.127
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:18:24.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:18:24.646
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 05/01/23 23:18:24.852
    STEP: Ensuring no jobs are scheduled 05/01/23 23:18:24.957
    STEP: Ensuring no job exists by listing jobs explicitly 05/01/23 23:23:25.163
    STEP: Removing cronjob 05/01/23 23:23:25.265
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    May  1 23:23:25.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2935" for this suite. 05/01/23 23:23:25.474
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:23:25.679
May  1 23:23:25.679: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime 05/01/23 23:23:25.681
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:25.989
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:26.193
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 05/01/23 23:23:26.396
STEP: wait for the container to reach Succeeded 05/01/23 23:23:26.503
STEP: get the container status 05/01/23 23:23:31.018
STEP: the container should be terminated 05/01/23 23:23:31.121
STEP: the termination message should be set 05/01/23 23:23:31.121
May  1 23:23:31.121: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 05/01/23 23:23:31.121
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
May  1 23:23:31.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7358" for this suite. 05/01/23 23:23:31.438
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":115,"skipped":2104,"failed":0}
------------------------------
• [SLOW TEST] [5.963 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:23:25.679
    May  1 23:23:25.679: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-runtime 05/01/23 23:23:25.681
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:25.989
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:26.193
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 05/01/23 23:23:26.396
    STEP: wait for the container to reach Succeeded 05/01/23 23:23:26.503
    STEP: get the container status 05/01/23 23:23:31.018
    STEP: the container should be terminated 05/01/23 23:23:31.121
    STEP: the termination message should be set 05/01/23 23:23:31.121
    May  1 23:23:31.121: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 05/01/23 23:23:31.121
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    May  1 23:23:31.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7358" for this suite. 05/01/23 23:23:31.438
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:23:31.643
May  1 23:23:31.643: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/01/23 23:23:31.644
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:31.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:32.158
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 05/01/23 23:23:32.362
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
 05/01/23 23:23:32.466
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
 05/01/23 23:23:32.466
STEP: creating a pod to probe DNS 05/01/23 23:23:32.466
STEP: submitting the pod to kubernetes 05/01/23 23:23:32.466
May  1 23:23:32.574: INFO: Waiting up to 15m0s for pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219" in namespace "dns-287" to be "running"
May  1 23:23:32.677: INFO: Pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219": Phase="Pending", Reason="", readiness=false. Elapsed: 102.651312ms
May  1 23:23:34.780: INFO: Pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219": Phase="Running", Reason="", readiness=true. Elapsed: 2.206231581s
May  1 23:23:34.780: INFO: Pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219" satisfied condition "running"
STEP: retrieving the pod 05/01/23 23:23:34.78
STEP: looking for the results for each expected name from probers 05/01/23 23:23:34.883
May  1 23:23:35.090: INFO: DNS probes using dns-test-c20ff887-2691-4b44-aeea-f03629edd219 succeeded

STEP: deleting the pod 05/01/23 23:23:35.09
STEP: changing the externalName to bar.example.com 05/01/23 23:23:35.202
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
 05/01/23 23:23:35.414
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
 05/01/23 23:23:35.414
STEP: creating a second pod to probe DNS 05/01/23 23:23:35.414
STEP: submitting the pod to kubernetes 05/01/23 23:23:35.415
May  1 23:23:35.521: INFO: Waiting up to 15m0s for pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10" in namespace "dns-287" to be "running"
May  1 23:23:35.625: INFO: Pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10": Phase="Pending", Reason="", readiness=false. Elapsed: 104.265727ms
May  1 23:23:37.729: INFO: Pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10": Phase="Running", Reason="", readiness=true. Elapsed: 2.208317469s
May  1 23:23:37.729: INFO: Pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10" satisfied condition "running"
STEP: retrieving the pod 05/01/23 23:23:37.729
STEP: looking for the results for each expected name from probers 05/01/23 23:23:37.832
May  1 23:23:37.936: INFO: File wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local from pod  dns-287/dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10 contains 'foo.example.com.
' instead of 'bar.example.com.'
May  1 23:23:38.039: INFO: Lookups using dns-287/dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10 failed for: [wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local]

May  1 23:23:43.249: INFO: DNS probes using dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10 succeeded

STEP: deleting the pod 05/01/23 23:23:43.249
STEP: changing the service to type=ClusterIP 05/01/23 23:23:43.361
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
 05/01/23 23:23:43.572
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
 05/01/23 23:23:43.572
STEP: creating a third pod to probe DNS 05/01/23 23:23:43.572
STEP: submitting the pod to kubernetes 05/01/23 23:23:43.674
May  1 23:23:43.779: INFO: Waiting up to 15m0s for pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f" in namespace "dns-287" to be "running"
May  1 23:23:43.882: INFO: Pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f": Phase="Pending", Reason="", readiness=false. Elapsed: 102.514419ms
May  1 23:23:45.985: INFO: Pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.206254738s
May  1 23:23:45.985: INFO: Pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f" satisfied condition "running"
STEP: retrieving the pod 05/01/23 23:23:45.985
STEP: looking for the results for each expected name from probers 05/01/23 23:23:46.089
May  1 23:23:46.296: INFO: DNS probes using dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f succeeded

STEP: deleting the pod 05/01/23 23:23:46.296
STEP: deleting the test externalName service 05/01/23 23:23:46.407
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  1 23:23:46.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-287" for this suite. 05/01/23 23:23:46.625
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":116,"skipped":2106,"failed":0}
------------------------------
• [SLOW TEST] [15.087 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:23:31.643
    May  1 23:23:31.643: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/01/23 23:23:31.644
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:31.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:32.158
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 05/01/23 23:23:32.362
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
     05/01/23 23:23:32.466
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
     05/01/23 23:23:32.466
    STEP: creating a pod to probe DNS 05/01/23 23:23:32.466
    STEP: submitting the pod to kubernetes 05/01/23 23:23:32.466
    May  1 23:23:32.574: INFO: Waiting up to 15m0s for pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219" in namespace "dns-287" to be "running"
    May  1 23:23:32.677: INFO: Pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219": Phase="Pending", Reason="", readiness=false. Elapsed: 102.651312ms
    May  1 23:23:34.780: INFO: Pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219": Phase="Running", Reason="", readiness=true. Elapsed: 2.206231581s
    May  1 23:23:34.780: INFO: Pod "dns-test-c20ff887-2691-4b44-aeea-f03629edd219" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 23:23:34.78
    STEP: looking for the results for each expected name from probers 05/01/23 23:23:34.883
    May  1 23:23:35.090: INFO: DNS probes using dns-test-c20ff887-2691-4b44-aeea-f03629edd219 succeeded

    STEP: deleting the pod 05/01/23 23:23:35.09
    STEP: changing the externalName to bar.example.com 05/01/23 23:23:35.202
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
     05/01/23 23:23:35.414
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
     05/01/23 23:23:35.414
    STEP: creating a second pod to probe DNS 05/01/23 23:23:35.414
    STEP: submitting the pod to kubernetes 05/01/23 23:23:35.415
    May  1 23:23:35.521: INFO: Waiting up to 15m0s for pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10" in namespace "dns-287" to be "running"
    May  1 23:23:35.625: INFO: Pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10": Phase="Pending", Reason="", readiness=false. Elapsed: 104.265727ms
    May  1 23:23:37.729: INFO: Pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10": Phase="Running", Reason="", readiness=true. Elapsed: 2.208317469s
    May  1 23:23:37.729: INFO: Pod "dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 23:23:37.729
    STEP: looking for the results for each expected name from probers 05/01/23 23:23:37.832
    May  1 23:23:37.936: INFO: File wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local from pod  dns-287/dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    May  1 23:23:38.039: INFO: Lookups using dns-287/dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10 failed for: [wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local]

    May  1 23:23:43.249: INFO: DNS probes using dns-test-6b1d3db5-b094-4838-80a1-892b979e4a10 succeeded

    STEP: deleting the pod 05/01/23 23:23:43.249
    STEP: changing the service to type=ClusterIP 05/01/23 23:23:43.361
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
     05/01/23 23:23:43.572
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-287.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-287.svc.cluster.local; sleep 1; done
     05/01/23 23:23:43.572
    STEP: creating a third pod to probe DNS 05/01/23 23:23:43.572
    STEP: submitting the pod to kubernetes 05/01/23 23:23:43.674
    May  1 23:23:43.779: INFO: Waiting up to 15m0s for pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f" in namespace "dns-287" to be "running"
    May  1 23:23:43.882: INFO: Pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f": Phase="Pending", Reason="", readiness=false. Elapsed: 102.514419ms
    May  1 23:23:45.985: INFO: Pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.206254738s
    May  1 23:23:45.985: INFO: Pod "dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 23:23:45.985
    STEP: looking for the results for each expected name from probers 05/01/23 23:23:46.089
    May  1 23:23:46.296: INFO: DNS probes using dns-test-3f9b7f4b-c7aa-4258-b414-966e0eeabb1f succeeded

    STEP: deleting the pod 05/01/23 23:23:46.296
    STEP: deleting the test externalName service 05/01/23 23:23:46.407
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  1 23:23:46.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-287" for this suite. 05/01/23 23:23:46.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:23:46.731
May  1 23:23:46.731: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:23:46.732
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:47.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:47.244
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:23:47.656
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:23:47.871
STEP: Deploying the webhook pod 05/01/23 23:23:47.977
STEP: Wait for the deployment to be ready 05/01/23 23:23:48.189
May  1 23:23:48.497: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:23:50.601
STEP: Verifying the service has paired with the endpoint 05/01/23 23:23:50.71
May  1 23:23:51.710: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 05/01/23 23:23:51.813
STEP: Creating a custom resource definition that should be denied by the webhook 05/01/23 23:23:52.032
May  1 23:23:52.032: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:23:52.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6970" for this suite. 05/01/23 23:23:52.349
STEP: Destroying namespace "webhook-6970-markers" for this suite. 05/01/23 23:23:52.455
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":117,"skipped":2112,"failed":0}
------------------------------
• [SLOW TEST] [6.267 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:23:46.731
    May  1 23:23:46.731: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:23:46.732
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:47.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:47.244
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:23:47.656
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:23:47.871
    STEP: Deploying the webhook pod 05/01/23 23:23:47.977
    STEP: Wait for the deployment to be ready 05/01/23 23:23:48.189
    May  1 23:23:48.497: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 23, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:23:50.601
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:23:50.71
    May  1 23:23:51.710: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 05/01/23 23:23:51.813
    STEP: Creating a custom resource definition that should be denied by the webhook 05/01/23 23:23:52.032
    May  1 23:23:52.032: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:23:52.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6970" for this suite. 05/01/23 23:23:52.349
    STEP: Destroying namespace "webhook-6970-markers" for this suite. 05/01/23 23:23:52.455
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:23:52.999
May  1 23:23:52.999: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:23:53
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:53.309
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:53.513
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 05/01/23 23:23:53.717
May  1 23:23:53.823: INFO: Waiting up to 5m0s for pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6" in namespace "downward-api-1907" to be "Succeeded or Failed"
May  1 23:23:53.926: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6": Phase="Pending", Reason="", readiness=false. Elapsed: 102.92663ms
May  1 23:23:56.030: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206204681s
May  1 23:23:58.032: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208777153s
STEP: Saw pod success 05/01/23 23:23:58.032
May  1 23:23:58.032: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6" satisfied condition "Succeeded or Failed"
May  1 23:23:58.135: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6 container dapi-container: <nil>
STEP: delete the pod 05/01/23 23:23:58.248
May  1 23:23:58.356: INFO: Waiting for pod downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6 to disappear
May  1 23:23:58.459: INFO: Pod downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
May  1 23:23:58.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1907" for this suite. 05/01/23 23:23:58.563
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":118,"skipped":2124,"failed":0}
------------------------------
• [SLOW TEST] [5.669 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:23:52.999
    May  1 23:23:52.999: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:23:53
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:53.309
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:53.513
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 05/01/23 23:23:53.717
    May  1 23:23:53.823: INFO: Waiting up to 5m0s for pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6" in namespace "downward-api-1907" to be "Succeeded or Failed"
    May  1 23:23:53.926: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6": Phase="Pending", Reason="", readiness=false. Elapsed: 102.92663ms
    May  1 23:23:56.030: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206204681s
    May  1 23:23:58.032: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208777153s
    STEP: Saw pod success 05/01/23 23:23:58.032
    May  1 23:23:58.032: INFO: Pod "downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6" satisfied condition "Succeeded or Failed"
    May  1 23:23:58.135: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6 container dapi-container: <nil>
    STEP: delete the pod 05/01/23 23:23:58.248
    May  1 23:23:58.356: INFO: Waiting for pod downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6 to disappear
    May  1 23:23:58.459: INFO: Pod downward-api-c2a837ab-1cf3-4271-a0da-c18b1e11cad6 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    May  1 23:23:58.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1907" for this suite. 05/01/23 23:23:58.563
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:23:58.67
May  1 23:23:58.671: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/01/23 23:23:58.672
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:58.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:59.184
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
May  1 23:23:59.819: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e333f535-bf2f-41d0-8ecd-5270e67bbe3c", Controller:(*bool)(0xc003e7f5de), BlockOwnerDeletion:(*bool)(0xc003e7f5df)}}
May  1 23:23:59.925: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3be18f16-c4ac-4909-99a8-d9c3ff083575", Controller:(*bool)(0xc003e7f866), BlockOwnerDeletion:(*bool)(0xc003e7f867)}}
May  1 23:24:00.031: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6255ccca-8b81-4dec-b442-06660794c766", Controller:(*bool)(0xc00326ce66), BlockOwnerDeletion:(*bool)(0xc00326ce67)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  1 23:24:05.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2279" for this suite. 05/01/23 23:24:05.344
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":119,"skipped":2163,"failed":0}
------------------------------
• [SLOW TEST] [6.878 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:23:58.67
    May  1 23:23:58.671: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/01/23 23:23:58.672
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:23:58.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:23:59.184
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    May  1 23:23:59.819: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e333f535-bf2f-41d0-8ecd-5270e67bbe3c", Controller:(*bool)(0xc003e7f5de), BlockOwnerDeletion:(*bool)(0xc003e7f5df)}}
    May  1 23:23:59.925: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3be18f16-c4ac-4909-99a8-d9c3ff083575", Controller:(*bool)(0xc003e7f866), BlockOwnerDeletion:(*bool)(0xc003e7f867)}}
    May  1 23:24:00.031: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6255ccca-8b81-4dec-b442-06660794c766", Controller:(*bool)(0xc00326ce66), BlockOwnerDeletion:(*bool)(0xc00326ce67)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  1 23:24:05.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2279" for this suite. 05/01/23 23:24:05.344
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:05.548
May  1 23:24:05.548: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:24:05.549
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:05.86
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:06.063
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
May  1 23:24:06.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1489" for this suite. 05/01/23 23:24:06.475
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":120,"skipped":2164,"failed":0}
------------------------------
• [1.032 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:05.548
    May  1 23:24:05.548: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:24:05.549
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:05.86
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:06.063
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    May  1 23:24:06.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1489" for this suite. 05/01/23 23:24:06.475
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:06.581
May  1 23:24:06.581: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:24:06.582
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:06.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:07.094
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-1750-delete-me 05/01/23 23:24:07.401
STEP: Waiting for the RuntimeClass to disappear 05/01/23 23:24:07.505
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
May  1 23:24:07.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1750" for this suite. 05/01/23 23:24:07.816
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":121,"skipped":2171,"failed":0}
------------------------------
• [1.339 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:06.581
    May  1 23:24:06.581: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:24:06.582
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:06.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:07.094
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-1750-delete-me 05/01/23 23:24:07.401
    STEP: Waiting for the RuntimeClass to disappear 05/01/23 23:24:07.505
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    May  1 23:24:07.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1750" for this suite. 05/01/23 23:24:07.816
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:07.922
May  1 23:24:07.922: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 23:24:07.923
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:08.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:08.435
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-b1aaec5f-5360-4301-a7e0-fc6256480904 05/01/23 23:24:08.638
STEP: Creating a pod to test consume secrets 05/01/23 23:24:08.742
May  1 23:24:08.849: INFO: Waiting up to 5m0s for pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af" in namespace "secrets-7016" to be "Succeeded or Failed"
May  1 23:24:08.951: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af": Phase="Pending", Reason="", readiness=false. Elapsed: 102.398902ms
May  1 23:24:11.055: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206508157s
May  1 23:24:13.054: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205040878s
STEP: Saw pod success 05/01/23 23:24:13.054
May  1 23:24:13.054: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af" satisfied condition "Succeeded or Failed"
May  1 23:24:13.157: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af container secret-volume-test: <nil>
STEP: delete the pod 05/01/23 23:24:13.268
May  1 23:24:13.378: INFO: Waiting for pod pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af to disappear
May  1 23:24:13.483: INFO: Pod pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  1 23:24:13.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7016" for this suite. 05/01/23 23:24:13.586
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":122,"skipped":2200,"failed":0}
------------------------------
• [SLOW TEST] [5.768 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:07.922
    May  1 23:24:07.922: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 23:24:07.923
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:08.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:08.435
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-b1aaec5f-5360-4301-a7e0-fc6256480904 05/01/23 23:24:08.638
    STEP: Creating a pod to test consume secrets 05/01/23 23:24:08.742
    May  1 23:24:08.849: INFO: Waiting up to 5m0s for pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af" in namespace "secrets-7016" to be "Succeeded or Failed"
    May  1 23:24:08.951: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af": Phase="Pending", Reason="", readiness=false. Elapsed: 102.398902ms
    May  1 23:24:11.055: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206508157s
    May  1 23:24:13.054: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205040878s
    STEP: Saw pod success 05/01/23 23:24:13.054
    May  1 23:24:13.054: INFO: Pod "pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af" satisfied condition "Succeeded or Failed"
    May  1 23:24:13.157: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af container secret-volume-test: <nil>
    STEP: delete the pod 05/01/23 23:24:13.268
    May  1 23:24:13.378: INFO: Waiting for pod pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af to disappear
    May  1 23:24:13.483: INFO: Pod pod-secrets-0191631f-f90d-4775-80e1-9f26bdbca8af no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  1 23:24:13.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7016" for this suite. 05/01/23 23:24:13.586
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:13.692
May  1 23:24:13.692: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:24:13.693
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:14.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:14.204
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:24:14.408
May  1 23:24:14.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0" in namespace "downward-api-8537" to be "Succeeded or Failed"
May  1 23:24:14.617: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 102.439196ms
May  1 23:24:16.720: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0": Phase="Running", Reason="", readiness=false. Elapsed: 2.205934044s
May  1 23:24:18.720: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205327834s
STEP: Saw pod success 05/01/23 23:24:18.72
May  1 23:24:18.720: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0" satisfied condition "Succeeded or Failed"
May  1 23:24:18.822: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0 container client-container: <nil>
STEP: delete the pod 05/01/23 23:24:18.927
May  1 23:24:19.035: INFO: Waiting for pod downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0 to disappear
May  1 23:24:19.138: INFO: Pod downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:24:19.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8537" for this suite. 05/01/23 23:24:19.241
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":123,"skipped":2224,"failed":0}
------------------------------
• [SLOW TEST] [5.754 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:13.692
    May  1 23:24:13.692: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:24:13.693
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:14.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:14.204
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:24:14.408
    May  1 23:24:14.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0" in namespace "downward-api-8537" to be "Succeeded or Failed"
    May  1 23:24:14.617: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 102.439196ms
    May  1 23:24:16.720: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0": Phase="Running", Reason="", readiness=false. Elapsed: 2.205934044s
    May  1 23:24:18.720: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205327834s
    STEP: Saw pod success 05/01/23 23:24:18.72
    May  1 23:24:18.720: INFO: Pod "downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0" satisfied condition "Succeeded or Failed"
    May  1 23:24:18.822: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:24:18.927
    May  1 23:24:19.035: INFO: Waiting for pod downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0 to disappear
    May  1 23:24:19.138: INFO: Pod downwardapi-volume-a04a9926-8609-47ff-ba32-cd1fc94ce1f0 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:24:19.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8537" for this suite. 05/01/23 23:24:19.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:19.448
May  1 23:24:19.448: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:24:19.449
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:19.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:19.961
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:24:20.375
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:24:20.809
STEP: Deploying the webhook pod 05/01/23 23:24:20.915
STEP: Wait for the deployment to be ready 05/01/23 23:24:21.125
May  1 23:24:21.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:24:23.537
STEP: Verifying the service has paired with the endpoint 05/01/23 23:24:23.645
May  1 23:24:24.645: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 05/01/23 23:24:24.748
STEP: create a namespace for the webhook 05/01/23 23:24:24.962
STEP: create a configmap should be unconditionally rejected by the webhook 05/01/23 23:24:25.067
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:24:25.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-388" for this suite. 05/01/23 23:24:25.487
STEP: Destroying namespace "webhook-388-markers" for this suite. 05/01/23 23:24:25.602
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":124,"skipped":2254,"failed":0}
------------------------------
• [SLOW TEST] [6.711 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:19.448
    May  1 23:24:19.448: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:24:19.449
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:19.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:19.961
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:24:20.375
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:24:20.809
    STEP: Deploying the webhook pod 05/01/23 23:24:20.915
    STEP: Wait for the deployment to be ready 05/01/23 23:24:21.125
    May  1 23:24:21.434: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 24, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:24:23.537
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:24:23.645
    May  1 23:24:24.645: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 05/01/23 23:24:24.748
    STEP: create a namespace for the webhook 05/01/23 23:24:24.962
    STEP: create a configmap should be unconditionally rejected by the webhook 05/01/23 23:24:25.067
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:24:25.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-388" for this suite. 05/01/23 23:24:25.487
    STEP: Destroying namespace "webhook-388-markers" for this suite. 05/01/23 23:24:25.602
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:26.16
May  1 23:24:26.161: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 23:24:26.162
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:26.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:26.676
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 05/01/23 23:24:26.879
STEP: Ensuring ResourceQuota status is calculated 05/01/23 23:24:26.985
STEP: Creating a ResourceQuota with not best effort scope 05/01/23 23:24:29.088
STEP: Ensuring ResourceQuota status is calculated 05/01/23 23:24:29.192
STEP: Creating a best-effort pod 05/01/23 23:24:31.296
STEP: Ensuring resource quota with best effort scope captures the pod usage 05/01/23 23:24:31.405
STEP: Ensuring resource quota with not best effort ignored the pod usage 05/01/23 23:24:33.509
STEP: Deleting the pod 05/01/23 23:24:35.613
STEP: Ensuring resource quota status released the pod usage 05/01/23 23:24:35.726
STEP: Creating a not best-effort pod 05/01/23 23:24:37.829
STEP: Ensuring resource quota with not best effort scope captures the pod usage 05/01/23 23:24:37.939
STEP: Ensuring resource quota with best effort scope ignored the pod usage 05/01/23 23:24:40.043
STEP: Deleting the pod 05/01/23 23:24:42.147
STEP: Ensuring resource quota status released the pod usage 05/01/23 23:24:42.262
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 23:24:44.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-365" for this suite. 05/01/23 23:24:44.47
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":125,"skipped":2289,"failed":0}
------------------------------
• [SLOW TEST] [18.414 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:26.16
    May  1 23:24:26.161: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 23:24:26.162
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:26.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:26.676
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 05/01/23 23:24:26.879
    STEP: Ensuring ResourceQuota status is calculated 05/01/23 23:24:26.985
    STEP: Creating a ResourceQuota with not best effort scope 05/01/23 23:24:29.088
    STEP: Ensuring ResourceQuota status is calculated 05/01/23 23:24:29.192
    STEP: Creating a best-effort pod 05/01/23 23:24:31.296
    STEP: Ensuring resource quota with best effort scope captures the pod usage 05/01/23 23:24:31.405
    STEP: Ensuring resource quota with not best effort ignored the pod usage 05/01/23 23:24:33.509
    STEP: Deleting the pod 05/01/23 23:24:35.613
    STEP: Ensuring resource quota status released the pod usage 05/01/23 23:24:35.726
    STEP: Creating a not best-effort pod 05/01/23 23:24:37.829
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 05/01/23 23:24:37.939
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 05/01/23 23:24:40.043
    STEP: Deleting the pod 05/01/23 23:24:42.147
    STEP: Ensuring resource quota status released the pod usage 05/01/23 23:24:42.262
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 23:24:44.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-365" for this suite. 05/01/23 23:24:44.47
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:44.578
May  1 23:24:44.578: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers 05/01/23 23:24:44.58
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:44.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:45.095
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 05/01/23 23:24:45.298
May  1 23:24:45.405: INFO: Waiting up to 5m0s for pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7" in namespace "containers-4439" to be "Succeeded or Failed"
May  1 23:24:45.507: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7": Phase="Pending", Reason="", readiness=false. Elapsed: 102.471102ms
May  1 23:24:47.610: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205373745s
May  1 23:24:49.612: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20717542s
STEP: Saw pod success 05/01/23 23:24:49.612
May  1 23:24:49.612: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7" satisfied condition "Succeeded or Failed"
May  1 23:24:49.715: INFO: Trying to get logs from node i-02d061b30635c230c pod client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 23:24:49.821
May  1 23:24:49.930: INFO: Waiting for pod client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7 to disappear
May  1 23:24:50.032: INFO: Pod client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
May  1 23:24:50.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4439" for this suite. 05/01/23 23:24:50.136
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":126,"skipped":2320,"failed":0}
------------------------------
• [SLOW TEST] [5.662 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:44.578
    May  1 23:24:44.578: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename containers 05/01/23 23:24:44.58
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:44.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:45.095
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 05/01/23 23:24:45.298
    May  1 23:24:45.405: INFO: Waiting up to 5m0s for pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7" in namespace "containers-4439" to be "Succeeded or Failed"
    May  1 23:24:45.507: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7": Phase="Pending", Reason="", readiness=false. Elapsed: 102.471102ms
    May  1 23:24:47.610: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205373745s
    May  1 23:24:49.612: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20717542s
    STEP: Saw pod success 05/01/23 23:24:49.612
    May  1 23:24:49.612: INFO: Pod "client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7" satisfied condition "Succeeded or Failed"
    May  1 23:24:49.715: INFO: Trying to get logs from node i-02d061b30635c230c pod client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 23:24:49.821
    May  1 23:24:49.930: INFO: Waiting for pod client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7 to disappear
    May  1 23:24:50.032: INFO: Pod client-containers-a9690656-88e7-4a51-bbee-36f139c3a7b7 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    May  1 23:24:50.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4439" for this suite. 05/01/23 23:24:50.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:24:50.241
May  1 23:24:50.241: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:24:50.243
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:50.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:50.755
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 05/01/23 23:24:50.959
May  1 23:24:50.959: INFO: >>> kubeConfig: /root/.kube/config
STEP: rename a version 05/01/23 23:25:13.509
STEP: check the new version name is served 05/01/23 23:25:13.84
STEP: check the old version name is removed 05/01/23 23:25:20.609
STEP: check the other version is not changed 05/01/23 23:25:25.647
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:25:41.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7889" for this suite. 05/01/23 23:25:41.765
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":127,"skipped":2334,"failed":0}
------------------------------
• [SLOW TEST] [51.630 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:24:50.241
    May  1 23:24:50.241: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:24:50.243
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:24:50.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:24:50.755
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 05/01/23 23:24:50.959
    May  1 23:24:50.959: INFO: >>> kubeConfig: /root/.kube/config
    STEP: rename a version 05/01/23 23:25:13.509
    STEP: check the new version name is served 05/01/23 23:25:13.84
    STEP: check the old version name is removed 05/01/23 23:25:20.609
    STEP: check the other version is not changed 05/01/23 23:25:25.647
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:25:41.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7889" for this suite. 05/01/23 23:25:41.765
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:25:41.875
May  1 23:25:41.876: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename proxy 05/01/23 23:25:41.877
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:25:42.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:25:42.396
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
May  1 23:25:42.603: INFO: Creating pod...
May  1 23:25:42.710: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6223" to be "running"
May  1 23:25:42.814: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 103.789034ms
May  1 23:25:44.919: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.208711673s
May  1 23:25:44.919: INFO: Pod "agnhost" satisfied condition "running"
May  1 23:25:44.919: INFO: Creating service...
May  1 23:25:45.029: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/DELETE
May  1 23:25:45.134: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May  1 23:25:45.135: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/GET
May  1 23:25:45.239: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
May  1 23:25:45.239: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/HEAD
May  1 23:25:45.343: INFO: http.Client request:HEAD | StatusCode:200
May  1 23:25:45.343: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/OPTIONS
May  1 23:25:45.448: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May  1 23:25:45.448: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/PATCH
May  1 23:25:45.553: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May  1 23:25:45.553: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/POST
May  1 23:25:45.659: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May  1 23:25:45.659: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/PUT
May  1 23:25:45.763: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May  1 23:25:45.763: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/DELETE
May  1 23:25:45.868: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May  1 23:25:45.868: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/GET
May  1 23:25:45.973: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
May  1 23:25:45.974: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/HEAD
May  1 23:25:46.079: INFO: http.Client request:HEAD | StatusCode:200
May  1 23:25:46.079: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/OPTIONS
May  1 23:25:46.185: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May  1 23:25:46.185: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/PATCH
May  1 23:25:46.290: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May  1 23:25:46.290: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/POST
May  1 23:25:46.395: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May  1 23:25:46.395: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/PUT
May  1 23:25:46.500: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
May  1 23:25:46.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6223" for this suite. 05/01/23 23:25:46.605
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":128,"skipped":2402,"failed":0}
------------------------------
• [4.836 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:25:41.875
    May  1 23:25:41.876: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename proxy 05/01/23 23:25:41.877
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:25:42.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:25:42.396
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    May  1 23:25:42.603: INFO: Creating pod...
    May  1 23:25:42.710: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6223" to be "running"
    May  1 23:25:42.814: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 103.789034ms
    May  1 23:25:44.919: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.208711673s
    May  1 23:25:44.919: INFO: Pod "agnhost" satisfied condition "running"
    May  1 23:25:44.919: INFO: Creating service...
    May  1 23:25:45.029: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/DELETE
    May  1 23:25:45.134: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    May  1 23:25:45.135: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/GET
    May  1 23:25:45.239: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    May  1 23:25:45.239: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/HEAD
    May  1 23:25:45.343: INFO: http.Client request:HEAD | StatusCode:200
    May  1 23:25:45.343: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/OPTIONS
    May  1 23:25:45.448: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    May  1 23:25:45.448: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/PATCH
    May  1 23:25:45.553: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    May  1 23:25:45.553: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/POST
    May  1 23:25:45.659: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    May  1 23:25:45.659: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/pods/agnhost/proxy/some/path/with/PUT
    May  1 23:25:45.763: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    May  1 23:25:45.763: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/DELETE
    May  1 23:25:45.868: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    May  1 23:25:45.868: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/GET
    May  1 23:25:45.973: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    May  1 23:25:45.974: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/HEAD
    May  1 23:25:46.079: INFO: http.Client request:HEAD | StatusCode:200
    May  1 23:25:46.079: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/OPTIONS
    May  1 23:25:46.185: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    May  1 23:25:46.185: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/PATCH
    May  1 23:25:46.290: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    May  1 23:25:46.290: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/POST
    May  1 23:25:46.395: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    May  1 23:25:46.395: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-6223/services/test-service/proxy/some/path/with/PUT
    May  1 23:25:46.500: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    May  1 23:25:46.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-6223" for this suite. 05/01/23 23:25:46.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:25:46.713
May  1 23:25:46.713: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:25:46.715
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:25:47.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:25:47.235
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-fd23cc76-f7f3-40df-a920-dcfd0d608022 05/01/23 23:25:47.546
STEP: Creating secret with name s-test-opt-upd-0ce3b683-9b87-42fb-85a4-74a8cc4a07b7 05/01/23 23:25:47.651
STEP: Creating the pod 05/01/23 23:25:47.758
May  1 23:25:47.867: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4" in namespace "projected-588" to be "running and ready"
May  1 23:25:47.971: INFO: Pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4": Phase="Pending", Reason="", readiness=false. Elapsed: 104.068731ms
May  1 23:25:47.971: INFO: The phase of Pod pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:25:50.077: INFO: Pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.209770388s
May  1 23:25:50.077: INFO: The phase of Pod pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4 is Running (Ready = true)
May  1 23:25:50.077: INFO: Pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-fd23cc76-f7f3-40df-a920-dcfd0d608022 05/01/23 23:25:50.499
STEP: Updating secret s-test-opt-upd-0ce3b683-9b87-42fb-85a4-74a8cc4a07b7 05/01/23 23:25:50.605
STEP: Creating secret with name s-test-opt-create-09e207bd-22fd-4400-a542-8f54c58453e3 05/01/23 23:25:50.71
STEP: waiting to observe update in volume 05/01/23 23:25:50.816
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  1 23:27:11.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-588" for this suite. 05/01/23 23:27:11.347
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":129,"skipped":2430,"failed":0}
------------------------------
• [SLOW TEST] [84.841 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:25:46.713
    May  1 23:25:46.713: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:25:46.715
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:25:47.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:25:47.235
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-fd23cc76-f7f3-40df-a920-dcfd0d608022 05/01/23 23:25:47.546
    STEP: Creating secret with name s-test-opt-upd-0ce3b683-9b87-42fb-85a4-74a8cc4a07b7 05/01/23 23:25:47.651
    STEP: Creating the pod 05/01/23 23:25:47.758
    May  1 23:25:47.867: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4" in namespace "projected-588" to be "running and ready"
    May  1 23:25:47.971: INFO: Pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4": Phase="Pending", Reason="", readiness=false. Elapsed: 104.068731ms
    May  1 23:25:47.971: INFO: The phase of Pod pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:25:50.077: INFO: Pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.209770388s
    May  1 23:25:50.077: INFO: The phase of Pod pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4 is Running (Ready = true)
    May  1 23:25:50.077: INFO: Pod "pod-projected-secrets-d2c1ac7a-1808-46f6-81c9-ea5ee12096f4" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-fd23cc76-f7f3-40df-a920-dcfd0d608022 05/01/23 23:25:50.499
    STEP: Updating secret s-test-opt-upd-0ce3b683-9b87-42fb-85a4-74a8cc4a07b7 05/01/23 23:25:50.605
    STEP: Creating secret with name s-test-opt-create-09e207bd-22fd-4400-a542-8f54c58453e3 05/01/23 23:25:50.71
    STEP: waiting to observe update in volume 05/01/23 23:25:50.816
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  1 23:27:11.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-588" for this suite. 05/01/23 23:27:11.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:27:11.555
May  1 23:27:11.555: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 23:27:11.556
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:27:11.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:27:12.076
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 05/01/23 23:27:29.387
STEP: Creating a ResourceQuota 05/01/23 23:27:34.491
STEP: Ensuring resource quota status is calculated 05/01/23 23:27:34.597
STEP: Creating a ConfigMap 05/01/23 23:27:36.703
STEP: Ensuring resource quota status captures configMap creation 05/01/23 23:27:36.813
STEP: Deleting a ConfigMap 05/01/23 23:27:38.919
STEP: Ensuring resource quota status released usage 05/01/23 23:27:39.024
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 23:27:41.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3463" for this suite. 05/01/23 23:27:41.235
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":130,"skipped":2445,"failed":0}
------------------------------
• [SLOW TEST] [29.786 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:27:11.555
    May  1 23:27:11.555: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 23:27:11.556
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:27:11.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:27:12.076
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 05/01/23 23:27:29.387
    STEP: Creating a ResourceQuota 05/01/23 23:27:34.491
    STEP: Ensuring resource quota status is calculated 05/01/23 23:27:34.597
    STEP: Creating a ConfigMap 05/01/23 23:27:36.703
    STEP: Ensuring resource quota status captures configMap creation 05/01/23 23:27:36.813
    STEP: Deleting a ConfigMap 05/01/23 23:27:38.919
    STEP: Ensuring resource quota status released usage 05/01/23 23:27:39.024
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 23:27:41.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3463" for this suite. 05/01/23 23:27:41.235
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:27:41.346
May  1 23:27:41.346: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:27:41.347
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:27:41.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:27:41.866
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-ef95bd98-dafe-495d-8fd3-a6c8c77cf337 05/01/23 23:27:42.073
STEP: Creating a pod to test consume configMaps 05/01/23 23:27:42.179
May  1 23:27:42.286: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7" in namespace "configmap-2725" to be "Succeeded or Failed"
May  1 23:27:42.390: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.938268ms
May  1 23:27:44.494: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208477063s
May  1 23:27:46.494: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208572794s
STEP: Saw pod success 05/01/23 23:27:46.494
May  1 23:27:46.495: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7" satisfied condition "Succeeded or Failed"
May  1 23:27:46.598: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 23:27:46.71
May  1 23:27:46.819: INFO: Waiting for pod pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7 to disappear
May  1 23:27:46.923: INFO: Pod pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:27:46.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2725" for this suite. 05/01/23 23:27:47.028
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":131,"skipped":2539,"failed":0}
------------------------------
• [SLOW TEST] [5.789 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:27:41.346
    May  1 23:27:41.346: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:27:41.347
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:27:41.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:27:41.866
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-ef95bd98-dafe-495d-8fd3-a6c8c77cf337 05/01/23 23:27:42.073
    STEP: Creating a pod to test consume configMaps 05/01/23 23:27:42.179
    May  1 23:27:42.286: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7" in namespace "configmap-2725" to be "Succeeded or Failed"
    May  1 23:27:42.390: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.938268ms
    May  1 23:27:44.494: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208477063s
    May  1 23:27:46.494: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208572794s
    STEP: Saw pod success 05/01/23 23:27:46.494
    May  1 23:27:46.495: INFO: Pod "pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7" satisfied condition "Succeeded or Failed"
    May  1 23:27:46.598: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 23:27:46.71
    May  1 23:27:46.819: INFO: Waiting for pod pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7 to disappear
    May  1 23:27:46.923: INFO: Pod pod-configmaps-1a90cc30-d628-4aae-9110-593f0f2e4ff7 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:27:46.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2725" for this suite. 05/01/23 23:27:47.028
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:27:47.135
May  1 23:27:47.135: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:27:47.136
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:27:47.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:27:47.655
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 05/01/23 23:27:47.862
May  1 23:27:47.863: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:27:55.013: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:28:26.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2091" for this suite. 05/01/23 23:28:26.856
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":132,"skipped":2552,"failed":0}
------------------------------
• [SLOW TEST] [39.829 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:27:47.135
    May  1 23:27:47.135: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:27:47.136
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:27:47.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:27:47.655
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 05/01/23 23:27:47.862
    May  1 23:27:47.863: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:27:55.013: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:28:26.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2091" for this suite. 05/01/23 23:28:26.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:28:26.968
May  1 23:28:26.968: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 23:28:26.969
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:27.283
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:27.491
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-8d4db39b-0ab4-4e2e-8f96-b0f35f1c0463 05/01/23 23:28:27.804
STEP: Creating secret with name s-test-opt-upd-50e77a65-251c-4741-ab77-33e025c07031 05/01/23 23:28:27.912
STEP: Creating the pod 05/01/23 23:28:28.017
May  1 23:28:28.127: INFO: Waiting up to 5m0s for pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34" in namespace "secrets-2723" to be "running and ready"
May  1 23:28:28.232: INFO: Pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34": Phase="Pending", Reason="", readiness=false. Elapsed: 104.883808ms
May  1 23:28:28.232: INFO: The phase of Pod pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:28:30.337: INFO: Pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34": Phase="Running", Reason="", readiness=true. Elapsed: 2.210200829s
May  1 23:28:30.337: INFO: The phase of Pod pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34 is Running (Ready = true)
May  1 23:28:30.337: INFO: Pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-8d4db39b-0ab4-4e2e-8f96-b0f35f1c0463 05/01/23 23:28:30.763
STEP: Updating secret s-test-opt-upd-50e77a65-251c-4741-ab77-33e025c07031 05/01/23 23:28:30.869
STEP: Creating secret with name s-test-opt-create-407c7cbb-ad74-4b04-b80b-579037091cc4 05/01/23 23:28:30.975
STEP: waiting to observe update in volume 05/01/23 23:28:31.08
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  1 23:28:33.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2723" for this suite. 05/01/23 23:28:33.615
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":133,"skipped":2602,"failed":0}
------------------------------
• [SLOW TEST] [6.754 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:28:26.968
    May  1 23:28:26.968: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 23:28:26.969
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:27.283
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:27.491
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-8d4db39b-0ab4-4e2e-8f96-b0f35f1c0463 05/01/23 23:28:27.804
    STEP: Creating secret with name s-test-opt-upd-50e77a65-251c-4741-ab77-33e025c07031 05/01/23 23:28:27.912
    STEP: Creating the pod 05/01/23 23:28:28.017
    May  1 23:28:28.127: INFO: Waiting up to 5m0s for pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34" in namespace "secrets-2723" to be "running and ready"
    May  1 23:28:28.232: INFO: Pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34": Phase="Pending", Reason="", readiness=false. Elapsed: 104.883808ms
    May  1 23:28:28.232: INFO: The phase of Pod pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:28:30.337: INFO: Pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34": Phase="Running", Reason="", readiness=true. Elapsed: 2.210200829s
    May  1 23:28:30.337: INFO: The phase of Pod pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34 is Running (Ready = true)
    May  1 23:28:30.337: INFO: Pod "pod-secrets-ff58443c-4bc1-4ed7-9c1c-5756b9363b34" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-8d4db39b-0ab4-4e2e-8f96-b0f35f1c0463 05/01/23 23:28:30.763
    STEP: Updating secret s-test-opt-upd-50e77a65-251c-4741-ab77-33e025c07031 05/01/23 23:28:30.869
    STEP: Creating secret with name s-test-opt-create-407c7cbb-ad74-4b04-b80b-579037091cc4 05/01/23 23:28:30.975
    STEP: waiting to observe update in volume 05/01/23 23:28:31.08
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  1 23:28:33.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2723" for this suite. 05/01/23 23:28:33.615
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:28:33.722
May  1 23:28:33.722: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:28:33.723
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:34.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:34.247
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-43dbffda-1f1a-46f9-acdd-8d489fb51a28 05/01/23 23:28:34.455
STEP: Creating a pod to test consume configMaps 05/01/23 23:28:34.56
May  1 23:28:34.669: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7" in namespace "projected-4624" to be "Succeeded or Failed"
May  1 23:28:34.774: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7": Phase="Pending", Reason="", readiness=false. Elapsed: 104.528913ms
May  1 23:28:36.879: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210100299s
May  1 23:28:38.881: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212106465s
STEP: Saw pod success 05/01/23 23:28:38.881
May  1 23:28:38.882: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7" satisfied condition "Succeeded or Failed"
May  1 23:28:38.986: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 23:28:39.093
May  1 23:28:39.206: INFO: Waiting for pod pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7 to disappear
May  1 23:28:39.310: INFO: Pod pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  1 23:28:39.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4624" for this suite. 05/01/23 23:28:39.416
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":134,"skipped":2603,"failed":0}
------------------------------
• [SLOW TEST] [5.800 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:28:33.722
    May  1 23:28:33.722: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:28:33.723
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:34.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:34.247
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-43dbffda-1f1a-46f9-acdd-8d489fb51a28 05/01/23 23:28:34.455
    STEP: Creating a pod to test consume configMaps 05/01/23 23:28:34.56
    May  1 23:28:34.669: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7" in namespace "projected-4624" to be "Succeeded or Failed"
    May  1 23:28:34.774: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7": Phase="Pending", Reason="", readiness=false. Elapsed: 104.528913ms
    May  1 23:28:36.879: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210100299s
    May  1 23:28:38.881: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212106465s
    STEP: Saw pod success 05/01/23 23:28:38.881
    May  1 23:28:38.882: INFO: Pod "pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7" satisfied condition "Succeeded or Failed"
    May  1 23:28:38.986: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 23:28:39.093
    May  1 23:28:39.206: INFO: Waiting for pod pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7 to disappear
    May  1 23:28:39.310: INFO: Pod pod-projected-configmaps-04f87110-1b87-47fd-8a77-cc3485df49a7 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  1 23:28:39.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4624" for this suite. 05/01/23 23:28:39.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:28:39.523
May  1 23:28:39.523: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 23:28:39.524
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:39.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:40.046
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 05/01/23 23:28:40.254
STEP: Getting a ResourceQuota 05/01/23 23:28:40.36
STEP: Updating a ResourceQuota 05/01/23 23:28:40.465
STEP: Verifying a ResourceQuota was modified 05/01/23 23:28:40.573
STEP: Deleting a ResourceQuota 05/01/23 23:28:40.678
STEP: Verifying the deleted ResourceQuota 05/01/23 23:28:40.784
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 23:28:40.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2708" for this suite. 05/01/23 23:28:40.995
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":135,"skipped":2619,"failed":0}
------------------------------
• [1.578 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:28:39.523
    May  1 23:28:39.523: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 23:28:39.524
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:39.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:40.046
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 05/01/23 23:28:40.254
    STEP: Getting a ResourceQuota 05/01/23 23:28:40.36
    STEP: Updating a ResourceQuota 05/01/23 23:28:40.465
    STEP: Verifying a ResourceQuota was modified 05/01/23 23:28:40.573
    STEP: Deleting a ResourceQuota 05/01/23 23:28:40.678
    STEP: Verifying the deleted ResourceQuota 05/01/23 23:28:40.784
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 23:28:40.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2708" for this suite. 05/01/23 23:28:40.995
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:28:41.101
May  1 23:28:41.102: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch 05/01/23 23:28:41.103
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:41.418
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:41.625
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 05/01/23 23:28:41.833
STEP: starting a background goroutine to produce watch events 05/01/23 23:28:41.938
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 05/01/23 23:28:41.938
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
May  1 23:28:52.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9939" for this suite. 05/01/23 23:28:52.888
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":136,"skipped":2625,"failed":0}
------------------------------
• [SLOW TEST] [11.893 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:28:41.101
    May  1 23:28:41.102: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename watch 05/01/23 23:28:41.103
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:41.418
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:41.625
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 05/01/23 23:28:41.833
    STEP: starting a background goroutine to produce watch events 05/01/23 23:28:41.938
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 05/01/23 23:28:41.938
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    May  1 23:28:52.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9939" for this suite. 05/01/23 23:28:52.888
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:28:52.996
May  1 23:28:52.996: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:28:52.997
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:53.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:53.519
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
May  1 23:28:53.836: INFO: Waiting up to 5m0s for pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13" in namespace "kubelet-test-4820" to be "running and ready"
May  1 23:28:53.941: INFO: Pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13": Phase="Pending", Reason="", readiness=false. Elapsed: 104.805047ms
May  1 23:28:53.941: INFO: The phase of Pod busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:28:56.046: INFO: Pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13": Phase="Running", Reason="", readiness=true. Elapsed: 2.210046954s
May  1 23:28:56.046: INFO: The phase of Pod busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13 is Running (Ready = true)
May  1 23:28:56.046: INFO: Pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
May  1 23:28:56.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4820" for this suite. 05/01/23 23:28:56.363
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":137,"skipped":2638,"failed":0}
------------------------------
• [3.475 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:28:52.996
    May  1 23:28:52.996: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:28:52.997
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:53.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:53.519
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    May  1 23:28:53.836: INFO: Waiting up to 5m0s for pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13" in namespace "kubelet-test-4820" to be "running and ready"
    May  1 23:28:53.941: INFO: Pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13": Phase="Pending", Reason="", readiness=false. Elapsed: 104.805047ms
    May  1 23:28:53.941: INFO: The phase of Pod busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:28:56.046: INFO: Pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13": Phase="Running", Reason="", readiness=true. Elapsed: 2.210046954s
    May  1 23:28:56.046: INFO: The phase of Pod busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13 is Running (Ready = true)
    May  1 23:28:56.046: INFO: Pod "busybox-scheduling-b999b75e-ddf1-4da9-8577-273c79675e13" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    May  1 23:28:56.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4820" for this suite. 05/01/23 23:28:56.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:28:56.473
May  1 23:28:56.473: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:28:56.474
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:56.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:56.997
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:28:57.205
May  1 23:28:57.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99" in namespace "downward-api-8964" to be "Succeeded or Failed"
May  1 23:28:57.417: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99": Phase="Pending", Reason="", readiness=false. Elapsed: 104.676522ms
May  1 23:28:59.523: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21052509s
May  1 23:29:01.522: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209654042s
STEP: Saw pod success 05/01/23 23:29:01.522
May  1 23:29:01.523: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99" satisfied condition "Succeeded or Failed"
May  1 23:29:01.627: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99 container client-container: <nil>
STEP: delete the pod 05/01/23 23:29:01.735
May  1 23:29:01.848: INFO: Waiting for pod downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99 to disappear
May  1 23:29:01.952: INFO: Pod downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:29:01.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8964" for this suite. 05/01/23 23:29:02.058
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":138,"skipped":2668,"failed":0}
------------------------------
• [SLOW TEST] [5.792 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:28:56.473
    May  1 23:28:56.473: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:28:56.474
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:28:56.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:28:56.997
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:28:57.205
    May  1 23:28:57.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99" in namespace "downward-api-8964" to be "Succeeded or Failed"
    May  1 23:28:57.417: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99": Phase="Pending", Reason="", readiness=false. Elapsed: 104.676522ms
    May  1 23:28:59.523: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21052509s
    May  1 23:29:01.522: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209654042s
    STEP: Saw pod success 05/01/23 23:29:01.522
    May  1 23:29:01.523: INFO: Pod "downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99" satisfied condition "Succeeded or Failed"
    May  1 23:29:01.627: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:29:01.735
    May  1 23:29:01.848: INFO: Waiting for pod downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99 to disappear
    May  1 23:29:01.952: INFO: Pod downwardapi-volume-b726164b-a15d-47a4-a180-539aff6b5c99 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:29:01.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8964" for this suite. 05/01/23 23:29:02.058
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:02.266
May  1 23:29:02.267: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 23:29:02.268
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:02.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:02.791
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 05/01/23 23:29:02.998
May  1 23:29:03.106: INFO: Waiting up to 5m0s for pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69" in namespace "emptydir-7266" to be "Succeeded or Failed"
May  1 23:29:03.211: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69": Phase="Pending", Reason="", readiness=false. Elapsed: 104.498761ms
May  1 23:29:05.316: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69": Phase="Running", Reason="", readiness=false. Elapsed: 2.209733575s
May  1 23:29:07.316: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209324703s
STEP: Saw pod success 05/01/23 23:29:07.316
May  1 23:29:07.316: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69" satisfied condition "Succeeded or Failed"
May  1 23:29:07.422: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-0ffb1938-4fda-488d-88fc-af78c1925b69 container test-container: <nil>
STEP: delete the pod 05/01/23 23:29:07.528
May  1 23:29:07.640: INFO: Waiting for pod pod-0ffb1938-4fda-488d-88fc-af78c1925b69 to disappear
May  1 23:29:07.744: INFO: Pod pod-0ffb1938-4fda-488d-88fc-af78c1925b69 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 23:29:07.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7266" for this suite. 05/01/23 23:29:07.85
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":139,"skipped":2680,"failed":0}
------------------------------
• [SLOW TEST] [5.791 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:02.266
    May  1 23:29:02.267: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 23:29:02.268
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:02.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:02.791
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 05/01/23 23:29:02.998
    May  1 23:29:03.106: INFO: Waiting up to 5m0s for pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69" in namespace "emptydir-7266" to be "Succeeded or Failed"
    May  1 23:29:03.211: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69": Phase="Pending", Reason="", readiness=false. Elapsed: 104.498761ms
    May  1 23:29:05.316: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69": Phase="Running", Reason="", readiness=false. Elapsed: 2.209733575s
    May  1 23:29:07.316: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209324703s
    STEP: Saw pod success 05/01/23 23:29:07.316
    May  1 23:29:07.316: INFO: Pod "pod-0ffb1938-4fda-488d-88fc-af78c1925b69" satisfied condition "Succeeded or Failed"
    May  1 23:29:07.422: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-0ffb1938-4fda-488d-88fc-af78c1925b69 container test-container: <nil>
    STEP: delete the pod 05/01/23 23:29:07.528
    May  1 23:29:07.640: INFO: Waiting for pod pod-0ffb1938-4fda-488d-88fc-af78c1925b69 to disappear
    May  1 23:29:07.744: INFO: Pod pod-0ffb1938-4fda-488d-88fc-af78c1925b69 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 23:29:07.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7266" for this suite. 05/01/23 23:29:07.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:08.059
May  1 23:29:08.059: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:29:08.06
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:08.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:08.583
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
May  1 23:29:09.005: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1596 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
May  1 23:29:09.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1596" for this suite. 05/01/23 23:29:09.32
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":140,"skipped":2687,"failed":0}
------------------------------
• [1.367 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:08.059
    May  1 23:29:08.059: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:29:08.06
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:08.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:08.583
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    May  1 23:29:09.005: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1596 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    May  1 23:29:09.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1596" for this suite. 05/01/23 23:29:09.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:09.428
May  1 23:29:09.428: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:29:09.429
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:09.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:09.95
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-082a8694-f6fb-4cb3-90fb-cbf96072e4bb 05/01/23 23:29:10.158
STEP: Creating a pod to test consume configMaps 05/01/23 23:29:10.265
May  1 23:29:10.373: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada" in namespace "projected-8603" to be "Succeeded or Failed"
May  1 23:29:10.477: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada": Phase="Pending", Reason="", readiness=false. Elapsed: 104.513098ms
May  1 23:29:12.583: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209601503s
May  1 23:29:14.582: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209522381s
STEP: Saw pod success 05/01/23 23:29:14.583
May  1 23:29:14.583: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada" satisfied condition "Succeeded or Failed"
May  1 23:29:14.687: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada container agnhost-container: <nil>
STEP: delete the pod 05/01/23 23:29:14.796
May  1 23:29:14.909: INFO: Waiting for pod pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada to disappear
May  1 23:29:15.013: INFO: Pod pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  1 23:29:15.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8603" for this suite. 05/01/23 23:29:15.12
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":141,"skipped":2733,"failed":0}
------------------------------
• [SLOW TEST] [5.799 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:09.428
    May  1 23:29:09.428: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:29:09.429
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:09.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:09.95
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-082a8694-f6fb-4cb3-90fb-cbf96072e4bb 05/01/23 23:29:10.158
    STEP: Creating a pod to test consume configMaps 05/01/23 23:29:10.265
    May  1 23:29:10.373: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada" in namespace "projected-8603" to be "Succeeded or Failed"
    May  1 23:29:10.477: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada": Phase="Pending", Reason="", readiness=false. Elapsed: 104.513098ms
    May  1 23:29:12.583: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209601503s
    May  1 23:29:14.582: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209522381s
    STEP: Saw pod success 05/01/23 23:29:14.583
    May  1 23:29:14.583: INFO: Pod "pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada" satisfied condition "Succeeded or Failed"
    May  1 23:29:14.687: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 23:29:14.796
    May  1 23:29:14.909: INFO: Waiting for pod pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada to disappear
    May  1 23:29:15.013: INFO: Pod pod-projected-configmaps-fb806f05-3dfb-4dab-8a0d-48ebc235aada no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  1 23:29:15.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8603" for this suite. 05/01/23 23:29:15.12
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:15.227
May  1 23:29:15.227: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:29:15.228
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:15.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:15.751
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
May  1 23:29:16.174: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5105 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
May  1 23:29:16.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5105" for this suite. 05/01/23 23:29:16.49
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":142,"skipped":2737,"failed":0}
------------------------------
• [1.371 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:15.227
    May  1 23:29:15.227: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename runtimeclass 05/01/23 23:29:15.228
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:15.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:15.751
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    May  1 23:29:16.174: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5105 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    May  1 23:29:16.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5105" for this suite. 05/01/23 23:29:16.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:16.6
May  1 23:29:16.600: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller 05/01/23 23:29:16.602
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:16.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:17.124
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 05/01/23 23:29:17.437
STEP: waiting for RC to be added 05/01/23 23:29:17.544
STEP: waiting for available Replicas 05/01/23 23:29:17.544
STEP: patching ReplicationController 05/01/23 23:29:18.991
STEP: waiting for RC to be modified 05/01/23 23:29:19.1
STEP: patching ReplicationController status 05/01/23 23:29:19.1
STEP: waiting for RC to be modified 05/01/23 23:29:19.208
STEP: waiting for available Replicas 05/01/23 23:29:19.209
STEP: fetching ReplicationController status 05/01/23 23:29:19.212
STEP: patching ReplicationController scale 05/01/23 23:29:19.317
STEP: waiting for RC to be modified 05/01/23 23:29:19.424
STEP: waiting for ReplicationController's scale to be the max amount 05/01/23 23:29:19.424
STEP: fetching ReplicationController; ensuring that it's patched 05/01/23 23:29:21.006
STEP: updating ReplicationController status 05/01/23 23:29:21.111
STEP: waiting for RC to be modified 05/01/23 23:29:21.219
STEP: listing all ReplicationControllers 05/01/23 23:29:21.22
STEP: checking that ReplicationController has expected values 05/01/23 23:29:21.324
STEP: deleting ReplicationControllers by collection 05/01/23 23:29:21.324
STEP: waiting for ReplicationController to have a DELETED watchEvent 05/01/23 23:29:21.434
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
May  1 23:29:21.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3300" for this suite. 05/01/23 23:29:21.691
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":143,"skipped":2782,"failed":0}
------------------------------
• [SLOW TEST] [5.199 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:16.6
    May  1 23:29:16.600: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replication-controller 05/01/23 23:29:16.602
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:16.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:17.124
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 05/01/23 23:29:17.437
    STEP: waiting for RC to be added 05/01/23 23:29:17.544
    STEP: waiting for available Replicas 05/01/23 23:29:17.544
    STEP: patching ReplicationController 05/01/23 23:29:18.991
    STEP: waiting for RC to be modified 05/01/23 23:29:19.1
    STEP: patching ReplicationController status 05/01/23 23:29:19.1
    STEP: waiting for RC to be modified 05/01/23 23:29:19.208
    STEP: waiting for available Replicas 05/01/23 23:29:19.209
    STEP: fetching ReplicationController status 05/01/23 23:29:19.212
    STEP: patching ReplicationController scale 05/01/23 23:29:19.317
    STEP: waiting for RC to be modified 05/01/23 23:29:19.424
    STEP: waiting for ReplicationController's scale to be the max amount 05/01/23 23:29:19.424
    STEP: fetching ReplicationController; ensuring that it's patched 05/01/23 23:29:21.006
    STEP: updating ReplicationController status 05/01/23 23:29:21.111
    STEP: waiting for RC to be modified 05/01/23 23:29:21.219
    STEP: listing all ReplicationControllers 05/01/23 23:29:21.22
    STEP: checking that ReplicationController has expected values 05/01/23 23:29:21.324
    STEP: deleting ReplicationControllers by collection 05/01/23 23:29:21.324
    STEP: waiting for ReplicationController to have a DELETED watchEvent 05/01/23 23:29:21.434
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    May  1 23:29:21.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3300" for this suite. 05/01/23 23:29:21.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:21.799
May  1 23:29:21.799: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:29:21.8
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:22.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:22.322
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
May  1 23:29:22.530: INFO: >>> kubeConfig: /root/.kube/config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 05/01/23 23:29:27.597
May  1 23:29:27.598: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 create -f -'
May  1 23:29:29.310: INFO: stderr: ""
May  1 23:29:29.310: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May  1 23:29:29.310: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
May  1 23:29:29.815: INFO: stderr: ""
May  1 23:29:29.815: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
May  1 23:29:29.815: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 apply -f -'
May  1 23:29:30.671: INFO: stderr: ""
May  1 23:29:30.671: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May  1 23:29:30.671: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
May  1 23:29:31.174: INFO: stderr: ""
May  1 23:29:31.174: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 05/01/23 23:29:31.174
May  1 23:29:31.174: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 explain e2e-test-crd-publish-openapi-4231-crds'
May  1 23:29:31.713: INFO: stderr: ""
May  1 23:29:31.713: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4231-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:29:38.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4710" for this suite. 05/01/23 23:29:39.378
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":144,"skipped":2792,"failed":0}
------------------------------
• [SLOW TEST] [17.684 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:21.799
    May  1 23:29:21.799: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:29:21.8
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:22.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:22.322
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    May  1 23:29:22.530: INFO: >>> kubeConfig: /root/.kube/config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 05/01/23 23:29:27.597
    May  1 23:29:27.598: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 create -f -'
    May  1 23:29:29.310: INFO: stderr: ""
    May  1 23:29:29.310: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    May  1 23:29:29.310: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
    May  1 23:29:29.815: INFO: stderr: ""
    May  1 23:29:29.815: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    May  1 23:29:29.815: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 apply -f -'
    May  1 23:29:30.671: INFO: stderr: ""
    May  1 23:29:30.671: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    May  1 23:29:30.671: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 --namespace=crd-publish-openapi-4710 delete e2e-test-crd-publish-openapi-4231-crds test-cr'
    May  1 23:29:31.174: INFO: stderr: ""
    May  1 23:29:31.174: INFO: stdout: "e2e-test-crd-publish-openapi-4231-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 05/01/23 23:29:31.174
    May  1 23:29:31.174: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4710 explain e2e-test-crd-publish-openapi-4231-crds'
    May  1 23:29:31.713: INFO: stderr: ""
    May  1 23:29:31.713: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4231-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:29:38.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4710" for this suite. 05/01/23 23:29:39.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:39.485
May  1 23:29:39.485: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename proxy 05/01/23 23:29:39.487
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:39.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:40.004
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
May  1 23:29:40.210: INFO: Creating pod...
May  1 23:29:40.318: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3029" to be "running"
May  1 23:29:40.422: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 103.787237ms
May  1 23:29:42.526: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.208651775s
May  1 23:29:42.526: INFO: Pod "agnhost" satisfied condition "running"
May  1 23:29:42.526: INFO: Creating service...
May  1 23:29:42.636: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=DELETE
May  1 23:29:42.740: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May  1 23:29:42.740: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=OPTIONS
May  1 23:29:42.844: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May  1 23:29:42.844: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=PATCH
May  1 23:29:42.948: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May  1 23:29:42.948: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=POST
May  1 23:29:43.051: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May  1 23:29:43.051: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=PUT
May  1 23:29:43.154: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May  1 23:29:43.154: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=DELETE
May  1 23:29:43.259: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
May  1 23:29:43.259: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=OPTIONS
May  1 23:29:43.363: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
May  1 23:29:43.363: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=PATCH
May  1 23:29:43.467: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
May  1 23:29:43.467: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=POST
May  1 23:29:43.571: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
May  1 23:29:43.571: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=PUT
May  1 23:29:43.675: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
May  1 23:29:43.675: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=GET
May  1 23:29:43.778: INFO: http.Client request:GET StatusCode:301
May  1 23:29:43.778: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=GET
May  1 23:29:43.882: INFO: http.Client request:GET StatusCode:301
May  1 23:29:43.882: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=HEAD
May  1 23:29:43.985: INFO: http.Client request:HEAD StatusCode:301
May  1 23:29:43.985: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=HEAD
May  1 23:29:44.088: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
May  1 23:29:44.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3029" for this suite. 05/01/23 23:29:44.193
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":145,"skipped":2803,"failed":0}
------------------------------
• [4.812 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:39.485
    May  1 23:29:39.485: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename proxy 05/01/23 23:29:39.487
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:39.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:40.004
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    May  1 23:29:40.210: INFO: Creating pod...
    May  1 23:29:40.318: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3029" to be "running"
    May  1 23:29:40.422: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 103.787237ms
    May  1 23:29:42.526: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.208651775s
    May  1 23:29:42.526: INFO: Pod "agnhost" satisfied condition "running"
    May  1 23:29:42.526: INFO: Creating service...
    May  1 23:29:42.636: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=DELETE
    May  1 23:29:42.740: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    May  1 23:29:42.740: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=OPTIONS
    May  1 23:29:42.844: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    May  1 23:29:42.844: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=PATCH
    May  1 23:29:42.948: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    May  1 23:29:42.948: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=POST
    May  1 23:29:43.051: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    May  1 23:29:43.051: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=PUT
    May  1 23:29:43.154: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    May  1 23:29:43.154: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=DELETE
    May  1 23:29:43.259: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    May  1 23:29:43.259: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=OPTIONS
    May  1 23:29:43.363: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    May  1 23:29:43.363: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=PATCH
    May  1 23:29:43.467: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    May  1 23:29:43.467: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=POST
    May  1 23:29:43.571: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    May  1 23:29:43.571: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=PUT
    May  1 23:29:43.675: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    May  1 23:29:43.675: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=GET
    May  1 23:29:43.778: INFO: http.Client request:GET StatusCode:301
    May  1 23:29:43.778: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=GET
    May  1 23:29:43.882: INFO: http.Client request:GET StatusCode:301
    May  1 23:29:43.882: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/pods/agnhost/proxy?method=HEAD
    May  1 23:29:43.985: INFO: http.Client request:HEAD StatusCode:301
    May  1 23:29:43.985: INFO: Starting http.Client for https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/proxy-3029/services/e2e-proxy-test-service/proxy?method=HEAD
    May  1 23:29:44.088: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    May  1 23:29:44.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3029" for this suite. 05/01/23 23:29:44.193
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:44.3
May  1 23:29:44.300: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:29:44.302
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:44.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:44.816
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:29:45.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-107" for this suite. 05/01/23 23:29:45.228
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":146,"skipped":2845,"failed":0}
------------------------------
• [1.033 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:44.3
    May  1 23:29:44.300: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:29:44.302
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:44.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:44.816
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:29:45.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-107" for this suite. 05/01/23 23:29:45.228
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:45.334
May  1 23:29:45.334: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 23:29:45.335
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:45.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:45.85
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 05/01/23 23:29:46.055
May  1 23:29:46.163: INFO: Waiting up to 5m0s for pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec" in namespace "emptydir-8555" to be "Succeeded or Failed"
May  1 23:29:46.266: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec": Phase="Pending", Reason="", readiness=false. Elapsed: 102.982331ms
May  1 23:29:48.370: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec": Phase="Running", Reason="", readiness=false. Elapsed: 2.206794138s
May  1 23:29:50.370: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206652425s
STEP: Saw pod success 05/01/23 23:29:50.37
May  1 23:29:50.370: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec" satisfied condition "Succeeded or Failed"
May  1 23:29:50.473: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec container test-container: <nil>
STEP: delete the pod 05/01/23 23:29:50.58
May  1 23:29:50.691: INFO: Waiting for pod pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec to disappear
May  1 23:29:50.794: INFO: Pod pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 23:29:50.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8555" for this suite. 05/01/23 23:29:50.899
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":147,"skipped":2866,"failed":0}
------------------------------
• [SLOW TEST] [5.769 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:45.334
    May  1 23:29:45.334: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 23:29:45.335
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:45.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:45.85
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 05/01/23 23:29:46.055
    May  1 23:29:46.163: INFO: Waiting up to 5m0s for pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec" in namespace "emptydir-8555" to be "Succeeded or Failed"
    May  1 23:29:46.266: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec": Phase="Pending", Reason="", readiness=false. Elapsed: 102.982331ms
    May  1 23:29:48.370: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec": Phase="Running", Reason="", readiness=false. Elapsed: 2.206794138s
    May  1 23:29:50.370: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206652425s
    STEP: Saw pod success 05/01/23 23:29:50.37
    May  1 23:29:50.370: INFO: Pod "pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec" satisfied condition "Succeeded or Failed"
    May  1 23:29:50.473: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec container test-container: <nil>
    STEP: delete the pod 05/01/23 23:29:50.58
    May  1 23:29:50.691: INFO: Waiting for pod pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec to disappear
    May  1 23:29:50.794: INFO: Pod pod-3c4a11d5-8a33-40fd-88e7-1fb863aa54ec no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 23:29:50.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8555" for this suite. 05/01/23 23:29:50.899
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:51.105
May  1 23:29:51.105: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition 05/01/23 23:29:51.106
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:51.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:51.62
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 05/01/23 23:29:51.825
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 05/01/23 23:29:51.928
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 05/01/23 23:29:51.928
STEP: fetching the /apis/apiextensions.k8s.io discovery document 05/01/23 23:29:51.928
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 05/01/23 23:29:52.088
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 05/01/23 23:29:52.088
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 05/01/23 23:29:52.191
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:29:52.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2389" for this suite. 05/01/23 23:29:52.295
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":148,"skipped":2898,"failed":0}
------------------------------
• [1.295 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:51.105
    May  1 23:29:51.105: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename custom-resource-definition 05/01/23 23:29:51.106
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:51.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:51.62
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 05/01/23 23:29:51.825
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 05/01/23 23:29:51.928
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 05/01/23 23:29:51.928
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 05/01/23 23:29:51.928
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 05/01/23 23:29:52.088
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 05/01/23 23:29:52.088
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 05/01/23 23:29:52.191
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:29:52.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2389" for this suite. 05/01/23 23:29:52.295
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:29:52.4
May  1 23:29:52.400: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 23:29:52.401
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:52.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:52.918
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 05/01/23 23:29:53.122
May  1 23:29:53.122: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 create -f -'
May  1 23:29:54.481: INFO: stderr: ""
May  1 23:29:54.481: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:29:54.481
May  1 23:29:54.481: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:29:54.982: INFO: stderr: ""
May  1 23:29:54.982: INFO: stdout: "update-demo-nautilus-kcbgs update-demo-nautilus-z8qz4 "
May  1 23:29:54.982: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-kcbgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:29:55.388: INFO: stderr: ""
May  1 23:29:55.388: INFO: stdout: ""
May  1 23:29:55.388: INFO: update-demo-nautilus-kcbgs is created but not running
May  1 23:30:00.388: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:30:00.915: INFO: stderr: ""
May  1 23:30:00.915: INFO: stdout: "update-demo-nautilus-kcbgs update-demo-nautilus-z8qz4 "
May  1 23:30:00.915: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-kcbgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:30:01.335: INFO: stderr: ""
May  1 23:30:01.335: INFO: stdout: "true"
May  1 23:30:01.335: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-kcbgs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:30:01.744: INFO: stderr: ""
May  1 23:30:01.744: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:30:01.744: INFO: validating pod update-demo-nautilus-kcbgs
May  1 23:30:01.849: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:30:01.849: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:30:01.849: INFO: update-demo-nautilus-kcbgs is verified up and running
May  1 23:30:01.849: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:30:02.261: INFO: stderr: ""
May  1 23:30:02.262: INFO: stdout: "true"
May  1 23:30:02.262: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:30:02.687: INFO: stderr: ""
May  1 23:30:02.687: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:30:02.687: INFO: validating pod update-demo-nautilus-z8qz4
May  1 23:30:02.792: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:30:02.792: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:30:02.792: INFO: update-demo-nautilus-z8qz4 is verified up and running
STEP: scaling down the replication controller 05/01/23 23:30:02.792
May  1 23:30:02.794: INFO: scanned /root for discovery docs: <nil>
May  1 23:30:02.794: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
May  1 23:30:03.408: INFO: stderr: ""
May  1 23:30:03.408: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:30:03.408
May  1 23:30:03.408: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:30:03.909: INFO: stderr: ""
May  1 23:30:03.909: INFO: stdout: "update-demo-nautilus-kcbgs update-demo-nautilus-z8qz4 "
STEP: Replicas for name=update-demo: expected=1 actual=2 05/01/23 23:30:03.909
May  1 23:30:08.910: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:30:09.332: INFO: stderr: ""
May  1 23:30:09.332: INFO: stdout: "update-demo-nautilus-z8qz4 "
May  1 23:30:09.332: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:30:09.750: INFO: stderr: ""
May  1 23:30:09.750: INFO: stdout: "true"
May  1 23:30:09.750: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:30:10.170: INFO: stderr: ""
May  1 23:30:10.170: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:30:10.170: INFO: validating pod update-demo-nautilus-z8qz4
May  1 23:30:10.274: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:30:10.274: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:30:10.274: INFO: update-demo-nautilus-z8qz4 is verified up and running
STEP: scaling up the replication controller 05/01/23 23:30:10.274
May  1 23:30:10.275: INFO: scanned /root for discovery docs: <nil>
May  1 23:30:10.275: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
May  1 23:30:10.914: INFO: stderr: ""
May  1 23:30:10.914: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:30:10.914
May  1 23:30:10.914: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:30:11.442: INFO: stderr: ""
May  1 23:30:11.442: INFO: stdout: "update-demo-nautilus-ln56q update-demo-nautilus-z8qz4 "
May  1 23:30:11.443: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-ln56q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:30:11.840: INFO: stderr: ""
May  1 23:30:11.840: INFO: stdout: ""
May  1 23:30:11.840: INFO: update-demo-nautilus-ln56q is created but not running
May  1 23:30:16.842: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:30:17.368: INFO: stderr: ""
May  1 23:30:17.368: INFO: stdout: "update-demo-nautilus-ln56q update-demo-nautilus-z8qz4 "
May  1 23:30:17.368: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-ln56q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:30:17.772: INFO: stderr: ""
May  1 23:30:17.772: INFO: stdout: "true"
May  1 23:30:17.772: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-ln56q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:30:18.176: INFO: stderr: ""
May  1 23:30:18.176: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:30:18.176: INFO: validating pod update-demo-nautilus-ln56q
May  1 23:30:18.281: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:30:18.281: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:30:18.281: INFO: update-demo-nautilus-ln56q is verified up and running
May  1 23:30:18.281: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:30:18.683: INFO: stderr: ""
May  1 23:30:18.683: INFO: stdout: "true"
May  1 23:30:18.683: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:30:19.100: INFO: stderr: ""
May  1 23:30:19.100: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:30:19.100: INFO: validating pod update-demo-nautilus-z8qz4
May  1 23:30:19.208: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:30:19.208: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:30:19.208: INFO: update-demo-nautilus-z8qz4 is verified up and running
STEP: using delete to clean up resources 05/01/23 23:30:19.208
May  1 23:30:19.208: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 delete --grace-period=0 --force -f -'
May  1 23:30:19.723: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  1 23:30:19.723: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  1 23:30:19.723: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get rc,svc -l name=update-demo --no-headers'
May  1 23:30:20.240: INFO: stderr: "No resources found in kubectl-5258 namespace.\n"
May  1 23:30:20.240: INFO: stdout: ""
May  1 23:30:20.240: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  1 23:30:20.634: INFO: stderr: ""
May  1 23:30:20.634: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 23:30:20.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5258" for this suite. 05/01/23 23:30:20.738
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":149,"skipped":2919,"failed":0}
------------------------------
• [SLOW TEST] [28.542 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:29:52.4
    May  1 23:29:52.400: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 23:29:52.401
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:29:52.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:29:52.918
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 05/01/23 23:29:53.122
    May  1 23:29:53.122: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 create -f -'
    May  1 23:29:54.481: INFO: stderr: ""
    May  1 23:29:54.481: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:29:54.481
    May  1 23:29:54.481: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:29:54.982: INFO: stderr: ""
    May  1 23:29:54.982: INFO: stdout: "update-demo-nautilus-kcbgs update-demo-nautilus-z8qz4 "
    May  1 23:29:54.982: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-kcbgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:29:55.388: INFO: stderr: ""
    May  1 23:29:55.388: INFO: stdout: ""
    May  1 23:29:55.388: INFO: update-demo-nautilus-kcbgs is created but not running
    May  1 23:30:00.388: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:30:00.915: INFO: stderr: ""
    May  1 23:30:00.915: INFO: stdout: "update-demo-nautilus-kcbgs update-demo-nautilus-z8qz4 "
    May  1 23:30:00.915: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-kcbgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:30:01.335: INFO: stderr: ""
    May  1 23:30:01.335: INFO: stdout: "true"
    May  1 23:30:01.335: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-kcbgs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:30:01.744: INFO: stderr: ""
    May  1 23:30:01.744: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:30:01.744: INFO: validating pod update-demo-nautilus-kcbgs
    May  1 23:30:01.849: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:30:01.849: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:30:01.849: INFO: update-demo-nautilus-kcbgs is verified up and running
    May  1 23:30:01.849: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:30:02.261: INFO: stderr: ""
    May  1 23:30:02.262: INFO: stdout: "true"
    May  1 23:30:02.262: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:30:02.687: INFO: stderr: ""
    May  1 23:30:02.687: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:30:02.687: INFO: validating pod update-demo-nautilus-z8qz4
    May  1 23:30:02.792: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:30:02.792: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:30:02.792: INFO: update-demo-nautilus-z8qz4 is verified up and running
    STEP: scaling down the replication controller 05/01/23 23:30:02.792
    May  1 23:30:02.794: INFO: scanned /root for discovery docs: <nil>
    May  1 23:30:02.794: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    May  1 23:30:03.408: INFO: stderr: ""
    May  1 23:30:03.408: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:30:03.408
    May  1 23:30:03.408: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:30:03.909: INFO: stderr: ""
    May  1 23:30:03.909: INFO: stdout: "update-demo-nautilus-kcbgs update-demo-nautilus-z8qz4 "
    STEP: Replicas for name=update-demo: expected=1 actual=2 05/01/23 23:30:03.909
    May  1 23:30:08.910: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:30:09.332: INFO: stderr: ""
    May  1 23:30:09.332: INFO: stdout: "update-demo-nautilus-z8qz4 "
    May  1 23:30:09.332: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:30:09.750: INFO: stderr: ""
    May  1 23:30:09.750: INFO: stdout: "true"
    May  1 23:30:09.750: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:30:10.170: INFO: stderr: ""
    May  1 23:30:10.170: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:30:10.170: INFO: validating pod update-demo-nautilus-z8qz4
    May  1 23:30:10.274: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:30:10.274: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:30:10.274: INFO: update-demo-nautilus-z8qz4 is verified up and running
    STEP: scaling up the replication controller 05/01/23 23:30:10.274
    May  1 23:30:10.275: INFO: scanned /root for discovery docs: <nil>
    May  1 23:30:10.275: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    May  1 23:30:10.914: INFO: stderr: ""
    May  1 23:30:10.914: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:30:10.914
    May  1 23:30:10.914: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:30:11.442: INFO: stderr: ""
    May  1 23:30:11.442: INFO: stdout: "update-demo-nautilus-ln56q update-demo-nautilus-z8qz4 "
    May  1 23:30:11.443: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-ln56q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:30:11.840: INFO: stderr: ""
    May  1 23:30:11.840: INFO: stdout: ""
    May  1 23:30:11.840: INFO: update-demo-nautilus-ln56q is created but not running
    May  1 23:30:16.842: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:30:17.368: INFO: stderr: ""
    May  1 23:30:17.368: INFO: stdout: "update-demo-nautilus-ln56q update-demo-nautilus-z8qz4 "
    May  1 23:30:17.368: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-ln56q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:30:17.772: INFO: stderr: ""
    May  1 23:30:17.772: INFO: stdout: "true"
    May  1 23:30:17.772: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-ln56q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:30:18.176: INFO: stderr: ""
    May  1 23:30:18.176: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:30:18.176: INFO: validating pod update-demo-nautilus-ln56q
    May  1 23:30:18.281: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:30:18.281: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:30:18.281: INFO: update-demo-nautilus-ln56q is verified up and running
    May  1 23:30:18.281: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:30:18.683: INFO: stderr: ""
    May  1 23:30:18.683: INFO: stdout: "true"
    May  1 23:30:18.683: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods update-demo-nautilus-z8qz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:30:19.100: INFO: stderr: ""
    May  1 23:30:19.100: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:30:19.100: INFO: validating pod update-demo-nautilus-z8qz4
    May  1 23:30:19.208: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:30:19.208: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:30:19.208: INFO: update-demo-nautilus-z8qz4 is verified up and running
    STEP: using delete to clean up resources 05/01/23 23:30:19.208
    May  1 23:30:19.208: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 delete --grace-period=0 --force -f -'
    May  1 23:30:19.723: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  1 23:30:19.723: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    May  1 23:30:19.723: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get rc,svc -l name=update-demo --no-headers'
    May  1 23:30:20.240: INFO: stderr: "No resources found in kubectl-5258 namespace.\n"
    May  1 23:30:20.240: INFO: stdout: ""
    May  1 23:30:20.240: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5258 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    May  1 23:30:20.634: INFO: stderr: ""
    May  1 23:30:20.634: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 23:30:20.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5258" for this suite. 05/01/23 23:30:20.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:30:20.944
May  1 23:30:20.944: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename disruption 05/01/23 23:30:20.945
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:21.257
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:21.461
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 05/01/23 23:30:21.666
STEP: Waiting for the pdb to be processed 05/01/23 23:30:21.77
STEP: updating the pdb 05/01/23 23:30:21.873
STEP: Waiting for the pdb to be processed 05/01/23 23:30:22.082
STEP: patching the pdb 05/01/23 23:30:22.185
STEP: Waiting for the pdb to be processed 05/01/23 23:30:22.392
STEP: Waiting for the pdb to be deleted 05/01/23 23:30:22.6
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
May  1 23:30:22.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5243" for this suite. 05/01/23 23:30:22.808
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":150,"skipped":2952,"failed":0}
------------------------------
• [1.969 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:30:20.944
    May  1 23:30:20.944: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename disruption 05/01/23 23:30:20.945
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:21.257
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:21.461
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 05/01/23 23:30:21.666
    STEP: Waiting for the pdb to be processed 05/01/23 23:30:21.77
    STEP: updating the pdb 05/01/23 23:30:21.873
    STEP: Waiting for the pdb to be processed 05/01/23 23:30:22.082
    STEP: patching the pdb 05/01/23 23:30:22.185
    STEP: Waiting for the pdb to be processed 05/01/23 23:30:22.392
    STEP: Waiting for the pdb to be deleted 05/01/23 23:30:22.6
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    May  1 23:30:22.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5243" for this suite. 05/01/23 23:30:22.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:30:22.916
May  1 23:30:22.917: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch 05/01/23 23:30:22.918
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:23.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:23.435
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 05/01/23 23:30:23.641
STEP: creating a new configmap 05/01/23 23:30:23.743
STEP: modifying the configmap once 05/01/23 23:30:23.848
STEP: changing the label value of the configmap 05/01/23 23:30:24.055
STEP: Expecting to observe a delete notification for the watched object 05/01/23 23:30:24.262
May  1 23:30:24.262: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18462 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:30:24.262: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18463 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:30:24.263: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18465 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 05/01/23 23:30:24.263
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 05/01/23 23:30:24.47
STEP: changing the label value of the configmap back 05/01/23 23:30:34.471
STEP: modifying the configmap a third time 05/01/23 23:30:34.679
STEP: deleting the configmap 05/01/23 23:30:34.886
STEP: Expecting to observe an add notification for the watched object when the label value was restored 05/01/23 23:30:34.991
May  1 23:30:34.991: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18508 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:30:34.991: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18510 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
May  1 23:30:34.991: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18511 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
May  1 23:30:34.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3812" for this suite. 05/01/23 23:30:35.095
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":151,"skipped":3002,"failed":0}
------------------------------
• [SLOW TEST] [12.284 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:30:22.916
    May  1 23:30:22.917: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename watch 05/01/23 23:30:22.918
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:23.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:23.435
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 05/01/23 23:30:23.641
    STEP: creating a new configmap 05/01/23 23:30:23.743
    STEP: modifying the configmap once 05/01/23 23:30:23.848
    STEP: changing the label value of the configmap 05/01/23 23:30:24.055
    STEP: Expecting to observe a delete notification for the watched object 05/01/23 23:30:24.262
    May  1 23:30:24.262: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18462 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:30:24.262: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18463 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:30:24.263: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18465 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 05/01/23 23:30:24.263
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 05/01/23 23:30:24.47
    STEP: changing the label value of the configmap back 05/01/23 23:30:34.471
    STEP: modifying the configmap a third time 05/01/23 23:30:34.679
    STEP: deleting the configmap 05/01/23 23:30:34.886
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 05/01/23 23:30:34.991
    May  1 23:30:34.991: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18508 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:30:34.991: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18510 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  1 23:30:34.991: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3812  c1443a33-d8af-4370-be9d-7ca4c9b07a6c 18511 0 2023-05-01 23:30:23 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-05-01 23:30:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    May  1 23:30:34.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3812" for this suite. 05/01/23 23:30:35.095
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:30:35.201
May  1 23:30:35.202: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:30:35.203
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:35.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:35.72
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 05/01/23 23:30:35.924
May  1 23:30:36.031: INFO: Waiting up to 5m0s for pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05" in namespace "downward-api-7476" to be "running and ready"
May  1 23:30:36.134: INFO: Pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05": Phase="Pending", Reason="", readiness=false. Elapsed: 103.256386ms
May  1 23:30:36.134: INFO: The phase of Pod labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:30:38.239: INFO: Pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05": Phase="Running", Reason="", readiness=true. Elapsed: 2.208131893s
May  1 23:30:38.239: INFO: The phase of Pod labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05 is Running (Ready = true)
May  1 23:30:38.239: INFO: Pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05" satisfied condition "running and ready"
May  1 23:30:39.160: INFO: Successfully updated pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:30:41.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7476" for this suite. 05/01/23 23:30:41.477
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":152,"skipped":3016,"failed":0}
------------------------------
• [SLOW TEST] [6.382 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:30:35.201
    May  1 23:30:35.202: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:30:35.203
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:35.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:35.72
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 05/01/23 23:30:35.924
    May  1 23:30:36.031: INFO: Waiting up to 5m0s for pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05" in namespace "downward-api-7476" to be "running and ready"
    May  1 23:30:36.134: INFO: Pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05": Phase="Pending", Reason="", readiness=false. Elapsed: 103.256386ms
    May  1 23:30:36.134: INFO: The phase of Pod labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:30:38.239: INFO: Pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05": Phase="Running", Reason="", readiness=true. Elapsed: 2.208131893s
    May  1 23:30:38.239: INFO: The phase of Pod labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05 is Running (Ready = true)
    May  1 23:30:38.239: INFO: Pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05" satisfied condition "running and ready"
    May  1 23:30:39.160: INFO: Successfully updated pod "labelsupdate41b511fd-9d40-41f6-8e67-2e5185caae05"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:30:41.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7476" for this suite. 05/01/23 23:30:41.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:30:41.584
May  1 23:30:41.584: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job 05/01/23 23:30:41.585
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:41.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:42.101
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 05/01/23 23:30:42.409
STEP: Patching the Job 05/01/23 23:30:42.514
STEP: Watching for Job to be patched 05/01/23 23:30:42.625
May  1 23:30:42.727: INFO: Event ADDED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv] and annotations: map[batch.kubernetes.io/job-tracking:]
May  1 23:30:42.727: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv] and annotations: map[batch.kubernetes.io/job-tracking:]
May  1 23:30:42.728: INFO: Event MODIFIED found for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 05/01/23 23:30:42.728
STEP: Watching for Job to be updated 05/01/23 23:30:42.937
May  1 23:30:43.040: INFO: Event MODIFIED found for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
May  1 23:30:43.040: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 05/01/23 23:30:43.04
May  1 23:30:43.143: INFO: Job: e2e-lkplv as labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched]
STEP: Waiting for job to complete 05/01/23 23:30:43.143
STEP: Delete a job collection with a labelselector 05/01/23 23:30:51.247
STEP: Watching for Job to be deleted 05/01/23 23:30:51.352
May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
May  1 23:30:51.455: INFO: Event DELETED found for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 05/01/23 23:30:51.455
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
May  1 23:30:51.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7255" for this suite. 05/01/23 23:30:51.664
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":153,"skipped":3021,"failed":0}
------------------------------
• [SLOW TEST] [10.186 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:30:41.584
    May  1 23:30:41.584: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename job 05/01/23 23:30:41.585
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:41.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:42.101
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 05/01/23 23:30:42.409
    STEP: Patching the Job 05/01/23 23:30:42.514
    STEP: Watching for Job to be patched 05/01/23 23:30:42.625
    May  1 23:30:42.727: INFO: Event ADDED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv] and annotations: map[batch.kubernetes.io/job-tracking:]
    May  1 23:30:42.727: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv] and annotations: map[batch.kubernetes.io/job-tracking:]
    May  1 23:30:42.728: INFO: Event MODIFIED found for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 05/01/23 23:30:42.728
    STEP: Watching for Job to be updated 05/01/23 23:30:42.937
    May  1 23:30:43.040: INFO: Event MODIFIED found for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    May  1 23:30:43.040: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 05/01/23 23:30:43.04
    May  1 23:30:43.143: INFO: Job: e2e-lkplv as labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched]
    STEP: Waiting for job to complete 05/01/23 23:30:43.143
    STEP: Delete a job collection with a labelselector 05/01/23 23:30:51.247
    STEP: Watching for Job to be deleted 05/01/23 23:30:51.352
    May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    May  1 23:30:51.455: INFO: Event MODIFIED observed for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    May  1 23:30:51.455: INFO: Event DELETED found for Job e2e-lkplv in namespace job-7255 with labels: map[e2e-job-label:e2e-lkplv e2e-lkplv:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 05/01/23 23:30:51.455
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    May  1 23:30:51.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7255" for this suite. 05/01/23 23:30:51.664
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:30:51.77
May  1 23:30:51.770: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/01/23 23:30:51.772
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:52.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:52.287
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 05/01/23 23:30:52.597
STEP: watching for Pod to be ready 05/01/23 23:30:52.703
May  1 23:30:52.805: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions []
May  1 23:30:52.805: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
May  1 23:30:52.806: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
May  1 23:30:53.203: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
May  1 23:30:54.243: INFO: Found Pod pod-test in namespace pods-5812 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 05/01/23 23:30:54.347
STEP: getting the Pod and ensuring that it's patched 05/01/23 23:30:54.557
STEP: replacing the Pod's status Ready condition to False 05/01/23 23:30:54.661
STEP: check the Pod again to ensure its Ready conditions are False 05/01/23 23:30:54.872
STEP: deleting the Pod via a Collection with a LabelSelector 05/01/23 23:30:54.872
STEP: watching for the Pod to be deleted 05/01/23 23:30:54.98
May  1 23:30:55.082: INFO: observed event type MODIFIED
May  1 23:30:56.246: INFO: observed event type MODIFIED
May  1 23:30:56.548: INFO: observed event type MODIFIED
May  1 23:30:57.248: INFO: observed event type MODIFIED
May  1 23:30:57.254: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  1 23:30:57.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5812" for this suite. 05/01/23 23:30:57.466
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":154,"skipped":3021,"failed":0}
------------------------------
• [SLOW TEST] [5.800 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:30:51.77
    May  1 23:30:51.770: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/01/23 23:30:51.772
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:52.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:52.287
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 05/01/23 23:30:52.597
    STEP: watching for Pod to be ready 05/01/23 23:30:52.703
    May  1 23:30:52.805: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions []
    May  1 23:30:52.805: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
    May  1 23:30:52.806: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
    May  1 23:30:53.203: INFO: observed Pod pod-test in namespace pods-5812 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
    May  1 23:30:54.243: INFO: Found Pod pod-test in namespace pods-5812 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:30:52 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 05/01/23 23:30:54.347
    STEP: getting the Pod and ensuring that it's patched 05/01/23 23:30:54.557
    STEP: replacing the Pod's status Ready condition to False 05/01/23 23:30:54.661
    STEP: check the Pod again to ensure its Ready conditions are False 05/01/23 23:30:54.872
    STEP: deleting the Pod via a Collection with a LabelSelector 05/01/23 23:30:54.872
    STEP: watching for the Pod to be deleted 05/01/23 23:30:54.98
    May  1 23:30:55.082: INFO: observed event type MODIFIED
    May  1 23:30:56.246: INFO: observed event type MODIFIED
    May  1 23:30:56.548: INFO: observed event type MODIFIED
    May  1 23:30:57.248: INFO: observed event type MODIFIED
    May  1 23:30:57.254: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  1 23:30:57.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5812" for this suite. 05/01/23 23:30:57.466
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:30:57.571
May  1 23:30:57.571: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/01/23 23:30:57.572
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:57.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:58.09
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 05/01/23 23:30:58.4
STEP: delete the rc 05/01/23 23:31:03.61
STEP: wait for the rc to be deleted 05/01/23 23:31:03.714
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 05/01/23 23:31:08.821
STEP: Gathering metrics 05/01/23 23:31:38.935
May  1 23:31:39.156: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
May  1 23:31:39.259: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 103.367951ms
May  1 23:31:39.260: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
May  1 23:31:39.260: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
May  1 23:31:40.149: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

May  1 23:31:40.149: INFO: Deleting pod "simpletest.rc-22fxs" in namespace "gc-5648"
May  1 23:31:40.261: INFO: Deleting pod "simpletest.rc-2jx7d" in namespace "gc-5648"
May  1 23:31:40.374: INFO: Deleting pod "simpletest.rc-2wxqf" in namespace "gc-5648"
May  1 23:31:40.485: INFO: Deleting pod "simpletest.rc-4hbnz" in namespace "gc-5648"
May  1 23:31:40.602: INFO: Deleting pod "simpletest.rc-4htbh" in namespace "gc-5648"
May  1 23:31:40.712: INFO: Deleting pod "simpletest.rc-5ss9w" in namespace "gc-5648"
May  1 23:31:40.821: INFO: Deleting pod "simpletest.rc-6kr4x" in namespace "gc-5648"
May  1 23:31:40.947: INFO: Deleting pod "simpletest.rc-6rgqh" in namespace "gc-5648"
May  1 23:31:41.066: INFO: Deleting pod "simpletest.rc-7b7h8" in namespace "gc-5648"
May  1 23:31:41.175: INFO: Deleting pod "simpletest.rc-7fwlc" in namespace "gc-5648"
May  1 23:31:41.286: INFO: Deleting pod "simpletest.rc-7kng5" in namespace "gc-5648"
May  1 23:31:41.398: INFO: Deleting pod "simpletest.rc-7v6xl" in namespace "gc-5648"
May  1 23:31:41.511: INFO: Deleting pod "simpletest.rc-7xjj5" in namespace "gc-5648"
May  1 23:31:41.624: INFO: Deleting pod "simpletest.rc-7z882" in namespace "gc-5648"
May  1 23:31:41.741: INFO: Deleting pod "simpletest.rc-84gf6" in namespace "gc-5648"
May  1 23:31:41.848: INFO: Deleting pod "simpletest.rc-88ng7" in namespace "gc-5648"
May  1 23:31:41.967: INFO: Deleting pod "simpletest.rc-8dsr6" in namespace "gc-5648"
May  1 23:31:42.081: INFO: Deleting pod "simpletest.rc-8lthc" in namespace "gc-5648"
May  1 23:31:42.194: INFO: Deleting pod "simpletest.rc-96djk" in namespace "gc-5648"
May  1 23:31:42.309: INFO: Deleting pod "simpletest.rc-9cncg" in namespace "gc-5648"
May  1 23:31:42.425: INFO: Deleting pod "simpletest.rc-9nlvc" in namespace "gc-5648"
May  1 23:31:42.537: INFO: Deleting pod "simpletest.rc-9z5t9" in namespace "gc-5648"
May  1 23:31:42.655: INFO: Deleting pod "simpletest.rc-b6hjn" in namespace "gc-5648"
May  1 23:31:42.770: INFO: Deleting pod "simpletest.rc-bzvck" in namespace "gc-5648"
May  1 23:31:42.886: INFO: Deleting pod "simpletest.rc-c49l2" in namespace "gc-5648"
May  1 23:31:42.995: INFO: Deleting pod "simpletest.rc-czcv7" in namespace "gc-5648"
May  1 23:31:43.107: INFO: Deleting pod "simpletest.rc-d42g9" in namespace "gc-5648"
May  1 23:31:43.222: INFO: Deleting pod "simpletest.rc-d5cwj" in namespace "gc-5648"
May  1 23:31:43.334: INFO: Deleting pod "simpletest.rc-d978k" in namespace "gc-5648"
May  1 23:31:43.444: INFO: Deleting pod "simpletest.rc-d9rjf" in namespace "gc-5648"
May  1 23:31:43.563: INFO: Deleting pod "simpletest.rc-dr42k" in namespace "gc-5648"
May  1 23:31:43.675: INFO: Deleting pod "simpletest.rc-f5c77" in namespace "gc-5648"
May  1 23:31:43.795: INFO: Deleting pod "simpletest.rc-ffm6q" in namespace "gc-5648"
May  1 23:31:43.905: INFO: Deleting pod "simpletest.rc-fkbzl" in namespace "gc-5648"
May  1 23:31:44.016: INFO: Deleting pod "simpletest.rc-fm9dg" in namespace "gc-5648"
May  1 23:31:44.128: INFO: Deleting pod "simpletest.rc-fss5p" in namespace "gc-5648"
May  1 23:31:44.241: INFO: Deleting pod "simpletest.rc-g7nfl" in namespace "gc-5648"
May  1 23:31:44.358: INFO: Deleting pod "simpletest.rc-gfjbk" in namespace "gc-5648"
May  1 23:31:44.474: INFO: Deleting pod "simpletest.rc-glldl" in namespace "gc-5648"
May  1 23:31:44.594: INFO: Deleting pod "simpletest.rc-gtpq5" in namespace "gc-5648"
May  1 23:31:44.710: INFO: Deleting pod "simpletest.rc-gvnb9" in namespace "gc-5648"
May  1 23:31:44.823: INFO: Deleting pod "simpletest.rc-hdsqm" in namespace "gc-5648"
May  1 23:31:44.938: INFO: Deleting pod "simpletest.rc-hk5nq" in namespace "gc-5648"
May  1 23:31:45.051: INFO: Deleting pod "simpletest.rc-hkfll" in namespace "gc-5648"
May  1 23:31:45.164: INFO: Deleting pod "simpletest.rc-hsnjw" in namespace "gc-5648"
May  1 23:31:45.275: INFO: Deleting pod "simpletest.rc-jbsc2" in namespace "gc-5648"
May  1 23:31:45.387: INFO: Deleting pod "simpletest.rc-jcdwg" in namespace "gc-5648"
May  1 23:31:45.501: INFO: Deleting pod "simpletest.rc-jmchd" in namespace "gc-5648"
May  1 23:31:45.639: INFO: Deleting pod "simpletest.rc-kx7fp" in namespace "gc-5648"
May  1 23:31:45.751: INFO: Deleting pod "simpletest.rc-kztnc" in namespace "gc-5648"
May  1 23:31:45.865: INFO: Deleting pod "simpletest.rc-l2qw4" in namespace "gc-5648"
May  1 23:31:45.982: INFO: Deleting pod "simpletest.rc-l9znn" in namespace "gc-5648"
May  1 23:31:46.091: INFO: Deleting pod "simpletest.rc-lgt6m" in namespace "gc-5648"
May  1 23:31:46.200: INFO: Deleting pod "simpletest.rc-lnssp" in namespace "gc-5648"
May  1 23:31:46.323: INFO: Deleting pod "simpletest.rc-lr2zr" in namespace "gc-5648"
May  1 23:31:46.435: INFO: Deleting pod "simpletest.rc-lwmjz" in namespace "gc-5648"
May  1 23:31:46.545: INFO: Deleting pod "simpletest.rc-mb98j" in namespace "gc-5648"
May  1 23:31:46.660: INFO: Deleting pod "simpletest.rc-mllj5" in namespace "gc-5648"
May  1 23:31:46.777: INFO: Deleting pod "simpletest.rc-mlsdb" in namespace "gc-5648"
May  1 23:31:46.889: INFO: Deleting pod "simpletest.rc-mt9qv" in namespace "gc-5648"
May  1 23:31:47.000: INFO: Deleting pod "simpletest.rc-npk76" in namespace "gc-5648"
May  1 23:31:47.110: INFO: Deleting pod "simpletest.rc-p5fp7" in namespace "gc-5648"
May  1 23:31:47.222: INFO: Deleting pod "simpletest.rc-p7t6z" in namespace "gc-5648"
May  1 23:31:47.333: INFO: Deleting pod "simpletest.rc-ptgm5" in namespace "gc-5648"
May  1 23:31:47.451: INFO: Deleting pod "simpletest.rc-q2dtg" in namespace "gc-5648"
May  1 23:31:47.564: INFO: Deleting pod "simpletest.rc-q74tz" in namespace "gc-5648"
May  1 23:31:47.677: INFO: Deleting pod "simpletest.rc-qc57x" in namespace "gc-5648"
May  1 23:31:47.790: INFO: Deleting pod "simpletest.rc-qkjpc" in namespace "gc-5648"
May  1 23:31:47.901: INFO: Deleting pod "simpletest.rc-qkqw7" in namespace "gc-5648"
May  1 23:31:48.016: INFO: Deleting pod "simpletest.rc-qsd2m" in namespace "gc-5648"
May  1 23:31:48.130: INFO: Deleting pod "simpletest.rc-qxgx4" in namespace "gc-5648"
May  1 23:31:48.251: INFO: Deleting pod "simpletest.rc-qxwzj" in namespace "gc-5648"
May  1 23:31:48.362: INFO: Deleting pod "simpletest.rc-rb59j" in namespace "gc-5648"
May  1 23:31:48.498: INFO: Deleting pod "simpletest.rc-rg6zz" in namespace "gc-5648"
May  1 23:31:48.617: INFO: Deleting pod "simpletest.rc-s8txt" in namespace "gc-5648"
May  1 23:31:48.727: INFO: Deleting pod "simpletest.rc-sjnb5" in namespace "gc-5648"
May  1 23:31:48.841: INFO: Deleting pod "simpletest.rc-sjwrc" in namespace "gc-5648"
May  1 23:31:48.955: INFO: Deleting pod "simpletest.rc-sqnkf" in namespace "gc-5648"
May  1 23:31:49.068: INFO: Deleting pod "simpletest.rc-srlwj" in namespace "gc-5648"
May  1 23:31:49.181: INFO: Deleting pod "simpletest.rc-tgb2b" in namespace "gc-5648"
May  1 23:31:49.291: INFO: Deleting pod "simpletest.rc-tkgwq" in namespace "gc-5648"
May  1 23:31:49.402: INFO: Deleting pod "simpletest.rc-tzwrw" in namespace "gc-5648"
May  1 23:31:49.511: INFO: Deleting pod "simpletest.rc-vc8jg" in namespace "gc-5648"
May  1 23:31:49.626: INFO: Deleting pod "simpletest.rc-vgfpf" in namespace "gc-5648"
May  1 23:31:49.737: INFO: Deleting pod "simpletest.rc-vpb5p" in namespace "gc-5648"
May  1 23:31:49.853: INFO: Deleting pod "simpletest.rc-vs4gr" in namespace "gc-5648"
May  1 23:31:49.964: INFO: Deleting pod "simpletest.rc-vxccf" in namespace "gc-5648"
May  1 23:31:50.077: INFO: Deleting pod "simpletest.rc-w6dl9" in namespace "gc-5648"
May  1 23:31:50.192: INFO: Deleting pod "simpletest.rc-w8245" in namespace "gc-5648"
May  1 23:31:50.303: INFO: Deleting pod "simpletest.rc-whwvn" in namespace "gc-5648"
May  1 23:31:50.417: INFO: Deleting pod "simpletest.rc-wtxbt" in namespace "gc-5648"
May  1 23:31:50.530: INFO: Deleting pod "simpletest.rc-wwgrw" in namespace "gc-5648"
May  1 23:31:50.643: INFO: Deleting pod "simpletest.rc-wzbr7" in namespace "gc-5648"
May  1 23:31:50.755: INFO: Deleting pod "simpletest.rc-x4tj6" in namespace "gc-5648"
May  1 23:31:50.866: INFO: Deleting pod "simpletest.rc-xfszl" in namespace "gc-5648"
May  1 23:31:50.982: INFO: Deleting pod "simpletest.rc-xkpm9" in namespace "gc-5648"
May  1 23:31:51.089: INFO: Deleting pod "simpletest.rc-xrrxt" in namespace "gc-5648"
May  1 23:31:51.201: INFO: Deleting pod "simpletest.rc-xvlvd" in namespace "gc-5648"
May  1 23:31:51.312: INFO: Deleting pod "simpletest.rc-z26ql" in namespace "gc-5648"
May  1 23:31:51.425: INFO: Deleting pod "simpletest.rc-zcmfd" in namespace "gc-5648"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  1 23:31:51.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5648" for this suite. 05/01/23 23:31:51.644
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":155,"skipped":3022,"failed":0}
------------------------------
• [SLOW TEST] [54.285 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:30:57.571
    May  1 23:30:57.571: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/01/23 23:30:57.572
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:30:57.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:30:58.09
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 05/01/23 23:30:58.4
    STEP: delete the rc 05/01/23 23:31:03.61
    STEP: wait for the rc to be deleted 05/01/23 23:31:03.714
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 05/01/23 23:31:08.821
    STEP: Gathering metrics 05/01/23 23:31:38.935
    May  1 23:31:39.156: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
    May  1 23:31:39.259: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 103.367951ms
    May  1 23:31:39.260: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
    May  1 23:31:39.260: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
    May  1 23:31:40.149: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    May  1 23:31:40.149: INFO: Deleting pod "simpletest.rc-22fxs" in namespace "gc-5648"
    May  1 23:31:40.261: INFO: Deleting pod "simpletest.rc-2jx7d" in namespace "gc-5648"
    May  1 23:31:40.374: INFO: Deleting pod "simpletest.rc-2wxqf" in namespace "gc-5648"
    May  1 23:31:40.485: INFO: Deleting pod "simpletest.rc-4hbnz" in namespace "gc-5648"
    May  1 23:31:40.602: INFO: Deleting pod "simpletest.rc-4htbh" in namespace "gc-5648"
    May  1 23:31:40.712: INFO: Deleting pod "simpletest.rc-5ss9w" in namespace "gc-5648"
    May  1 23:31:40.821: INFO: Deleting pod "simpletest.rc-6kr4x" in namespace "gc-5648"
    May  1 23:31:40.947: INFO: Deleting pod "simpletest.rc-6rgqh" in namespace "gc-5648"
    May  1 23:31:41.066: INFO: Deleting pod "simpletest.rc-7b7h8" in namespace "gc-5648"
    May  1 23:31:41.175: INFO: Deleting pod "simpletest.rc-7fwlc" in namespace "gc-5648"
    May  1 23:31:41.286: INFO: Deleting pod "simpletest.rc-7kng5" in namespace "gc-5648"
    May  1 23:31:41.398: INFO: Deleting pod "simpletest.rc-7v6xl" in namespace "gc-5648"
    May  1 23:31:41.511: INFO: Deleting pod "simpletest.rc-7xjj5" in namespace "gc-5648"
    May  1 23:31:41.624: INFO: Deleting pod "simpletest.rc-7z882" in namespace "gc-5648"
    May  1 23:31:41.741: INFO: Deleting pod "simpletest.rc-84gf6" in namespace "gc-5648"
    May  1 23:31:41.848: INFO: Deleting pod "simpletest.rc-88ng7" in namespace "gc-5648"
    May  1 23:31:41.967: INFO: Deleting pod "simpletest.rc-8dsr6" in namespace "gc-5648"
    May  1 23:31:42.081: INFO: Deleting pod "simpletest.rc-8lthc" in namespace "gc-5648"
    May  1 23:31:42.194: INFO: Deleting pod "simpletest.rc-96djk" in namespace "gc-5648"
    May  1 23:31:42.309: INFO: Deleting pod "simpletest.rc-9cncg" in namespace "gc-5648"
    May  1 23:31:42.425: INFO: Deleting pod "simpletest.rc-9nlvc" in namespace "gc-5648"
    May  1 23:31:42.537: INFO: Deleting pod "simpletest.rc-9z5t9" in namespace "gc-5648"
    May  1 23:31:42.655: INFO: Deleting pod "simpletest.rc-b6hjn" in namespace "gc-5648"
    May  1 23:31:42.770: INFO: Deleting pod "simpletest.rc-bzvck" in namespace "gc-5648"
    May  1 23:31:42.886: INFO: Deleting pod "simpletest.rc-c49l2" in namespace "gc-5648"
    May  1 23:31:42.995: INFO: Deleting pod "simpletest.rc-czcv7" in namespace "gc-5648"
    May  1 23:31:43.107: INFO: Deleting pod "simpletest.rc-d42g9" in namespace "gc-5648"
    May  1 23:31:43.222: INFO: Deleting pod "simpletest.rc-d5cwj" in namespace "gc-5648"
    May  1 23:31:43.334: INFO: Deleting pod "simpletest.rc-d978k" in namespace "gc-5648"
    May  1 23:31:43.444: INFO: Deleting pod "simpletest.rc-d9rjf" in namespace "gc-5648"
    May  1 23:31:43.563: INFO: Deleting pod "simpletest.rc-dr42k" in namespace "gc-5648"
    May  1 23:31:43.675: INFO: Deleting pod "simpletest.rc-f5c77" in namespace "gc-5648"
    May  1 23:31:43.795: INFO: Deleting pod "simpletest.rc-ffm6q" in namespace "gc-5648"
    May  1 23:31:43.905: INFO: Deleting pod "simpletest.rc-fkbzl" in namespace "gc-5648"
    May  1 23:31:44.016: INFO: Deleting pod "simpletest.rc-fm9dg" in namespace "gc-5648"
    May  1 23:31:44.128: INFO: Deleting pod "simpletest.rc-fss5p" in namespace "gc-5648"
    May  1 23:31:44.241: INFO: Deleting pod "simpletest.rc-g7nfl" in namespace "gc-5648"
    May  1 23:31:44.358: INFO: Deleting pod "simpletest.rc-gfjbk" in namespace "gc-5648"
    May  1 23:31:44.474: INFO: Deleting pod "simpletest.rc-glldl" in namespace "gc-5648"
    May  1 23:31:44.594: INFO: Deleting pod "simpletest.rc-gtpq5" in namespace "gc-5648"
    May  1 23:31:44.710: INFO: Deleting pod "simpletest.rc-gvnb9" in namespace "gc-5648"
    May  1 23:31:44.823: INFO: Deleting pod "simpletest.rc-hdsqm" in namespace "gc-5648"
    May  1 23:31:44.938: INFO: Deleting pod "simpletest.rc-hk5nq" in namespace "gc-5648"
    May  1 23:31:45.051: INFO: Deleting pod "simpletest.rc-hkfll" in namespace "gc-5648"
    May  1 23:31:45.164: INFO: Deleting pod "simpletest.rc-hsnjw" in namespace "gc-5648"
    May  1 23:31:45.275: INFO: Deleting pod "simpletest.rc-jbsc2" in namespace "gc-5648"
    May  1 23:31:45.387: INFO: Deleting pod "simpletest.rc-jcdwg" in namespace "gc-5648"
    May  1 23:31:45.501: INFO: Deleting pod "simpletest.rc-jmchd" in namespace "gc-5648"
    May  1 23:31:45.639: INFO: Deleting pod "simpletest.rc-kx7fp" in namespace "gc-5648"
    May  1 23:31:45.751: INFO: Deleting pod "simpletest.rc-kztnc" in namespace "gc-5648"
    May  1 23:31:45.865: INFO: Deleting pod "simpletest.rc-l2qw4" in namespace "gc-5648"
    May  1 23:31:45.982: INFO: Deleting pod "simpletest.rc-l9znn" in namespace "gc-5648"
    May  1 23:31:46.091: INFO: Deleting pod "simpletest.rc-lgt6m" in namespace "gc-5648"
    May  1 23:31:46.200: INFO: Deleting pod "simpletest.rc-lnssp" in namespace "gc-5648"
    May  1 23:31:46.323: INFO: Deleting pod "simpletest.rc-lr2zr" in namespace "gc-5648"
    May  1 23:31:46.435: INFO: Deleting pod "simpletest.rc-lwmjz" in namespace "gc-5648"
    May  1 23:31:46.545: INFO: Deleting pod "simpletest.rc-mb98j" in namespace "gc-5648"
    May  1 23:31:46.660: INFO: Deleting pod "simpletest.rc-mllj5" in namespace "gc-5648"
    May  1 23:31:46.777: INFO: Deleting pod "simpletest.rc-mlsdb" in namespace "gc-5648"
    May  1 23:31:46.889: INFO: Deleting pod "simpletest.rc-mt9qv" in namespace "gc-5648"
    May  1 23:31:47.000: INFO: Deleting pod "simpletest.rc-npk76" in namespace "gc-5648"
    May  1 23:31:47.110: INFO: Deleting pod "simpletest.rc-p5fp7" in namespace "gc-5648"
    May  1 23:31:47.222: INFO: Deleting pod "simpletest.rc-p7t6z" in namespace "gc-5648"
    May  1 23:31:47.333: INFO: Deleting pod "simpletest.rc-ptgm5" in namespace "gc-5648"
    May  1 23:31:47.451: INFO: Deleting pod "simpletest.rc-q2dtg" in namespace "gc-5648"
    May  1 23:31:47.564: INFO: Deleting pod "simpletest.rc-q74tz" in namespace "gc-5648"
    May  1 23:31:47.677: INFO: Deleting pod "simpletest.rc-qc57x" in namespace "gc-5648"
    May  1 23:31:47.790: INFO: Deleting pod "simpletest.rc-qkjpc" in namespace "gc-5648"
    May  1 23:31:47.901: INFO: Deleting pod "simpletest.rc-qkqw7" in namespace "gc-5648"
    May  1 23:31:48.016: INFO: Deleting pod "simpletest.rc-qsd2m" in namespace "gc-5648"
    May  1 23:31:48.130: INFO: Deleting pod "simpletest.rc-qxgx4" in namespace "gc-5648"
    May  1 23:31:48.251: INFO: Deleting pod "simpletest.rc-qxwzj" in namespace "gc-5648"
    May  1 23:31:48.362: INFO: Deleting pod "simpletest.rc-rb59j" in namespace "gc-5648"
    May  1 23:31:48.498: INFO: Deleting pod "simpletest.rc-rg6zz" in namespace "gc-5648"
    May  1 23:31:48.617: INFO: Deleting pod "simpletest.rc-s8txt" in namespace "gc-5648"
    May  1 23:31:48.727: INFO: Deleting pod "simpletest.rc-sjnb5" in namespace "gc-5648"
    May  1 23:31:48.841: INFO: Deleting pod "simpletest.rc-sjwrc" in namespace "gc-5648"
    May  1 23:31:48.955: INFO: Deleting pod "simpletest.rc-sqnkf" in namespace "gc-5648"
    May  1 23:31:49.068: INFO: Deleting pod "simpletest.rc-srlwj" in namespace "gc-5648"
    May  1 23:31:49.181: INFO: Deleting pod "simpletest.rc-tgb2b" in namespace "gc-5648"
    May  1 23:31:49.291: INFO: Deleting pod "simpletest.rc-tkgwq" in namespace "gc-5648"
    May  1 23:31:49.402: INFO: Deleting pod "simpletest.rc-tzwrw" in namespace "gc-5648"
    May  1 23:31:49.511: INFO: Deleting pod "simpletest.rc-vc8jg" in namespace "gc-5648"
    May  1 23:31:49.626: INFO: Deleting pod "simpletest.rc-vgfpf" in namespace "gc-5648"
    May  1 23:31:49.737: INFO: Deleting pod "simpletest.rc-vpb5p" in namespace "gc-5648"
    May  1 23:31:49.853: INFO: Deleting pod "simpletest.rc-vs4gr" in namespace "gc-5648"
    May  1 23:31:49.964: INFO: Deleting pod "simpletest.rc-vxccf" in namespace "gc-5648"
    May  1 23:31:50.077: INFO: Deleting pod "simpletest.rc-w6dl9" in namespace "gc-5648"
    May  1 23:31:50.192: INFO: Deleting pod "simpletest.rc-w8245" in namespace "gc-5648"
    May  1 23:31:50.303: INFO: Deleting pod "simpletest.rc-whwvn" in namespace "gc-5648"
    May  1 23:31:50.417: INFO: Deleting pod "simpletest.rc-wtxbt" in namespace "gc-5648"
    May  1 23:31:50.530: INFO: Deleting pod "simpletest.rc-wwgrw" in namespace "gc-5648"
    May  1 23:31:50.643: INFO: Deleting pod "simpletest.rc-wzbr7" in namespace "gc-5648"
    May  1 23:31:50.755: INFO: Deleting pod "simpletest.rc-x4tj6" in namespace "gc-5648"
    May  1 23:31:50.866: INFO: Deleting pod "simpletest.rc-xfszl" in namespace "gc-5648"
    May  1 23:31:50.982: INFO: Deleting pod "simpletest.rc-xkpm9" in namespace "gc-5648"
    May  1 23:31:51.089: INFO: Deleting pod "simpletest.rc-xrrxt" in namespace "gc-5648"
    May  1 23:31:51.201: INFO: Deleting pod "simpletest.rc-xvlvd" in namespace "gc-5648"
    May  1 23:31:51.312: INFO: Deleting pod "simpletest.rc-z26ql" in namespace "gc-5648"
    May  1 23:31:51.425: INFO: Deleting pod "simpletest.rc-zcmfd" in namespace "gc-5648"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  1 23:31:51.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5648" for this suite. 05/01/23 23:31:51.644
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:31:51.86
May  1 23:31:51.861: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename cronjob 05/01/23 23:31:51.862
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:31:52.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:31:52.379
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 05/01/23 23:31:52.585
STEP: Ensuring a job is scheduled 05/01/23 23:31:52.69
STEP: Ensuring exactly one is scheduled 05/01/23 23:32:00.794
STEP: Ensuring exactly one running job exists by listing jobs explicitly 05/01/23 23:32:00.897
STEP: Ensuring no more jobs are scheduled 05/01/23 23:32:01
STEP: Removing cronjob 05/01/23 23:37:01.205
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
May  1 23:37:01.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2850" for this suite. 05/01/23 23:37:01.414
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":156,"skipped":3088,"failed":0}
------------------------------
• [SLOW TEST] [309.659 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:31:51.86
    May  1 23:31:51.861: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename cronjob 05/01/23 23:31:51.862
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:31:52.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:31:52.379
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 05/01/23 23:31:52.585
    STEP: Ensuring a job is scheduled 05/01/23 23:31:52.69
    STEP: Ensuring exactly one is scheduled 05/01/23 23:32:00.794
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 05/01/23 23:32:00.897
    STEP: Ensuring no more jobs are scheduled 05/01/23 23:32:01
    STEP: Removing cronjob 05/01/23 23:37:01.205
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    May  1 23:37:01.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2850" for this suite. 05/01/23 23:37:01.414
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:37:01.521
May  1 23:37:01.521: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:37:01.522
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:37:01.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:37:02.035
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-cc7787d2-1a2b-4939-8935-bb605efb386b 05/01/23 23:37:02.342
STEP: Creating the pod 05/01/23 23:37:02.448
May  1 23:37:02.554: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306" in namespace "configmap-4995" to be "running and ready"
May  1 23:37:02.657: INFO: Pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306": Phase="Pending", Reason="", readiness=false. Elapsed: 102.715064ms
May  1 23:37:02.657: INFO: The phase of Pod pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:37:04.760: INFO: Pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306": Phase="Running", Reason="", readiness=true. Elapsed: 2.205658314s
May  1 23:37:04.760: INFO: The phase of Pod pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306 is Running (Ready = true)
May  1 23:37:04.760: INFO: Pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-cc7787d2-1a2b-4939-8935-bb605efb386b 05/01/23 23:37:04.974
STEP: waiting to observe update in volume 05/01/23 23:37:05.078
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:38:27.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4995" for this suite. 05/01/23 23:38:27.449
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":157,"skipped":3093,"failed":0}
------------------------------
• [SLOW TEST] [86.033 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:37:01.521
    May  1 23:37:01.521: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:37:01.522
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:37:01.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:37:02.035
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-cc7787d2-1a2b-4939-8935-bb605efb386b 05/01/23 23:37:02.342
    STEP: Creating the pod 05/01/23 23:37:02.448
    May  1 23:37:02.554: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306" in namespace "configmap-4995" to be "running and ready"
    May  1 23:37:02.657: INFO: Pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306": Phase="Pending", Reason="", readiness=false. Elapsed: 102.715064ms
    May  1 23:37:02.657: INFO: The phase of Pod pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:37:04.760: INFO: Pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306": Phase="Running", Reason="", readiness=true. Elapsed: 2.205658314s
    May  1 23:37:04.760: INFO: The phase of Pod pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306 is Running (Ready = true)
    May  1 23:37:04.760: INFO: Pod "pod-configmaps-ff59efe3-cf0c-4786-8bc9-29548effd306" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-cc7787d2-1a2b-4939-8935-bb605efb386b 05/01/23 23:37:04.974
    STEP: waiting to observe update in volume 05/01/23 23:37:05.078
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:38:27.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4995" for this suite. 05/01/23 23:38:27.449
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:38:27.554
May  1 23:38:27.554: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:38:27.555
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:27.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:28.07
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:38:28.274
May  1 23:38:28.380: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51" in namespace "downward-api-3812" to be "Succeeded or Failed"
May  1 23:38:28.482: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51": Phase="Pending", Reason="", readiness=false. Elapsed: 102.409818ms
May  1 23:38:30.586: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51": Phase="Running", Reason="", readiness=false. Elapsed: 2.206056137s
May  1 23:38:32.586: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206536275s
STEP: Saw pod success 05/01/23 23:38:32.586
May  1 23:38:32.587: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51" satisfied condition "Succeeded or Failed"
May  1 23:38:32.689: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51 container client-container: <nil>
STEP: delete the pod 05/01/23 23:38:32.801
May  1 23:38:32.910: INFO: Waiting for pod downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51 to disappear
May  1 23:38:33.012: INFO: Pod downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:38:33.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3812" for this suite. 05/01/23 23:38:33.116
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":158,"skipped":3094,"failed":0}
------------------------------
• [SLOW TEST] [5.766 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:38:27.554
    May  1 23:38:27.554: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:38:27.555
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:27.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:28.07
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:38:28.274
    May  1 23:38:28.380: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51" in namespace "downward-api-3812" to be "Succeeded or Failed"
    May  1 23:38:28.482: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51": Phase="Pending", Reason="", readiness=false. Elapsed: 102.409818ms
    May  1 23:38:30.586: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51": Phase="Running", Reason="", readiness=false. Elapsed: 2.206056137s
    May  1 23:38:32.586: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206536275s
    STEP: Saw pod success 05/01/23 23:38:32.586
    May  1 23:38:32.587: INFO: Pod "downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51" satisfied condition "Succeeded or Failed"
    May  1 23:38:32.689: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:38:32.801
    May  1 23:38:32.910: INFO: Waiting for pod downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51 to disappear
    May  1 23:38:33.012: INFO: Pod downwardapi-volume-b96a7dee-2fdc-454c-b12c-545e90ef3a51 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:38:33.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3812" for this suite. 05/01/23 23:38:33.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:38:33.32
May  1 23:38:33.320: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/01/23 23:38:33.321
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:33.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:33.834
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 05/01/23 23:38:34.037
STEP: submitting the pod to kubernetes 05/01/23 23:38:34.038
May  1 23:38:34.144: INFO: Waiting up to 5m0s for pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" in namespace "pods-207" to be "running and ready"
May  1 23:38:34.246: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020": Phase="Pending", Reason="", readiness=false. Elapsed: 102.602928ms
May  1 23:38:34.247: INFO: The phase of Pod pod-update-6d8f0533-d143-4087-b113-8a0499d5f020 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:38:36.351: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020": Phase="Running", Reason="", readiness=true. Elapsed: 2.207246997s
May  1 23:38:36.351: INFO: The phase of Pod pod-update-6d8f0533-d143-4087-b113-8a0499d5f020 is Running (Ready = true)
May  1 23:38:36.351: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 05/01/23 23:38:36.454
STEP: updating the pod 05/01/23 23:38:36.557
May  1 23:38:37.268: INFO: Successfully updated pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020"
May  1 23:38:37.268: INFO: Waiting up to 5m0s for pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" in namespace "pods-207" to be "running"
May  1 23:38:37.370: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020": Phase="Running", Reason="", readiness=true. Elapsed: 102.631724ms
May  1 23:38:37.370: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 05/01/23 23:38:37.371
May  1 23:38:37.474: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  1 23:38:37.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-207" for this suite. 05/01/23 23:38:37.577
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":159,"skipped":3102,"failed":0}
------------------------------
• [4.362 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:38:33.32
    May  1 23:38:33.320: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/01/23 23:38:33.321
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:33.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:33.834
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 05/01/23 23:38:34.037
    STEP: submitting the pod to kubernetes 05/01/23 23:38:34.038
    May  1 23:38:34.144: INFO: Waiting up to 5m0s for pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" in namespace "pods-207" to be "running and ready"
    May  1 23:38:34.246: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020": Phase="Pending", Reason="", readiness=false. Elapsed: 102.602928ms
    May  1 23:38:34.247: INFO: The phase of Pod pod-update-6d8f0533-d143-4087-b113-8a0499d5f020 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:38:36.351: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020": Phase="Running", Reason="", readiness=true. Elapsed: 2.207246997s
    May  1 23:38:36.351: INFO: The phase of Pod pod-update-6d8f0533-d143-4087-b113-8a0499d5f020 is Running (Ready = true)
    May  1 23:38:36.351: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 05/01/23 23:38:36.454
    STEP: updating the pod 05/01/23 23:38:36.557
    May  1 23:38:37.268: INFO: Successfully updated pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020"
    May  1 23:38:37.268: INFO: Waiting up to 5m0s for pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" in namespace "pods-207" to be "running"
    May  1 23:38:37.370: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020": Phase="Running", Reason="", readiness=true. Elapsed: 102.631724ms
    May  1 23:38:37.370: INFO: Pod "pod-update-6d8f0533-d143-4087-b113-8a0499d5f020" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 05/01/23 23:38:37.371
    May  1 23:38:37.474: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  1 23:38:37.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-207" for this suite. 05/01/23 23:38:37.577
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:38:37.684
May  1 23:38:37.684: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/01/23 23:38:37.685
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:37.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:38.198
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 05/01/23 23:38:38.402
May  1 23:38:38.509: INFO: Waiting up to 5m0s for pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118" in namespace "pods-5870" to be "running and ready"
May  1 23:38:38.611: INFO: Pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118": Phase="Pending", Reason="", readiness=false. Elapsed: 102.461954ms
May  1 23:38:38.611: INFO: The phase of Pod pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:38:40.714: INFO: Pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118": Phase="Running", Reason="", readiness=true. Elapsed: 2.205401239s
May  1 23:38:40.714: INFO: The phase of Pod pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118 is Running (Ready = true)
May  1 23:38:40.715: INFO: Pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118" satisfied condition "running and ready"
May  1 23:38:40.920: INFO: Pod pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118 has hostIP: 172.20.62.149
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  1 23:38:40.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5870" for this suite. 05/01/23 23:38:41.024
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":160,"skipped":3110,"failed":0}
------------------------------
• [3.444 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:38:37.684
    May  1 23:38:37.684: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/01/23 23:38:37.685
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:37.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:38.198
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 05/01/23 23:38:38.402
    May  1 23:38:38.509: INFO: Waiting up to 5m0s for pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118" in namespace "pods-5870" to be "running and ready"
    May  1 23:38:38.611: INFO: Pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118": Phase="Pending", Reason="", readiness=false. Elapsed: 102.461954ms
    May  1 23:38:38.611: INFO: The phase of Pod pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:38:40.714: INFO: Pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118": Phase="Running", Reason="", readiness=true. Elapsed: 2.205401239s
    May  1 23:38:40.714: INFO: The phase of Pod pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118 is Running (Ready = true)
    May  1 23:38:40.715: INFO: Pod "pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118" satisfied condition "running and ready"
    May  1 23:38:40.920: INFO: Pod pod-hostip-8da48010-82ec-49a4-a968-69dd29a0e118 has hostIP: 172.20.62.149
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  1 23:38:40.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5870" for this suite. 05/01/23 23:38:41.024
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:38:41.128
May  1 23:38:41.128: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 05/01/23 23:38:41.13
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:41.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:41.643
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 05/01/23 23:38:41.847
STEP: Creating hostNetwork=false pod 05/01/23 23:38:41.847
May  1 23:38:41.955: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5840" to be "running and ready"
May  1 23:38:42.058: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 102.710745ms
May  1 23:38:42.058: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
May  1 23:38:44.161: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.2062388s
May  1 23:38:44.161: INFO: The phase of Pod test-pod is Running (Ready = true)
May  1 23:38:44.161: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 05/01/23 23:38:44.264
May  1 23:38:44.370: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5840" to be "running and ready"
May  1 23:38:44.473: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 102.865148ms
May  1 23:38:44.473: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
May  1 23:38:46.577: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.206896314s
May  1 23:38:46.577: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
May  1 23:38:46.577: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 05/01/23 23:38:46.68
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 05/01/23 23:38:46.68
May  1 23:38:46.680: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:46.680: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:46.681: INFO: ExecWithOptions: Clientset creation
May  1 23:38:46.681: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May  1 23:38:47.402: INFO: Exec stderr: ""
May  1 23:38:47.402: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:47.402: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:47.403: INFO: ExecWithOptions: Clientset creation
May  1 23:38:47.403: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May  1 23:38:48.125: INFO: Exec stderr: ""
May  1 23:38:48.126: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:48.126: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:48.126: INFO: ExecWithOptions: Clientset creation
May  1 23:38:48.126: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May  1 23:38:48.837: INFO: Exec stderr: ""
May  1 23:38:48.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:48.837: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:48.838: INFO: ExecWithOptions: Clientset creation
May  1 23:38:48.838: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May  1 23:38:49.524: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 05/01/23 23:38:49.524
May  1 23:38:49.524: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:49.524: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:49.525: INFO: ExecWithOptions: Clientset creation
May  1 23:38:49.525: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
May  1 23:38:50.200: INFO: Exec stderr: ""
May  1 23:38:50.200: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:50.200: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:50.201: INFO: ExecWithOptions: Clientset creation
May  1 23:38:50.201: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
May  1 23:38:50.904: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 05/01/23 23:38:50.904
May  1 23:38:50.904: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:50.904: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:50.905: INFO: ExecWithOptions: Clientset creation
May  1 23:38:50.905: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May  1 23:38:51.590: INFO: Exec stderr: ""
May  1 23:38:51.590: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:51.590: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:51.591: INFO: ExecWithOptions: Clientset creation
May  1 23:38:51.591: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
May  1 23:38:52.294: INFO: Exec stderr: ""
May  1 23:38:52.295: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:52.295: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:52.295: INFO: ExecWithOptions: Clientset creation
May  1 23:38:52.295: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May  1 23:38:52.974: INFO: Exec stderr: ""
May  1 23:38:52.974: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:38:52.974: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:38:52.976: INFO: ExecWithOptions: Clientset creation
May  1 23:38:52.976: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
May  1 23:38:53.666: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
May  1 23:38:53.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5840" for this suite. 05/01/23 23:38:53.77
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":161,"skipped":3116,"failed":0}
------------------------------
• [SLOW TEST] [12.746 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:38:41.128
    May  1 23:38:41.128: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 05/01/23 23:38:41.13
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:41.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:41.643
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 05/01/23 23:38:41.847
    STEP: Creating hostNetwork=false pod 05/01/23 23:38:41.847
    May  1 23:38:41.955: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5840" to be "running and ready"
    May  1 23:38:42.058: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 102.710745ms
    May  1 23:38:42.058: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:38:44.161: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.2062388s
    May  1 23:38:44.161: INFO: The phase of Pod test-pod is Running (Ready = true)
    May  1 23:38:44.161: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 05/01/23 23:38:44.264
    May  1 23:38:44.370: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5840" to be "running and ready"
    May  1 23:38:44.473: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 102.865148ms
    May  1 23:38:44.473: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:38:46.577: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.206896314s
    May  1 23:38:46.577: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    May  1 23:38:46.577: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 05/01/23 23:38:46.68
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 05/01/23 23:38:46.68
    May  1 23:38:46.680: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:46.680: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:46.681: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:46.681: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    May  1 23:38:47.402: INFO: Exec stderr: ""
    May  1 23:38:47.402: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:47.402: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:47.403: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:47.403: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    May  1 23:38:48.125: INFO: Exec stderr: ""
    May  1 23:38:48.126: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:48.126: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:48.126: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:48.126: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    May  1 23:38:48.837: INFO: Exec stderr: ""
    May  1 23:38:48.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:48.837: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:48.838: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:48.838: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    May  1 23:38:49.524: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 05/01/23 23:38:49.524
    May  1 23:38:49.524: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:49.524: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:49.525: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:49.525: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    May  1 23:38:50.200: INFO: Exec stderr: ""
    May  1 23:38:50.200: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:50.200: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:50.201: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:50.201: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    May  1 23:38:50.904: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 05/01/23 23:38:50.904
    May  1 23:38:50.904: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:50.904: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:50.905: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:50.905: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    May  1 23:38:51.590: INFO: Exec stderr: ""
    May  1 23:38:51.590: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:51.590: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:51.591: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:51.591: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    May  1 23:38:52.294: INFO: Exec stderr: ""
    May  1 23:38:52.295: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:52.295: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:52.295: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:52.295: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    May  1 23:38:52.974: INFO: Exec stderr: ""
    May  1 23:38:52.974: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5840 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:38:52.974: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:38:52.976: INFO: ExecWithOptions: Clientset creation
    May  1 23:38:52.976: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/e2e-kubelet-etc-hosts-5840/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    May  1 23:38:53.666: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    May  1 23:38:53.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-5840" for this suite. 05/01/23 23:38:53.77
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:38:53.875
May  1 23:38:53.875: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir-wrapper 05/01/23 23:38:53.876
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:54.185
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:54.388
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
May  1 23:38:54.905: INFO: Waiting up to 5m0s for pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90" in namespace "emptydir-wrapper-4338" to be "running and ready"
May  1 23:38:55.008: INFO: Pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90": Phase="Pending", Reason="", readiness=false. Elapsed: 102.903829ms
May  1 23:38:55.008: INFO: The phase of Pod pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:38:57.112: INFO: Pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90": Phase="Running", Reason="", readiness=true. Elapsed: 2.206840046s
May  1 23:38:57.112: INFO: The phase of Pod pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90 is Running (Ready = true)
May  1 23:38:57.112: INFO: Pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90" satisfied condition "running and ready"
STEP: Cleaning up the secret 05/01/23 23:38:57.215
STEP: Cleaning up the configmap 05/01/23 23:38:57.32
STEP: Cleaning up the pod 05/01/23 23:38:57.424
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
May  1 23:38:57.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4338" for this suite. 05/01/23 23:38:57.638
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":162,"skipped":3119,"failed":0}
------------------------------
• [3.867 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:38:53.875
    May  1 23:38:53.875: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir-wrapper 05/01/23 23:38:53.876
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:54.185
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:54.388
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    May  1 23:38:54.905: INFO: Waiting up to 5m0s for pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90" in namespace "emptydir-wrapper-4338" to be "running and ready"
    May  1 23:38:55.008: INFO: Pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90": Phase="Pending", Reason="", readiness=false. Elapsed: 102.903829ms
    May  1 23:38:55.008: INFO: The phase of Pod pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:38:57.112: INFO: Pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90": Phase="Running", Reason="", readiness=true. Elapsed: 2.206840046s
    May  1 23:38:57.112: INFO: The phase of Pod pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90 is Running (Ready = true)
    May  1 23:38:57.112: INFO: Pod "pod-secrets-bb456294-001a-4b9c-ac89-38dbf60b5d90" satisfied condition "running and ready"
    STEP: Cleaning up the secret 05/01/23 23:38:57.215
    STEP: Cleaning up the configmap 05/01/23 23:38:57.32
    STEP: Cleaning up the pod 05/01/23 23:38:57.424
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    May  1 23:38:57.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-4338" for this suite. 05/01/23 23:38:57.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:38:57.746
May  1 23:38:57.746: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/01/23 23:38:57.747
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:58.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:58.26
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
May  1 23:38:58.569: INFO: Waiting up to 2m0s for pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" in namespace "var-expansion-1309" to be "container 0 failed with reason CreateContainerConfigError"
May  1 23:38:58.672: INFO: Pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa": Phase="Pending", Reason="", readiness=false. Elapsed: 102.47083ms
May  1 23:39:00.775: INFO: Pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205815602s
May  1 23:39:00.775: INFO: Pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" satisfied condition "container 0 failed with reason CreateContainerConfigError"
May  1 23:39:00.775: INFO: Deleting pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" in namespace "var-expansion-1309"
May  1 23:39:00.881: INFO: Wait up to 5m0s for pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  1 23:39:05.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1309" for this suite. 05/01/23 23:39:05.19
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":163,"skipped":3133,"failed":0}
------------------------------
• [SLOW TEST] [7.648 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:38:57.746
    May  1 23:38:57.746: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/01/23 23:38:57.747
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:38:58.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:38:58.26
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    May  1 23:38:58.569: INFO: Waiting up to 2m0s for pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" in namespace "var-expansion-1309" to be "container 0 failed with reason CreateContainerConfigError"
    May  1 23:38:58.672: INFO: Pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa": Phase="Pending", Reason="", readiness=false. Elapsed: 102.47083ms
    May  1 23:39:00.775: INFO: Pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205815602s
    May  1 23:39:00.775: INFO: Pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    May  1 23:39:00.775: INFO: Deleting pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" in namespace "var-expansion-1309"
    May  1 23:39:00.881: INFO: Wait up to 5m0s for pod "var-expansion-fb9db6cf-0d9a-4b8f-a3fc-834edd08a2fa" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  1 23:39:05.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1309" for this suite. 05/01/23 23:39:05.19
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:39:05.397
May  1 23:39:05.397: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:39:05.399
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:05.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:05.913
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
STEP: creating service in namespace services-2568 05/01/23 23:39:06.117
STEP: creating service affinity-nodeport in namespace services-2568 05/01/23 23:39:06.118
STEP: creating replication controller affinity-nodeport in namespace services-2568 05/01/23 23:39:06.226
I0501 23:39:06.331809    6969 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2568, replica count: 3
I0501 23:39:09.483162    6969 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  1 23:39:09.792: INFO: Creating new exec pod
May  1 23:39:09.897: INFO: Waiting up to 5m0s for pod "execpod-affinityvj4tq" in namespace "services-2568" to be "running"
May  1 23:39:10.000: INFO: Pod "execpod-affinityvj4tq": Phase="Pending", Reason="", readiness=false. Elapsed: 102.893274ms
May  1 23:39:12.103: INFO: Pod "execpod-affinityvj4tq": Phase="Running", Reason="", readiness=true. Elapsed: 2.206111769s
May  1 23:39:12.103: INFO: Pod "execpod-affinityvj4tq" satisfied condition "running"
May  1 23:39:13.208: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
May  1 23:39:14.331: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
May  1 23:39:14.332: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:39:14.332: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.16.183 80'
May  1 23:39:15.437: INFO: stderr: "+ nc -v -t -w 2 100.64.16.183 80\nConnection to 100.64.16.183 80 port [tcp/http] succeeded!\n+ echo hostName\n"
May  1 23:39:15.438: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:39:15.438: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 31152'
May  1 23:39:16.513: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.39.145 31152\nConnection to 172.20.39.145 31152 port [tcp/*] succeeded!\n"
May  1 23:39:16.513: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:39:16.513: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.62.149 31152'
May  1 23:39:17.637: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.62.149 31152\nConnection to 172.20.62.149 31152 port [tcp/*] succeeded!\n"
May  1 23:39:17.637: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  1 23:39:17.637: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.44.200:31152/ ; done'
May  1 23:39:18.912: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n"
May  1 23:39:18.912: INFO: stdout: "\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859"
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
May  1 23:39:18.912: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-2568, will wait for the garbage collector to delete the pods 05/01/23 23:39:19.024
May  1 23:39:19.382: INFO: Deleting ReplicationController affinity-nodeport took: 104.120072ms
May  1 23:39:19.483: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.136727ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:39:21.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2568" for this suite. 05/01/23 23:39:21.904
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":164,"skipped":3174,"failed":0}
------------------------------
• [SLOW TEST] [16.612 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:39:05.397
    May  1 23:39:05.397: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:39:05.399
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:05.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:05.913
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2194
    STEP: creating service in namespace services-2568 05/01/23 23:39:06.117
    STEP: creating service affinity-nodeport in namespace services-2568 05/01/23 23:39:06.118
    STEP: creating replication controller affinity-nodeport in namespace services-2568 05/01/23 23:39:06.226
    I0501 23:39:06.331809    6969 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-2568, replica count: 3
    I0501 23:39:09.483162    6969 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  1 23:39:09.792: INFO: Creating new exec pod
    May  1 23:39:09.897: INFO: Waiting up to 5m0s for pod "execpod-affinityvj4tq" in namespace "services-2568" to be "running"
    May  1 23:39:10.000: INFO: Pod "execpod-affinityvj4tq": Phase="Pending", Reason="", readiness=false. Elapsed: 102.893274ms
    May  1 23:39:12.103: INFO: Pod "execpod-affinityvj4tq": Phase="Running", Reason="", readiness=true. Elapsed: 2.206111769s
    May  1 23:39:12.103: INFO: Pod "execpod-affinityvj4tq" satisfied condition "running"
    May  1 23:39:13.208: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    May  1 23:39:14.331: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    May  1 23:39:14.332: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:39:14.332: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.16.183 80'
    May  1 23:39:15.437: INFO: stderr: "+ nc -v -t -w 2 100.64.16.183 80\nConnection to 100.64.16.183 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    May  1 23:39:15.438: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:39:15.438: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 31152'
    May  1 23:39:16.513: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.39.145 31152\nConnection to 172.20.39.145 31152 port [tcp/*] succeeded!\n"
    May  1 23:39:16.513: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:39:16.513: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.62.149 31152'
    May  1 23:39:17.637: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.62.149 31152\nConnection to 172.20.62.149 31152 port [tcp/*] succeeded!\n"
    May  1 23:39:17.637: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  1 23:39:17.637: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-2568 exec execpod-affinityvj4tq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.44.200:31152/ ; done'
    May  1 23:39:18.912: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.44.200:31152/\n"
    May  1 23:39:18.912: INFO: stdout: "\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859\naffinity-nodeport-sb859"
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Received response from host: affinity-nodeport-sb859
    May  1 23:39:18.912: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-2568, will wait for the garbage collector to delete the pods 05/01/23 23:39:19.024
    May  1 23:39:19.382: INFO: Deleting ReplicationController affinity-nodeport took: 104.120072ms
    May  1 23:39:19.483: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.136727ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:39:21.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2568" for this suite. 05/01/23 23:39:21.904
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:39:22.01
May  1 23:39:22.010: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:39:22.012
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:22.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:22.524
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3138 05/01/23 23:39:22.728
STEP: changing the ExternalName service to type=ClusterIP 05/01/23 23:39:22.833
STEP: creating replication controller externalname-service in namespace services-3138 05/01/23 23:39:23.044
I0501 23:39:23.149476    6969 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3138, replica count: 2
I0501 23:39:26.300831    6969 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  1 23:39:26.300: INFO: Creating new exec pod
May  1 23:39:26.404: INFO: Waiting up to 5m0s for pod "execpod7rknq" in namespace "services-3138" to be "running"
May  1 23:39:26.507: INFO: Pod "execpod7rknq": Phase="Pending", Reason="", readiness=false. Elapsed: 102.690765ms
May  1 23:39:28.611: INFO: Pod "execpod7rknq": Phase="Running", Reason="", readiness=true. Elapsed: 2.206602726s
May  1 23:39:28.611: INFO: Pod "execpod7rknq" satisfied condition "running"
May  1 23:39:29.611: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  1 23:39:30.741: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  1 23:39:30.741: INFO: stdout: "externalname-service-mkrcq"
May  1 23:39:30.741: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
May  1 23:39:31.845: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
May  1 23:39:31.845: INFO: stdout: ""
May  1 23:39:32.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
May  1 23:39:33.986: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
May  1 23:39:33.986: INFO: stdout: ""
May  1 23:39:34.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
May  1 23:39:35.966: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
May  1 23:39:35.966: INFO: stdout: ""
May  1 23:39:36.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
May  1 23:39:37.966: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
May  1 23:39:37.966: INFO: stdout: ""
May  1 23:39:38.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
May  1 23:39:39.924: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
May  1 23:39:39.924: INFO: stdout: "externalname-service-bhm5f"
May  1 23:39:39.924: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:39:40.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3138" for this suite. 05/01/23 23:39:40.141
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":165,"skipped":3185,"failed":0}
------------------------------
• [SLOW TEST] [18.235 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:39:22.01
    May  1 23:39:22.010: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:39:22.012
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:22.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:22.524
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-3138 05/01/23 23:39:22.728
    STEP: changing the ExternalName service to type=ClusterIP 05/01/23 23:39:22.833
    STEP: creating replication controller externalname-service in namespace services-3138 05/01/23 23:39:23.044
    I0501 23:39:23.149476    6969 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3138, replica count: 2
    I0501 23:39:26.300831    6969 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  1 23:39:26.300: INFO: Creating new exec pod
    May  1 23:39:26.404: INFO: Waiting up to 5m0s for pod "execpod7rknq" in namespace "services-3138" to be "running"
    May  1 23:39:26.507: INFO: Pod "execpod7rknq": Phase="Pending", Reason="", readiness=false. Elapsed: 102.690765ms
    May  1 23:39:28.611: INFO: Pod "execpod7rknq": Phase="Running", Reason="", readiness=true. Elapsed: 2.206602726s
    May  1 23:39:28.611: INFO: Pod "execpod7rknq" satisfied condition "running"
    May  1 23:39:29.611: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    May  1 23:39:30.741: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    May  1 23:39:30.741: INFO: stdout: "externalname-service-mkrcq"
    May  1 23:39:30.741: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
    May  1 23:39:31.845: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
    May  1 23:39:31.845: INFO: stdout: ""
    May  1 23:39:32.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
    May  1 23:39:33.986: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
    May  1 23:39:33.986: INFO: stdout: ""
    May  1 23:39:34.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
    May  1 23:39:35.966: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
    May  1 23:39:35.966: INFO: stdout: ""
    May  1 23:39:36.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
    May  1 23:39:37.966: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
    May  1 23:39:37.966: INFO: stdout: ""
    May  1 23:39:38.846: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3138 exec execpod7rknq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.136.94 80'
    May  1 23:39:39.924: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.136.94 80\nConnection to 100.67.136.94 80 port [tcp/http] succeeded!\n"
    May  1 23:39:39.924: INFO: stdout: "externalname-service-bhm5f"
    May  1 23:39:39.924: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:39:40.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3138" for this suite. 05/01/23 23:39:40.141
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:39:40.247
May  1 23:39:40.247: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:39:40.248
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:40.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:40.761
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-0aadbddf-ba5f-42f5-9e76-780c78451ca4 05/01/23 23:39:40.964
STEP: Creating a pod to test consume secrets 05/01/23 23:39:41.068
May  1 23:39:41.175: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c" in namespace "projected-7758" to be "Succeeded or Failed"
May  1 23:39:41.278: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c": Phase="Pending", Reason="", readiness=false. Elapsed: 102.553133ms
May  1 23:39:43.382: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206281371s
May  1 23:39:45.382: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206172606s
STEP: Saw pod success 05/01/23 23:39:45.382
May  1 23:39:45.382: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c" satisfied condition "Succeeded or Failed"
May  1 23:39:45.484: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c container projected-secret-volume-test: <nil>
STEP: delete the pod 05/01/23 23:39:45.614
May  1 23:39:45.733: INFO: Waiting for pod pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c to disappear
May  1 23:39:45.835: INFO: Pod pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  1 23:39:45.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7758" for this suite. 05/01/23 23:39:45.939
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":166,"skipped":3219,"failed":0}
------------------------------
• [SLOW TEST] [5.796 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:39:40.247
    May  1 23:39:40.247: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:39:40.248
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:40.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:40.761
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-0aadbddf-ba5f-42f5-9e76-780c78451ca4 05/01/23 23:39:40.964
    STEP: Creating a pod to test consume secrets 05/01/23 23:39:41.068
    May  1 23:39:41.175: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c" in namespace "projected-7758" to be "Succeeded or Failed"
    May  1 23:39:41.278: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c": Phase="Pending", Reason="", readiness=false. Elapsed: 102.553133ms
    May  1 23:39:43.382: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206281371s
    May  1 23:39:45.382: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206172606s
    STEP: Saw pod success 05/01/23 23:39:45.382
    May  1 23:39:45.382: INFO: Pod "pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c" satisfied condition "Succeeded or Failed"
    May  1 23:39:45.484: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c container projected-secret-volume-test: <nil>
    STEP: delete the pod 05/01/23 23:39:45.614
    May  1 23:39:45.733: INFO: Waiting for pod pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c to disappear
    May  1 23:39:45.835: INFO: Pod pod-projected-secrets-a0eae1c0-c0a5-45a9-9e7e-8e20cdf7699c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  1 23:39:45.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7758" for this suite. 05/01/23 23:39:45.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:39:46.045
May  1 23:39:46.046: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/01/23 23:39:46.047
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:46.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:46.562
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6359 05/01/23 23:39:46.766
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-6359 05/01/23 23:39:46.872
May  1 23:39:47.084: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May  1 23:39:57.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 05/01/23 23:39:57.395
STEP: updating a scale subresource 05/01/23 23:39:57.498
STEP: verifying the statefulset Spec.Replicas was modified 05/01/23 23:39:57.604
STEP: Patch a scale subresource 05/01/23 23:39:57.706
STEP: verifying the statefulset Spec.Replicas was modified 05/01/23 23:39:57.811
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  1 23:39:57.914: INFO: Deleting all statefulset in ns statefulset-6359
May  1 23:39:58.017: INFO: Scaling statefulset ss to 0
May  1 23:40:08.437: INFO: Waiting for statefulset status.replicas updated to 0
May  1 23:40:08.539: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  1 23:40:08.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6359" for this suite. 05/01/23 23:40:08.953
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":167,"skipped":3258,"failed":0}
------------------------------
• [SLOW TEST] [23.012 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:39:46.045
    May  1 23:39:46.046: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/01/23 23:39:46.047
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:39:46.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:39:46.562
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6359 05/01/23 23:39:46.766
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-6359 05/01/23 23:39:46.872
    May  1 23:39:47.084: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    May  1 23:39:57.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 05/01/23 23:39:57.395
    STEP: updating a scale subresource 05/01/23 23:39:57.498
    STEP: verifying the statefulset Spec.Replicas was modified 05/01/23 23:39:57.604
    STEP: Patch a scale subresource 05/01/23 23:39:57.706
    STEP: verifying the statefulset Spec.Replicas was modified 05/01/23 23:39:57.811
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  1 23:39:57.914: INFO: Deleting all statefulset in ns statefulset-6359
    May  1 23:39:58.017: INFO: Scaling statefulset ss to 0
    May  1 23:40:08.437: INFO: Waiting for statefulset status.replicas updated to 0
    May  1 23:40:08.539: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  1 23:40:08.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6359" for this suite. 05/01/23 23:40:08.953
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:09.061
May  1 23:40:09.061: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces 05/01/23 23:40:09.063
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:09.372
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:09.576
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 05/01/23 23:40:09.78
STEP: patching the Namespace 05/01/23 23:40:10.089
STEP: get the Namespace and ensuring it has the label 05/01/23 23:40:10.193
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
May  1 23:40:10.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3816" for this suite. 05/01/23 23:40:10.399
STEP: Destroying namespace "nspatchtest-0b234b6c-13c3-4a95-a12a-9ec8c71ca436-9142" for this suite. 05/01/23 23:40:10.503
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":168,"skipped":3365,"failed":0}
------------------------------
• [1.548 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:09.061
    May  1 23:40:09.061: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename namespaces 05/01/23 23:40:09.063
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:09.372
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:09.576
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 05/01/23 23:40:09.78
    STEP: patching the Namespace 05/01/23 23:40:10.089
    STEP: get the Namespace and ensuring it has the label 05/01/23 23:40:10.193
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:40:10.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3816" for this suite. 05/01/23 23:40:10.399
    STEP: Destroying namespace "nspatchtest-0b234b6c-13c3-4a95-a12a-9ec8c71ca436-9142" for this suite. 05/01/23 23:40:10.503
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:10.609
May  1 23:40:10.609: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/01/23 23:40:10.611
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:10.92
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:11.124
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 05/01/23 23:40:11.946
STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:40:12.05
May  1 23:40:12.153: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:12.256: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:40:12.256: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  1 23:40:13.360: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:13.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May  1 23:40:13.463: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  1 23:40:14.360: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:14.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 23:40:14.464: INFO: Node i-0627b78ff917cf2ae is running 0 daemon pod, expected 1
May  1 23:40:15.361: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:15.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 23:40:15.464: INFO: Node i-0627b78ff917cf2ae is running 0 daemon pod, expected 1
May  1 23:40:16.361: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:16.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  1 23:40:16.464: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 05/01/23 23:40:16.567
May  1 23:40:16.879: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:16.983: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 23:40:16.983: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
May  1 23:40:18.095: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:18.199: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  1 23:40:18.199: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
May  1 23:40:19.087: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:40:19.190: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  1 23:40:19.190: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 05/01/23 23:40:19.293
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2928, will wait for the garbage collector to delete the pods 05/01/23 23:40:19.293
May  1 23:40:19.651: INFO: Deleting DaemonSet.extensions daemon-set took: 104.434536ms
May  1 23:40:19.751: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.230713ms
May  1 23:40:21.654: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:40:21.654: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May  1 23:40:21.757: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22314"},"items":null}

May  1 23:40:21.859: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22314"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  1 23:40:22.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2928" for this suite. 05/01/23 23:40:22.477
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":169,"skipped":3369,"failed":0}
------------------------------
• [SLOW TEST] [11.972 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:10.609
    May  1 23:40:10.609: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/01/23 23:40:10.611
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:10.92
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:11.124
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 05/01/23 23:40:11.946
    STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:40:12.05
    May  1 23:40:12.153: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:12.256: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:40:12.256: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  1 23:40:13.360: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:13.463: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    May  1 23:40:13.463: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  1 23:40:14.360: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:14.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 23:40:14.464: INFO: Node i-0627b78ff917cf2ae is running 0 daemon pod, expected 1
    May  1 23:40:15.361: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:15.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 23:40:15.464: INFO: Node i-0627b78ff917cf2ae is running 0 daemon pod, expected 1
    May  1 23:40:16.361: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:16.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  1 23:40:16.464: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 05/01/23 23:40:16.567
    May  1 23:40:16.879: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:16.983: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 23:40:16.983: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
    May  1 23:40:18.095: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:18.199: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  1 23:40:18.199: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
    May  1 23:40:19.087: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:40:19.190: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  1 23:40:19.190: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 05/01/23 23:40:19.293
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2928, will wait for the garbage collector to delete the pods 05/01/23 23:40:19.293
    May  1 23:40:19.651: INFO: Deleting DaemonSet.extensions daemon-set took: 104.434536ms
    May  1 23:40:19.751: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.230713ms
    May  1 23:40:21.654: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:40:21.654: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    May  1 23:40:21.757: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22314"},"items":null}

    May  1 23:40:21.859: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22314"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:40:22.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2928" for this suite. 05/01/23 23:40:22.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:22.582
May  1 23:40:22.582: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 23:40:22.583
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:22.892
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:23.096
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 05/01/23 23:40:23.3
May  1 23:40:23.407: INFO: Waiting up to 5m0s for pod "pod-851106d8-d464-4f18-9656-29753be63bbe" in namespace "emptydir-3329" to be "Succeeded or Failed"
May  1 23:40:23.511: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 103.568879ms
May  1 23:40:25.615: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207744652s
May  1 23:40:27.614: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207022874s
STEP: Saw pod success 05/01/23 23:40:27.614
May  1 23:40:27.614: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe" satisfied condition "Succeeded or Failed"
May  1 23:40:27.717: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-851106d8-d464-4f18-9656-29753be63bbe container test-container: <nil>
STEP: delete the pod 05/01/23 23:40:27.828
May  1 23:40:27.939: INFO: Waiting for pod pod-851106d8-d464-4f18-9656-29753be63bbe to disappear
May  1 23:40:28.041: INFO: Pod pod-851106d8-d464-4f18-9656-29753be63bbe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 23:40:28.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3329" for this suite. 05/01/23 23:40:28.145
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":170,"skipped":3374,"failed":0}
------------------------------
• [SLOW TEST] [5.767 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:22.582
    May  1 23:40:22.582: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 23:40:22.583
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:22.892
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:23.096
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 05/01/23 23:40:23.3
    May  1 23:40:23.407: INFO: Waiting up to 5m0s for pod "pod-851106d8-d464-4f18-9656-29753be63bbe" in namespace "emptydir-3329" to be "Succeeded or Failed"
    May  1 23:40:23.511: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 103.568879ms
    May  1 23:40:25.615: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207744652s
    May  1 23:40:27.614: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207022874s
    STEP: Saw pod success 05/01/23 23:40:27.614
    May  1 23:40:27.614: INFO: Pod "pod-851106d8-d464-4f18-9656-29753be63bbe" satisfied condition "Succeeded or Failed"
    May  1 23:40:27.717: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-851106d8-d464-4f18-9656-29753be63bbe container test-container: <nil>
    STEP: delete the pod 05/01/23 23:40:27.828
    May  1 23:40:27.939: INFO: Waiting for pod pod-851106d8-d464-4f18-9656-29753be63bbe to disappear
    May  1 23:40:28.041: INFO: Pod pod-851106d8-d464-4f18-9656-29753be63bbe no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 23:40:28.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3329" for this suite. 05/01/23 23:40:28.145
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:28.349
May  1 23:40:28.349: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:40:28.351
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:28.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:28.863
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-9888 05/01/23 23:40:29.068
STEP: creating replication controller nodeport-test in namespace services-9888 05/01/23 23:40:29.179
I0501 23:40:29.286702    6969 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-9888, replica count: 2
I0501 23:40:32.437956    6969 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  1 23:40:32.438: INFO: Creating new exec pod
May  1 23:40:32.542: INFO: Waiting up to 5m0s for pod "execpodl79ck" in namespace "services-9888" to be "running"
May  1 23:40:32.645: INFO: Pod "execpodl79ck": Phase="Pending", Reason="", readiness=false. Elapsed: 102.901235ms
May  1 23:40:34.748: INFO: Pod "execpodl79ck": Phase="Running", Reason="", readiness=true. Elapsed: 2.206223918s
May  1 23:40:34.748: INFO: Pod "execpodl79ck" satisfied condition "running"
May  1 23:40:35.852: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
May  1 23:40:36.971: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
May  1 23:40:36.971: INFO: stdout: "nodeport-test-9lf2n"
May  1 23:40:36.971: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
May  1 23:40:38.073: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
May  1 23:40:38.073: INFO: stdout: ""
May  1 23:40:39.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
May  1 23:40:40.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
May  1 23:40:40.184: INFO: stdout: ""
May  1 23:40:41.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
May  1 23:40:42.173: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
May  1 23:40:42.173: INFO: stdout: ""
May  1 23:40:43.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
May  1 23:40:44.164: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
May  1 23:40:44.164: INFO: stdout: ""
May  1 23:40:45.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
May  1 23:40:46.185: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
May  1 23:40:46.185: INFO: stdout: ""
May  1 23:40:47.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
May  1 23:40:48.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
May  1 23:40:48.184: INFO: stdout: "nodeport-test-8hjwk"
May  1 23:40:48.184: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 32595'
May  1 23:40:49.269: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.39.145 32595\nConnection to 172.20.39.145 32595 port [tcp/*] succeeded!\n"
May  1 23:40:49.269: INFO: stdout: "nodeport-test-8hjwk"
May  1 23:40:49.269: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.62.149 32595'
May  1 23:40:50.354: INFO: stderr: "+ nc -v -t -w 2 172.20.62.149 32595\n+ echo hostName\nConnection to 172.20.62.149 32595 port [tcp/*] succeeded!\n"
May  1 23:40:50.354: INFO: stdout: "nodeport-test-8hjwk"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:40:50.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9888" for this suite. 05/01/23 23:40:50.458
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":171,"skipped":3374,"failed":0}
------------------------------
• [SLOW TEST] [22.213 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:28.349
    May  1 23:40:28.349: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:40:28.351
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:28.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:28.863
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-9888 05/01/23 23:40:29.068
    STEP: creating replication controller nodeport-test in namespace services-9888 05/01/23 23:40:29.179
    I0501 23:40:29.286702    6969 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-9888, replica count: 2
    I0501 23:40:32.437956    6969 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  1 23:40:32.438: INFO: Creating new exec pod
    May  1 23:40:32.542: INFO: Waiting up to 5m0s for pod "execpodl79ck" in namespace "services-9888" to be "running"
    May  1 23:40:32.645: INFO: Pod "execpodl79ck": Phase="Pending", Reason="", readiness=false. Elapsed: 102.901235ms
    May  1 23:40:34.748: INFO: Pod "execpodl79ck": Phase="Running", Reason="", readiness=true. Elapsed: 2.206223918s
    May  1 23:40:34.748: INFO: Pod "execpodl79ck" satisfied condition "running"
    May  1 23:40:35.852: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    May  1 23:40:36.971: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    May  1 23:40:36.971: INFO: stdout: "nodeport-test-9lf2n"
    May  1 23:40:36.971: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
    May  1 23:40:38.073: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
    May  1 23:40:38.073: INFO: stdout: ""
    May  1 23:40:39.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
    May  1 23:40:40.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
    May  1 23:40:40.184: INFO: stdout: ""
    May  1 23:40:41.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
    May  1 23:40:42.173: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
    May  1 23:40:42.173: INFO: stdout: ""
    May  1 23:40:43.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
    May  1 23:40:44.164: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
    May  1 23:40:44.164: INFO: stdout: ""
    May  1 23:40:45.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
    May  1 23:40:46.185: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
    May  1 23:40:46.185: INFO: stdout: ""
    May  1 23:40:47.074: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.210.106 80'
    May  1 23:40:48.184: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.210.106 80\nConnection to 100.65.210.106 80 port [tcp/http] succeeded!\n"
    May  1 23:40:48.184: INFO: stdout: "nodeport-test-8hjwk"
    May  1 23:40:48.184: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 32595'
    May  1 23:40:49.269: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.39.145 32595\nConnection to 172.20.39.145 32595 port [tcp/*] succeeded!\n"
    May  1 23:40:49.269: INFO: stdout: "nodeport-test-8hjwk"
    May  1 23:40:49.269: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-9888 exec execpodl79ck -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.62.149 32595'
    May  1 23:40:50.354: INFO: stderr: "+ nc -v -t -w 2 172.20.62.149 32595\n+ echo hostName\nConnection to 172.20.62.149 32595 port [tcp/*] succeeded!\n"
    May  1 23:40:50.354: INFO: stdout: "nodeport-test-8hjwk"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:40:50.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9888" for this suite. 05/01/23 23:40:50.458
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:50.563
May  1 23:40:50.563: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:40:50.564
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:50.872
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:51.076
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
May  1 23:40:51.385: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed" in namespace "kubelet-test-6551" to be "running and ready"
May  1 23:40:51.487: INFO: Pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed": Phase="Pending", Reason="", readiness=false. Elapsed: 102.615291ms
May  1 23:40:51.487: INFO: The phase of Pod busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed is Pending, waiting for it to be Running (with Ready = true)
May  1 23:40:53.592: INFO: Pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed": Phase="Running", Reason="", readiness=true. Elapsed: 2.206801686s
May  1 23:40:53.592: INFO: The phase of Pod busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed is Running (Ready = true)
May  1 23:40:53.592: INFO: Pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
May  1 23:40:53.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6551" for this suite. 05/01/23 23:40:53.904
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":172,"skipped":3381,"failed":0}
------------------------------
• [3.446 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:50.563
    May  1 23:40:50.563: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:40:50.564
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:50.872
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:51.076
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    May  1 23:40:51.385: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed" in namespace "kubelet-test-6551" to be "running and ready"
    May  1 23:40:51.487: INFO: Pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed": Phase="Pending", Reason="", readiness=false. Elapsed: 102.615291ms
    May  1 23:40:51.487: INFO: The phase of Pod busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:40:53.592: INFO: Pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed": Phase="Running", Reason="", readiness=true. Elapsed: 2.206801686s
    May  1 23:40:53.592: INFO: The phase of Pod busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed is Running (Ready = true)
    May  1 23:40:53.592: INFO: Pod "busybox-readonly-fs53e3cd39-37f9-4d2f-8dfe-3cda8d4d52ed" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    May  1 23:40:53.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6551" for this suite. 05/01/23 23:40:53.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:54.011
May  1 23:40:54.011: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:40:54.013
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:54.322
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:54.525
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-7f78dad1-24cf-4e1a-8382-c590a98a2607 05/01/23 23:40:54.729
STEP: Creating a pod to test consume configMaps 05/01/23 23:40:54.833
May  1 23:40:54.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de" in namespace "configmap-3670" to be "Succeeded or Failed"
May  1 23:40:55.042: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de": Phase="Pending", Reason="", readiness=false. Elapsed: 102.668143ms
May  1 23:40:57.146: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207044106s
May  1 23:40:59.146: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206846351s
STEP: Saw pod success 05/01/23 23:40:59.146
May  1 23:40:59.146: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de" satisfied condition "Succeeded or Failed"
May  1 23:40:59.249: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de container configmap-volume-test: <nil>
STEP: delete the pod 05/01/23 23:40:59.354
May  1 23:40:59.466: INFO: Waiting for pod pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de to disappear
May  1 23:40:59.568: INFO: Pod pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:40:59.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3670" for this suite. 05/01/23 23:40:59.672
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":173,"skipped":3422,"failed":0}
------------------------------
• [SLOW TEST] [5.765 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:54.011
    May  1 23:40:54.011: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:40:54.013
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:40:54.322
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:40:54.525
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-7f78dad1-24cf-4e1a-8382-c590a98a2607 05/01/23 23:40:54.729
    STEP: Creating a pod to test consume configMaps 05/01/23 23:40:54.833
    May  1 23:40:54.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de" in namespace "configmap-3670" to be "Succeeded or Failed"
    May  1 23:40:55.042: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de": Phase="Pending", Reason="", readiness=false. Elapsed: 102.668143ms
    May  1 23:40:57.146: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207044106s
    May  1 23:40:59.146: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206846351s
    STEP: Saw pod success 05/01/23 23:40:59.146
    May  1 23:40:59.146: INFO: Pod "pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de" satisfied condition "Succeeded or Failed"
    May  1 23:40:59.249: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de container configmap-volume-test: <nil>
    STEP: delete the pod 05/01/23 23:40:59.354
    May  1 23:40:59.466: INFO: Waiting for pod pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de to disappear
    May  1 23:40:59.568: INFO: Pod pod-configmaps-c6f65333-eb74-42bf-b749-12598058f7de no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:40:59.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3670" for this suite. 05/01/23 23:40:59.672
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:40:59.778
May  1 23:40:59.778: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:40:59.78
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:00.09
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:00.293
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-b9dfd7f6-e246-41c3-8dd7-b6bc5f748a68 05/01/23 23:41:00.497
STEP: Creating secret with name secret-projected-all-test-volume-73f7cfae-3459-440f-adbf-b446486931a5 05/01/23 23:41:00.601
STEP: Creating a pod to test Check all projections for projected volume plugin 05/01/23 23:41:00.707
May  1 23:41:00.813: INFO: Waiting up to 5m0s for pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f" in namespace "projected-1944" to be "Succeeded or Failed"
May  1 23:41:00.915: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f": Phase="Pending", Reason="", readiness=false. Elapsed: 102.63263ms
May  1 23:41:03.019: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206757039s
May  1 23:41:05.019: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20593857s
STEP: Saw pod success 05/01/23 23:41:05.019
May  1 23:41:05.019: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f" satisfied condition "Succeeded or Failed"
May  1 23:41:05.122: INFO: Trying to get logs from node i-02d061b30635c230c pod projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f container projected-all-volume-test: <nil>
STEP: delete the pod 05/01/23 23:41:05.227
May  1 23:41:05.336: INFO: Waiting for pod projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f to disappear
May  1 23:41:05.439: INFO: Pod projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
May  1 23:41:05.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1944" for this suite. 05/01/23 23:41:05.544
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":174,"skipped":3453,"failed":0}
------------------------------
• [SLOW TEST] [5.875 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:40:59.778
    May  1 23:40:59.778: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:40:59.78
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:00.09
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:00.293
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-b9dfd7f6-e246-41c3-8dd7-b6bc5f748a68 05/01/23 23:41:00.497
    STEP: Creating secret with name secret-projected-all-test-volume-73f7cfae-3459-440f-adbf-b446486931a5 05/01/23 23:41:00.601
    STEP: Creating a pod to test Check all projections for projected volume plugin 05/01/23 23:41:00.707
    May  1 23:41:00.813: INFO: Waiting up to 5m0s for pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f" in namespace "projected-1944" to be "Succeeded or Failed"
    May  1 23:41:00.915: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f": Phase="Pending", Reason="", readiness=false. Elapsed: 102.63263ms
    May  1 23:41:03.019: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206757039s
    May  1 23:41:05.019: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20593857s
    STEP: Saw pod success 05/01/23 23:41:05.019
    May  1 23:41:05.019: INFO: Pod "projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f" satisfied condition "Succeeded or Failed"
    May  1 23:41:05.122: INFO: Trying to get logs from node i-02d061b30635c230c pod projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f container projected-all-volume-test: <nil>
    STEP: delete the pod 05/01/23 23:41:05.227
    May  1 23:41:05.336: INFO: Waiting for pod projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f to disappear
    May  1 23:41:05.439: INFO: Pod projected-volume-debf16f4-1233-43f6-8b5b-d37fbe3df15f no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    May  1 23:41:05.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1944" for this suite. 05/01/23 23:41:05.544
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:41:05.656
May  1 23:41:05.656: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 23:41:05.657
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:05.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:06.17
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 05/01/23 23:41:06.374
May  1 23:41:06.374: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3205 api-versions'
May  1 23:41:06.887: INFO: stderr: ""
May  1 23:41:06.887: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 23:41:06.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3205" for this suite. 05/01/23 23:41:06.991
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":175,"skipped":3473,"failed":0}
------------------------------
• [1.539 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:41:05.656
    May  1 23:41:05.656: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 23:41:05.657
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:05.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:06.17
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 05/01/23 23:41:06.374
    May  1 23:41:06.374: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3205 api-versions'
    May  1 23:41:06.887: INFO: stderr: ""
    May  1 23:41:06.887: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 23:41:06.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3205" for this suite. 05/01/23 23:41:06.991
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:41:07.195
May  1 23:41:07.195: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 23:41:07.196
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:07.506
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:07.71
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 05/01/23 23:41:07.914
May  1 23:41:07.914: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5194 create -f -'
May  1 23:41:08.593: INFO: stderr: ""
May  1 23:41:08.593: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 05/01/23 23:41:08.593
May  1 23:41:09.698: INFO: Selector matched 1 pods for map[app:agnhost]
May  1 23:41:09.698: INFO: Found 1 / 1
May  1 23:41:09.698: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 05/01/23 23:41:09.698
May  1 23:41:09.801: INFO: Selector matched 1 pods for map[app:agnhost]
May  1 23:41:09.801: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  1 23:41:09.801: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5194 patch pod agnhost-primary-tjz9c -p {"metadata":{"annotations":{"x":"y"}}}'
May  1 23:41:10.311: INFO: stderr: ""
May  1 23:41:10.311: INFO: stdout: "pod/agnhost-primary-tjz9c patched\n"
STEP: checking annotations 05/01/23 23:41:10.311
May  1 23:41:10.414: INFO: Selector matched 1 pods for map[app:agnhost]
May  1 23:41:10.414: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 23:41:10.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5194" for this suite. 05/01/23 23:41:10.518
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":176,"skipped":3478,"failed":0}
------------------------------
• [3.428 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:41:07.195
    May  1 23:41:07.195: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 23:41:07.196
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:07.506
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:07.71
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 05/01/23 23:41:07.914
    May  1 23:41:07.914: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5194 create -f -'
    May  1 23:41:08.593: INFO: stderr: ""
    May  1 23:41:08.593: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 05/01/23 23:41:08.593
    May  1 23:41:09.698: INFO: Selector matched 1 pods for map[app:agnhost]
    May  1 23:41:09.698: INFO: Found 1 / 1
    May  1 23:41:09.698: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 05/01/23 23:41:09.698
    May  1 23:41:09.801: INFO: Selector matched 1 pods for map[app:agnhost]
    May  1 23:41:09.801: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    May  1 23:41:09.801: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-5194 patch pod agnhost-primary-tjz9c -p {"metadata":{"annotations":{"x":"y"}}}'
    May  1 23:41:10.311: INFO: stderr: ""
    May  1 23:41:10.311: INFO: stdout: "pod/agnhost-primary-tjz9c patched\n"
    STEP: checking annotations 05/01/23 23:41:10.311
    May  1 23:41:10.414: INFO: Selector matched 1 pods for map[app:agnhost]
    May  1 23:41:10.414: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 23:41:10.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5194" for this suite. 05/01/23 23:41:10.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:41:10.624
May  1 23:41:10.624: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath 05/01/23 23:41:10.625
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:10.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:11.143
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 05/01/23 23:41:11.347
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-775c 05/01/23 23:41:11.557
STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:41:11.557
May  1 23:41:11.663: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-775c" in namespace "subpath-1868" to be "Succeeded or Failed"
May  1 23:41:11.766: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Pending", Reason="", readiness=false. Elapsed: 102.646524ms
May  1 23:41:13.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 2.205808854s
May  1 23:41:15.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 4.206642443s
May  1 23:41:17.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 6.205996109s
May  1 23:41:19.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 8.206654361s
May  1 23:41:21.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 10.205850588s
May  1 23:41:23.871: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 12.207688979s
May  1 23:41:25.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 14.206146728s
May  1 23:41:27.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 16.205887926s
May  1 23:41:29.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 18.206794545s
May  1 23:41:31.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 20.205976411s
May  1 23:41:33.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=false. Elapsed: 22.206669363s
May  1 23:41:35.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.20601079s
STEP: Saw pod success 05/01/23 23:41:35.869
May  1 23:41:35.869: INFO: Pod "pod-subpath-test-configmap-775c" satisfied condition "Succeeded or Failed"
May  1 23:41:35.972: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-configmap-775c container test-container-subpath-configmap-775c: <nil>
STEP: delete the pod 05/01/23 23:41:36.078
May  1 23:41:36.187: INFO: Waiting for pod pod-subpath-test-configmap-775c to disappear
May  1 23:41:36.290: INFO: Pod pod-subpath-test-configmap-775c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-775c 05/01/23 23:41:36.29
May  1 23:41:36.290: INFO: Deleting pod "pod-subpath-test-configmap-775c" in namespace "subpath-1868"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
May  1 23:41:36.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1868" for this suite. 05/01/23 23:41:36.501
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":177,"skipped":3484,"failed":0}
------------------------------
• [SLOW TEST] [26.080 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:41:10.624
    May  1 23:41:10.624: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename subpath 05/01/23 23:41:10.625
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:10.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:11.143
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 05/01/23 23:41:11.347
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-775c 05/01/23 23:41:11.557
    STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:41:11.557
    May  1 23:41:11.663: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-775c" in namespace "subpath-1868" to be "Succeeded or Failed"
    May  1 23:41:11.766: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Pending", Reason="", readiness=false. Elapsed: 102.646524ms
    May  1 23:41:13.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 2.205808854s
    May  1 23:41:15.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 4.206642443s
    May  1 23:41:17.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 6.205996109s
    May  1 23:41:19.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 8.206654361s
    May  1 23:41:21.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 10.205850588s
    May  1 23:41:23.871: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 12.207688979s
    May  1 23:41:25.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 14.206146728s
    May  1 23:41:27.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 16.205887926s
    May  1 23:41:29.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 18.206794545s
    May  1 23:41:31.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=true. Elapsed: 20.205976411s
    May  1 23:41:33.870: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Running", Reason="", readiness=false. Elapsed: 22.206669363s
    May  1 23:41:35.869: INFO: Pod "pod-subpath-test-configmap-775c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.20601079s
    STEP: Saw pod success 05/01/23 23:41:35.869
    May  1 23:41:35.869: INFO: Pod "pod-subpath-test-configmap-775c" satisfied condition "Succeeded or Failed"
    May  1 23:41:35.972: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-configmap-775c container test-container-subpath-configmap-775c: <nil>
    STEP: delete the pod 05/01/23 23:41:36.078
    May  1 23:41:36.187: INFO: Waiting for pod pod-subpath-test-configmap-775c to disappear
    May  1 23:41:36.290: INFO: Pod pod-subpath-test-configmap-775c no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-775c 05/01/23 23:41:36.29
    May  1 23:41:36.290: INFO: Deleting pod "pod-subpath-test-configmap-775c" in namespace "subpath-1868"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    May  1 23:41:36.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1868" for this suite. 05/01/23 23:41:36.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:41:36.705
May  1 23:41:36.705: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:41:36.706
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:37.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:37.219
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:41:37.633
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:41:38.233
STEP: Deploying the webhook pod 05/01/23 23:41:38.339
STEP: Wait for the deployment to be ready 05/01/23 23:41:38.549
May  1 23:41:38.857: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:41:40.961
STEP: Verifying the service has paired with the endpoint 05/01/23 23:41:41.071
May  1 23:41:42.071: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 05/01/23 23:41:42.174
STEP: create a pod that should be updated by the webhook 05/01/23 23:41:42.389
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:41:42.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3430" for this suite. 05/01/23 23:41:42.71
STEP: Destroying namespace "webhook-3430-markers" for this suite. 05/01/23 23:41:42.816
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":178,"skipped":3501,"failed":0}
------------------------------
• [SLOW TEST] [6.673 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:41:36.705
    May  1 23:41:36.705: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:41:36.706
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:37.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:37.219
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:41:37.633
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:41:38.233
    STEP: Deploying the webhook pod 05/01/23 23:41:38.339
    STEP: Wait for the deployment to be ready 05/01/23 23:41:38.549
    May  1 23:41:38.857: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:41:40.961
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:41:41.071
    May  1 23:41:42.071: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 05/01/23 23:41:42.174
    STEP: create a pod that should be updated by the webhook 05/01/23 23:41:42.389
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:41:42.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3430" for this suite. 05/01/23 23:41:42.71
    STEP: Destroying namespace "webhook-3430-markers" for this suite. 05/01/23 23:41:42.816
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:41:43.379
May  1 23:41:43.379: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container 05/01/23 23:41:43.381
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:43.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:43.893
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 05/01/23 23:41:44.096
May  1 23:41:44.096: INFO: PodSpec: initContainers in spec.initContainers
May  1 23:42:27.507: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-dc7e1088-b261-409c-bcc5-5e76b2abd42b", GenerateName:"", Namespace:"init-container-412", SelfLink:"", UID:"9d9e4f6f-8a03-46b6-8fbc-9ee90a4843b5", ResourceVersion:"23014", Generation:0, CreationTimestamp:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"96812673"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"edf08bfa0c59f5806e3fd4ed458f8bf041d2e5f132616baa3a2ca4317cc4dd50", "cni.projectcalico.org/podIP":"100.96.36.27/32", "cni.projectcalico.org/podIPs":"100.96.36.27/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f4c048), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f4c078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.May, 1, 23, 42, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f4c0c0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-dx7wp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00779b240), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dx7wp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dx7wp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dx7wp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003edaf08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"i-02d061b30635c230c", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003d11180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003edafa0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003edafc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003edafc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003edafcc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00105c2b0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.48.211", PodIP:"100.96.36.27", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.36.27"}}, StartTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003d11260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003d112d0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://3e26745b1cbae471961f1de8d85cd50e7c1b5d495c21904d1730c59fd8920814", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00779b2c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00779b2a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003edb04f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
May  1 23:42:27.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-412" for this suite. 05/01/23 23:42:27.612
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":179,"skipped":3506,"failed":0}
------------------------------
• [SLOW TEST] [44.338 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:41:43.379
    May  1 23:41:43.379: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename init-container 05/01/23 23:41:43.381
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:41:43.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:41:43.893
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 05/01/23 23:41:44.096
    May  1 23:41:44.096: INFO: PodSpec: initContainers in spec.initContainers
    May  1 23:42:27.507: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-dc7e1088-b261-409c-bcc5-5e76b2abd42b", GenerateName:"", Namespace:"init-container-412", SelfLink:"", UID:"9d9e4f6f-8a03-46b6-8fbc-9ee90a4843b5", ResourceVersion:"23014", Generation:0, CreationTimestamp:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"96812673"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"edf08bfa0c59f5806e3fd4ed458f8bf041d2e5f132616baa3a2ca4317cc4dd50", "cni.projectcalico.org/podIP":"100.96.36.27/32", "cni.projectcalico.org/podIPs":"100.96.36.27/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f4c048), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f4c078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.May, 1, 23, 42, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f4c0c0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-dx7wp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00779b240), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dx7wp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dx7wp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-dx7wp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003edaf08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"i-02d061b30635c230c", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003d11180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003edafa0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003edafc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003edafc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003edafcc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00105c2b0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.48.211", PodIP:"100.96.36.27", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.36.27"}}, StartTime:time.Date(2023, time.May, 1, 23, 41, 44, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003d11260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003d112d0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://3e26745b1cbae471961f1de8d85cd50e7c1b5d495c21904d1730c59fd8920814", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00779b2c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00779b2a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003edb04f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    May  1 23:42:27.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-412" for this suite. 05/01/23 23:42:27.612
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:42:27.718
May  1 23:42:27.718: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename discovery 05/01/23 23:42:27.72
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:28.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:28.233
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 05/01/23 23:42:28.538
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
May  1 23:42:29.464: INFO: Checking APIGroup: apiregistration.k8s.io
May  1 23:42:29.565: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
May  1 23:42:29.565: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
May  1 23:42:29.565: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
May  1 23:42:29.565: INFO: Checking APIGroup: apps
May  1 23:42:29.667: INFO: PreferredVersion.GroupVersion: apps/v1
May  1 23:42:29.667: INFO: Versions found [{apps/v1 v1}]
May  1 23:42:29.667: INFO: apps/v1 matches apps/v1
May  1 23:42:29.667: INFO: Checking APIGroup: events.k8s.io
May  1 23:42:29.768: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
May  1 23:42:29.768: INFO: Versions found [{events.k8s.io/v1 v1}]
May  1 23:42:29.768: INFO: events.k8s.io/v1 matches events.k8s.io/v1
May  1 23:42:29.768: INFO: Checking APIGroup: authentication.k8s.io
May  1 23:42:29.869: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
May  1 23:42:29.869: INFO: Versions found [{authentication.k8s.io/v1 v1}]
May  1 23:42:29.869: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
May  1 23:42:29.869: INFO: Checking APIGroup: authorization.k8s.io
May  1 23:42:29.971: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
May  1 23:42:29.971: INFO: Versions found [{authorization.k8s.io/v1 v1}]
May  1 23:42:29.971: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
May  1 23:42:29.971: INFO: Checking APIGroup: autoscaling
May  1 23:42:30.073: INFO: PreferredVersion.GroupVersion: autoscaling/v2
May  1 23:42:30.073: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
May  1 23:42:30.073: INFO: autoscaling/v2 matches autoscaling/v2
May  1 23:42:30.073: INFO: Checking APIGroup: batch
May  1 23:42:30.174: INFO: PreferredVersion.GroupVersion: batch/v1
May  1 23:42:30.174: INFO: Versions found [{batch/v1 v1}]
May  1 23:42:30.174: INFO: batch/v1 matches batch/v1
May  1 23:42:30.174: INFO: Checking APIGroup: certificates.k8s.io
May  1 23:42:30.275: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
May  1 23:42:30.275: INFO: Versions found [{certificates.k8s.io/v1 v1}]
May  1 23:42:30.275: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
May  1 23:42:30.275: INFO: Checking APIGroup: networking.k8s.io
May  1 23:42:30.377: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
May  1 23:42:30.377: INFO: Versions found [{networking.k8s.io/v1 v1}]
May  1 23:42:30.377: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
May  1 23:42:30.377: INFO: Checking APIGroup: policy
May  1 23:42:30.478: INFO: PreferredVersion.GroupVersion: policy/v1
May  1 23:42:30.478: INFO: Versions found [{policy/v1 v1}]
May  1 23:42:30.478: INFO: policy/v1 matches policy/v1
May  1 23:42:30.478: INFO: Checking APIGroup: rbac.authorization.k8s.io
May  1 23:42:30.580: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
May  1 23:42:30.580: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
May  1 23:42:30.580: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
May  1 23:42:30.580: INFO: Checking APIGroup: storage.k8s.io
May  1 23:42:30.681: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
May  1 23:42:30.681: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
May  1 23:42:30.681: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
May  1 23:42:30.681: INFO: Checking APIGroup: admissionregistration.k8s.io
May  1 23:42:30.783: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
May  1 23:42:30.783: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
May  1 23:42:30.783: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
May  1 23:42:30.783: INFO: Checking APIGroup: apiextensions.k8s.io
May  1 23:42:30.884: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
May  1 23:42:30.884: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
May  1 23:42:30.884: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
May  1 23:42:30.884: INFO: Checking APIGroup: scheduling.k8s.io
May  1 23:42:30.986: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
May  1 23:42:30.986: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
May  1 23:42:30.986: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
May  1 23:42:30.986: INFO: Checking APIGroup: coordination.k8s.io
May  1 23:42:31.087: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
May  1 23:42:31.087: INFO: Versions found [{coordination.k8s.io/v1 v1}]
May  1 23:42:31.087: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
May  1 23:42:31.087: INFO: Checking APIGroup: node.k8s.io
May  1 23:42:31.189: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
May  1 23:42:31.189: INFO: Versions found [{node.k8s.io/v1 v1}]
May  1 23:42:31.189: INFO: node.k8s.io/v1 matches node.k8s.io/v1
May  1 23:42:31.189: INFO: Checking APIGroup: discovery.k8s.io
May  1 23:42:31.290: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
May  1 23:42:31.290: INFO: Versions found [{discovery.k8s.io/v1 v1}]
May  1 23:42:31.290: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
May  1 23:42:31.290: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
May  1 23:42:31.392: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
May  1 23:42:31.392: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
May  1 23:42:31.392: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
May  1 23:42:31.392: INFO: Checking APIGroup: crd.projectcalico.org
May  1 23:42:31.493: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
May  1 23:42:31.493: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
May  1 23:42:31.493: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
May  1 23:42:31.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-5823" for this suite. 05/01/23 23:42:31.598
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":180,"skipped":3509,"failed":0}
------------------------------
• [4.084 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:42:27.718
    May  1 23:42:27.718: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename discovery 05/01/23 23:42:27.72
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:28.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:28.233
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 05/01/23 23:42:28.538
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    May  1 23:42:29.464: INFO: Checking APIGroup: apiregistration.k8s.io
    May  1 23:42:29.565: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    May  1 23:42:29.565: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    May  1 23:42:29.565: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    May  1 23:42:29.565: INFO: Checking APIGroup: apps
    May  1 23:42:29.667: INFO: PreferredVersion.GroupVersion: apps/v1
    May  1 23:42:29.667: INFO: Versions found [{apps/v1 v1}]
    May  1 23:42:29.667: INFO: apps/v1 matches apps/v1
    May  1 23:42:29.667: INFO: Checking APIGroup: events.k8s.io
    May  1 23:42:29.768: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    May  1 23:42:29.768: INFO: Versions found [{events.k8s.io/v1 v1}]
    May  1 23:42:29.768: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    May  1 23:42:29.768: INFO: Checking APIGroup: authentication.k8s.io
    May  1 23:42:29.869: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    May  1 23:42:29.869: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    May  1 23:42:29.869: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    May  1 23:42:29.869: INFO: Checking APIGroup: authorization.k8s.io
    May  1 23:42:29.971: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    May  1 23:42:29.971: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    May  1 23:42:29.971: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    May  1 23:42:29.971: INFO: Checking APIGroup: autoscaling
    May  1 23:42:30.073: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    May  1 23:42:30.073: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    May  1 23:42:30.073: INFO: autoscaling/v2 matches autoscaling/v2
    May  1 23:42:30.073: INFO: Checking APIGroup: batch
    May  1 23:42:30.174: INFO: PreferredVersion.GroupVersion: batch/v1
    May  1 23:42:30.174: INFO: Versions found [{batch/v1 v1}]
    May  1 23:42:30.174: INFO: batch/v1 matches batch/v1
    May  1 23:42:30.174: INFO: Checking APIGroup: certificates.k8s.io
    May  1 23:42:30.275: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    May  1 23:42:30.275: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    May  1 23:42:30.275: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    May  1 23:42:30.275: INFO: Checking APIGroup: networking.k8s.io
    May  1 23:42:30.377: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    May  1 23:42:30.377: INFO: Versions found [{networking.k8s.io/v1 v1}]
    May  1 23:42:30.377: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    May  1 23:42:30.377: INFO: Checking APIGroup: policy
    May  1 23:42:30.478: INFO: PreferredVersion.GroupVersion: policy/v1
    May  1 23:42:30.478: INFO: Versions found [{policy/v1 v1}]
    May  1 23:42:30.478: INFO: policy/v1 matches policy/v1
    May  1 23:42:30.478: INFO: Checking APIGroup: rbac.authorization.k8s.io
    May  1 23:42:30.580: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    May  1 23:42:30.580: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    May  1 23:42:30.580: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    May  1 23:42:30.580: INFO: Checking APIGroup: storage.k8s.io
    May  1 23:42:30.681: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    May  1 23:42:30.681: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    May  1 23:42:30.681: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    May  1 23:42:30.681: INFO: Checking APIGroup: admissionregistration.k8s.io
    May  1 23:42:30.783: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    May  1 23:42:30.783: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    May  1 23:42:30.783: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    May  1 23:42:30.783: INFO: Checking APIGroup: apiextensions.k8s.io
    May  1 23:42:30.884: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    May  1 23:42:30.884: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    May  1 23:42:30.884: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    May  1 23:42:30.884: INFO: Checking APIGroup: scheduling.k8s.io
    May  1 23:42:30.986: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    May  1 23:42:30.986: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    May  1 23:42:30.986: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    May  1 23:42:30.986: INFO: Checking APIGroup: coordination.k8s.io
    May  1 23:42:31.087: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    May  1 23:42:31.087: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    May  1 23:42:31.087: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    May  1 23:42:31.087: INFO: Checking APIGroup: node.k8s.io
    May  1 23:42:31.189: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    May  1 23:42:31.189: INFO: Versions found [{node.k8s.io/v1 v1}]
    May  1 23:42:31.189: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    May  1 23:42:31.189: INFO: Checking APIGroup: discovery.k8s.io
    May  1 23:42:31.290: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    May  1 23:42:31.290: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    May  1 23:42:31.290: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    May  1 23:42:31.290: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    May  1 23:42:31.392: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    May  1 23:42:31.392: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    May  1 23:42:31.392: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    May  1 23:42:31.392: INFO: Checking APIGroup: crd.projectcalico.org
    May  1 23:42:31.493: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    May  1 23:42:31.493: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    May  1 23:42:31.493: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    May  1 23:42:31.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-5823" for this suite. 05/01/23 23:42:31.598
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:42:31.803
May  1 23:42:31.803: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename prestop 05/01/23 23:42:31.804
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:32.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:32.316
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-6735 05/01/23 23:42:32.52
STEP: Waiting for pods to come up. 05/01/23 23:42:32.626
May  1 23:42:32.626: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6735" to be "running"
May  1 23:42:32.729: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 102.746286ms
May  1 23:42:34.832: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.206332379s
May  1 23:42:34.832: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-6735 05/01/23 23:42:34.935
May  1 23:42:35.040: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6735" to be "running"
May  1 23:42:35.143: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 102.603073ms
May  1 23:42:37.247: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.206987026s
May  1 23:42:37.247: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 05/01/23 23:42:37.247
May  1 23:42:42.459: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 05/01/23 23:42:42.459
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
May  1 23:42:42.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6735" for this suite. 05/01/23 23:42:42.676
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":181,"skipped":3511,"failed":0}
------------------------------
• [SLOW TEST] [11.083 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:42:31.803
    May  1 23:42:31.803: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename prestop 05/01/23 23:42:31.804
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:32.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:32.316
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-6735 05/01/23 23:42:32.52
    STEP: Waiting for pods to come up. 05/01/23 23:42:32.626
    May  1 23:42:32.626: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6735" to be "running"
    May  1 23:42:32.729: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 102.746286ms
    May  1 23:42:34.832: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.206332379s
    May  1 23:42:34.832: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-6735 05/01/23 23:42:34.935
    May  1 23:42:35.040: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6735" to be "running"
    May  1 23:42:35.143: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 102.603073ms
    May  1 23:42:37.247: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.206987026s
    May  1 23:42:37.247: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 05/01/23 23:42:37.247
    May  1 23:42:42.459: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 05/01/23 23:42:42.459
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    May  1 23:42:42.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-6735" for this suite. 05/01/23 23:42:42.676
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:42:42.886
May  1 23:42:42.886: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition 05/01/23 23:42:42.887
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:43.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:43.402
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
May  1 23:42:43.605: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:42:44.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3449" for this suite. 05/01/23 23:42:44.166
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":182,"skipped":3511,"failed":0}
------------------------------
• [1.385 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:42:42.886
    May  1 23:42:42.886: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename custom-resource-definition 05/01/23 23:42:42.887
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:43.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:43.402
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    May  1 23:42:43.605: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:42:44.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3449" for this suite. 05/01/23 23:42:44.166
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:42:44.271
May  1 23:42:44.271: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:42:44.272
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:44.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:44.785
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-029b4582-91f3-46df-9ba5-0aba4fd10736 05/01/23 23:42:44.989
STEP: Creating a pod to test consume configMaps 05/01/23 23:42:45.093
May  1 23:42:45.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0" in namespace "projected-71" to be "Succeeded or Failed"
May  1 23:42:45.305: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 102.754853ms
May  1 23:42:47.409: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206965441s
May  1 23:42:49.407: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205537044s
STEP: Saw pod success 05/01/23 23:42:49.408
May  1 23:42:49.408: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0" satisfied condition "Succeeded or Failed"
May  1 23:42:49.510: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0 container agnhost-container: <nil>
STEP: delete the pod 05/01/23 23:42:49.615
May  1 23:42:49.728: INFO: Waiting for pod pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0 to disappear
May  1 23:42:49.830: INFO: Pod pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  1 23:42:49.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-71" for this suite. 05/01/23 23:42:49.935
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":183,"skipped":3515,"failed":0}
------------------------------
• [SLOW TEST] [5.768 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:42:44.271
    May  1 23:42:44.271: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:42:44.272
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:44.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:44.785
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-029b4582-91f3-46df-9ba5-0aba4fd10736 05/01/23 23:42:44.989
    STEP: Creating a pod to test consume configMaps 05/01/23 23:42:45.093
    May  1 23:42:45.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0" in namespace "projected-71" to be "Succeeded or Failed"
    May  1 23:42:45.305: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 102.754853ms
    May  1 23:42:47.409: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206965441s
    May  1 23:42:49.407: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205537044s
    STEP: Saw pod success 05/01/23 23:42:49.408
    May  1 23:42:49.408: INFO: Pod "pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0" satisfied condition "Succeeded or Failed"
    May  1 23:42:49.510: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0 container agnhost-container: <nil>
    STEP: delete the pod 05/01/23 23:42:49.615
    May  1 23:42:49.728: INFO: Waiting for pod pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0 to disappear
    May  1 23:42:49.830: INFO: Pod pod-projected-configmaps-ddc3501f-9287-402d-9a5d-650c955ee1f0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  1 23:42:49.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-71" for this suite. 05/01/23 23:42:49.935
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:42:50.04
May  1 23:42:50.040: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/01/23 23:42:50.041
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:50.35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:50.554
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6 in namespace container-probe-622 05/01/23 23:42:50.758
May  1 23:42:50.865: INFO: Waiting up to 5m0s for pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6" in namespace "container-probe-622" to be "not pending"
May  1 23:42:50.968: INFO: Pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6": Phase="Pending", Reason="", readiness=false. Elapsed: 102.705403ms
May  1 23:42:53.071: INFO: Pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.205676894s
May  1 23:42:53.071: INFO: Pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6" satisfied condition "not pending"
May  1 23:42:53.071: INFO: Started pod test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6 in namespace container-probe-622
STEP: checking the pod's current state and verifying that restartCount is present 05/01/23 23:42:53.071
May  1 23:42:53.174: INFO: Initial restart count of pod test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6 is 0
STEP: deleting the pod 05/01/23 23:46:55.065
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  1 23:46:55.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-622" for this suite. 05/01/23 23:46:55.28
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":184,"skipped":3541,"failed":0}
------------------------------
• [SLOW TEST] [245.346 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:42:50.04
    May  1 23:42:50.040: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/01/23 23:42:50.041
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:42:50.35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:42:50.554
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6 in namespace container-probe-622 05/01/23 23:42:50.758
    May  1 23:42:50.865: INFO: Waiting up to 5m0s for pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6" in namespace "container-probe-622" to be "not pending"
    May  1 23:42:50.968: INFO: Pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6": Phase="Pending", Reason="", readiness=false. Elapsed: 102.705403ms
    May  1 23:42:53.071: INFO: Pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.205676894s
    May  1 23:42:53.071: INFO: Pod "test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6" satisfied condition "not pending"
    May  1 23:42:53.071: INFO: Started pod test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6 in namespace container-probe-622
    STEP: checking the pod's current state and verifying that restartCount is present 05/01/23 23:42:53.071
    May  1 23:42:53.174: INFO: Initial restart count of pod test-webserver-502f3242-4844-417d-bf14-1ad49350b5f6 is 0
    STEP: deleting the pod 05/01/23 23:46:55.065
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  1 23:46:55.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-622" for this suite. 05/01/23 23:46:55.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:46:55.388
May  1 23:46:55.388: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:46:55.39
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:46:55.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:46:55.905
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:46:56.317
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:46:56.641
STEP: Deploying the webhook pod 05/01/23 23:46:56.746
STEP: Wait for the deployment to be ready 05/01/23 23:46:56.956
May  1 23:46:57.264: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:46:59.368
STEP: Verifying the service has paired with the endpoint 05/01/23 23:46:59.477
May  1 23:47:00.479: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
May  1 23:47:00.581: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3524-crds.webhook.example.com via the AdmissionRegistration API 05/01/23 23:47:00.889
STEP: Creating a custom resource that should be mutated by the webhook 05/01/23 23:47:01.102
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:47:03.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1162" for this suite. 05/01/23 23:47:03.769
STEP: Destroying namespace "webhook-1162-markers" for this suite. 05/01/23 23:47:03.873
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":185,"skipped":3552,"failed":0}
------------------------------
• [SLOW TEST] [9.026 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:46:55.388
    May  1 23:46:55.388: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:46:55.39
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:46:55.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:46:55.905
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:46:56.317
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:46:56.641
    STEP: Deploying the webhook pod 05/01/23 23:46:56.746
    STEP: Wait for the deployment to be ready 05/01/23 23:46:56.956
    May  1 23:46:57.264: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 46, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:46:59.368
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:46:59.477
    May  1 23:47:00.479: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    May  1 23:47:00.581: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3524-crds.webhook.example.com via the AdmissionRegistration API 05/01/23 23:47:00.889
    STEP: Creating a custom resource that should be mutated by the webhook 05/01/23 23:47:01.102
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:47:03.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1162" for this suite. 05/01/23 23:47:03.769
    STEP: Destroying namespace "webhook-1162-markers" for this suite. 05/01/23 23:47:03.873
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:47:04.415
May  1 23:47:04.415: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/01/23 23:47:04.416
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:04.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:04.929
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 05/01/23 23:47:05.133
STEP: waiting for pod running 05/01/23 23:47:05.24
May  1 23:47:05.240: INFO: Waiting up to 2m0s for pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" in namespace "var-expansion-2491" to be "running"
May  1 23:47:05.343: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996": Phase="Pending", Reason="", readiness=false. Elapsed: 102.537004ms
May  1 23:47:07.445: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996": Phase="Running", Reason="", readiness=true. Elapsed: 2.205520822s
May  1 23:47:07.446: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" satisfied condition "running"
STEP: creating a file in subpath 05/01/23 23:47:07.446
May  1 23:47:07.548: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2491 PodName:var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:47:07.548: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:47:07.549: INFO: ExecWithOptions: Clientset creation
May  1 23:47:07.549: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/var-expansion-2491/pods/var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 05/01/23 23:47:08.293
May  1 23:47:08.396: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2491 PodName:var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:47:08.396: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:47:08.397: INFO: ExecWithOptions: Clientset creation
May  1 23:47:08.397: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/var-expansion-2491/pods/var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 05/01/23 23:47:09.136
May  1 23:47:09.848: INFO: Successfully updated pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996"
STEP: waiting for annotated pod running 05/01/23 23:47:09.848
May  1 23:47:09.848: INFO: Waiting up to 2m0s for pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" in namespace "var-expansion-2491" to be "running"
May  1 23:47:09.950: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996": Phase="Running", Reason="", readiness=true. Elapsed: 102.633686ms
May  1 23:47:09.950: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" satisfied condition "running"
STEP: deleting the pod gracefully 05/01/23 23:47:09.95
May  1 23:47:09.951: INFO: Deleting pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" in namespace "var-expansion-2491"
May  1 23:47:10.056: INFO: Wait up to 5m0s for pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  1 23:47:42.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2491" for this suite. 05/01/23 23:47:42.366
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":186,"skipped":3560,"failed":0}
------------------------------
• [SLOW TEST] [38.155 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:47:04.415
    May  1 23:47:04.415: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/01/23 23:47:04.416
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:04.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:04.929
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 05/01/23 23:47:05.133
    STEP: waiting for pod running 05/01/23 23:47:05.24
    May  1 23:47:05.240: INFO: Waiting up to 2m0s for pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" in namespace "var-expansion-2491" to be "running"
    May  1 23:47:05.343: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996": Phase="Pending", Reason="", readiness=false. Elapsed: 102.537004ms
    May  1 23:47:07.445: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996": Phase="Running", Reason="", readiness=true. Elapsed: 2.205520822s
    May  1 23:47:07.446: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" satisfied condition "running"
    STEP: creating a file in subpath 05/01/23 23:47:07.446
    May  1 23:47:07.548: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2491 PodName:var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:47:07.548: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:47:07.549: INFO: ExecWithOptions: Clientset creation
    May  1 23:47:07.549: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/var-expansion-2491/pods/var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 05/01/23 23:47:08.293
    May  1 23:47:08.396: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2491 PodName:var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:47:08.396: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:47:08.397: INFO: ExecWithOptions: Clientset creation
    May  1 23:47:08.397: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/var-expansion-2491/pods/var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 05/01/23 23:47:09.136
    May  1 23:47:09.848: INFO: Successfully updated pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996"
    STEP: waiting for annotated pod running 05/01/23 23:47:09.848
    May  1 23:47:09.848: INFO: Waiting up to 2m0s for pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" in namespace "var-expansion-2491" to be "running"
    May  1 23:47:09.950: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996": Phase="Running", Reason="", readiness=true. Elapsed: 102.633686ms
    May  1 23:47:09.950: INFO: Pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" satisfied condition "running"
    STEP: deleting the pod gracefully 05/01/23 23:47:09.95
    May  1 23:47:09.951: INFO: Deleting pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" in namespace "var-expansion-2491"
    May  1 23:47:10.056: INFO: Wait up to 5m0s for pod "var-expansion-b44706fc-3f97-49e9-bcbe-4c3e1e0ee996" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  1 23:47:42.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2491" for this suite. 05/01/23 23:47:42.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:47:42.571
May  1 23:47:42.571: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename endpointslice 05/01/23 23:47:42.572
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:42.881
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:43.085
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
May  1 23:47:43.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-687" for this suite. 05/01/23 23:47:44.033
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":187,"skipped":3573,"failed":0}
------------------------------
• [1.566 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:47:42.571
    May  1 23:47:42.571: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename endpointslice 05/01/23 23:47:42.572
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:42.881
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:43.085
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    May  1 23:47:43.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-687" for this suite. 05/01/23 23:47:44.033
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:47:44.139
May  1 23:47:44.139: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts 05/01/23 23:47:44.14
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:44.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:44.654
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
May  1 23:47:44.960: INFO: Got root ca configmap in namespace "svcaccounts-8706"
May  1 23:47:45.065: INFO: Deleted root ca configmap in namespace "svcaccounts-8706"
STEP: waiting for a new root ca configmap created 05/01/23 23:47:45.565
May  1 23:47:45.668: INFO: Recreated root ca configmap in namespace "svcaccounts-8706"
May  1 23:47:45.772: INFO: Updated root ca configmap in namespace "svcaccounts-8706"
STEP: waiting for the root ca configmap reconciled 05/01/23 23:47:46.273
May  1 23:47:46.376: INFO: Reconciled root ca configmap in namespace "svcaccounts-8706"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
May  1 23:47:46.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8706" for this suite. 05/01/23 23:47:46.48
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":188,"skipped":3588,"failed":0}
------------------------------
• [2.445 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:47:44.139
    May  1 23:47:44.139: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svcaccounts 05/01/23 23:47:44.14
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:44.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:44.654
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    May  1 23:47:44.960: INFO: Got root ca configmap in namespace "svcaccounts-8706"
    May  1 23:47:45.065: INFO: Deleted root ca configmap in namespace "svcaccounts-8706"
    STEP: waiting for a new root ca configmap created 05/01/23 23:47:45.565
    May  1 23:47:45.668: INFO: Recreated root ca configmap in namespace "svcaccounts-8706"
    May  1 23:47:45.772: INFO: Updated root ca configmap in namespace "svcaccounts-8706"
    STEP: waiting for the root ca configmap reconciled 05/01/23 23:47:46.273
    May  1 23:47:46.376: INFO: Reconciled root ca configmap in namespace "svcaccounts-8706"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    May  1 23:47:46.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8706" for this suite. 05/01/23 23:47:46.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:47:46.586
May  1 23:47:46.586: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred 05/01/23 23:47:46.588
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:46.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:47.099
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May  1 23:47:47.303: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  1 23:47:47.512: INFO: Waiting for terminating namespaces to be deleted...
May  1 23:47:47.615: INFO: 
Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
May  1 23:47:47.721: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.721: INFO: 	Container calico-node ready: true, restart count 0
May  1 23:47:47.721: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.721: INFO: 	Container coredns ready: true, restart count 0
May  1 23:47:47.721: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.721: INFO: 	Container autoscaler ready: true, restart count 0
May  1 23:47:47.721: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
May  1 23:47:47.721: INFO: 	Container csi-attacher ready: true, restart count 0
May  1 23:47:47.721: INFO: 	Container csi-provisioner ready: true, restart count 0
May  1 23:47:47.721: INFO: 	Container csi-resizer ready: true, restart count 0
May  1 23:47:47.721: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 23:47:47.721: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 23:47:47.721: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
May  1 23:47:47.721: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 23:47:47.721: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 23:47:47.721: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 23:47:47.721: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.721: INFO: 	Container kube-proxy ready: true, restart count 0
May  1 23:47:47.721: INFO: 
Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
May  1 23:47:47.826: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.826: INFO: 	Container calico-node ready: true, restart count 0
May  1 23:47:47.826: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
May  1 23:47:47.826: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 23:47:47.826: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 23:47:47.826: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 23:47:47.826: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.826: INFO: 	Container kube-proxy ready: true, restart count 0
May  1 23:47:47.826: INFO: 
Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
May  1 23:47:47.932: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.932: INFO: 	Container calico-node ready: true, restart count 0
May  1 23:47:47.932: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
May  1 23:47:47.932: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 23:47:47.932: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 23:47:47.932: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 23:47:47.932: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
May  1 23:47:47.932: INFO: 	Container kube-proxy ready: true, restart count 0
May  1 23:47:47.932: INFO: 
Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
May  1 23:47:48.038: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
May  1 23:47:48.038: INFO: 	Container calico-node ready: true, restart count 0
May  1 23:47:48.038: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
May  1 23:47:48.038: INFO: 	Container coredns ready: true, restart count 0
May  1 23:47:48.038: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
May  1 23:47:48.038: INFO: 	Container csi-attacher ready: true, restart count 0
May  1 23:47:48.039: INFO: 	Container csi-provisioner ready: true, restart count 0
May  1 23:47:48.039: INFO: 	Container csi-resizer ready: true, restart count 0
May  1 23:47:48.039: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 23:47:48.039: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 23:47:48.039: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
May  1 23:47:48.039: INFO: 	Container ebs-plugin ready: true, restart count 0
May  1 23:47:48.039: INFO: 	Container liveness-probe ready: true, restart count 0
May  1 23:47:48.039: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  1 23:47:48.039: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
May  1 23:47:48.039: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 05/01/23 23:47:48.039
May  1 23:47:48.144: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2735" to be "running"
May  1 23:47:48.247: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 102.551227ms
May  1 23:47:50.350: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.205906969s
May  1 23:47:50.350: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 05/01/23 23:47:50.453
STEP: Trying to apply a random label on the found node. 05/01/23 23:47:50.567
STEP: verifying the node has the label kubernetes.io/e2e-b61a2c2a-74d3-47d0-9a6a-0c998c63b7e1 42 05/01/23 23:47:50.677
STEP: Trying to relaunch the pod, now with labels. 05/01/23 23:47:50.78
May  1 23:47:50.886: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-2735" to be "not pending"
May  1 23:47:50.988: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 102.488314ms
May  1 23:47:53.091: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.205683761s
May  1 23:47:53.091: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-b61a2c2a-74d3-47d0-9a6a-0c998c63b7e1 off the node i-0627b78ff917cf2ae 05/01/23 23:47:53.194
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b61a2c2a-74d3-47d0-9a6a-0c998c63b7e1 05/01/23 23:47:53.406
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
May  1 23:47:53.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2735" for this suite. 05/01/23 23:47:53.614
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":189,"skipped":3614,"failed":0}
------------------------------
• [SLOW TEST] [7.134 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:47:46.586
    May  1 23:47:46.586: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-pred 05/01/23 23:47:46.588
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:46.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:47.099
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    May  1 23:47:47.303: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    May  1 23:47:47.512: INFO: Waiting for terminating namespaces to be deleted...
    May  1 23:47:47.615: INFO: 
    Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
    May  1 23:47:47.721: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.721: INFO: 	Container calico-node ready: true, restart count 0
    May  1 23:47:47.721: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.721: INFO: 	Container coredns ready: true, restart count 0
    May  1 23:47:47.721: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.721: INFO: 	Container autoscaler ready: true, restart count 0
    May  1 23:47:47.721: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
    May  1 23:47:47.721: INFO: 	Container csi-attacher ready: true, restart count 0
    May  1 23:47:47.721: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  1 23:47:47.721: INFO: 	Container csi-resizer ready: true, restart count 0
    May  1 23:47:47.721: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 23:47:47.721: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 23:47:47.721: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
    May  1 23:47:47.721: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 23:47:47.721: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 23:47:47.721: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 23:47:47.721: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.721: INFO: 	Container kube-proxy ready: true, restart count 0
    May  1 23:47:47.721: INFO: 
    Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
    May  1 23:47:47.826: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.826: INFO: 	Container calico-node ready: true, restart count 0
    May  1 23:47:47.826: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
    May  1 23:47:47.826: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 23:47:47.826: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 23:47:47.826: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 23:47:47.826: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.826: INFO: 	Container kube-proxy ready: true, restart count 0
    May  1 23:47:47.826: INFO: 
    Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
    May  1 23:47:47.932: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.932: INFO: 	Container calico-node ready: true, restart count 0
    May  1 23:47:47.932: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
    May  1 23:47:47.932: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 23:47:47.932: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 23:47:47.932: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 23:47:47.932: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
    May  1 23:47:47.932: INFO: 	Container kube-proxy ready: true, restart count 0
    May  1 23:47:47.932: INFO: 
    Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
    May  1 23:47:48.038: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
    May  1 23:47:48.038: INFO: 	Container calico-node ready: true, restart count 0
    May  1 23:47:48.038: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
    May  1 23:47:48.038: INFO: 	Container coredns ready: true, restart count 0
    May  1 23:47:48.038: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
    May  1 23:47:48.038: INFO: 	Container csi-attacher ready: true, restart count 0
    May  1 23:47:48.039: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  1 23:47:48.039: INFO: 	Container csi-resizer ready: true, restart count 0
    May  1 23:47:48.039: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 23:47:48.039: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 23:47:48.039: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
    May  1 23:47:48.039: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  1 23:47:48.039: INFO: 	Container liveness-probe ready: true, restart count 0
    May  1 23:47:48.039: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  1 23:47:48.039: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
    May  1 23:47:48.039: INFO: 	Container kube-proxy ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 05/01/23 23:47:48.039
    May  1 23:47:48.144: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2735" to be "running"
    May  1 23:47:48.247: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 102.551227ms
    May  1 23:47:50.350: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.205906969s
    May  1 23:47:50.350: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 05/01/23 23:47:50.453
    STEP: Trying to apply a random label on the found node. 05/01/23 23:47:50.567
    STEP: verifying the node has the label kubernetes.io/e2e-b61a2c2a-74d3-47d0-9a6a-0c998c63b7e1 42 05/01/23 23:47:50.677
    STEP: Trying to relaunch the pod, now with labels. 05/01/23 23:47:50.78
    May  1 23:47:50.886: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-2735" to be "not pending"
    May  1 23:47:50.988: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 102.488314ms
    May  1 23:47:53.091: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.205683761s
    May  1 23:47:53.091: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-b61a2c2a-74d3-47d0-9a6a-0c998c63b7e1 off the node i-0627b78ff917cf2ae 05/01/23 23:47:53.194
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-b61a2c2a-74d3-47d0-9a6a-0c998c63b7e1 05/01/23 23:47:53.406
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:47:53.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2735" for this suite. 05/01/23 23:47:53.614
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:47:53.72
May  1 23:47:53.721: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset 05/01/23 23:47:53.722
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:54.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:54.235
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 05/01/23 23:47:54.542
STEP: Verify that the required pods have come up. 05/01/23 23:47:54.647
May  1 23:47:54.750: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 05/01/23 23:47:54.75
May  1 23:47:54.750: INFO: Waiting up to 5m0s for pod "test-rs-gp6pl" in namespace "replicaset-8741" to be "running"
May  1 23:47:54.853: INFO: Pod "test-rs-gp6pl": Phase="Pending", Reason="", readiness=false. Elapsed: 102.669346ms
May  1 23:47:56.955: INFO: Pod "test-rs-gp6pl": Phase="Running", Reason="", readiness=true. Elapsed: 2.205494516s
May  1 23:47:56.955: INFO: Pod "test-rs-gp6pl" satisfied condition "running"
STEP: Getting /status 05/01/23 23:47:56.955
May  1 23:47:57.059: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 05/01/23 23:47:57.059
May  1 23:47:57.265: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 05/01/23 23:47:57.266
May  1 23:47:57.368: INFO: Observed &ReplicaSet event: ADDED
May  1 23:47:57.369: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.369: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.369: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.369: INFO: Found replicaset test-rs in namespace replicaset-8741 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
May  1 23:47:57.369: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 05/01/23 23:47:57.369
May  1 23:47:57.369: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May  1 23:47:57.474: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 05/01/23 23:47:57.474
May  1 23:47:57.577: INFO: Observed &ReplicaSet event: ADDED
May  1 23:47:57.577: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.577: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.577: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.578: INFO: Observed replicaset test-rs in namespace replicaset-8741 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  1 23:47:57.578: INFO: Observed &ReplicaSet event: MODIFIED
May  1 23:47:57.578: INFO: Found replicaset test-rs in namespace replicaset-8741 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
May  1 23:47:57.578: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
May  1 23:47:57.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8741" for this suite. 05/01/23 23:47:57.681
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":190,"skipped":3614,"failed":0}
------------------------------
• [4.066 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:47:53.72
    May  1 23:47:53.721: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replicaset 05/01/23 23:47:53.722
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:54.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:54.235
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 05/01/23 23:47:54.542
    STEP: Verify that the required pods have come up. 05/01/23 23:47:54.647
    May  1 23:47:54.750: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 05/01/23 23:47:54.75
    May  1 23:47:54.750: INFO: Waiting up to 5m0s for pod "test-rs-gp6pl" in namespace "replicaset-8741" to be "running"
    May  1 23:47:54.853: INFO: Pod "test-rs-gp6pl": Phase="Pending", Reason="", readiness=false. Elapsed: 102.669346ms
    May  1 23:47:56.955: INFO: Pod "test-rs-gp6pl": Phase="Running", Reason="", readiness=true. Elapsed: 2.205494516s
    May  1 23:47:56.955: INFO: Pod "test-rs-gp6pl" satisfied condition "running"
    STEP: Getting /status 05/01/23 23:47:56.955
    May  1 23:47:57.059: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 05/01/23 23:47:57.059
    May  1 23:47:57.265: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 05/01/23 23:47:57.266
    May  1 23:47:57.368: INFO: Observed &ReplicaSet event: ADDED
    May  1 23:47:57.369: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.369: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.369: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.369: INFO: Found replicaset test-rs in namespace replicaset-8741 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    May  1 23:47:57.369: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 05/01/23 23:47:57.369
    May  1 23:47:57.369: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    May  1 23:47:57.474: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 05/01/23 23:47:57.474
    May  1 23:47:57.577: INFO: Observed &ReplicaSet event: ADDED
    May  1 23:47:57.577: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.577: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.577: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.578: INFO: Observed replicaset test-rs in namespace replicaset-8741 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    May  1 23:47:57.578: INFO: Observed &ReplicaSet event: MODIFIED
    May  1 23:47:57.578: INFO: Found replicaset test-rs in namespace replicaset-8741 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    May  1 23:47:57.578: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    May  1 23:47:57.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8741" for this suite. 05/01/23 23:47:57.681
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:47:57.789
May  1 23:47:57.789: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:47:57.79
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:58.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:58.302
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 05/01/23 23:47:58.611
May  1 23:47:58.611: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773" in namespace "kubelet-test-9749" to be "completed"
May  1 23:47:58.713: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773": Phase="Pending", Reason="", readiness=false. Elapsed: 102.420406ms
May  1 23:48:00.816: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773": Phase="Running", Reason="", readiness=false. Elapsed: 2.205361979s
May  1 23:48:02.816: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20504256s
May  1 23:48:02.816: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
May  1 23:48:02.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9749" for this suite. 05/01/23 23:48:03.036
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":191,"skipped":3648,"failed":0}
------------------------------
• [SLOW TEST] [5.351 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:47:57.789
    May  1 23:47:57.789: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:47:57.79
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:47:58.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:47:58.302
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 05/01/23 23:47:58.611
    May  1 23:47:58.611: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773" in namespace "kubelet-test-9749" to be "completed"
    May  1 23:47:58.713: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773": Phase="Pending", Reason="", readiness=false. Elapsed: 102.420406ms
    May  1 23:48:00.816: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773": Phase="Running", Reason="", readiness=false. Elapsed: 2.205361979s
    May  1 23:48:02.816: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20504256s
    May  1 23:48:02.816: INFO: Pod "agnhost-host-aliases8e7102be-168c-4f75-8568-37659b4c9773" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    May  1 23:48:02.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9749" for this suite. 05/01/23 23:48:03.036
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:03.141
May  1 23:48:03.141: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 23:48:03.142
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:03.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:03.655
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 05/01/23 23:48:03.858
May  1 23:48:03.858: INFO: namespace kubectl-8081
May  1 23:48:03.858: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 create -f -'
May  1 23:48:05.162: INFO: stderr: ""
May  1 23:48:05.162: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 05/01/23 23:48:05.162
May  1 23:48:06.265: INFO: Selector matched 1 pods for map[app:agnhost]
May  1 23:48:06.265: INFO: Found 0 / 1
May  1 23:48:07.266: INFO: Selector matched 1 pods for map[app:agnhost]
May  1 23:48:07.266: INFO: Found 1 / 1
May  1 23:48:07.266: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  1 23:48:07.368: INFO: Selector matched 1 pods for map[app:agnhost]
May  1 23:48:07.368: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  1 23:48:07.368: INFO: wait on agnhost-primary startup in kubectl-8081 
May  1 23:48:07.368: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 logs agnhost-primary-76n8b agnhost-primary'
May  1 23:48:07.915: INFO: stderr: ""
May  1 23:48:07.915: INFO: stdout: "Paused\n"
STEP: exposing RC 05/01/23 23:48:07.915
May  1 23:48:07.915: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
May  1 23:48:08.463: INFO: stderr: ""
May  1 23:48:08.463: INFO: stdout: "service/rm2 exposed\n"
May  1 23:48:08.566: INFO: Service rm2 in namespace kubectl-8081 found.
STEP: exposing service 05/01/23 23:48:10.772
May  1 23:48:10.772: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
May  1 23:48:11.315: INFO: stderr: ""
May  1 23:48:11.315: INFO: stdout: "service/rm3 exposed\n"
May  1 23:48:11.418: INFO: Service rm3 in namespace kubectl-8081 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 23:48:13.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8081" for this suite. 05/01/23 23:48:13.73
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":192,"skipped":3652,"failed":0}
------------------------------
• [SLOW TEST] [10.793 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:03.141
    May  1 23:48:03.141: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 23:48:03.142
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:03.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:03.655
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 05/01/23 23:48:03.858
    May  1 23:48:03.858: INFO: namespace kubectl-8081
    May  1 23:48:03.858: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 create -f -'
    May  1 23:48:05.162: INFO: stderr: ""
    May  1 23:48:05.162: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 05/01/23 23:48:05.162
    May  1 23:48:06.265: INFO: Selector matched 1 pods for map[app:agnhost]
    May  1 23:48:06.265: INFO: Found 0 / 1
    May  1 23:48:07.266: INFO: Selector matched 1 pods for map[app:agnhost]
    May  1 23:48:07.266: INFO: Found 1 / 1
    May  1 23:48:07.266: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    May  1 23:48:07.368: INFO: Selector matched 1 pods for map[app:agnhost]
    May  1 23:48:07.368: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    May  1 23:48:07.368: INFO: wait on agnhost-primary startup in kubectl-8081 
    May  1 23:48:07.368: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 logs agnhost-primary-76n8b agnhost-primary'
    May  1 23:48:07.915: INFO: stderr: ""
    May  1 23:48:07.915: INFO: stdout: "Paused\n"
    STEP: exposing RC 05/01/23 23:48:07.915
    May  1 23:48:07.915: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    May  1 23:48:08.463: INFO: stderr: ""
    May  1 23:48:08.463: INFO: stdout: "service/rm2 exposed\n"
    May  1 23:48:08.566: INFO: Service rm2 in namespace kubectl-8081 found.
    STEP: exposing service 05/01/23 23:48:10.772
    May  1 23:48:10.772: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8081 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    May  1 23:48:11.315: INFO: stderr: ""
    May  1 23:48:11.315: INFO: stdout: "service/rm3 exposed\n"
    May  1 23:48:11.418: INFO: Service rm3 in namespace kubectl-8081 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 23:48:13.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8081" for this suite. 05/01/23 23:48:13.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:13.935
May  1 23:48:13.935: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/01/23 23:48:13.936
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:14.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:14.451
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
May  1 23:48:14.761: INFO: Waiting up to 5m0s for pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7" in namespace "container-probe-8012" to be "running and ready"
May  1 23:48:14.863: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Pending", Reason="", readiness=false. Elapsed: 102.644481ms
May  1 23:48:14.863: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:48:16.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 2.205910833s
May  1 23:48:16.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:18.971: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 4.209892886s
May  1 23:48:18.971: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:20.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 6.206397833s
May  1 23:48:20.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:22.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 8.206529847s
May  1 23:48:22.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:24.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 10.205850885s
May  1 23:48:24.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:26.966: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 12.205571825s
May  1 23:48:26.966: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:28.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 14.205845064s
May  1 23:48:28.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:30.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 16.205978619s
May  1 23:48:30.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:32.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 18.205960184s
May  1 23:48:32.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:34.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 20.206490172s
May  1 23:48:34.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
May  1 23:48:36.966: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=true. Elapsed: 22.205779408s
May  1 23:48:36.966: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = true)
May  1 23:48:36.966: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7" satisfied condition "running and ready"
May  1 23:48:37.069: INFO: Container started at 2023-05-01 23:48:15 +0000 UTC, pod became ready at 2023-05-01 23:48:35 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  1 23:48:37.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8012" for this suite. 05/01/23 23:48:37.173
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":193,"skipped":3678,"failed":0}
------------------------------
• [SLOW TEST] [23.442 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:13.935
    May  1 23:48:13.935: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/01/23 23:48:13.936
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:14.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:14.451
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    May  1 23:48:14.761: INFO: Waiting up to 5m0s for pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7" in namespace "container-probe-8012" to be "running and ready"
    May  1 23:48:14.863: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Pending", Reason="", readiness=false. Elapsed: 102.644481ms
    May  1 23:48:14.863: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:48:16.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 2.205910833s
    May  1 23:48:16.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:18.971: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 4.209892886s
    May  1 23:48:18.971: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:20.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 6.206397833s
    May  1 23:48:20.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:22.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 8.206529847s
    May  1 23:48:22.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:24.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 10.205850885s
    May  1 23:48:24.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:26.966: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 12.205571825s
    May  1 23:48:26.966: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:28.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 14.205845064s
    May  1 23:48:28.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:30.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 16.205978619s
    May  1 23:48:30.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:32.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 18.205960184s
    May  1 23:48:32.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:34.967: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=false. Elapsed: 20.206490172s
    May  1 23:48:34.967: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = false)
    May  1 23:48:36.966: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7": Phase="Running", Reason="", readiness=true. Elapsed: 22.205779408s
    May  1 23:48:36.966: INFO: The phase of Pod test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7 is Running (Ready = true)
    May  1 23:48:36.966: INFO: Pod "test-webserver-7bd7e88a-27a5-4335-9e34-5b39af0f6ef7" satisfied condition "running and ready"
    May  1 23:48:37.069: INFO: Container started at 2023-05-01 23:48:15 +0000 UTC, pod became ready at 2023-05-01 23:48:35 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  1 23:48:37.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8012" for this suite. 05/01/23 23:48:37.173
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:37.378
May  1 23:48:37.378: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:48:37.379
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:37.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:37.893
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:48:38.097
May  1 23:48:38.205: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5" in namespace "downward-api-501" to be "Succeeded or Failed"
May  1 23:48:38.307: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5": Phase="Pending", Reason="", readiness=false. Elapsed: 102.522037ms
May  1 23:48:40.411: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206059352s
May  1 23:48:42.411: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206001885s
STEP: Saw pod success 05/01/23 23:48:42.411
May  1 23:48:42.411: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5" satisfied condition "Succeeded or Failed"
May  1 23:48:42.513: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5 container client-container: <nil>
STEP: delete the pod 05/01/23 23:48:42.619
May  1 23:48:42.729: INFO: Waiting for pod downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5 to disappear
May  1 23:48:42.832: INFO: Pod downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:48:42.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-501" for this suite. 05/01/23 23:48:42.936
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":194,"skipped":3681,"failed":0}
------------------------------
• [SLOW TEST] [5.667 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:37.378
    May  1 23:48:37.378: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:48:37.379
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:37.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:37.893
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:48:38.097
    May  1 23:48:38.205: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5" in namespace "downward-api-501" to be "Succeeded or Failed"
    May  1 23:48:38.307: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5": Phase="Pending", Reason="", readiness=false. Elapsed: 102.522037ms
    May  1 23:48:40.411: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206059352s
    May  1 23:48:42.411: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206001885s
    STEP: Saw pod success 05/01/23 23:48:42.411
    May  1 23:48:42.411: INFO: Pod "downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5" satisfied condition "Succeeded or Failed"
    May  1 23:48:42.513: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:48:42.619
    May  1 23:48:42.729: INFO: Waiting for pod downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5 to disappear
    May  1 23:48:42.832: INFO: Pod downwardapi-volume-ccfeb735-5c3a-4842-9993-bb932db441e5 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:48:42.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-501" for this suite. 05/01/23 23:48:42.936
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:43.047
May  1 23:48:43.047: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job 05/01/23 23:48:43.049
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:43.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:43.562
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 05/01/23 23:48:43.765
STEP: Ensuring active pods == parallelism 05/01/23 23:48:43.87
STEP: Orphaning one of the Job's Pods 05/01/23 23:48:45.975
May  1 23:48:46.790: INFO: Successfully updated pod "adopt-release-lrqhm"
STEP: Checking that the Job readopts the Pod 05/01/23 23:48:46.79
May  1 23:48:46.790: INFO: Waiting up to 15m0s for pod "adopt-release-lrqhm" in namespace "job-6217" to be "adopted"
May  1 23:48:46.893: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 103.11584ms
May  1 23:48:48.997: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 2.206445717s
May  1 23:48:48.997: INFO: Pod "adopt-release-lrqhm" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 05/01/23 23:48:48.997
May  1 23:48:49.707: INFO: Successfully updated pod "adopt-release-lrqhm"
STEP: Checking that the Job releases the Pod 05/01/23 23:48:49.707
May  1 23:48:49.707: INFO: Waiting up to 15m0s for pod "adopt-release-lrqhm" in namespace "job-6217" to be "released"
May  1 23:48:49.810: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 102.617803ms
May  1 23:48:51.915: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 2.207463551s
May  1 23:48:51.915: INFO: Pod "adopt-release-lrqhm" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
May  1 23:48:51.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6217" for this suite. 05/01/23 23:48:52.019
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":195,"skipped":3707,"failed":0}
------------------------------
• [SLOW TEST] [9.076 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:43.047
    May  1 23:48:43.047: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename job 05/01/23 23:48:43.049
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:43.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:43.562
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 05/01/23 23:48:43.765
    STEP: Ensuring active pods == parallelism 05/01/23 23:48:43.87
    STEP: Orphaning one of the Job's Pods 05/01/23 23:48:45.975
    May  1 23:48:46.790: INFO: Successfully updated pod "adopt-release-lrqhm"
    STEP: Checking that the Job readopts the Pod 05/01/23 23:48:46.79
    May  1 23:48:46.790: INFO: Waiting up to 15m0s for pod "adopt-release-lrqhm" in namespace "job-6217" to be "adopted"
    May  1 23:48:46.893: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 103.11584ms
    May  1 23:48:48.997: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 2.206445717s
    May  1 23:48:48.997: INFO: Pod "adopt-release-lrqhm" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 05/01/23 23:48:48.997
    May  1 23:48:49.707: INFO: Successfully updated pod "adopt-release-lrqhm"
    STEP: Checking that the Job releases the Pod 05/01/23 23:48:49.707
    May  1 23:48:49.707: INFO: Waiting up to 15m0s for pod "adopt-release-lrqhm" in namespace "job-6217" to be "released"
    May  1 23:48:49.810: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 102.617803ms
    May  1 23:48:51.915: INFO: Pod "adopt-release-lrqhm": Phase="Running", Reason="", readiness=true. Elapsed: 2.207463551s
    May  1 23:48:51.915: INFO: Pod "adopt-release-lrqhm" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    May  1 23:48:51.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6217" for this suite. 05/01/23 23:48:52.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:52.126
May  1 23:48:52.126: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 23:48:52.127
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:52.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:52.641
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
May  1 23:48:52.845: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May  1 23:48:53.053: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 05/01/23 23:48:53.053
May  1 23:48:53.053: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-6svbs" in namespace "deployment-2251" to be "running"
May  1 23:48:53.155: INFO: Pod "test-rolling-update-controller-6svbs": Phase="Pending", Reason="", readiness=false. Elapsed: 102.549903ms
May  1 23:48:55.259: INFO: Pod "test-rolling-update-controller-6svbs": Phase="Running", Reason="", readiness=true. Elapsed: 2.206160799s
May  1 23:48:55.259: INFO: Pod "test-rolling-update-controller-6svbs" satisfied condition "running"
May  1 23:48:55.259: INFO: Creating deployment "test-rolling-update-deployment"
May  1 23:48:55.363: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May  1 23:48:55.571: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May  1 23:48:55.673: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:48:57.778: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 23:48:58.086: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2251  6d4fce6c-8472-428b-80dc-38493ed3ee57 24676 1 2023-05-01 23:48:55 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007388fe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 23:48:55 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-05-01 23:48:56 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  1 23:48:58.190: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-2251  a8ba5714-9aff-4fde-8c31-a212f156c3c3 24666 1 2023-05-01 23:48:55 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6d4fce6c-8472-428b-80dc-38493ed3ee57 0xc0073894d7 0xc0073894d8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d4fce6c-8472-428b-80dc-38493ed3ee57\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007389588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  1 23:48:58.190: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May  1 23:48:58.190: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2251  b1cb6613-859e-4509-8a73-648fbcfea0f7 24674 2 2023-05-01 23:48:52 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6d4fce6c-8472-428b-80dc-38493ed3ee57 0xc0073893a7 0xc0073893a8}] [] [{e2e.test Update apps/v1 2023-05-01 23:48:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d4fce6c-8472-428b-80dc-38493ed3ee57\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc007389468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  1 23:48:58.293: INFO: Pod "test-rolling-update-deployment-78f575d8ff-flqt2" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-flqt2 test-rolling-update-deployment-78f575d8ff- deployment-2251  e636995e-241f-4620-ba84-23a5c9889cd1 24665 0 2023-05-01 23:48:55 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:6eecc622fdfa9915e55bda120fe5dd12d3ef0e75928f4492a2e35ee27df1f4b0 cni.projectcalico.org/podIP:100.96.36.35/32 cni.projectcalico.org/podIPs:100.96.36.35/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff a8ba5714-9aff-4fde-8c31-a212f156c3c3 0xc003f2b527 0xc003f2b528}] [] [{calico Update v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a8ba5714-9aff-4fde-8c31-a212f156c3c3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.35\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xlvpj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xlvpj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.35,StartTime:2023-05-01 23:48:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 23:48:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://034a0c6b5d4675241ec61b6dca452a6dd8b206ead96af598b5341a116d4c06b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 23:48:58.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2251" for this suite. 05/01/23 23:48:58.397
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":196,"skipped":3733,"failed":0}
------------------------------
• [SLOW TEST] [6.474 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:52.126
    May  1 23:48:52.126: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 23:48:52.127
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:52.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:52.641
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    May  1 23:48:52.845: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    May  1 23:48:53.053: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 05/01/23 23:48:53.053
    May  1 23:48:53.053: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-6svbs" in namespace "deployment-2251" to be "running"
    May  1 23:48:53.155: INFO: Pod "test-rolling-update-controller-6svbs": Phase="Pending", Reason="", readiness=false. Elapsed: 102.549903ms
    May  1 23:48:55.259: INFO: Pod "test-rolling-update-controller-6svbs": Phase="Running", Reason="", readiness=true. Elapsed: 2.206160799s
    May  1 23:48:55.259: INFO: Pod "test-rolling-update-controller-6svbs" satisfied condition "running"
    May  1 23:48:55.259: INFO: Creating deployment "test-rolling-update-deployment"
    May  1 23:48:55.363: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    May  1 23:48:55.571: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    May  1 23:48:55.673: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 48, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:48:57.778: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 23:48:58.086: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2251  6d4fce6c-8472-428b-80dc-38493ed3ee57 24676 1 2023-05-01 23:48:55 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007388fe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-05-01 23:48:55 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-05-01 23:48:56 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    May  1 23:48:58.190: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-2251  a8ba5714-9aff-4fde-8c31-a212f156c3c3 24666 1 2023-05-01 23:48:55 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6d4fce6c-8472-428b-80dc-38493ed3ee57 0xc0073894d7 0xc0073894d8}] [] [{kube-controller-manager Update apps/v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d4fce6c-8472-428b-80dc-38493ed3ee57\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc007389588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    May  1 23:48:58.190: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    May  1 23:48:58.190: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2251  b1cb6613-859e-4509-8a73-648fbcfea0f7 24674 2 2023-05-01 23:48:52 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6d4fce6c-8472-428b-80dc-38493ed3ee57 0xc0073893a7 0xc0073893a8}] [] [{e2e.test Update apps/v1 2023-05-01 23:48:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d4fce6c-8472-428b-80dc-38493ed3ee57\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc007389468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    May  1 23:48:58.293: INFO: Pod "test-rolling-update-deployment-78f575d8ff-flqt2" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-flqt2 test-rolling-update-deployment-78f575d8ff- deployment-2251  e636995e-241f-4620-ba84-23a5c9889cd1 24665 0 2023-05-01 23:48:55 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:6eecc622fdfa9915e55bda120fe5dd12d3ef0e75928f4492a2e35ee27df1f4b0 cni.projectcalico.org/podIP:100.96.36.35/32 cni.projectcalico.org/podIPs:100.96.36.35/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff a8ba5714-9aff-4fde-8c31-a212f156c3c3 0xc003f2b527 0xc003f2b528}] [] [{calico Update v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-01 23:48:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a8ba5714-9aff-4fde-8c31-a212f156c3c3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-01 23:48:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.35\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xlvpj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xlvpj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-01 23:48:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.35,StartTime:2023-05-01 23:48:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-01 23:48:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://034a0c6b5d4675241ec61b6dca452a6dd8b206ead96af598b5341a116d4c06b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 23:48:58.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2251" for this suite. 05/01/23 23:48:58.397
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:58.601
May  1 23:48:58.601: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:48:58.602
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:58.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:59.115
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
May  1 23:48:59.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-399" for this suite. 05/01/23 23:48:59.634
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":197,"skipped":3736,"failed":0}
------------------------------
• [1.137 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:58.601
    May  1 23:48:58.601: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:48:58.602
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:48:58.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:48:59.115
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    May  1 23:48:59.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-399" for this suite. 05/01/23 23:48:59.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:48:59.739
May  1 23:48:59.739: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:48:59.74
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:00.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:00.254
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:49:00.668
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:49:01.153
STEP: Deploying the webhook pod 05/01/23 23:49:01.26
STEP: Wait for the deployment to be ready 05/01/23 23:49:01.47
May  1 23:49:01.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:49:03.883
STEP: Verifying the service has paired with the endpoint 05/01/23 23:49:03.991
May  1 23:49:04.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 05/01/23 23:49:05.094
STEP: Creating a configMap that does not comply to the validation webhook rules 05/01/23 23:49:05.307
STEP: Updating a validating webhook configuration's rules to not include the create operation 05/01/23 23:49:05.421
STEP: Creating a configMap that does not comply to the validation webhook rules 05/01/23 23:49:05.632
STEP: Patching a validating webhook configuration's rules to include the create operation 05/01/23 23:49:05.84
STEP: Creating a configMap that does not comply to the validation webhook rules 05/01/23 23:49:05.947
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:49:06.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9537" for this suite. 05/01/23 23:49:06.258
STEP: Destroying namespace "webhook-9537-markers" for this suite. 05/01/23 23:49:06.364
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":198,"skipped":3743,"failed":0}
------------------------------
• [SLOW TEST] [7.170 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:48:59.739
    May  1 23:48:59.739: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:48:59.74
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:00.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:00.254
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:49:00.668
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:49:01.153
    STEP: Deploying the webhook pod 05/01/23 23:49:01.26
    STEP: Wait for the deployment to be ready 05/01/23 23:49:01.47
    May  1 23:49:01.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:49:03.883
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:49:03.991
    May  1 23:49:04.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 05/01/23 23:49:05.094
    STEP: Creating a configMap that does not comply to the validation webhook rules 05/01/23 23:49:05.307
    STEP: Updating a validating webhook configuration's rules to not include the create operation 05/01/23 23:49:05.421
    STEP: Creating a configMap that does not comply to the validation webhook rules 05/01/23 23:49:05.632
    STEP: Patching a validating webhook configuration's rules to include the create operation 05/01/23 23:49:05.84
    STEP: Creating a configMap that does not comply to the validation webhook rules 05/01/23 23:49:05.947
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:49:06.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9537" for this suite. 05/01/23 23:49:06.258
    STEP: Destroying namespace "webhook-9537-markers" for this suite. 05/01/23 23:49:06.364
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:06.91
May  1 23:49:06.910: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:49:06.912
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:07.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:07.426
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
May  1 23:49:11.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7165" for this suite. 05/01/23 23:49:12.046
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":199,"skipped":3754,"failed":0}
------------------------------
• [SLOW TEST] [5.341 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:06.91
    May  1 23:49:06.910: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubelet-test 05/01/23 23:49:06.912
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:07.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:07.426
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    May  1 23:49:11.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7165" for this suite. 05/01/23 23:49:12.046
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:12.252
May  1 23:49:12.252: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename podtemplate 05/01/23 23:49:12.253
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:12.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:12.766
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
May  1 23:49:13.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-173" for this suite. 05/01/23 23:49:13.8
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":200,"skipped":3770,"failed":0}
------------------------------
• [1.652 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:12.252
    May  1 23:49:12.252: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename podtemplate 05/01/23 23:49:12.253
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:12.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:12.766
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    May  1 23:49:13.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-173" for this suite. 05/01/23 23:49:13.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:13.906
May  1 23:49:13.906: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:49:13.907
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:14.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:14.42
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:49:14.835
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:49:15.304
STEP: Deploying the webhook pod 05/01/23 23:49:15.408
STEP: Wait for the deployment to be ready 05/01/23 23:49:15.622
May  1 23:49:15.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:49:18.035
STEP: Verifying the service has paired with the endpoint 05/01/23 23:49:18.143
May  1 23:49:19.143: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 05/01/23 23:49:19.246
STEP: create a configmap that should be updated by the webhook 05/01/23 23:49:19.46
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:49:19.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6676" for this suite. 05/01/23 23:49:19.786
STEP: Destroying namespace "webhook-6676-markers" for this suite. 05/01/23 23:49:19.89
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":201,"skipped":3792,"failed":0}
------------------------------
• [SLOW TEST] [6.521 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:13.906
    May  1 23:49:13.906: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:49:13.907
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:14.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:14.42
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:49:14.835
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:49:15.304
    STEP: Deploying the webhook pod 05/01/23 23:49:15.408
    STEP: Wait for the deployment to be ready 05/01/23 23:49:15.622
    May  1 23:49:15.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 49, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:49:18.035
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:49:18.143
    May  1 23:49:19.143: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 05/01/23 23:49:19.246
    STEP: create a configmap that should be updated by the webhook 05/01/23 23:49:19.46
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:49:19.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6676" for this suite. 05/01/23 23:49:19.786
    STEP: Destroying namespace "webhook-6676-markers" for this suite. 05/01/23 23:49:19.89
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:20.428
May  1 23:49:20.428: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 23:49:20.43
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:20.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:20.943
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-291819b5-8480-4b60-9628-274214b90bcf 05/01/23 23:49:21.147
STEP: Creating a pod to test consume secrets 05/01/23 23:49:21.251
May  1 23:49:21.359: INFO: Waiting up to 5m0s for pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825" in namespace "secrets-816" to be "Succeeded or Failed"
May  1 23:49:21.462: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825": Phase="Pending", Reason="", readiness=false. Elapsed: 102.634421ms
May  1 23:49:23.565: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206018868s
May  1 23:49:25.566: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206506925s
STEP: Saw pod success 05/01/23 23:49:25.566
May  1 23:49:25.566: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825" satisfied condition "Succeeded or Failed"
May  1 23:49:25.669: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825 container secret-env-test: <nil>
STEP: delete the pod 05/01/23 23:49:25.774
May  1 23:49:25.884: INFO: Waiting for pod pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825 to disappear
May  1 23:49:25.986: INFO: Pod pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
May  1 23:49:25.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-816" for this suite. 05/01/23 23:49:26.09
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":202,"skipped":3799,"failed":0}
------------------------------
• [SLOW TEST] [5.768 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:20.428
    May  1 23:49:20.428: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 23:49:20.43
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:20.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:20.943
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-291819b5-8480-4b60-9628-274214b90bcf 05/01/23 23:49:21.147
    STEP: Creating a pod to test consume secrets 05/01/23 23:49:21.251
    May  1 23:49:21.359: INFO: Waiting up to 5m0s for pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825" in namespace "secrets-816" to be "Succeeded or Failed"
    May  1 23:49:21.462: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825": Phase="Pending", Reason="", readiness=false. Elapsed: 102.634421ms
    May  1 23:49:23.565: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206018868s
    May  1 23:49:25.566: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.206506925s
    STEP: Saw pod success 05/01/23 23:49:25.566
    May  1 23:49:25.566: INFO: Pod "pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825" satisfied condition "Succeeded or Failed"
    May  1 23:49:25.669: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825 container secret-env-test: <nil>
    STEP: delete the pod 05/01/23 23:49:25.774
    May  1 23:49:25.884: INFO: Waiting for pod pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825 to disappear
    May  1 23:49:25.986: INFO: Pod pod-secrets-af6b6adb-8953-4d12-8d84-f46d75811825 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    May  1 23:49:25.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-816" for this suite. 05/01/23 23:49:26.09
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:26.196
May  1 23:49:26.196: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/01/23 23:49:26.198
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:26.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:26.71
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3460 05/01/23 23:49:26.914
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
May  1 23:49:27.224: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May  1 23:49:37.328: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 05/01/23 23:49:37.533
W0501 23:49:37.643506    6969 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
May  1 23:49:37.849: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  1 23:49:37.849: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
May  1 23:49:47.955: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  1 23:49:47.955: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 05/01/23 23:49:48.161
STEP: Delete all of the StatefulSets 05/01/23 23:49:48.264
STEP: Verify that StatefulSets have been deleted 05/01/23 23:49:48.37
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  1 23:49:48.472: INFO: Deleting all statefulset in ns statefulset-3460
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  1 23:49:48.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3460" for this suite. 05/01/23 23:49:48.882
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":203,"skipped":3802,"failed":0}
------------------------------
• [SLOW TEST] [22.790 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:26.196
    May  1 23:49:26.196: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/01/23 23:49:26.198
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:26.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:26.71
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3460 05/01/23 23:49:26.914
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    May  1 23:49:27.224: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    May  1 23:49:37.328: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 05/01/23 23:49:37.533
    W0501 23:49:37.643506    6969 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    May  1 23:49:37.849: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    May  1 23:49:37.849: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
    May  1 23:49:47.955: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    May  1 23:49:47.955: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 05/01/23 23:49:48.161
    STEP: Delete all of the StatefulSets 05/01/23 23:49:48.264
    STEP: Verify that StatefulSets have been deleted 05/01/23 23:49:48.37
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  1 23:49:48.472: INFO: Deleting all statefulset in ns statefulset-3460
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  1 23:49:48.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3460" for this suite. 05/01/23 23:49:48.882
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:48.989
May  1 23:49:48.989: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 23:49:48.99
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:49.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:49.503
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 05/01/23 23:49:49.707
May  1 23:49:49.813: INFO: Waiting up to 5m0s for pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a" in namespace "emptydir-753" to be "Succeeded or Failed"
May  1 23:49:49.915: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a": Phase="Pending", Reason="", readiness=false. Elapsed: 102.414865ms
May  1 23:49:52.028: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215363775s
May  1 23:49:54.021: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207891889s
STEP: Saw pod success 05/01/23 23:49:54.021
May  1 23:49:54.021: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a" satisfied condition "Succeeded or Failed"
May  1 23:49:54.124: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-e0e2abe0-0472-482c-bffa-432e5d6e935a container test-container: <nil>
STEP: delete the pod 05/01/23 23:49:54.229
May  1 23:49:54.339: INFO: Waiting for pod pod-e0e2abe0-0472-482c-bffa-432e5d6e935a to disappear
May  1 23:49:54.441: INFO: Pod pod-e0e2abe0-0472-482c-bffa-432e5d6e935a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 23:49:54.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-753" for this suite. 05/01/23 23:49:54.545
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":204,"skipped":3844,"failed":0}
------------------------------
• [SLOW TEST] [5.760 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:48.989
    May  1 23:49:48.989: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 23:49:48.99
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:49.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:49.503
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 05/01/23 23:49:49.707
    May  1 23:49:49.813: INFO: Waiting up to 5m0s for pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a" in namespace "emptydir-753" to be "Succeeded or Failed"
    May  1 23:49:49.915: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a": Phase="Pending", Reason="", readiness=false. Elapsed: 102.414865ms
    May  1 23:49:52.028: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215363775s
    May  1 23:49:54.021: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207891889s
    STEP: Saw pod success 05/01/23 23:49:54.021
    May  1 23:49:54.021: INFO: Pod "pod-e0e2abe0-0472-482c-bffa-432e5d6e935a" satisfied condition "Succeeded or Failed"
    May  1 23:49:54.124: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-e0e2abe0-0472-482c-bffa-432e5d6e935a container test-container: <nil>
    STEP: delete the pod 05/01/23 23:49:54.229
    May  1 23:49:54.339: INFO: Waiting for pod pod-e0e2abe0-0472-482c-bffa-432e5d6e935a to disappear
    May  1 23:49:54.441: INFO: Pod pod-e0e2abe0-0472-482c-bffa-432e5d6e935a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 23:49:54.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-753" for this suite. 05/01/23 23:49:54.545
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:49:54.752
May  1 23:49:54.752: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath 05/01/23 23:49:54.753
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:55.062
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:55.266
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 05/01/23 23:49:55.47
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-l8gs 05/01/23 23:49:55.683
STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:49:55.683
May  1 23:49:55.791: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l8gs" in namespace "subpath-393" to be "Succeeded or Failed"
May  1 23:49:55.894: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Pending", Reason="", readiness=false. Elapsed: 102.927612ms
May  1 23:49:57.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 2.206679775s
May  1 23:49:59.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 4.206923856s
May  1 23:50:01.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 6.20618495s
May  1 23:50:03.999: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 8.20790352s
May  1 23:50:05.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 10.206363796s
May  1 23:50:07.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 12.206340165s
May  1 23:50:09.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 14.206590876s
May  1 23:50:11.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 16.206202085s
May  1 23:50:13.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 18.20609306s
May  1 23:50:15.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 20.206299023s
May  1 23:50:17.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=false. Elapsed: 22.20603603s
May  1 23:50:19.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.206232447s
STEP: Saw pod success 05/01/23 23:50:19.998
May  1 23:50:19.998: INFO: Pod "pod-subpath-test-projected-l8gs" satisfied condition "Succeeded or Failed"
May  1 23:50:20.103: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-projected-l8gs container test-container-subpath-projected-l8gs: <nil>
STEP: delete the pod 05/01/23 23:50:20.208
May  1 23:50:20.318: INFO: Waiting for pod pod-subpath-test-projected-l8gs to disappear
May  1 23:50:20.421: INFO: Pod pod-subpath-test-projected-l8gs no longer exists
STEP: Deleting pod pod-subpath-test-projected-l8gs 05/01/23 23:50:20.421
May  1 23:50:20.421: INFO: Deleting pod "pod-subpath-test-projected-l8gs" in namespace "subpath-393"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
May  1 23:50:20.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-393" for this suite. 05/01/23 23:50:20.628
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":205,"skipped":3902,"failed":0}
------------------------------
• [SLOW TEST] [25.981 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:49:54.752
    May  1 23:49:54.752: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename subpath 05/01/23 23:49:54.753
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:49:55.062
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:49:55.266
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 05/01/23 23:49:55.47
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-l8gs 05/01/23 23:49:55.683
    STEP: Creating a pod to test atomic-volume-subpath 05/01/23 23:49:55.683
    May  1 23:49:55.791: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l8gs" in namespace "subpath-393" to be "Succeeded or Failed"
    May  1 23:49:55.894: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Pending", Reason="", readiness=false. Elapsed: 102.927612ms
    May  1 23:49:57.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 2.206679775s
    May  1 23:49:59.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 4.206923856s
    May  1 23:50:01.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 6.20618495s
    May  1 23:50:03.999: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 8.20790352s
    May  1 23:50:05.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 10.206363796s
    May  1 23:50:07.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 12.206340165s
    May  1 23:50:09.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 14.206590876s
    May  1 23:50:11.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 16.206202085s
    May  1 23:50:13.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 18.20609306s
    May  1 23:50:15.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=true. Elapsed: 20.206299023s
    May  1 23:50:17.997: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Running", Reason="", readiness=false. Elapsed: 22.20603603s
    May  1 23:50:19.998: INFO: Pod "pod-subpath-test-projected-l8gs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.206232447s
    STEP: Saw pod success 05/01/23 23:50:19.998
    May  1 23:50:19.998: INFO: Pod "pod-subpath-test-projected-l8gs" satisfied condition "Succeeded or Failed"
    May  1 23:50:20.103: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-subpath-test-projected-l8gs container test-container-subpath-projected-l8gs: <nil>
    STEP: delete the pod 05/01/23 23:50:20.208
    May  1 23:50:20.318: INFO: Waiting for pod pod-subpath-test-projected-l8gs to disappear
    May  1 23:50:20.421: INFO: Pod pod-subpath-test-projected-l8gs no longer exists
    STEP: Deleting pod pod-subpath-test-projected-l8gs 05/01/23 23:50:20.421
    May  1 23:50:20.421: INFO: Deleting pod "pod-subpath-test-projected-l8gs" in namespace "subpath-393"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    May  1 23:50:20.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-393" for this suite. 05/01/23 23:50:20.628
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:20.734
May  1 23:50:20.734: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/01/23 23:50:20.735
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:21.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:21.247
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 05/01/23 23:50:21.553
STEP: waiting for Deployment to be created 05/01/23 23:50:21.658
STEP: waiting for all Replicas to be Ready 05/01/23 23:50:21.76
May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.863: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.863: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:21.863: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
May  1 23:50:22.972: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment-static:true]
May  1 23:50:22.972: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment-static:true]
May  1 23:50:23.638: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 05/01/23 23:50:23.638
W0501 23:50:23.744625    6969 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
May  1 23:50:23.846: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 05/01/23 23:50:23.847
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:24.651: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:24.651: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:24.671: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
STEP: listing Deployments 05/01/23 23:50:24.671
May  1 23:50:24.774: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 05/01/23 23:50:24.774
May  1 23:50:24.985: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 05/01/23 23:50:24.985
May  1 23:50:25.191: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:25.191: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:25.191: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:25.192: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:25.192: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:25.985: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:26.653: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:26.698: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:26.709: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
May  1 23:50:27.996: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 05/01/23 23:50:28.016
STEP: fetching the DeploymentStatus 05/01/23 23:50:28.222
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3
May  1 23:50:28.428: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:28.428: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
May  1 23:50:28.428: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3
STEP: deleting the Deployment 05/01/23 23:50:28.428
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.735: INFO: observed event type MODIFIED
May  1 23:50:28.736: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  1 23:50:28.838: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  1 23:50:28.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1002" for this suite. 05/01/23 23:50:29.044
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":206,"skipped":3903,"failed":0}
------------------------------
• [SLOW TEST] [8.415 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:20.734
    May  1 23:50:20.734: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/01/23 23:50:20.735
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:21.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:21.247
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 05/01/23 23:50:21.553
    STEP: waiting for Deployment to be created 05/01/23 23:50:21.658
    STEP: waiting for all Replicas to be Ready 05/01/23 23:50:21.76
    May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.862: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.863: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.863: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:21.863: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    May  1 23:50:22.972: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    May  1 23:50:22.972: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    May  1 23:50:23.638: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 05/01/23 23:50:23.638
    W0501 23:50:23.744625    6969 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    May  1 23:50:23.846: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 05/01/23 23:50:23.847
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 0
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.949: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:23.950: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:24.651: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:24.651: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:24.671: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    STEP: listing Deployments 05/01/23 23:50:24.671
    May  1 23:50:24.774: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 05/01/23 23:50:24.774
    May  1 23:50:24.985: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 05/01/23 23:50:24.985
    May  1 23:50:25.191: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:25.191: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:25.191: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:25.192: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:25.192: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:25.985: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:26.653: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:26.698: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:26.709: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    May  1 23:50:27.996: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 05/01/23 23:50:28.016
    STEP: fetching the DeploymentStatus 05/01/23 23:50:28.222
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 1
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:28.427: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3
    May  1 23:50:28.428: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:28.428: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 2
    May  1 23:50:28.428: INFO: observed Deployment test-deployment in namespace deployment-1002 with ReadyReplicas 3
    STEP: deleting the Deployment 05/01/23 23:50:28.428
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.735: INFO: observed event type MODIFIED
    May  1 23:50:28.736: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  1 23:50:28.838: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  1 23:50:28.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1002" for this suite. 05/01/23 23:50:29.044
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:29.149
May  1 23:50:29.150: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename controllerrevisions 05/01/23 23:50:29.151
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:29.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:29.664
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-ltqd5-daemon-set" 05/01/23 23:50:30.484
STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:50:30.59
May  1 23:50:30.694: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:50:30.797: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 0
May  1 23:50:30.797: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  1 23:50:31.901: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:50:32.004: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 2
May  1 23:50:32.004: INFO: Node i-0627b78ff917cf2ae is running 0 daemon pod, expected 1
May  1 23:50:32.902: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:50:33.005: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 3
May  1 23:50:33.005: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
May  1 23:50:33.901: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:50:34.004: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 4
May  1 23:50:34.004: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset e2e-ltqd5-daemon-set
STEP: Confirm DaemonSet "e2e-ltqd5-daemon-set" successfully created with "daemonset-name=e2e-ltqd5-daemon-set" label 05/01/23 23:50:34.107
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-ltqd5-daemon-set" 05/01/23 23:50:34.312
May  1 23:50:34.415: INFO: Located ControllerRevision: "e2e-ltqd5-daemon-set-84d7656947"
STEP: Patching ControllerRevision "e2e-ltqd5-daemon-set-84d7656947" 05/01/23 23:50:34.518
May  1 23:50:34.623: INFO: e2e-ltqd5-daemon-set-84d7656947 has been patched
STEP: Create a new ControllerRevision 05/01/23 23:50:34.623
May  1 23:50:34.727: INFO: Created ControllerRevision: e2e-ltqd5-daemon-set-6b85784875
STEP: Confirm that there are two ControllerRevisions 05/01/23 23:50:34.727
May  1 23:50:34.727: INFO: Requesting list of ControllerRevisions to confirm quantity
May  1 23:50:34.835: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-ltqd5-daemon-set-84d7656947" 05/01/23 23:50:34.835
STEP: Confirm that there is only one ControllerRevision 05/01/23 23:50:34.939
May  1 23:50:34.939: INFO: Requesting list of ControllerRevisions to confirm quantity
May  1 23:50:35.042: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-ltqd5-daemon-set-6b85784875" 05/01/23 23:50:35.144
May  1 23:50:35.353: INFO: e2e-ltqd5-daemon-set-6b85784875 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 05/01/23 23:50:35.353
W0501 23:50:35.459422    6969 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 05/01/23 23:50:35.459
May  1 23:50:35.459: INFO: Requesting list of ControllerRevisions to confirm quantity
May  1 23:50:35.564: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-ltqd5-daemon-set-6b85784875=updated" 05/01/23 23:50:35.564
STEP: Confirm that there is only one ControllerRevision 05/01/23 23:50:35.669
May  1 23:50:35.669: INFO: Requesting list of ControllerRevisions to confirm quantity
May  1 23:50:35.772: INFO: Found 1 ControllerRevisions
May  1 23:50:35.874: INFO: ControllerRevision "e2e-ltqd5-daemon-set-6558fbd96b" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-ltqd5-daemon-set" 05/01/23 23:50:35.977
STEP: deleting DaemonSet.extensions e2e-ltqd5-daemon-set in namespace controllerrevisions-6381, will wait for the garbage collector to delete the pods 05/01/23 23:50:35.977
May  1 23:50:36.334: INFO: Deleting DaemonSet.extensions e2e-ltqd5-daemon-set took: 104.357538ms
May  1 23:50:36.434: INFO: Terminating DaemonSet.extensions e2e-ltqd5-daemon-set pods took: 100.248772ms
May  1 23:50:38.237: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 0
May  1 23:50:38.237: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-ltqd5-daemon-set
May  1 23:50:38.340: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25613"},"items":null}

May  1 23:50:38.442: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25613"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
May  1 23:50:38.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-6381" for this suite. 05/01/23 23:50:39.061
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":207,"skipped":3903,"failed":0}
------------------------------
• [SLOW TEST] [10.017 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:29.149
    May  1 23:50:29.150: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename controllerrevisions 05/01/23 23:50:29.151
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:29.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:29.664
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-ltqd5-daemon-set" 05/01/23 23:50:30.484
    STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:50:30.59
    May  1 23:50:30.694: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:50:30.797: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 0
    May  1 23:50:30.797: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  1 23:50:31.901: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:50:32.004: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 2
    May  1 23:50:32.004: INFO: Node i-0627b78ff917cf2ae is running 0 daemon pod, expected 1
    May  1 23:50:32.902: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:50:33.005: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 3
    May  1 23:50:33.005: INFO: Node i-0aa263047c51ef669 is running 0 daemon pod, expected 1
    May  1 23:50:33.901: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:50:34.004: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 4
    May  1 23:50:34.004: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset e2e-ltqd5-daemon-set
    STEP: Confirm DaemonSet "e2e-ltqd5-daemon-set" successfully created with "daemonset-name=e2e-ltqd5-daemon-set" label 05/01/23 23:50:34.107
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-ltqd5-daemon-set" 05/01/23 23:50:34.312
    May  1 23:50:34.415: INFO: Located ControllerRevision: "e2e-ltqd5-daemon-set-84d7656947"
    STEP: Patching ControllerRevision "e2e-ltqd5-daemon-set-84d7656947" 05/01/23 23:50:34.518
    May  1 23:50:34.623: INFO: e2e-ltqd5-daemon-set-84d7656947 has been patched
    STEP: Create a new ControllerRevision 05/01/23 23:50:34.623
    May  1 23:50:34.727: INFO: Created ControllerRevision: e2e-ltqd5-daemon-set-6b85784875
    STEP: Confirm that there are two ControllerRevisions 05/01/23 23:50:34.727
    May  1 23:50:34.727: INFO: Requesting list of ControllerRevisions to confirm quantity
    May  1 23:50:34.835: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-ltqd5-daemon-set-84d7656947" 05/01/23 23:50:34.835
    STEP: Confirm that there is only one ControllerRevision 05/01/23 23:50:34.939
    May  1 23:50:34.939: INFO: Requesting list of ControllerRevisions to confirm quantity
    May  1 23:50:35.042: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-ltqd5-daemon-set-6b85784875" 05/01/23 23:50:35.144
    May  1 23:50:35.353: INFO: e2e-ltqd5-daemon-set-6b85784875 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 05/01/23 23:50:35.353
    W0501 23:50:35.459422    6969 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 05/01/23 23:50:35.459
    May  1 23:50:35.459: INFO: Requesting list of ControllerRevisions to confirm quantity
    May  1 23:50:35.564: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-ltqd5-daemon-set-6b85784875=updated" 05/01/23 23:50:35.564
    STEP: Confirm that there is only one ControllerRevision 05/01/23 23:50:35.669
    May  1 23:50:35.669: INFO: Requesting list of ControllerRevisions to confirm quantity
    May  1 23:50:35.772: INFO: Found 1 ControllerRevisions
    May  1 23:50:35.874: INFO: ControllerRevision "e2e-ltqd5-daemon-set-6558fbd96b" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-ltqd5-daemon-set" 05/01/23 23:50:35.977
    STEP: deleting DaemonSet.extensions e2e-ltqd5-daemon-set in namespace controllerrevisions-6381, will wait for the garbage collector to delete the pods 05/01/23 23:50:35.977
    May  1 23:50:36.334: INFO: Deleting DaemonSet.extensions e2e-ltqd5-daemon-set took: 104.357538ms
    May  1 23:50:36.434: INFO: Terminating DaemonSet.extensions e2e-ltqd5-daemon-set pods took: 100.248772ms
    May  1 23:50:38.237: INFO: Number of nodes with available pods controlled by daemonset e2e-ltqd5-daemon-set: 0
    May  1 23:50:38.237: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-ltqd5-daemon-set
    May  1 23:50:38.340: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25613"},"items":null}

    May  1 23:50:38.442: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25613"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:50:38.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-6381" for this suite. 05/01/23 23:50:39.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:39.168
May  1 23:50:39.168: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset 05/01/23 23:50:39.169
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:39.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:39.681
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 05/01/23 23:50:39.885
May  1 23:50:40.091: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 05/01/23 23:50:40.092
May  1 23:50:40.092: INFO: Waiting up to 5m0s for pod "test-rs-9vbkv" in namespace "replicaset-9788" to be "running"
May  1 23:50:40.195: INFO: Pod "test-rs-9vbkv": Phase="Pending", Reason="", readiness=false. Elapsed: 103.270379ms
May  1 23:50:42.298: INFO: Pod "test-rs-9vbkv": Phase="Running", Reason="", readiness=true. Elapsed: 2.206275773s
May  1 23:50:42.298: INFO: Pod "test-rs-9vbkv" satisfied condition "running"
STEP: getting scale subresource 05/01/23 23:50:42.298
STEP: updating a scale subresource 05/01/23 23:50:42.401
STEP: verifying the replicaset Spec.Replicas was modified 05/01/23 23:50:42.506
STEP: Patch a scale subresource 05/01/23 23:50:42.608
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
May  1 23:50:42.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9788" for this suite. 05/01/23 23:50:42.919
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":208,"skipped":3913,"failed":0}
------------------------------
• [3.856 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:39.168
    May  1 23:50:39.168: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replicaset 05/01/23 23:50:39.169
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:39.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:39.681
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 05/01/23 23:50:39.885
    May  1 23:50:40.091: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 05/01/23 23:50:40.092
    May  1 23:50:40.092: INFO: Waiting up to 5m0s for pod "test-rs-9vbkv" in namespace "replicaset-9788" to be "running"
    May  1 23:50:40.195: INFO: Pod "test-rs-9vbkv": Phase="Pending", Reason="", readiness=false. Elapsed: 103.270379ms
    May  1 23:50:42.298: INFO: Pod "test-rs-9vbkv": Phase="Running", Reason="", readiness=true. Elapsed: 2.206275773s
    May  1 23:50:42.298: INFO: Pod "test-rs-9vbkv" satisfied condition "running"
    STEP: getting scale subresource 05/01/23 23:50:42.298
    STEP: updating a scale subresource 05/01/23 23:50:42.401
    STEP: verifying the replicaset Spec.Replicas was modified 05/01/23 23:50:42.506
    STEP: Patch a scale subresource 05/01/23 23:50:42.608
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    May  1 23:50:42.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9788" for this suite. 05/01/23 23:50:42.919
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:43.024
May  1 23:50:43.024: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/01/23 23:50:43.025
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:43.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:43.542
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:50:43.745
May  1 23:50:43.855: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6" in namespace "downward-api-1863" to be "Succeeded or Failed"
May  1 23:50:43.957: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6": Phase="Pending", Reason="", readiness=false. Elapsed: 102.590793ms
May  1 23:50:46.062: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206868006s
May  1 23:50:48.062: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207361209s
STEP: Saw pod success 05/01/23 23:50:48.062
May  1 23:50:48.062: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6" satisfied condition "Succeeded or Failed"
May  1 23:50:48.168: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6 container client-container: <nil>
STEP: delete the pod 05/01/23 23:50:48.274
May  1 23:50:48.386: INFO: Waiting for pod downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6 to disappear
May  1 23:50:48.489: INFO: Pod downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  1 23:50:48.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1863" for this suite. 05/01/23 23:50:48.593
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":209,"skipped":3919,"failed":0}
------------------------------
• [SLOW TEST] [5.674 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:43.024
    May  1 23:50:43.024: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/01/23 23:50:43.025
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:43.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:43.542
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:50:43.745
    May  1 23:50:43.855: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6" in namespace "downward-api-1863" to be "Succeeded or Failed"
    May  1 23:50:43.957: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6": Phase="Pending", Reason="", readiness=false. Elapsed: 102.590793ms
    May  1 23:50:46.062: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.206868006s
    May  1 23:50:48.062: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207361209s
    STEP: Saw pod success 05/01/23 23:50:48.062
    May  1 23:50:48.062: INFO: Pod "downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6" satisfied condition "Succeeded or Failed"
    May  1 23:50:48.168: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:50:48.274
    May  1 23:50:48.386: INFO: Waiting for pod downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6 to disappear
    May  1 23:50:48.489: INFO: Pod downwardapi-volume-47f37993-d922-42a4-8f66-3ef1dd52ebb6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  1 23:50:48.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1863" for this suite. 05/01/23 23:50:48.593
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:48.699
May  1 23:50:48.700: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:50:48.701
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:49.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:49.214
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-96088eba-e5e3-4ce5-a150-4a34a801f915 05/01/23 23:50:49.521
STEP: Creating the pod 05/01/23 23:50:49.624
May  1 23:50:49.732: INFO: Waiting up to 5m0s for pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64" in namespace "configmap-1597" to be "running"
May  1 23:50:49.834: INFO: Pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64": Phase="Pending", Reason="", readiness=false. Elapsed: 102.428227ms
May  1 23:50:51.937: INFO: Pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64": Phase="Running", Reason="", readiness=false. Elapsed: 2.205541618s
May  1 23:50:51.937: INFO: Pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64" satisfied condition "running"
STEP: Waiting for pod with text data 05/01/23 23:50:51.937
STEP: Waiting for pod with binary data 05/01/23 23:50:52.042
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:50:52.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1597" for this suite. 05/01/23 23:50:52.251
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":210,"skipped":3927,"failed":0}
------------------------------
• [3.657 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:48.699
    May  1 23:50:48.700: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:50:48.701
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:49.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:49.214
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-96088eba-e5e3-4ce5-a150-4a34a801f915 05/01/23 23:50:49.521
    STEP: Creating the pod 05/01/23 23:50:49.624
    May  1 23:50:49.732: INFO: Waiting up to 5m0s for pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64" in namespace "configmap-1597" to be "running"
    May  1 23:50:49.834: INFO: Pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64": Phase="Pending", Reason="", readiness=false. Elapsed: 102.428227ms
    May  1 23:50:51.937: INFO: Pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64": Phase="Running", Reason="", readiness=false. Elapsed: 2.205541618s
    May  1 23:50:51.937: INFO: Pod "pod-configmaps-20165463-0ddc-46e7-99fe-407ee13f3c64" satisfied condition "running"
    STEP: Waiting for pod with text data 05/01/23 23:50:51.937
    STEP: Waiting for pod with binary data 05/01/23 23:50:52.042
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:50:52.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1597" for this suite. 05/01/23 23:50:52.251
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:52.359
May  1 23:50:52.359: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename csistoragecapacity 05/01/23 23:50:52.36
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:52.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:52.872
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 05/01/23 23:50:53.075
STEP: getting /apis/storage.k8s.io 05/01/23 23:50:53.278
STEP: getting /apis/storage.k8s.io/v1 05/01/23 23:50:53.379
STEP: creating 05/01/23 23:50:53.481
STEP: watching 05/01/23 23:50:53.793
May  1 23:50:53.794: INFO: starting watch
STEP: getting 05/01/23 23:50:54.1
STEP: listing in namespace 05/01/23 23:50:54.203
STEP: listing across namespaces 05/01/23 23:50:54.306
STEP: patching 05/01/23 23:50:54.408
STEP: updating 05/01/23 23:50:54.512
May  1 23:50:54.618: INFO: waiting for watch events with expected annotations in namespace
May  1 23:50:54.618: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 05/01/23 23:50:54.618
STEP: deleting a collection 05/01/23 23:50:54.927
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
May  1 23:50:55.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-3704" for this suite. 05/01/23 23:50:55.242
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":211,"skipped":3972,"failed":0}
------------------------------
• [2.988 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:52.359
    May  1 23:50:52.359: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename csistoragecapacity 05/01/23 23:50:52.36
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:52.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:52.872
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 05/01/23 23:50:53.075
    STEP: getting /apis/storage.k8s.io 05/01/23 23:50:53.278
    STEP: getting /apis/storage.k8s.io/v1 05/01/23 23:50:53.379
    STEP: creating 05/01/23 23:50:53.481
    STEP: watching 05/01/23 23:50:53.793
    May  1 23:50:53.794: INFO: starting watch
    STEP: getting 05/01/23 23:50:54.1
    STEP: listing in namespace 05/01/23 23:50:54.203
    STEP: listing across namespaces 05/01/23 23:50:54.306
    STEP: patching 05/01/23 23:50:54.408
    STEP: updating 05/01/23 23:50:54.512
    May  1 23:50:54.618: INFO: waiting for watch events with expected annotations in namespace
    May  1 23:50:54.618: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 05/01/23 23:50:54.618
    STEP: deleting a collection 05/01/23 23:50:54.927
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    May  1 23:50:55.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-3704" for this suite. 05/01/23 23:50:55.242
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:55.348
May  1 23:50:55.348: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/01/23 23:50:55.349
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:55.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:55.862
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 05/01/23 23:50:56.065
May  1 23:50:56.172: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453" in namespace "emptydir-7703" to be "running"
May  1 23:50:56.274: INFO: Pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453": Phase="Pending", Reason="", readiness=false. Elapsed: 102.54127ms
May  1 23:50:58.379: INFO: Pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453": Phase="Running", Reason="", readiness=false. Elapsed: 2.206844664s
May  1 23:50:58.379: INFO: Pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453" satisfied condition "running"
STEP: Reading file content from the nginx-container 05/01/23 23:50:58.379
May  1 23:50:58.379: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7703 PodName:pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:50:58.379: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:50:58.380: INFO: ExecWithOptions: Clientset creation
May  1 23:50:58.380: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/emptydir-7703/pods/pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
May  1 23:50:59.153: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  1 23:50:59.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7703" for this suite. 05/01/23 23:50:59.257
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":212,"skipped":3973,"failed":0}
------------------------------
• [4.015 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:55.348
    May  1 23:50:55.348: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/01/23 23:50:55.349
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:55.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:55.862
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 05/01/23 23:50:56.065
    May  1 23:50:56.172: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453" in namespace "emptydir-7703" to be "running"
    May  1 23:50:56.274: INFO: Pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453": Phase="Pending", Reason="", readiness=false. Elapsed: 102.54127ms
    May  1 23:50:58.379: INFO: Pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453": Phase="Running", Reason="", readiness=false. Elapsed: 2.206844664s
    May  1 23:50:58.379: INFO: Pod "pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453" satisfied condition "running"
    STEP: Reading file content from the nginx-container 05/01/23 23:50:58.379
    May  1 23:50:58.379: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7703 PodName:pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:50:58.379: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:50:58.380: INFO: ExecWithOptions: Clientset creation
    May  1 23:50:58.380: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/emptydir-7703/pods/pod-sharedvolume-cebb8011-3ae9-4047-9af2-71bbe4a2d453/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    May  1 23:50:59.153: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  1 23:50:59.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7703" for this suite. 05/01/23 23:50:59.257
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:50:59.363
May  1 23:50:59.363: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename ingress 05/01/23 23:50:59.364
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:59.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:59.877
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 05/01/23 23:51:00.08
STEP: getting /apis/networking.k8s.io 05/01/23 23:51:00.283
STEP: getting /apis/networking.k8s.iov1 05/01/23 23:51:00.385
STEP: creating 05/01/23 23:51:00.486
STEP: getting 05/01/23 23:51:00.798
STEP: listing 05/01/23 23:51:00.901
STEP: watching 05/01/23 23:51:01.003
May  1 23:51:01.004: INFO: starting watch
STEP: cluster-wide listing 05/01/23 23:51:01.105
STEP: cluster-wide watching 05/01/23 23:51:01.207
May  1 23:51:01.207: INFO: starting watch
STEP: patching 05/01/23 23:51:01.309
STEP: updating 05/01/23 23:51:01.413
May  1 23:51:01.621: INFO: waiting for watch events with expected annotations
May  1 23:51:01.621: INFO: saw patched and updated annotations
STEP: patching /status 05/01/23 23:51:01.621
STEP: updating /status 05/01/23 23:51:01.725
STEP: get /status 05/01/23 23:51:01.932
STEP: deleting 05/01/23 23:51:02.035
STEP: deleting a collection 05/01/23 23:51:02.345
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
May  1 23:51:02.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-519" for this suite. 05/01/23 23:51:02.658
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":213,"skipped":3979,"failed":0}
------------------------------
• [3.399 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:50:59.363
    May  1 23:50:59.363: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename ingress 05/01/23 23:50:59.364
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:50:59.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:50:59.877
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 05/01/23 23:51:00.08
    STEP: getting /apis/networking.k8s.io 05/01/23 23:51:00.283
    STEP: getting /apis/networking.k8s.iov1 05/01/23 23:51:00.385
    STEP: creating 05/01/23 23:51:00.486
    STEP: getting 05/01/23 23:51:00.798
    STEP: listing 05/01/23 23:51:00.901
    STEP: watching 05/01/23 23:51:01.003
    May  1 23:51:01.004: INFO: starting watch
    STEP: cluster-wide listing 05/01/23 23:51:01.105
    STEP: cluster-wide watching 05/01/23 23:51:01.207
    May  1 23:51:01.207: INFO: starting watch
    STEP: patching 05/01/23 23:51:01.309
    STEP: updating 05/01/23 23:51:01.413
    May  1 23:51:01.621: INFO: waiting for watch events with expected annotations
    May  1 23:51:01.621: INFO: saw patched and updated annotations
    STEP: patching /status 05/01/23 23:51:01.621
    STEP: updating /status 05/01/23 23:51:01.725
    STEP: get /status 05/01/23 23:51:01.932
    STEP: deleting 05/01/23 23:51:02.035
    STEP: deleting a collection 05/01/23 23:51:02.345
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    May  1 23:51:02.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-519" for this suite. 05/01/23 23:51:02.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:51:02.762
May  1 23:51:02.762: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook 05/01/23 23:51:02.763
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:03.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:03.275
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 05/01/23 23:51:03.583
May  1 23:51:03.690: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3122" to be "running and ready"
May  1 23:51:03.793: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 102.465187ms
May  1 23:51:03.793: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  1 23:51:05.896: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.205969373s
May  1 23:51:05.897: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
May  1 23:51:05.897: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 05/01/23 23:51:05.999
May  1 23:51:06.103: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-3122" to be "running and ready"
May  1 23:51:06.206: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 102.76288ms
May  1 23:51:06.206: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  1 23:51:08.310: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.206735079s
May  1 23:51:08.310: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
May  1 23:51:08.310: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 05/01/23 23:51:08.413
May  1 23:51:08.518: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  1 23:51:08.621: INFO: Pod pod-with-prestop-http-hook still exists
May  1 23:51:10.621: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  1 23:51:10.724: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 05/01/23 23:51:10.725
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
May  1 23:51:10.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3122" for this suite. 05/01/23 23:51:10.94
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":214,"skipped":3984,"failed":0}
------------------------------
• [SLOW TEST] [8.282 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:51:02.762
    May  1 23:51:02.762: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-lifecycle-hook 05/01/23 23:51:02.763
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:03.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:03.275
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 05/01/23 23:51:03.583
    May  1 23:51:03.690: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3122" to be "running and ready"
    May  1 23:51:03.793: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 102.465187ms
    May  1 23:51:03.793: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:51:05.896: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.205969373s
    May  1 23:51:05.897: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    May  1 23:51:05.897: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 05/01/23 23:51:05.999
    May  1 23:51:06.103: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-3122" to be "running and ready"
    May  1 23:51:06.206: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 102.76288ms
    May  1 23:51:06.206: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:51:08.310: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.206735079s
    May  1 23:51:08.310: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    May  1 23:51:08.310: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 05/01/23 23:51:08.413
    May  1 23:51:08.518: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    May  1 23:51:08.621: INFO: Pod pod-with-prestop-http-hook still exists
    May  1 23:51:10.621: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    May  1 23:51:10.724: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 05/01/23 23:51:10.725
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    May  1 23:51:10.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3122" for this suite. 05/01/23 23:51:10.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:51:11.045
May  1 23:51:11.045: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job 05/01/23 23:51:11.046
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:11.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:11.559
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 05/01/23 23:51:11.763
STEP: Ensuring job reaches completions 05/01/23 23:51:11.867
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
May  1 23:51:23.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8088" for this suite. 05/01/23 23:51:24.073
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":215,"skipped":3997,"failed":0}
------------------------------
• [SLOW TEST] [13.134 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:51:11.045
    May  1 23:51:11.045: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename job 05/01/23 23:51:11.046
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:11.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:11.559
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 05/01/23 23:51:11.763
    STEP: Ensuring job reaches completions 05/01/23 23:51:11.867
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    May  1 23:51:23.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8088" for this suite. 05/01/23 23:51:24.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:51:24.18
May  1 23:51:24.180: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/01/23 23:51:24.181
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:24.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:24.694
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-ae201fa1-2518-41e9-bded-e1566c4c8437 05/01/23 23:51:25.311
STEP: Creating a pod to test consume secrets 05/01/23 23:51:25.416
May  1 23:51:25.522: INFO: Waiting up to 5m0s for pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a" in namespace "secrets-935" to be "Succeeded or Failed"
May  1 23:51:25.628: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a": Phase="Pending", Reason="", readiness=false. Elapsed: 106.216957ms
May  1 23:51:27.733: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210944258s
May  1 23:51:29.732: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20995656s
STEP: Saw pod success 05/01/23 23:51:29.732
May  1 23:51:29.732: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a" satisfied condition "Succeeded or Failed"
May  1 23:51:29.835: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a container secret-volume-test: <nil>
STEP: delete the pod 05/01/23 23:51:29.941
May  1 23:51:30.050: INFO: Waiting for pod pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a to disappear
May  1 23:51:30.154: INFO: Pod pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  1 23:51:30.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-935" for this suite. 05/01/23 23:51:30.258
STEP: Destroying namespace "secret-namespace-8543" for this suite. 05/01/23 23:51:30.364
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":216,"skipped":4014,"failed":0}
------------------------------
• [SLOW TEST] [6.290 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:51:24.18
    May  1 23:51:24.180: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/01/23 23:51:24.181
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:24.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:24.694
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-ae201fa1-2518-41e9-bded-e1566c4c8437 05/01/23 23:51:25.311
    STEP: Creating a pod to test consume secrets 05/01/23 23:51:25.416
    May  1 23:51:25.522: INFO: Waiting up to 5m0s for pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a" in namespace "secrets-935" to be "Succeeded or Failed"
    May  1 23:51:25.628: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a": Phase="Pending", Reason="", readiness=false. Elapsed: 106.216957ms
    May  1 23:51:27.733: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210944258s
    May  1 23:51:29.732: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20995656s
    STEP: Saw pod success 05/01/23 23:51:29.732
    May  1 23:51:29.732: INFO: Pod "pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a" satisfied condition "Succeeded or Failed"
    May  1 23:51:29.835: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a container secret-volume-test: <nil>
    STEP: delete the pod 05/01/23 23:51:29.941
    May  1 23:51:30.050: INFO: Waiting for pod pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a to disappear
    May  1 23:51:30.154: INFO: Pod pod-secrets-c869fa09-15e0-4499-a358-73ee8f025a7a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  1 23:51:30.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-935" for this suite. 05/01/23 23:51:30.258
    STEP: Destroying namespace "secret-namespace-8543" for this suite. 05/01/23 23:51:30.364
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:51:30.47
May  1 23:51:30.470: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:51:30.471
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:30.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:30.986
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
May  1 23:51:31.191: INFO: >>> kubeConfig: /root/.kube/config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 05/01/23 23:51:38.214
May  1 23:51:38.214: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 create -f -'
May  1 23:51:40.059: INFO: stderr: ""
May  1 23:51:40.059: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May  1 23:51:40.059: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 delete e2e-test-crd-publish-openapi-5016-crds test-cr'
May  1 23:51:40.570: INFO: stderr: ""
May  1 23:51:40.570: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
May  1 23:51:40.570: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 apply -f -'
May  1 23:51:41.427: INFO: stderr: ""
May  1 23:51:41.427: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May  1 23:51:41.427: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 delete e2e-test-crd-publish-openapi-5016-crds test-cr'
May  1 23:51:41.935: INFO: stderr: ""
May  1 23:51:41.935: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 05/01/23 23:51:41.935
May  1 23:51:41.935: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 explain e2e-test-crd-publish-openapi-5016-crds'
May  1 23:51:42.489: INFO: stderr: ""
May  1 23:51:42.489: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5016-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:51:47.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1597" for this suite. 05/01/23 23:51:48.468
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":217,"skipped":4032,"failed":0}
------------------------------
• [SLOW TEST] [18.104 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:51:30.47
    May  1 23:51:30.470: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:51:30.471
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:30.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:30.986
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    May  1 23:51:31.191: INFO: >>> kubeConfig: /root/.kube/config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 05/01/23 23:51:38.214
    May  1 23:51:38.214: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 create -f -'
    May  1 23:51:40.059: INFO: stderr: ""
    May  1 23:51:40.059: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    May  1 23:51:40.059: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 delete e2e-test-crd-publish-openapi-5016-crds test-cr'
    May  1 23:51:40.570: INFO: stderr: ""
    May  1 23:51:40.570: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    May  1 23:51:40.570: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 apply -f -'
    May  1 23:51:41.427: INFO: stderr: ""
    May  1 23:51:41.427: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    May  1 23:51:41.427: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 --namespace=crd-publish-openapi-1597 delete e2e-test-crd-publish-openapi-5016-crds test-cr'
    May  1 23:51:41.935: INFO: stderr: ""
    May  1 23:51:41.935: INFO: stdout: "e2e-test-crd-publish-openapi-5016-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 05/01/23 23:51:41.935
    May  1 23:51:41.935: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-1597 explain e2e-test-crd-publish-openapi-5016-crds'
    May  1 23:51:42.489: INFO: stderr: ""
    May  1 23:51:42.489: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5016-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:51:47.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1597" for this suite. 05/01/23 23:51:48.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:51:48.576
May  1 23:51:48.576: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 23:51:48.577
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:48.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:49.097
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 05/01/23 23:51:49.304
STEP: Counting existing ResourceQuota 05/01/23 23:51:54.411
STEP: Creating a ResourceQuota 05/01/23 23:51:59.516
STEP: Ensuring resource quota status is calculated 05/01/23 23:51:59.622
STEP: Creating a Secret 05/01/23 23:52:01.727
STEP: Ensuring resource quota status captures secret creation 05/01/23 23:52:01.839
STEP: Deleting a secret 05/01/23 23:52:03.944
STEP: Ensuring resource quota status released usage 05/01/23 23:52:04.05
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 23:52:06.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1879" for this suite. 05/01/23 23:52:06.261
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":218,"skipped":4057,"failed":0}
------------------------------
• [SLOW TEST] [17.791 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:51:48.576
    May  1 23:51:48.576: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 23:51:48.577
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:51:48.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:51:49.097
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 05/01/23 23:51:49.304
    STEP: Counting existing ResourceQuota 05/01/23 23:51:54.411
    STEP: Creating a ResourceQuota 05/01/23 23:51:59.516
    STEP: Ensuring resource quota status is calculated 05/01/23 23:51:59.622
    STEP: Creating a Secret 05/01/23 23:52:01.727
    STEP: Ensuring resource quota status captures secret creation 05/01/23 23:52:01.839
    STEP: Deleting a secret 05/01/23 23:52:03.944
    STEP: Ensuring resource quota status released usage 05/01/23 23:52:04.05
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 23:52:06.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1879" for this suite. 05/01/23 23:52:06.261
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:06.367
May  1 23:52:06.368: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 23:52:06.369
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:06.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:06.891
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 05/01/23 23:52:07.098
May  1 23:52:07.098: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6644 cluster-info'
May  1 23:52:07.524: INFO: stderr: ""
May  1 23:52:07.524: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 23:52:07.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6644" for this suite. 05/01/23 23:52:07.629
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":219,"skipped":4067,"failed":0}
------------------------------
• [1.469 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:06.367
    May  1 23:52:06.368: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 23:52:06.369
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:06.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:06.891
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 05/01/23 23:52:07.098
    May  1 23:52:07.098: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-6644 cluster-info'
    May  1 23:52:07.524: INFO: stderr: ""
    May  1 23:52:07.524: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 23:52:07.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6644" for this suite. 05/01/23 23:52:07.629
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:07.841
May  1 23:52:07.841: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:52:07.842
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:08.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:08.362
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:52:08.781
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:52:09.065
STEP: Deploying the webhook pod 05/01/23 23:52:09.172
STEP: Wait for the deployment to be ready 05/01/23 23:52:09.386
May  1 23:52:09.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:52:11.803
STEP: Verifying the service has paired with the endpoint 05/01/23 23:52:11.915
May  1 23:52:12.916: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
May  1 23:52:13.019: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1641-crds.webhook.example.com via the AdmissionRegistration API 05/01/23 23:52:13.23
STEP: Creating a custom resource that should be mutated by the webhook 05/01/23 23:52:13.448
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:52:15.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6347" for this suite. 05/01/23 23:52:16.032
STEP: Destroying namespace "webhook-6347-markers" for this suite. 05/01/23 23:52:16.24
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":220,"skipped":4103,"failed":0}
------------------------------
• [SLOW TEST] [8.956 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:07.841
    May  1 23:52:07.841: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:52:07.842
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:08.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:08.362
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:52:08.781
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:52:09.065
    STEP: Deploying the webhook pod 05/01/23 23:52:09.172
    STEP: Wait for the deployment to be ready 05/01/23 23:52:09.386
    May  1 23:52:09.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 52, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:52:11.803
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:52:11.915
    May  1 23:52:12.916: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    May  1 23:52:13.019: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1641-crds.webhook.example.com via the AdmissionRegistration API 05/01/23 23:52:13.23
    STEP: Creating a custom resource that should be mutated by the webhook 05/01/23 23:52:13.448
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:52:15.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6347" for this suite. 05/01/23 23:52:16.032
    STEP: Destroying namespace "webhook-6347-markers" for this suite. 05/01/23 23:52:16.24
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:16.798
May  1 23:52:16.798: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename endpointslicemirroring 05/01/23 23:52:16.799
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:17.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:17.319
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 05/01/23 23:52:17.638
STEP: mirroring an update to a custom Endpoint 05/01/23 23:52:17.85
STEP: mirroring deletion of a custom Endpoint 05/01/23 23:52:18.06
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
May  1 23:52:18.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-1670" for this suite. 05/01/23 23:52:18.377
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":221,"skipped":4126,"failed":0}
------------------------------
• [1.685 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:16.798
    May  1 23:52:16.798: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename endpointslicemirroring 05/01/23 23:52:16.799
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:17.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:17.319
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 05/01/23 23:52:17.638
    STEP: mirroring an update to a custom Endpoint 05/01/23 23:52:17.85
    STEP: mirroring deletion of a custom Endpoint 05/01/23 23:52:18.06
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    May  1 23:52:18.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-1670" for this suite. 05/01/23 23:52:18.377
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:18.484
May  1 23:52:18.485: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename ephemeral-containers-test 05/01/23 23:52:18.486
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:18.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:19.007
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 05/01/23 23:52:19.215
May  1 23:52:19.323: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1239" to be "running and ready"
May  1 23:52:19.428: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.335191ms
May  1 23:52:19.428: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
May  1 23:52:21.534: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.210122272s
May  1 23:52:21.534: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
May  1 23:52:21.534: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 05/01/23 23:52:21.638
May  1 23:52:21.752: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1239" to be "container debugger running"
May  1 23:52:21.856: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 104.215011ms
May  1 23:52:23.962: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209578726s
May  1 23:52:23.962: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 05/01/23 23:52:23.962
May  1 23:52:23.962: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1239 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  1 23:52:23.962: INFO: >>> kubeConfig: /root/.kube/config
May  1 23:52:23.963: INFO: ExecWithOptions: Clientset creation
May  1 23:52:23.963: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/ephemeral-containers-test-1239/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
May  1 23:52:24.673: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
May  1 23:52:24.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-1239" for this suite. 05/01/23 23:52:24.886
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":222,"skipped":4142,"failed":0}
------------------------------
• [SLOW TEST] [6.507 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:18.484
    May  1 23:52:18.485: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename ephemeral-containers-test 05/01/23 23:52:18.486
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:18.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:19.007
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 05/01/23 23:52:19.215
    May  1 23:52:19.323: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1239" to be "running and ready"
    May  1 23:52:19.428: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.335191ms
    May  1 23:52:19.428: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:52:21.534: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.210122272s
    May  1 23:52:21.534: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    May  1 23:52:21.534: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 05/01/23 23:52:21.638
    May  1 23:52:21.752: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-1239" to be "container debugger running"
    May  1 23:52:21.856: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 104.215011ms
    May  1 23:52:23.962: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209578726s
    May  1 23:52:23.962: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 05/01/23 23:52:23.962
    May  1 23:52:23.962: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1239 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  1 23:52:23.962: INFO: >>> kubeConfig: /root/.kube/config
    May  1 23:52:23.963: INFO: ExecWithOptions: Clientset creation
    May  1 23:52:23.963: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/ephemeral-containers-test-1239/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    May  1 23:52:24.673: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    May  1 23:52:24.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-1239" for this suite. 05/01/23 23:52:24.886
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:24.992
May  1 23:52:24.992: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/01/23 23:52:24.993
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:25.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:25.513
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 05/01/23 23:52:26.351
STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:52:26.459
May  1 23:52:26.565: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:52:26.670: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  1 23:52:26.670: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  1 23:52:27.776: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:52:27.880: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
May  1 23:52:27.880: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  1 23:52:28.776: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  1 23:52:28.881: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  1 23:52:28.881: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: listing all DeamonSets 05/01/23 23:52:28.985
STEP: DeleteCollection of the DaemonSets 05/01/23 23:52:29.09
STEP: Verify that ReplicaSets have been deleted 05/01/23 23:52:29.197
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
May  1 23:52:29.510: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26462"},"items":null}

May  1 23:52:29.615: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26462"},"items":[{"metadata":{"name":"daemon-set-b22l5","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"7729e770-30d4-4fe8-b918-4c075d7d38d7","resourceVersion":"26459","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"0c5871cb957c6ab463e65a01f96f9bf5e4b3335dcf603e32b489bb03f8d22632","cni.projectcalico.org/podIP":"100.101.231.138/32","cni.projectcalico.org/podIPs":"100.101.231.138/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.138\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hl58j","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hl58j","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-0aa263047c51ef669","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-0aa263047c51ef669"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.39.145","podIP":"100.101.231.138","podIPs":[{"ip":"100.101.231.138"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c0c4664c82a5d2802f8315dcd52f14641287e918982eccfcfe2646fcfa71841d","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-dzfv8","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"cefeacba-53b5-456b-b282-de09046244c5","resourceVersion":"26458","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"599e98e8651b4ea8e94d1dfdf2f569afe9a0e64231d13396062598b4869c0719","cni.projectcalico.org/podIP":"100.96.36.3/32","cni.projectcalico.org/podIPs":"100.96.36.3/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-drnrv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-drnrv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-02d061b30635c230c","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-02d061b30635c230c"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.48.211","podIP":"100.96.36.3","podIPs":[{"ip":"100.96.36.3"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://b3fe1387a3a7edb1b29adf274cda16f7ce1b1ef7659ac1ee71d2d28d38c4eae2","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-l84bg","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"b5473761-32e7-41bb-b24e-99026e531ddc","resourceVersion":"26460","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"db5a45beda97177f7a9782decacb9083af20ff527e86258a39d7d0021f865679","cni.projectcalico.org/podIP":"100.105.72.130/32","cni.projectcalico.org/podIPs":"100.105.72.130/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.130\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-cdcbl","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-cdcbl","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-0627b78ff917cf2ae","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-0627b78ff917cf2ae"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.62.149","podIP":"100.105.72.130","podIPs":[{"ip":"100.105.72.130"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://10dc59936504328c803652ed0d3a397d13537a0e079bb0b3f85d328e789808da","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-vkpbz","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"4e5c758d-db2a-4370-8837-72dab967de0c","resourceVersion":"26461","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"24364fec2a1cf44f9e14db77488dff3bb591e40ae617437775e8c401a8346bd9","cni.projectcalico.org/podIP":"100.123.145.216/32","cni.projectcalico.org/podIPs":"100.123.145.216/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-7cc7q","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-7cc7q","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-00fed7c0a42791aae","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-00fed7c0a42791aae"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.44.200","podIP":"100.123.145.216","podIPs":[{"ip":"100.123.145.216"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c10a235e18638be97ee09c23acbf279d73b34a713085e59445f5d5576b3916b1","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  1 23:52:30.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3483" for this suite. 05/01/23 23:52:30.243
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":223,"skipped":4143,"failed":0}
------------------------------
• [SLOW TEST] [5.358 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:24.992
    May  1 23:52:24.992: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/01/23 23:52:24.993
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:25.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:25.513
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 05/01/23 23:52:26.351
    STEP: Check that daemon pods launch on every node of the cluster. 05/01/23 23:52:26.459
    May  1 23:52:26.565: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:52:26.670: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  1 23:52:26.670: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  1 23:52:27.776: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:52:27.880: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    May  1 23:52:27.880: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  1 23:52:28.776: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  1 23:52:28.881: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  1 23:52:28.881: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: listing all DeamonSets 05/01/23 23:52:28.985
    STEP: DeleteCollection of the DaemonSets 05/01/23 23:52:29.09
    STEP: Verify that ReplicaSets have been deleted 05/01/23 23:52:29.197
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    May  1 23:52:29.510: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26462"},"items":null}

    May  1 23:52:29.615: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26462"},"items":[{"metadata":{"name":"daemon-set-b22l5","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"7729e770-30d4-4fe8-b918-4c075d7d38d7","resourceVersion":"26459","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"0c5871cb957c6ab463e65a01f96f9bf5e4b3335dcf603e32b489bb03f8d22632","cni.projectcalico.org/podIP":"100.101.231.138/32","cni.projectcalico.org/podIPs":"100.101.231.138/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.138\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hl58j","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hl58j","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-0aa263047c51ef669","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-0aa263047c51ef669"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.39.145","podIP":"100.101.231.138","podIPs":[{"ip":"100.101.231.138"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c0c4664c82a5d2802f8315dcd52f14641287e918982eccfcfe2646fcfa71841d","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-dzfv8","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"cefeacba-53b5-456b-b282-de09046244c5","resourceVersion":"26458","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"599e98e8651b4ea8e94d1dfdf2f569afe9a0e64231d13396062598b4869c0719","cni.projectcalico.org/podIP":"100.96.36.3/32","cni.projectcalico.org/podIPs":"100.96.36.3/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-drnrv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-drnrv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-02d061b30635c230c","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-02d061b30635c230c"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.48.211","podIP":"100.96.36.3","podIPs":[{"ip":"100.96.36.3"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://b3fe1387a3a7edb1b29adf274cda16f7ce1b1ef7659ac1ee71d2d28d38c4eae2","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-l84bg","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"b5473761-32e7-41bb-b24e-99026e531ddc","resourceVersion":"26460","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"db5a45beda97177f7a9782decacb9083af20ff527e86258a39d7d0021f865679","cni.projectcalico.org/podIP":"100.105.72.130/32","cni.projectcalico.org/podIPs":"100.105.72.130/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.130\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-cdcbl","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-cdcbl","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-0627b78ff917cf2ae","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-0627b78ff917cf2ae"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.62.149","podIP":"100.105.72.130","podIPs":[{"ip":"100.105.72.130"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://10dc59936504328c803652ed0d3a397d13537a0e079bb0b3f85d328e789808da","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-vkpbz","generateName":"daemon-set-","namespace":"daemonsets-3483","uid":"4e5c758d-db2a-4370-8837-72dab967de0c","resourceVersion":"26461","creationTimestamp":"2023-05-01T23:52:26Z","deletionTimestamp":"2023-05-01T23:52:59Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"24364fec2a1cf44f9e14db77488dff3bb591e40ae617437775e8c401a8346bd9","cni.projectcalico.org/podIP":"100.123.145.216/32","cni.projectcalico.org/podIPs":"100.123.145.216/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"37752992-8272-47c2-80e4-639bb7122412","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37752992-8272-47c2-80e4-639bb7122412\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-05-01T23:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-7cc7q","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-7cc7q","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"i-00fed7c0a42791aae","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["i-00fed7c0a42791aae"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:27Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-05-01T23:52:26Z"}],"hostIP":"172.20.44.200","podIP":"100.123.145.216","podIPs":[{"ip":"100.123.145.216"}],"startTime":"2023-05-01T23:52:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-05-01T23:52:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c10a235e18638be97ee09c23acbf279d73b34a713085e59445f5d5576b3916b1","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:52:30.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3483" for this suite. 05/01/23 23:52:30.243
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:30.35
May  1 23:52:30.350: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:52:30.351
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:30.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:30.873
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-5266/configmap-test-8186833b-9100-4f55-a644-2c1c5446bc27 05/01/23 23:52:31.079
STEP: Creating a pod to test consume configMaps 05/01/23 23:52:31.185
May  1 23:52:31.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a" in namespace "configmap-5266" to be "Succeeded or Failed"
May  1 23:52:31.398: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a": Phase="Pending", Reason="", readiness=false. Elapsed: 104.350215ms
May  1 23:52:33.503: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a": Phase="Running", Reason="", readiness=false. Elapsed: 2.20960939s
May  1 23:52:35.503: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20985148s
STEP: Saw pod success 05/01/23 23:52:35.503
May  1 23:52:35.504: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a" satisfied condition "Succeeded or Failed"
May  1 23:52:35.609: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a container env-test: <nil>
STEP: delete the pod 05/01/23 23:52:35.721
May  1 23:52:35.831: INFO: Waiting for pod pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a to disappear
May  1 23:52:35.936: INFO: Pod pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:52:35.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5266" for this suite. 05/01/23 23:52:36.041
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":224,"skipped":4145,"failed":0}
------------------------------
• [SLOW TEST] [5.797 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:30.35
    May  1 23:52:30.350: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:52:30.351
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:30.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:30.873
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-5266/configmap-test-8186833b-9100-4f55-a644-2c1c5446bc27 05/01/23 23:52:31.079
    STEP: Creating a pod to test consume configMaps 05/01/23 23:52:31.185
    May  1 23:52:31.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a" in namespace "configmap-5266" to be "Succeeded or Failed"
    May  1 23:52:31.398: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a": Phase="Pending", Reason="", readiness=false. Elapsed: 104.350215ms
    May  1 23:52:33.503: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a": Phase="Running", Reason="", readiness=false. Elapsed: 2.20960939s
    May  1 23:52:35.503: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20985148s
    STEP: Saw pod success 05/01/23 23:52:35.503
    May  1 23:52:35.504: INFO: Pod "pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a" satisfied condition "Succeeded or Failed"
    May  1 23:52:35.609: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a container env-test: <nil>
    STEP: delete the pod 05/01/23 23:52:35.721
    May  1 23:52:35.831: INFO: Waiting for pod pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a to disappear
    May  1 23:52:35.936: INFO: Pod pod-configmaps-1dc0ee4a-0bd9-49d9-b7be-683aa327e95a no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:52:35.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5266" for this suite. 05/01/23 23:52:36.041
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:36.148
May  1 23:52:36.148: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:52:36.15
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:36.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:36.671
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
STEP: fetching services 05/01/23 23:52:36.878
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:52:36.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9386" for this suite. 05/01/23 23:52:37.088
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":225,"skipped":4151,"failed":0}
------------------------------
• [1.046 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:36.148
    May  1 23:52:36.148: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:52:36.15
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:36.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:36.671
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3185
    STEP: fetching services 05/01/23 23:52:36.878
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:52:36.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9386" for this suite. 05/01/23 23:52:37.088
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:37.195
May  1 23:52:37.196: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/01/23 23:52:37.197
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:37.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:37.718
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7078.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7078.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 05/01/23 23:52:37.925
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7078.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7078.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 05/01/23 23:52:37.925
STEP: creating a pod to probe /etc/hosts 05/01/23 23:52:37.926
STEP: submitting the pod to kubernetes 05/01/23 23:52:37.926
May  1 23:52:38.035: INFO: Waiting up to 15m0s for pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f" in namespace "dns-7078" to be "running"
May  1 23:52:38.139: INFO: Pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f": Phase="Pending", Reason="", readiness=false. Elapsed: 104.500773ms
May  1 23:52:40.245: INFO: Pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f": Phase="Running", Reason="", readiness=true. Elapsed: 2.210325064s
May  1 23:52:40.245: INFO: Pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f" satisfied condition "running"
STEP: retrieving the pod 05/01/23 23:52:40.245
STEP: looking for the results for each expected name from probers 05/01/23 23:52:40.35
May  1 23:52:40.770: INFO: DNS probes using dns-7078/dns-test-89621d47-6dfe-4f61-8857-3b36f903723f succeeded

STEP: deleting the pod 05/01/23 23:52:40.77
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  1 23:52:40.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7078" for this suite. 05/01/23 23:52:40.989
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":226,"skipped":4171,"failed":0}
------------------------------
• [3.900 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:37.195
    May  1 23:52:37.196: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/01/23 23:52:37.197
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:37.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:37.718
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7078.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7078.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     05/01/23 23:52:37.925
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7078.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7078.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     05/01/23 23:52:37.925
    STEP: creating a pod to probe /etc/hosts 05/01/23 23:52:37.926
    STEP: submitting the pod to kubernetes 05/01/23 23:52:37.926
    May  1 23:52:38.035: INFO: Waiting up to 15m0s for pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f" in namespace "dns-7078" to be "running"
    May  1 23:52:38.139: INFO: Pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f": Phase="Pending", Reason="", readiness=false. Elapsed: 104.500773ms
    May  1 23:52:40.245: INFO: Pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f": Phase="Running", Reason="", readiness=true. Elapsed: 2.210325064s
    May  1 23:52:40.245: INFO: Pod "dns-test-89621d47-6dfe-4f61-8857-3b36f903723f" satisfied condition "running"
    STEP: retrieving the pod 05/01/23 23:52:40.245
    STEP: looking for the results for each expected name from probers 05/01/23 23:52:40.35
    May  1 23:52:40.770: INFO: DNS probes using dns-7078/dns-test-89621d47-6dfe-4f61-8857-3b36f903723f succeeded

    STEP: deleting the pod 05/01/23 23:52:40.77
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  1 23:52:40.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7078" for this suite. 05/01/23 23:52:40.989
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:52:41.097
May  1 23:52:41.097: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:52:41.099
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:41.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:41.622
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-7d90e636-74ea-46de-a2d1-aed2c2f597ea 05/01/23 23:52:41.934
STEP: Creating configMap with name cm-test-opt-upd-60894bd0-5d18-43e0-b975-f7c8be3e108b 05/01/23 23:52:42.041
STEP: Creating the pod 05/01/23 23:52:42.147
May  1 23:52:42.257: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816" in namespace "projected-1051" to be "running and ready"
May  1 23:52:42.362: INFO: Pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816": Phase="Pending", Reason="", readiness=false. Elapsed: 105.005593ms
May  1 23:52:42.362: INFO: The phase of Pod pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816 is Pending, waiting for it to be Running (with Ready = true)
May  1 23:52:44.467: INFO: Pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816": Phase="Running", Reason="", readiness=true. Elapsed: 2.209835601s
May  1 23:52:44.467: INFO: The phase of Pod pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816 is Running (Ready = true)
May  1 23:52:44.467: INFO: Pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-7d90e636-74ea-46de-a2d1-aed2c2f597ea 05/01/23 23:52:44.891
STEP: Updating configmap cm-test-opt-upd-60894bd0-5d18-43e0-b975-f7c8be3e108b 05/01/23 23:52:44.997
STEP: Creating configMap with name cm-test-opt-create-1e9d36ca-2cdc-4a57-85b3-e6bd2a4cef83 05/01/23 23:52:45.103
STEP: waiting to observe update in volume 05/01/23 23:52:45.21
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  1 23:54:07.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1051" for this suite. 05/01/23 23:54:07.892
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":227,"skipped":4190,"failed":0}
------------------------------
• [SLOW TEST] [86.902 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:52:41.097
    May  1 23:52:41.097: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:52:41.099
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:52:41.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:52:41.622
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-7d90e636-74ea-46de-a2d1-aed2c2f597ea 05/01/23 23:52:41.934
    STEP: Creating configMap with name cm-test-opt-upd-60894bd0-5d18-43e0-b975-f7c8be3e108b 05/01/23 23:52:42.041
    STEP: Creating the pod 05/01/23 23:52:42.147
    May  1 23:52:42.257: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816" in namespace "projected-1051" to be "running and ready"
    May  1 23:52:42.362: INFO: Pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816": Phase="Pending", Reason="", readiness=false. Elapsed: 105.005593ms
    May  1 23:52:42.362: INFO: The phase of Pod pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816 is Pending, waiting for it to be Running (with Ready = true)
    May  1 23:52:44.467: INFO: Pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816": Phase="Running", Reason="", readiness=true. Elapsed: 2.209835601s
    May  1 23:52:44.467: INFO: The phase of Pod pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816 is Running (Ready = true)
    May  1 23:52:44.467: INFO: Pod "pod-projected-configmaps-e4abed28-6a45-4258-88ce-09ce26b40816" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-7d90e636-74ea-46de-a2d1-aed2c2f597ea 05/01/23 23:52:44.891
    STEP: Updating configmap cm-test-opt-upd-60894bd0-5d18-43e0-b975-f7c8be3e108b 05/01/23 23:52:44.997
    STEP: Creating configMap with name cm-test-opt-create-1e9d36ca-2cdc-4a57-85b3-e6bd2a4cef83 05/01/23 23:52:45.103
    STEP: waiting to observe update in volume 05/01/23 23:52:45.21
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  1 23:54:07.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1051" for this suite. 05/01/23 23:54:07.892
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:54:08
May  1 23:54:08.000: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename cronjob 05/01/23 23:54:08.002
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:54:08.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:54:08.528
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 05/01/23 23:54:08.738
STEP: Ensuring more than one job is running at a time 05/01/23 23:54:08.846
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 05/01/23 23:56:00.952
STEP: Removing cronjob 05/01/23 23:56:01.058
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
May  1 23:56:01.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2539" for this suite. 05/01/23 23:56:01.272
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":228,"skipped":4191,"failed":0}
------------------------------
• [SLOW TEST] [113.380 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:54:08
    May  1 23:54:08.000: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename cronjob 05/01/23 23:54:08.002
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:54:08.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:54:08.528
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 05/01/23 23:54:08.738
    STEP: Ensuring more than one job is running at a time 05/01/23 23:54:08.846
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 05/01/23 23:56:00.952
    STEP: Removing cronjob 05/01/23 23:56:01.058
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    May  1 23:56:01.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2539" for this suite. 05/01/23 23:56:01.272
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:01.382
May  1 23:56:01.382: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/01/23 23:56:01.383
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:01.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:01.912
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/01/23 23:56:02.342
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:56:02.623
STEP: Deploying the webhook pod 05/01/23 23:56:02.732
STEP: Wait for the deployment to be ready 05/01/23 23:56:02.948
May  1 23:56:03.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/01/23 23:56:05.371
STEP: Verifying the service has paired with the endpoint 05/01/23 23:56:05.483
May  1 23:56:06.483: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 05/01/23 23:56:06.589
STEP: Updating a mutating webhook configuration's rules to not include the create operation 05/01/23 23:56:06.912
STEP: Creating a configMap that should not be mutated 05/01/23 23:56:07.022
STEP: Patching a mutating webhook configuration's rules to include the create operation 05/01/23 23:56:07.237
STEP: Creating a configMap that should be mutated 05/01/23 23:56:07.348
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:56:07.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1725" for this suite. 05/01/23 23:56:07.783
STEP: Destroying namespace "webhook-1725-markers" for this suite. 05/01/23 23:56:07.89
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":229,"skipped":4205,"failed":0}
------------------------------
• [SLOW TEST] [7.072 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:01.382
    May  1 23:56:01.382: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/01/23 23:56:01.383
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:01.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:01.912
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/01/23 23:56:02.342
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/01/23 23:56:02.623
    STEP: Deploying the webhook pod 05/01/23 23:56:02.732
    STEP: Wait for the deployment to be ready 05/01/23 23:56:02.948
    May  1 23:56:03.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/01/23 23:56:05.371
    STEP: Verifying the service has paired with the endpoint 05/01/23 23:56:05.483
    May  1 23:56:06.483: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 05/01/23 23:56:06.589
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 05/01/23 23:56:06.912
    STEP: Creating a configMap that should not be mutated 05/01/23 23:56:07.022
    STEP: Patching a mutating webhook configuration's rules to include the create operation 05/01/23 23:56:07.237
    STEP: Creating a configMap that should be mutated 05/01/23 23:56:07.348
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:56:07.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1725" for this suite. 05/01/23 23:56:07.783
    STEP: Destroying namespace "webhook-1725-markers" for this suite. 05/01/23 23:56:07.89
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:08.454
May  1 23:56:08.455: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/01/23 23:56:08.456
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:08.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:08.985
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 05/01/23 23:56:09.194
May  1 23:56:09.305: INFO: created test-pod-1
May  1 23:56:09.412: INFO: created test-pod-2
May  1 23:56:09.520: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 05/01/23 23:56:09.52
May  1 23:56:09.520: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6846' to be running and ready
May  1 23:56:09.837: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May  1 23:56:09.837: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May  1 23:56:09.837: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May  1 23:56:09.837: INFO: 0 / 3 pods in namespace 'pods-6846' are running and ready (0 seconds elapsed)
May  1 23:56:09.837: INFO: expected 0 pod replicas in namespace 'pods-6846', 0 are Running and Ready.
May  1 23:56:09.837: INFO: POD         NODE                 PHASE    GRACE  CONDITIONS
May  1 23:56:09.837: INFO: test-pod-1  i-0627b78ff917cf2ae  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  }]
May  1 23:56:09.837: INFO: test-pod-2  i-02d061b30635c230c  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  }]
May  1 23:56:09.837: INFO: test-pod-3  i-0627b78ff917cf2ae  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  }]
May  1 23:56:09.837: INFO: 
May  1 23:56:12.154: INFO: 3 / 3 pods in namespace 'pods-6846' are running and ready (2 seconds elapsed)
May  1 23:56:12.154: INFO: expected 0 pod replicas in namespace 'pods-6846', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 05/01/23 23:56:12.273
May  1 23:56:12.380: INFO: Pod quantity 3 is different from expected quantity 0
May  1 23:56:13.486: INFO: Pod quantity 2 is different from expected quantity 0
May  1 23:56:14.486: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  1 23:56:15.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6846" for this suite. 05/01/23 23:56:15.6
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":230,"skipped":4217,"failed":0}
------------------------------
• [SLOW TEST] [7.253 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:08.454
    May  1 23:56:08.455: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/01/23 23:56:08.456
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:08.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:08.985
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 05/01/23 23:56:09.194
    May  1 23:56:09.305: INFO: created test-pod-1
    May  1 23:56:09.412: INFO: created test-pod-2
    May  1 23:56:09.520: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 05/01/23 23:56:09.52
    May  1 23:56:09.520: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6846' to be running and ready
    May  1 23:56:09.837: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    May  1 23:56:09.837: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    May  1 23:56:09.837: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    May  1 23:56:09.837: INFO: 0 / 3 pods in namespace 'pods-6846' are running and ready (0 seconds elapsed)
    May  1 23:56:09.837: INFO: expected 0 pod replicas in namespace 'pods-6846', 0 are Running and Ready.
    May  1 23:56:09.837: INFO: POD         NODE                 PHASE    GRACE  CONDITIONS
    May  1 23:56:09.837: INFO: test-pod-1  i-0627b78ff917cf2ae  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  }]
    May  1 23:56:09.837: INFO: test-pod-2  i-02d061b30635c230c  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  }]
    May  1 23:56:09.837: INFO: test-pod-3  i-0627b78ff917cf2ae  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-05-01 23:56:09 +0000 UTC  }]
    May  1 23:56:09.837: INFO: 
    May  1 23:56:12.154: INFO: 3 / 3 pods in namespace 'pods-6846' are running and ready (2 seconds elapsed)
    May  1 23:56:12.154: INFO: expected 0 pod replicas in namespace 'pods-6846', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 05/01/23 23:56:12.273
    May  1 23:56:12.380: INFO: Pod quantity 3 is different from expected quantity 0
    May  1 23:56:13.486: INFO: Pod quantity 2 is different from expected quantity 0
    May  1 23:56:14.486: INFO: Pod quantity 1 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  1 23:56:15.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6846" for this suite. 05/01/23 23:56:15.6
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:15.709
May  1 23:56:15.709: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename aggregator 05/01/23 23:56:15.71
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:16.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:16.239
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
May  1 23:56:16.450: INFO: >>> kubeConfig: /root/.kube/config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 05/01/23 23:56:16.452
May  1 23:56:18.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:20.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:22.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:24.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:26.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:28.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:30.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:32.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:34.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:36.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:38.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  1 23:56:40.910: INFO: Waited 424.585732ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 05/01/23 23:56:42.09
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 05/01/23 23:56:42.196
STEP: List APIServices 05/01/23 23:56:42.304
May  1 23:56:42.412: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
May  1 23:56:44.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5034" for this suite. 05/01/23 23:56:44.678
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":231,"skipped":4224,"failed":0}
------------------------------
• [SLOW TEST] [29.079 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:15.709
    May  1 23:56:15.709: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename aggregator 05/01/23 23:56:15.71
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:16.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:16.239
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    May  1 23:56:16.450: INFO: >>> kubeConfig: /root/.kube/config
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 05/01/23 23:56:16.452
    May  1 23:56:18.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:20.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:22.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:24.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:26.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:28.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:30.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:32.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:34.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:36.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:38.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 1, 23, 56, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    May  1 23:56:40.910: INFO: Waited 424.585732ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 05/01/23 23:56:42.09
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 05/01/23 23:56:42.196
    STEP: List APIServices 05/01/23 23:56:42.304
    May  1 23:56:42.412: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    May  1 23:56:44.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-5034" for this suite. 05/01/23 23:56:44.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:44.79
May  1 23:56:44.790: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test 05/01/23 23:56:44.792
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:45.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:45.323
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
May  1 23:56:45.650: INFO: Waiting up to 5m0s for pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc" in namespace "security-context-test-8107" to be "Succeeded or Failed"
May  1 23:56:45.756: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc": Phase="Pending", Reason="", readiness=false. Elapsed: 105.708538ms
May  1 23:56:47.864: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213603453s
May  1 23:56:49.862: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212482346s
May  1 23:56:49.862: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
May  1 23:56:49.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8107" for this suite. 05/01/23 23:56:49.97
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":232,"skipped":4246,"failed":0}
------------------------------
• [SLOW TEST] [5.289 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:44.79
    May  1 23:56:44.790: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename security-context-test 05/01/23 23:56:44.792
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:45.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:45.323
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    May  1 23:56:45.650: INFO: Waiting up to 5m0s for pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc" in namespace "security-context-test-8107" to be "Succeeded or Failed"
    May  1 23:56:45.756: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc": Phase="Pending", Reason="", readiness=false. Elapsed: 105.708538ms
    May  1 23:56:47.864: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213603453s
    May  1 23:56:49.862: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212482346s
    May  1 23:56:49.862: INFO: Pod "busybox-user-65534-4de94499-774e-4271-b07a-f43d7a5db2fc" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    May  1 23:56:49.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8107" for this suite. 05/01/23 23:56:49.97
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:50.08
May  1 23:56:50.080: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/01/23 23:56:50.082
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:50.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:50.61
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
STEP: creating a collection of services 05/01/23 23:56:50.82
May  1 23:56:50.821: INFO: Creating e2e-svc-a-2bhz7
May  1 23:56:50.931: INFO: Creating e2e-svc-b-qwp5w
May  1 23:56:51.042: INFO: Creating e2e-svc-c-xjvqx
STEP: deleting service collection 05/01/23 23:56:51.262
May  1 23:56:51.496: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  1 23:56:51.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-246" for this suite. 05/01/23 23:56:51.603
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":233,"skipped":4255,"failed":0}
------------------------------
• [1.629 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:50.08
    May  1 23:56:50.080: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/01/23 23:56:50.082
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:50.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:50.61
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3620
    STEP: creating a collection of services 05/01/23 23:56:50.82
    May  1 23:56:50.821: INFO: Creating e2e-svc-a-2bhz7
    May  1 23:56:50.931: INFO: Creating e2e-svc-b-qwp5w
    May  1 23:56:51.042: INFO: Creating e2e-svc-c-xjvqx
    STEP: deleting service collection 05/01/23 23:56:51.262
    May  1 23:56:51.496: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  1 23:56:51.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-246" for this suite. 05/01/23 23:56:51.603
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:51.71
May  1 23:56:51.711: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/01/23 23:56:51.712
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:52.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:52.24
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-9468/configmap-test-789a8e27-1582-4c3d-b793-df19883ef8a4 05/01/23 23:56:52.45
STEP: Creating a pod to test consume configMaps 05/01/23 23:56:52.557
May  1 23:56:52.666: INFO: Waiting up to 5m0s for pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e" in namespace "configmap-9468" to be "Succeeded or Failed"
May  1 23:56:52.772: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e": Phase="Pending", Reason="", readiness=false. Elapsed: 105.865619ms
May  1 23:56:54.879: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.212568575s
May  1 23:56:56.880: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.213379474s
STEP: Saw pod success 05/01/23 23:56:56.88
May  1 23:56:56.880: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e" satisfied condition "Succeeded or Failed"
May  1 23:56:56.989: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e container env-test: <nil>
STEP: delete the pod 05/01/23 23:56:57.103
May  1 23:56:57.218: INFO: Waiting for pod pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e to disappear
May  1 23:56:57.324: INFO: Pod pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
May  1 23:56:57.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9468" for this suite. 05/01/23 23:56:57.431
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":234,"skipped":4260,"failed":0}
------------------------------
• [SLOW TEST] [5.931 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:51.71
    May  1 23:56:51.711: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/01/23 23:56:51.712
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:52.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:52.24
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-9468/configmap-test-789a8e27-1582-4c3d-b793-df19883ef8a4 05/01/23 23:56:52.45
    STEP: Creating a pod to test consume configMaps 05/01/23 23:56:52.557
    May  1 23:56:52.666: INFO: Waiting up to 5m0s for pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e" in namespace "configmap-9468" to be "Succeeded or Failed"
    May  1 23:56:52.772: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e": Phase="Pending", Reason="", readiness=false. Elapsed: 105.865619ms
    May  1 23:56:54.879: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.212568575s
    May  1 23:56:56.880: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.213379474s
    STEP: Saw pod success 05/01/23 23:56:56.88
    May  1 23:56:56.880: INFO: Pod "pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e" satisfied condition "Succeeded or Failed"
    May  1 23:56:56.989: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e container env-test: <nil>
    STEP: delete the pod 05/01/23 23:56:57.103
    May  1 23:56:57.218: INFO: Waiting for pod pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e to disappear
    May  1 23:56:57.324: INFO: Pod pod-configmaps-deb1198c-95db-43d7-95ab-4d3554d4d05e no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    May  1 23:56:57.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9468" for this suite. 05/01/23 23:56:57.431
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:56:57.642
May  1 23:56:57.643: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:56:57.645
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:57.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:58.173
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
May  1 23:56:58.384: INFO: >>> kubeConfig: /root/.kube/config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 05/01/23 23:57:03.695
May  1 23:57:03.695: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 create -f -'
May  1 23:57:05.453: INFO: stderr: ""
May  1 23:57:05.453: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May  1 23:57:05.453: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 delete e2e-test-crd-publish-openapi-4939-crds test-cr'
May  1 23:57:06.003: INFO: stderr: ""
May  1 23:57:06.003: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
May  1 23:57:06.003: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 apply -f -'
May  1 23:57:06.939: INFO: stderr: ""
May  1 23:57:06.939: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May  1 23:57:06.939: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 delete e2e-test-crd-publish-openapi-4939-crds test-cr'
May  1 23:57:07.473: INFO: stderr: ""
May  1 23:57:07.473: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 05/01/23 23:57:07.473
May  1 23:57:07.474: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 explain e2e-test-crd-publish-openapi-4939-crds'
May  1 23:57:08.080: INFO: stderr: ""
May  1 23:57:08.080: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4939-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  1 23:57:15.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5087" for this suite. 05/01/23 23:57:15.782
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":235,"skipped":4261,"failed":0}
------------------------------
• [SLOW TEST] [18.247 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:56:57.642
    May  1 23:56:57.643: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/01/23 23:56:57.645
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:56:57.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:56:58.173
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    May  1 23:56:58.384: INFO: >>> kubeConfig: /root/.kube/config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 05/01/23 23:57:03.695
    May  1 23:57:03.695: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 create -f -'
    May  1 23:57:05.453: INFO: stderr: ""
    May  1 23:57:05.453: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    May  1 23:57:05.453: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 delete e2e-test-crd-publish-openapi-4939-crds test-cr'
    May  1 23:57:06.003: INFO: stderr: ""
    May  1 23:57:06.003: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    May  1 23:57:06.003: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 apply -f -'
    May  1 23:57:06.939: INFO: stderr: ""
    May  1 23:57:06.939: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    May  1 23:57:06.939: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 --namespace=crd-publish-openapi-5087 delete e2e-test-crd-publish-openapi-4939-crds test-cr'
    May  1 23:57:07.473: INFO: stderr: ""
    May  1 23:57:07.473: INFO: stdout: "e2e-test-crd-publish-openapi-4939-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 05/01/23 23:57:07.473
    May  1 23:57:07.474: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-5087 explain e2e-test-crd-publish-openapi-4939-crds'
    May  1 23:57:08.080: INFO: stderr: ""
    May  1 23:57:08.080: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4939-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  1 23:57:15.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5087" for this suite. 05/01/23 23:57:15.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:57:15.891
May  1 23:57:15.891: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/01/23 23:57:15.892
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:57:16.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:57:16.422
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 05/01/23 23:57:16.633
May  1 23:57:16.633: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 create -f -'
May  1 23:57:18.118: INFO: stderr: ""
May  1 23:57:18.118: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:57:18.118
May  1 23:57:18.118: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
May  1 23:57:18.650: INFO: stderr: ""
May  1 23:57:18.650: INFO: stdout: "update-demo-nautilus-dcg97 update-demo-nautilus-qgckn "
May  1 23:57:18.650: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-dcg97 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:57:19.080: INFO: stderr: ""
May  1 23:57:19.080: INFO: stdout: "true"
May  1 23:57:19.080: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-dcg97 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:57:19.503: INFO: stderr: ""
May  1 23:57:19.503: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:57:19.503: INFO: validating pod update-demo-nautilus-dcg97
May  1 23:57:19.610: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:57:19.610: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:57:19.610: INFO: update-demo-nautilus-dcg97 is verified up and running
May  1 23:57:19.611: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-qgckn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
May  1 23:57:20.035: INFO: stderr: ""
May  1 23:57:20.035: INFO: stdout: "true"
May  1 23:57:20.035: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-qgckn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
May  1 23:57:20.455: INFO: stderr: ""
May  1 23:57:20.455: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
May  1 23:57:20.455: INFO: validating pod update-demo-nautilus-qgckn
May  1 23:57:20.562: INFO: got data: {
  "image": "nautilus.jpg"
}

May  1 23:57:20.562: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  1 23:57:20.562: INFO: update-demo-nautilus-qgckn is verified up and running
STEP: using delete to clean up resources 05/01/23 23:57:20.562
May  1 23:57:20.562: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 delete --grace-period=0 --force -f -'
May  1 23:57:21.084: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  1 23:57:21.084: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  1 23:57:21.084: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get rc,svc -l name=update-demo --no-headers'
May  1 23:57:21.609: INFO: stderr: "No resources found in kubectl-7957 namespace.\n"
May  1 23:57:21.609: INFO: stdout: ""
May  1 23:57:21.609: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  1 23:57:22.045: INFO: stderr: ""
May  1 23:57:22.045: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  1 23:57:22.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7957" for this suite. 05/01/23 23:57:22.152
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":236,"skipped":4294,"failed":0}
------------------------------
• [SLOW TEST] [6.368 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:57:15.891
    May  1 23:57:15.891: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/01/23 23:57:15.892
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:57:16.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:57:16.422
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 05/01/23 23:57:16.633
    May  1 23:57:16.633: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 create -f -'
    May  1 23:57:18.118: INFO: stderr: ""
    May  1 23:57:18.118: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 05/01/23 23:57:18.118
    May  1 23:57:18.118: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    May  1 23:57:18.650: INFO: stderr: ""
    May  1 23:57:18.650: INFO: stdout: "update-demo-nautilus-dcg97 update-demo-nautilus-qgckn "
    May  1 23:57:18.650: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-dcg97 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:57:19.080: INFO: stderr: ""
    May  1 23:57:19.080: INFO: stdout: "true"
    May  1 23:57:19.080: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-dcg97 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:57:19.503: INFO: stderr: ""
    May  1 23:57:19.503: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:57:19.503: INFO: validating pod update-demo-nautilus-dcg97
    May  1 23:57:19.610: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:57:19.610: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:57:19.610: INFO: update-demo-nautilus-dcg97 is verified up and running
    May  1 23:57:19.611: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-qgckn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    May  1 23:57:20.035: INFO: stderr: ""
    May  1 23:57:20.035: INFO: stdout: "true"
    May  1 23:57:20.035: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods update-demo-nautilus-qgckn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    May  1 23:57:20.455: INFO: stderr: ""
    May  1 23:57:20.455: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    May  1 23:57:20.455: INFO: validating pod update-demo-nautilus-qgckn
    May  1 23:57:20.562: INFO: got data: {
      "image": "nautilus.jpg"
    }

    May  1 23:57:20.562: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    May  1 23:57:20.562: INFO: update-demo-nautilus-qgckn is verified up and running
    STEP: using delete to clean up resources 05/01/23 23:57:20.562
    May  1 23:57:20.562: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 delete --grace-period=0 --force -f -'
    May  1 23:57:21.084: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  1 23:57:21.084: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    May  1 23:57:21.084: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get rc,svc -l name=update-demo --no-headers'
    May  1 23:57:21.609: INFO: stderr: "No resources found in kubectl-7957 namespace.\n"
    May  1 23:57:21.609: INFO: stdout: ""
    May  1 23:57:21.609: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7957 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    May  1 23:57:22.045: INFO: stderr: ""
    May  1 23:57:22.045: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  1 23:57:22.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7957" for this suite. 05/01/23 23:57:22.152
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:57:22.261
May  1 23:57:22.261: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/01/23 23:57:22.262
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:57:22.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:57:22.791
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 05/01/23 23:57:23.002
May  1 23:57:23.111: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040" in namespace "projected-6716" to be "Succeeded or Failed"
May  1 23:57:23.217: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040": Phase="Pending", Reason="", readiness=false. Elapsed: 106.149132ms
May  1 23:57:25.325: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213563959s
May  1 23:57:27.323: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212247032s
STEP: Saw pod success 05/01/23 23:57:27.323
May  1 23:57:27.324: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040" satisfied condition "Succeeded or Failed"
May  1 23:57:27.430: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040 container client-container: <nil>
STEP: delete the pod 05/01/23 23:57:27.544
May  1 23:57:27.660: INFO: Waiting for pod downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040 to disappear
May  1 23:57:27.766: INFO: Pod downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  1 23:57:27.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6716" for this suite. 05/01/23 23:57:27.873
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":237,"skipped":4321,"failed":0}
------------------------------
• [SLOW TEST] [5.721 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:57:22.261
    May  1 23:57:22.261: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/01/23 23:57:22.262
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:57:22.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:57:22.791
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 05/01/23 23:57:23.002
    May  1 23:57:23.111: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040" in namespace "projected-6716" to be "Succeeded or Failed"
    May  1 23:57:23.217: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040": Phase="Pending", Reason="", readiness=false. Elapsed: 106.149132ms
    May  1 23:57:25.325: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213563959s
    May  1 23:57:27.323: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.212247032s
    STEP: Saw pod success 05/01/23 23:57:27.323
    May  1 23:57:27.324: INFO: Pod "downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040" satisfied condition "Succeeded or Failed"
    May  1 23:57:27.430: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040 container client-container: <nil>
    STEP: delete the pod 05/01/23 23:57:27.544
    May  1 23:57:27.660: INFO: Waiting for pod downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040 to disappear
    May  1 23:57:27.766: INFO: Pod downwardapi-volume-ebbf7d40-e3e5-49dd-9e4e-73b9cd6b9040 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  1 23:57:27.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6716" for this suite. 05/01/23 23:57:27.873
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:57:27.985
May  1 23:57:27.985: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts 05/01/23 23:57:27.986
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:57:28.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:57:28.515
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
May  1 23:57:28.943: INFO: created pod
May  1 23:57:28.943: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-5540" to be "Succeeded or Failed"
May  1 23:57:29.049: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 105.988074ms
May  1 23:57:31.157: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=true. Elapsed: 2.21365038s
May  1 23:57:33.156: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 4.213198468s
May  1 23:57:35.156: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.212897779s
STEP: Saw pod success 05/01/23 23:57:35.156
May  1 23:57:35.156: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
May  1 23:58:05.157: INFO: polling logs
May  1 23:58:05.266: INFO: Pod logs: 
I0501 23:57:29.592397       1 log.go:195] OK: Got token
I0501 23:57:29.592516       1 log.go:195] validating with in-cluster discovery
I0501 23:57:29.592901       1 log.go:195] OK: got issuer https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io
I0501 23:57:29.592943       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io", Subject:"system:serviceaccount:svcaccounts-5540:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682986049, NotBefore:1682985449, IssuedAt:1682985449, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5540", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d604f73b-6bfa-4fe3-8102-a9de1cb24af4"}}}
I0501 23:57:29.887952       1 log.go:195] failed to validate with in-cluster discovery: Get "https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/.well-known/openid-configuration": x509: certificate signed by unknown authority
I0501 23:57:29.887970       1 log.go:195] falling back to validating with external discovery
I0501 23:57:29.888100       1 log.go:195] OK: got issuer https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io
I0501 23:57:29.888129       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io", Subject:"system:serviceaccount:svcaccounts-5540:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682986049, NotBefore:1682985449, IssuedAt:1682985449, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5540", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d604f73b-6bfa-4fe3-8102-a9de1cb24af4"}}}
I0501 23:57:30.515103       1 log.go:195] OK: Constructed OIDC provider for issuer https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io
I0501 23:57:30.679439       1 log.go:195] OK: Validated signature on JWT
I0501 23:57:30.679540       1 log.go:195] OK: Got valid claims from token!
I0501 23:57:30.679595       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io", Subject:"system:serviceaccount:svcaccounts-5540:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682986049, NotBefore:1682985449, IssuedAt:1682985449, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5540", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d604f73b-6bfa-4fe3-8102-a9de1cb24af4"}}}

May  1 23:58:05.266: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
May  1 23:58:05.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5540" for this suite. 05/01/23 23:58:05.48
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":238,"skipped":4357,"failed":0}
------------------------------
• [SLOW TEST] [37.606 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:57:27.985
    May  1 23:57:27.985: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svcaccounts 05/01/23 23:57:27.986
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:57:28.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:57:28.515
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    May  1 23:57:28.943: INFO: created pod
    May  1 23:57:28.943: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-5540" to be "Succeeded or Failed"
    May  1 23:57:29.049: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 105.988074ms
    May  1 23:57:31.157: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=true. Elapsed: 2.21365038s
    May  1 23:57:33.156: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 4.213198468s
    May  1 23:57:35.156: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.212897779s
    STEP: Saw pod success 05/01/23 23:57:35.156
    May  1 23:57:35.156: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    May  1 23:58:05.157: INFO: polling logs
    May  1 23:58:05.266: INFO: Pod logs: 
    I0501 23:57:29.592397       1 log.go:195] OK: Got token
    I0501 23:57:29.592516       1 log.go:195] validating with in-cluster discovery
    I0501 23:57:29.592901       1 log.go:195] OK: got issuer https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io
    I0501 23:57:29.592943       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io", Subject:"system:serviceaccount:svcaccounts-5540:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682986049, NotBefore:1682985449, IssuedAt:1682985449, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5540", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d604f73b-6bfa-4fe3-8102-a9de1cb24af4"}}}
    I0501 23:57:29.887952       1 log.go:195] failed to validate with in-cluster discovery: Get "https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/.well-known/openid-configuration": x509: certificate signed by unknown authority
    I0501 23:57:29.887970       1 log.go:195] falling back to validating with external discovery
    I0501 23:57:29.888100       1 log.go:195] OK: got issuer https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io
    I0501 23:57:29.888129       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io", Subject:"system:serviceaccount:svcaccounts-5540:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682986049, NotBefore:1682985449, IssuedAt:1682985449, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5540", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d604f73b-6bfa-4fe3-8102-a9de1cb24af4"}}}
    I0501 23:57:30.515103       1 log.go:195] OK: Constructed OIDC provider for issuer https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io
    I0501 23:57:30.679439       1 log.go:195] OK: Validated signature on JWT
    I0501 23:57:30.679540       1 log.go:195] OK: Got valid claims from token!
    I0501 23:57:30.679595       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://k8s-kops-prow.s3.us-west-1.amazonaws.com/discovery/e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io", Subject:"system:serviceaccount:svcaccounts-5540:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682986049, NotBefore:1682985449, IssuedAt:1682985449, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5540", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"d604f73b-6bfa-4fe3-8102-a9de1cb24af4"}}}

    May  1 23:58:05.266: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    May  1 23:58:05.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5540" for this suite. 05/01/23 23:58:05.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:58:05.591
May  1 23:58:05.591: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime 05/01/23 23:58:05.592
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:05.912
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:06.122
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 05/01/23 23:58:06.445
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 05/01/23 23:58:26.473
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 05/01/23 23:58:26.58
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 05/01/23 23:58:26.793
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 05/01/23 23:58:26.794
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 05/01/23 23:58:27.124
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 05/01/23 23:58:29.444
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 05/01/23 23:58:31.761
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 05/01/23 23:58:31.972
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 05/01/23 23:58:31.973
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 05/01/23 23:58:32.297
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 05/01/23 23:58:32.402
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 05/01/23 23:58:35.824
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 05/01/23 23:58:36.034
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 05/01/23 23:58:36.035
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
May  1 23:58:36.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3363" for this suite. 05/01/23 23:58:36.671
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":239,"skipped":4363,"failed":0}
------------------------------
• [SLOW TEST] [31.289 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:58:05.591
    May  1 23:58:05.591: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-runtime 05/01/23 23:58:05.592
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:05.912
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:06.122
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 05/01/23 23:58:06.445
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 05/01/23 23:58:26.473
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 05/01/23 23:58:26.58
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 05/01/23 23:58:26.793
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 05/01/23 23:58:26.794
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 05/01/23 23:58:27.124
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 05/01/23 23:58:29.444
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 05/01/23 23:58:31.761
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 05/01/23 23:58:31.972
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 05/01/23 23:58:31.973
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 05/01/23 23:58:32.297
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 05/01/23 23:58:32.402
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 05/01/23 23:58:35.824
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 05/01/23 23:58:36.034
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 05/01/23 23:58:36.035
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    May  1 23:58:36.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3363" for this suite. 05/01/23 23:58:36.671
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:58:36.881
May  1 23:58:36.881: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename conformance-tests 05/01/23 23:58:36.882
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:37.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:37.406
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 05/01/23 23:58:37.614
May  1 23:58:37.615: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
May  1 23:58:37.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-259" for this suite. 05/01/23 23:58:37.931
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":240,"skipped":4367,"failed":0}
------------------------------
• [1.158 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:58:36.881
    May  1 23:58:36.881: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename conformance-tests 05/01/23 23:58:36.882
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:37.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:37.406
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 05/01/23 23:58:37.614
    May  1 23:58:37.615: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    May  1 23:58:37.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-259" for this suite. 05/01/23 23:58:37.931
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:58:38.04
May  1 23:58:38.040: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/01/23 23:58:38.042
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:38.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:38.566
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 05/01/23 23:58:38.775
STEP: delete the rc 05/01/23 23:58:43.988
STEP: wait for all pods to be garbage collected 05/01/23 23:58:44.095
STEP: Gathering metrics 05/01/23 23:58:49.305
May  1 23:58:49.532: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
May  1 23:58:49.638: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 105.585115ms
May  1 23:58:49.638: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
May  1 23:58:49.638: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
May  1 23:58:50.559: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  1 23:58:50.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5890" for this suite. 05/01/23 23:58:50.666
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":241,"skipped":4380,"failed":0}
------------------------------
• [SLOW TEST] [12.732 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:58:38.04
    May  1 23:58:38.040: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/01/23 23:58:38.042
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:38.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:38.566
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 05/01/23 23:58:38.775
    STEP: delete the rc 05/01/23 23:58:43.988
    STEP: wait for all pods to be garbage collected 05/01/23 23:58:44.095
    STEP: Gathering metrics 05/01/23 23:58:49.305
    May  1 23:58:49.532: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
    May  1 23:58:49.638: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 105.585115ms
    May  1 23:58:49.638: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
    May  1 23:58:49.638: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
    May  1 23:58:50.559: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  1 23:58:50.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5890" for this suite. 05/01/23 23:58:50.666
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:58:50.774
May  1 23:58:50.774: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/01/23 23:58:50.776
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:51.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:51.3
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 05/01/23 23:58:51.509
STEP: Getting a ResourceQuota 05/01/23 23:58:51.615
STEP: Listing all ResourceQuotas with LabelSelector 05/01/23 23:58:51.72
STEP: Patching the ResourceQuota 05/01/23 23:58:51.826
STEP: Deleting a Collection of ResourceQuotas 05/01/23 23:58:51.935
STEP: Verifying the deleted ResourceQuota 05/01/23 23:58:52.044
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  1 23:58:52.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5846" for this suite. 05/01/23 23:58:52.255
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":242,"skipped":4400,"failed":0}
------------------------------
• [1.588 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:58:50.774
    May  1 23:58:50.774: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/01/23 23:58:50.776
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:51.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:51.3
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 05/01/23 23:58:51.509
    STEP: Getting a ResourceQuota 05/01/23 23:58:51.615
    STEP: Listing all ResourceQuotas with LabelSelector 05/01/23 23:58:51.72
    STEP: Patching the ResourceQuota 05/01/23 23:58:51.826
    STEP: Deleting a Collection of ResourceQuotas 05/01/23 23:58:51.935
    STEP: Verifying the deleted ResourceQuota 05/01/23 23:58:52.044
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  1 23:58:52.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5846" for this suite. 05/01/23 23:58:52.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:58:52.363
May  1 23:58:52.363: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename ingressclass 05/01/23 23:58:52.364
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:52.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:52.89
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 05/01/23 23:58:53.098
STEP: getting /apis/networking.k8s.io 05/01/23 23:58:53.305
STEP: getting /apis/networking.k8s.iov1 05/01/23 23:58:53.409
STEP: creating 05/01/23 23:58:53.513
STEP: getting 05/01/23 23:58:53.833
STEP: listing 05/01/23 23:58:53.939
STEP: watching 05/01/23 23:58:54.044
May  1 23:58:54.044: INFO: starting watch
STEP: patching 05/01/23 23:58:54.148
STEP: updating 05/01/23 23:58:54.256
May  1 23:58:54.362: INFO: waiting for watch events with expected annotations
May  1 23:58:54.362: INFO: saw patched and updated annotations
STEP: deleting 05/01/23 23:58:54.363
STEP: deleting a collection 05/01/23 23:58:54.678
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
May  1 23:58:54.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5077" for this suite. 05/01/23 23:58:55
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":243,"skipped":4414,"failed":0}
------------------------------
• [2.744 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:58:52.363
    May  1 23:58:52.363: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename ingressclass 05/01/23 23:58:52.364
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:52.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:52.89
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 05/01/23 23:58:53.098
    STEP: getting /apis/networking.k8s.io 05/01/23 23:58:53.305
    STEP: getting /apis/networking.k8s.iov1 05/01/23 23:58:53.409
    STEP: creating 05/01/23 23:58:53.513
    STEP: getting 05/01/23 23:58:53.833
    STEP: listing 05/01/23 23:58:53.939
    STEP: watching 05/01/23 23:58:54.044
    May  1 23:58:54.044: INFO: starting watch
    STEP: patching 05/01/23 23:58:54.148
    STEP: updating 05/01/23 23:58:54.256
    May  1 23:58:54.362: INFO: waiting for watch events with expected annotations
    May  1 23:58:54.362: INFO: saw patched and updated annotations
    STEP: deleting 05/01/23 23:58:54.363
    STEP: deleting a collection 05/01/23 23:58:54.678
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    May  1 23:58:54.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-5077" for this suite. 05/01/23 23:58:55
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:58:55.108
May  1 23:58:55.109: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces 05/01/23 23:58:55.11
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:55.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:55.635
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 05/01/23 23:58:55.844
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:56.16
STEP: Creating a service in the namespace 05/01/23 23:58:56.369
STEP: Deleting the namespace 05/01/23 23:58:56.48
STEP: Waiting for the namespace to be removed. 05/01/23 23:58:56.587
STEP: Recreating the namespace 05/01/23 23:59:02.693
STEP: Verifying there is no service in the namespace 05/01/23 23:59:03.01
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
May  1 23:59:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9481" for this suite. 05/01/23 23:59:03.222
STEP: Destroying namespace "nsdeletetest-8676" for this suite. 05/01/23 23:59:03.33
May  1 23:59:03.435: INFO: Namespace nsdeletetest-8676 was already deleted
STEP: Destroying namespace "nsdeletetest-6059" for this suite. 05/01/23 23:59:03.435
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":244,"skipped":4456,"failed":0}
------------------------------
• [SLOW TEST] [8.434 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:58:55.108
    May  1 23:58:55.109: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename namespaces 05/01/23 23:58:55.11
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:55.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:58:55.635
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 05/01/23 23:58:55.844
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:58:56.16
    STEP: Creating a service in the namespace 05/01/23 23:58:56.369
    STEP: Deleting the namespace 05/01/23 23:58:56.48
    STEP: Waiting for the namespace to be removed. 05/01/23 23:58:56.587
    STEP: Recreating the namespace 05/01/23 23:59:02.693
    STEP: Verifying there is no service in the namespace 05/01/23 23:59:03.01
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    May  1 23:59:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9481" for this suite. 05/01/23 23:59:03.222
    STEP: Destroying namespace "nsdeletetest-8676" for this suite. 05/01/23 23:59:03.33
    May  1 23:59:03.435: INFO: Namespace nsdeletetest-8676 was already deleted
    STEP: Destroying namespace "nsdeletetest-6059" for this suite. 05/01/23 23:59:03.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/01/23 23:59:03.543
May  1 23:59:03.543: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/01/23 23:59:03.544
STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:59:03.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:59:04.07
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  2 00:00:04.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1332" for this suite. 05/02/23 00:00:04.599
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":245,"skipped":4471,"failed":0}
------------------------------
• [SLOW TEST] [61.162 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/01/23 23:59:03.543
    May  1 23:59:03.543: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/01/23 23:59:03.544
    STEP: Waiting for a default service account to be provisioned in namespace 05/01/23 23:59:03.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/01/23 23:59:04.07
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  2 00:00:04.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1332" for this suite. 05/02/23 00:00:04.599
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:00:04.712
May  2 00:00:04.712: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/02/23 00:00:04.713
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:05.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:05.237
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-aede33d1-76c4-4a87-ae65-e8d516d75c30 05/02/23 00:00:05.446
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
May  2 00:00:05.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3014" for this suite. 05/02/23 00:00:05.657
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":246,"skipped":4582,"failed":0}
------------------------------
• [1.052 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:00:04.712
    May  2 00:00:04.712: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/02/23 00:00:04.713
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:05.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:05.237
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-aede33d1-76c4-4a87-ae65-e8d516d75c30 05/02/23 00:00:05.446
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    May  2 00:00:05.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3014" for this suite. 05/02/23 00:00:05.657
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:00:05.765
May  2 00:00:05.765: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset 05/02/23 00:00:05.767
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:06.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:06.294
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
May  2 00:00:06.866: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 05/02/23 00:00:06.866
May  2 00:00:06.867: INFO: Waiting up to 5m0s for pod "test-rs-ttkmg" in namespace "replicaset-9437" to be "running"
May  2 00:00:06.974: INFO: Pod "test-rs-ttkmg": Phase="Pending", Reason="", readiness=false. Elapsed: 107.187512ms
May  2 00:00:09.079: INFO: Pod "test-rs-ttkmg": Phase="Running", Reason="", readiness=true. Elapsed: 2.212689675s
May  2 00:00:09.079: INFO: Pod "test-rs-ttkmg" satisfied condition "running"
STEP: Scaling up "test-rs" replicaset  05/02/23 00:00:09.079
May  2 00:00:09.291: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 05/02/23 00:00:09.291
W0502 00:00:09.400109    6969 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
May  2 00:00:09.504: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 1, AvailableReplicas 1
May  2 00:00:09.504: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 1, AvailableReplicas 1
May  2 00:00:09.504: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 1, AvailableReplicas 1
May  2 00:00:11.031: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 2, AvailableReplicas 2
May  2 00:00:11.132: INFO: observed Replicaset test-rs in namespace replicaset-9437 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
May  2 00:00:11.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9437" for this suite. 05/02/23 00:00:11.238
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":247,"skipped":4587,"failed":0}
------------------------------
• [SLOW TEST] [5.580 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:00:05.765
    May  2 00:00:05.765: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replicaset 05/02/23 00:00:05.767
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:06.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:06.294
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    May  2 00:00:06.866: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 05/02/23 00:00:06.866
    May  2 00:00:06.867: INFO: Waiting up to 5m0s for pod "test-rs-ttkmg" in namespace "replicaset-9437" to be "running"
    May  2 00:00:06.974: INFO: Pod "test-rs-ttkmg": Phase="Pending", Reason="", readiness=false. Elapsed: 107.187512ms
    May  2 00:00:09.079: INFO: Pod "test-rs-ttkmg": Phase="Running", Reason="", readiness=true. Elapsed: 2.212689675s
    May  2 00:00:09.079: INFO: Pod "test-rs-ttkmg" satisfied condition "running"
    STEP: Scaling up "test-rs" replicaset  05/02/23 00:00:09.079
    May  2 00:00:09.291: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 05/02/23 00:00:09.291
    W0502 00:00:09.400109    6969 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    May  2 00:00:09.504: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 1, AvailableReplicas 1
    May  2 00:00:09.504: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 1, AvailableReplicas 1
    May  2 00:00:09.504: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 1, AvailableReplicas 1
    May  2 00:00:11.031: INFO: observed ReplicaSet test-rs in namespace replicaset-9437 with ReadyReplicas 2, AvailableReplicas 2
    May  2 00:00:11.132: INFO: observed Replicaset test-rs in namespace replicaset-9437 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    May  2 00:00:11.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9437" for this suite. 05/02/23 00:00:11.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:00:11.347
May  2 00:00:11.347: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-webhook 05/02/23 00:00:11.348
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:11.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:11.871
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 05/02/23 00:00:12.079
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 05/02/23 00:00:12.633
STEP: Deploying the custom resource conversion webhook pod 05/02/23 00:00:12.74
STEP: Wait for the deployment to be ready 05/02/23 00:00:12.956
May  2 00:00:13.272: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/02/23 00:00:15.379
STEP: Verifying the service has paired with the endpoint 05/02/23 00:00:15.49
May  2 00:00:16.490: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
May  2 00:00:16.595: INFO: >>> kubeConfig: /root/.kube/config
STEP: Creating a v1 custom resource 05/02/23 00:00:19.146
STEP: v2 custom resource should be converted 05/02/23 00:00:19.253
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:00:19.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-861" for this suite. 05/02/23 00:00:19.784
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":248,"skipped":4632,"failed":0}
------------------------------
• [SLOW TEST] [9.101 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:00:11.347
    May  2 00:00:11.347: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-webhook 05/02/23 00:00:11.348
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:11.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:11.871
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 05/02/23 00:00:12.079
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 05/02/23 00:00:12.633
    STEP: Deploying the custom resource conversion webhook pod 05/02/23 00:00:12.74
    STEP: Wait for the deployment to be ready 05/02/23 00:00:12.956
    May  2 00:00:13.272: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 0, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/02/23 00:00:15.379
    STEP: Verifying the service has paired with the endpoint 05/02/23 00:00:15.49
    May  2 00:00:16.490: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    May  2 00:00:16.595: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Creating a v1 custom resource 05/02/23 00:00:19.146
    STEP: v2 custom resource should be converted 05/02/23 00:00:19.253
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:00:19.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-861" for this suite. 05/02/23 00:00:19.784
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:00:20.45
May  2 00:00:20.450: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/02/23 00:00:20.452
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:20.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:20.976
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 05/02/23 00:00:21.184
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 05/02/23 00:00:21.185
STEP: creating a pod to probe DNS 05/02/23 00:00:21.185
STEP: submitting the pod to kubernetes 05/02/23 00:00:21.185
May  2 00:00:21.292: INFO: Waiting up to 15m0s for pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe" in namespace "dns-2425" to be "running"
May  2 00:00:21.398: INFO: Pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 105.13744ms
May  2 00:00:23.505: INFO: Pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe": Phase="Running", Reason="", readiness=true. Elapsed: 2.213023662s
May  2 00:00:23.505: INFO: Pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe" satisfied condition "running"
STEP: retrieving the pod 05/02/23 00:00:23.505
STEP: looking for the results for each expected name from probers 05/02/23 00:00:23.61
May  2 00:00:24.033: INFO: DNS probes using dns-2425/dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe succeeded

STEP: deleting the pod 05/02/23 00:00:24.033
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  2 00:00:24.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2425" for this suite. 05/02/23 00:00:24.253
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":249,"skipped":4648,"failed":0}
------------------------------
• [3.910 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:00:20.45
    May  2 00:00:20.450: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/02/23 00:00:20.452
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:20.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:20.976
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     05/02/23 00:00:21.184
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     05/02/23 00:00:21.185
    STEP: creating a pod to probe DNS 05/02/23 00:00:21.185
    STEP: submitting the pod to kubernetes 05/02/23 00:00:21.185
    May  2 00:00:21.292: INFO: Waiting up to 15m0s for pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe" in namespace "dns-2425" to be "running"
    May  2 00:00:21.398: INFO: Pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 105.13744ms
    May  2 00:00:23.505: INFO: Pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe": Phase="Running", Reason="", readiness=true. Elapsed: 2.213023662s
    May  2 00:00:23.505: INFO: Pod "dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe" satisfied condition "running"
    STEP: retrieving the pod 05/02/23 00:00:23.505
    STEP: looking for the results for each expected name from probers 05/02/23 00:00:23.61
    May  2 00:00:24.033: INFO: DNS probes using dns-2425/dns-test-e0c5c957-4481-4574-ad88-a454b8a62cbe succeeded

    STEP: deleting the pod 05/02/23 00:00:24.033
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  2 00:00:24.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2425" for this suite. 05/02/23 00:00:24.253
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:00:24.361
May  2 00:00:24.361: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/02/23 00:00:24.363
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:24.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:24.887
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-5174 05/02/23 00:00:25.095
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[] 05/02/23 00:00:25.207
May  2 00:00:25.522: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5174 05/02/23 00:00:25.522
May  2 00:00:25.637: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5174" to be "running and ready"
May  2 00:00:25.742: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 105.121228ms
May  2 00:00:25.742: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:00:27.848: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.21044162s
May  2 00:00:27.848: INFO: The phase of Pod pod1 is Running (Ready = true)
May  2 00:00:27.848: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[pod1:[100]] 05/02/23 00:00:27.953
May  2 00:00:28.372: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5174 05/02/23 00:00:28.372
May  2 00:00:28.478: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5174" to be "running and ready"
May  2 00:00:28.583: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.975942ms
May  2 00:00:28.583: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:00:30.689: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.210475848s
May  2 00:00:30.689: INFO: The phase of Pod pod2 is Running (Ready = true)
May  2 00:00:30.689: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[pod1:[100] pod2:[101]] 05/02/23 00:00:30.796
May  2 00:00:31.319: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 05/02/23 00:00:31.319
May  2 00:00:31.320: INFO: Creating new exec pod
May  2 00:00:31.427: INFO: Waiting up to 5m0s for pod "execpodtst9b" in namespace "services-5174" to be "running"
May  2 00:00:31.532: INFO: Pod "execpodtst9b": Phase="Pending", Reason="", readiness=false. Elapsed: 105.217656ms
May  2 00:00:33.638: INFO: Pod "execpodtst9b": Phase="Running", Reason="", readiness=true. Elapsed: 2.211033416s
May  2 00:00:33.638: INFO: Pod "execpodtst9b" satisfied condition "running"
May  2 00:00:34.639: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
May  2 00:00:35.822: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
May  2 00:00:35.822: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 00:00:35.822: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.127.119 80'
May  2 00:00:36.984: INFO: stderr: "+ + nc -v -t -w 2 100.67.127.119 80\necho hostName\nConnection to 100.67.127.119 80 port [tcp/http] succeeded!\n"
May  2 00:00:36.984: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 00:00:36.984: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
May  2 00:00:38.132: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
May  2 00:00:38.132: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 00:00:38.132: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.127.119 81'
May  2 00:00:39.282: INFO: stderr: "+ nc -v -t -w 2 100.67.127.119 81\nConnection to 100.67.127.119 81 port [tcp/*] succeeded!\n+ echo hostName\n"
May  2 00:00:39.282: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5174 05/02/23 00:00:39.282
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[pod2:[101]] 05/02/23 00:00:39.398
May  2 00:00:39.818: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5174 05/02/23 00:00:39.818
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[] 05/02/23 00:00:39.936
May  2 00:00:40.250: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  2 00:00:40.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5174" for this suite. 05/02/23 00:00:40.479
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":250,"skipped":4667,"failed":0}
------------------------------
• [SLOW TEST] [16.225 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:00:24.361
    May  2 00:00:24.361: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/02/23 00:00:24.363
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:24.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:24.887
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-5174 05/02/23 00:00:25.095
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[] 05/02/23 00:00:25.207
    May  2 00:00:25.522: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5174 05/02/23 00:00:25.522
    May  2 00:00:25.637: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5174" to be "running and ready"
    May  2 00:00:25.742: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 105.121228ms
    May  2 00:00:25.742: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:00:27.848: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.21044162s
    May  2 00:00:27.848: INFO: The phase of Pod pod1 is Running (Ready = true)
    May  2 00:00:27.848: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[pod1:[100]] 05/02/23 00:00:27.953
    May  2 00:00:28.372: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-5174 05/02/23 00:00:28.372
    May  2 00:00:28.478: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5174" to be "running and ready"
    May  2 00:00:28.583: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 104.975942ms
    May  2 00:00:28.583: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:00:30.689: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.210475848s
    May  2 00:00:30.689: INFO: The phase of Pod pod2 is Running (Ready = true)
    May  2 00:00:30.689: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[pod1:[100] pod2:[101]] 05/02/23 00:00:30.796
    May  2 00:00:31.319: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 05/02/23 00:00:31.319
    May  2 00:00:31.320: INFO: Creating new exec pod
    May  2 00:00:31.427: INFO: Waiting up to 5m0s for pod "execpodtst9b" in namespace "services-5174" to be "running"
    May  2 00:00:31.532: INFO: Pod "execpodtst9b": Phase="Pending", Reason="", readiness=false. Elapsed: 105.217656ms
    May  2 00:00:33.638: INFO: Pod "execpodtst9b": Phase="Running", Reason="", readiness=true. Elapsed: 2.211033416s
    May  2 00:00:33.638: INFO: Pod "execpodtst9b" satisfied condition "running"
    May  2 00:00:34.639: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    May  2 00:00:35.822: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    May  2 00:00:35.822: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  2 00:00:35.822: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.127.119 80'
    May  2 00:00:36.984: INFO: stderr: "+ + nc -v -t -w 2 100.67.127.119 80\necho hostName\nConnection to 100.67.127.119 80 port [tcp/http] succeeded!\n"
    May  2 00:00:36.984: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  2 00:00:36.984: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    May  2 00:00:38.132: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    May  2 00:00:38.132: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  2 00:00:38.132: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-5174 exec execpodtst9b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.127.119 81'
    May  2 00:00:39.282: INFO: stderr: "+ nc -v -t -w 2 100.67.127.119 81\nConnection to 100.67.127.119 81 port [tcp/*] succeeded!\n+ echo hostName\n"
    May  2 00:00:39.282: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5174 05/02/23 00:00:39.282
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[pod2:[101]] 05/02/23 00:00:39.398
    May  2 00:00:39.818: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-5174 05/02/23 00:00:39.818
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5174 to expose endpoints map[] 05/02/23 00:00:39.936
    May  2 00:00:40.250: INFO: successfully validated that service multi-endpoint-test in namespace services-5174 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  2 00:00:40.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5174" for this suite. 05/02/23 00:00:40.479
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:00:40.587
May  2 00:00:40.587: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/02/23 00:00:40.589
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:40.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:41.113
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 05/02/23 00:00:41.427
STEP: create the rc2 05/02/23 00:00:41.537
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 05/02/23 00:00:46.783
STEP: delete the rc simpletest-rc-to-be-deleted 05/02/23 00:00:52.438
STEP: wait for the rc to be deleted 05/02/23 00:00:52.545
May  2 00:00:57.767: INFO: 70 pods remaining
May  2 00:00:57.767: INFO: 70 pods has nil DeletionTimestamp
May  2 00:00:57.767: INFO: 
STEP: Gathering metrics 05/02/23 00:01:02.761
May  2 00:01:02.988: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
May  2 00:01:03.094: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 105.388037ms
May  2 00:01:03.094: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
May  2 00:01:03.094: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
May  2 00:01:04.032: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

May  2 00:01:04.032: INFO: Deleting pod "simpletest-rc-to-be-deleted-27cql" in namespace "gc-8850"
May  2 00:01:04.146: INFO: Deleting pod "simpletest-rc-to-be-deleted-2c8jw" in namespace "gc-8850"
May  2 00:01:04.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-56g8v" in namespace "gc-8850"
May  2 00:01:04.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-59n28" in namespace "gc-8850"
May  2 00:01:04.489: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b4mq" in namespace "gc-8850"
May  2 00:01:04.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dc4p" in namespace "gc-8850"
May  2 00:01:04.718: INFO: Deleting pod "simpletest-rc-to-be-deleted-5k72x" in namespace "gc-8850"
May  2 00:01:04.830: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bp86" in namespace "gc-8850"
May  2 00:01:04.947: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bxl6" in namespace "gc-8850"
May  2 00:01:05.062: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h5fk" in namespace "gc-8850"
May  2 00:01:05.175: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jv9k" in namespace "gc-8850"
May  2 00:01:05.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lmck" in namespace "gc-8850"
May  2 00:01:05.400: INFO: Deleting pod "simpletest-rc-to-be-deleted-6q9bd" in namespace "gc-8850"
May  2 00:01:05.515: INFO: Deleting pod "simpletest-rc-to-be-deleted-6vjdq" in namespace "gc-8850"
May  2 00:01:05.644: INFO: Deleting pod "simpletest-rc-to-be-deleted-6vjr9" in namespace "gc-8850"
May  2 00:01:05.757: INFO: Deleting pod "simpletest-rc-to-be-deleted-7j58x" in namespace "gc-8850"
May  2 00:01:05.869: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jhvt" in namespace "gc-8850"
May  2 00:01:05.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-84zsb" in namespace "gc-8850"
May  2 00:01:06.099: INFO: Deleting pod "simpletest-rc-to-be-deleted-8766v" in namespace "gc-8850"
May  2 00:01:06.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-896rp" in namespace "gc-8850"
May  2 00:01:06.330: INFO: Deleting pod "simpletest-rc-to-be-deleted-8jbzk" in namespace "gc-8850"
May  2 00:01:06.446: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rphg" in namespace "gc-8850"
May  2 00:01:06.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-97wdz" in namespace "gc-8850"
May  2 00:01:06.672: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fhnh" in namespace "gc-8850"
May  2 00:01:06.796: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rgts" in namespace "gc-8850"
May  2 00:01:06.913: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xjtl" in namespace "gc-8850"
May  2 00:01:07.027: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6zq8" in namespace "gc-8850"
May  2 00:01:07.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-bd24n" in namespace "gc-8850"
May  2 00:01:07.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-bh5sj" in namespace "gc-8850"
May  2 00:01:07.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-bp2n8" in namespace "gc-8850"
May  2 00:01:07.497: INFO: Deleting pod "simpletest-rc-to-be-deleted-bw5cq" in namespace "gc-8850"
May  2 00:01:07.610: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbqcn" in namespace "gc-8850"
May  2 00:01:07.739: INFO: Deleting pod "simpletest-rc-to-be-deleted-czphk" in namespace "gc-8850"
May  2 00:01:07.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5pnb" in namespace "gc-8850"
May  2 00:01:07.990: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7vbd" in namespace "gc-8850"
May  2 00:01:08.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-dgvcz" in namespace "gc-8850"
May  2 00:01:08.224: INFO: Deleting pod "simpletest-rc-to-be-deleted-dn8jb" in namespace "gc-8850"
May  2 00:01:08.336: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7jmg" in namespace "gc-8850"
May  2 00:01:08.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9cs8" in namespace "gc-8850"
May  2 00:01:08.576: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgslp" in namespace "gc-8850"
May  2 00:01:08.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-fx2cm" in namespace "gc-8850"
May  2 00:01:08.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfvl5" in namespace "gc-8850"
May  2 00:01:08.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-gnltj" in namespace "gc-8850"
May  2 00:01:09.055: INFO: Deleting pod "simpletest-rc-to-be-deleted-gprk5" in namespace "gc-8850"
May  2 00:01:09.166: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6d7w" in namespace "gc-8850"
May  2 00:01:09.277: INFO: Deleting pod "simpletest-rc-to-be-deleted-h7xzq" in namespace "gc-8850"
May  2 00:01:09.390: INFO: Deleting pod "simpletest-rc-to-be-deleted-hdmx4" in namespace "gc-8850"
May  2 00:01:09.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-hm5cb" in namespace "gc-8850"
May  2 00:01:09.617: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrjfj" in namespace "gc-8850"
May  2 00:01:09.732: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrn68" in namespace "gc-8850"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  2 00:01:09.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8850" for this suite. 05/02/23 00:01:09.954
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":251,"skipped":4672,"failed":0}
------------------------------
• [SLOW TEST] [29.473 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:00:40.587
    May  2 00:00:40.587: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/02/23 00:00:40.589
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:00:40.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:00:41.113
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 05/02/23 00:00:41.427
    STEP: create the rc2 05/02/23 00:00:41.537
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 05/02/23 00:00:46.783
    STEP: delete the rc simpletest-rc-to-be-deleted 05/02/23 00:00:52.438
    STEP: wait for the rc to be deleted 05/02/23 00:00:52.545
    May  2 00:00:57.767: INFO: 70 pods remaining
    May  2 00:00:57.767: INFO: 70 pods has nil DeletionTimestamp
    May  2 00:00:57.767: INFO: 
    STEP: Gathering metrics 05/02/23 00:01:02.761
    May  2 00:01:02.988: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
    May  2 00:01:03.094: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 105.388037ms
    May  2 00:01:03.094: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
    May  2 00:01:03.094: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
    May  2 00:01:04.032: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    May  2 00:01:04.032: INFO: Deleting pod "simpletest-rc-to-be-deleted-27cql" in namespace "gc-8850"
    May  2 00:01:04.146: INFO: Deleting pod "simpletest-rc-to-be-deleted-2c8jw" in namespace "gc-8850"
    May  2 00:01:04.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-56g8v" in namespace "gc-8850"
    May  2 00:01:04.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-59n28" in namespace "gc-8850"
    May  2 00:01:04.489: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b4mq" in namespace "gc-8850"
    May  2 00:01:04.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-5dc4p" in namespace "gc-8850"
    May  2 00:01:04.718: INFO: Deleting pod "simpletest-rc-to-be-deleted-5k72x" in namespace "gc-8850"
    May  2 00:01:04.830: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bp86" in namespace "gc-8850"
    May  2 00:01:04.947: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bxl6" in namespace "gc-8850"
    May  2 00:01:05.062: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h5fk" in namespace "gc-8850"
    May  2 00:01:05.175: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jv9k" in namespace "gc-8850"
    May  2 00:01:05.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lmck" in namespace "gc-8850"
    May  2 00:01:05.400: INFO: Deleting pod "simpletest-rc-to-be-deleted-6q9bd" in namespace "gc-8850"
    May  2 00:01:05.515: INFO: Deleting pod "simpletest-rc-to-be-deleted-6vjdq" in namespace "gc-8850"
    May  2 00:01:05.644: INFO: Deleting pod "simpletest-rc-to-be-deleted-6vjr9" in namespace "gc-8850"
    May  2 00:01:05.757: INFO: Deleting pod "simpletest-rc-to-be-deleted-7j58x" in namespace "gc-8850"
    May  2 00:01:05.869: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jhvt" in namespace "gc-8850"
    May  2 00:01:05.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-84zsb" in namespace "gc-8850"
    May  2 00:01:06.099: INFO: Deleting pod "simpletest-rc-to-be-deleted-8766v" in namespace "gc-8850"
    May  2 00:01:06.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-896rp" in namespace "gc-8850"
    May  2 00:01:06.330: INFO: Deleting pod "simpletest-rc-to-be-deleted-8jbzk" in namespace "gc-8850"
    May  2 00:01:06.446: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rphg" in namespace "gc-8850"
    May  2 00:01:06.559: INFO: Deleting pod "simpletest-rc-to-be-deleted-97wdz" in namespace "gc-8850"
    May  2 00:01:06.672: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fhnh" in namespace "gc-8850"
    May  2 00:01:06.796: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rgts" in namespace "gc-8850"
    May  2 00:01:06.913: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xjtl" in namespace "gc-8850"
    May  2 00:01:07.027: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6zq8" in namespace "gc-8850"
    May  2 00:01:07.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-bd24n" in namespace "gc-8850"
    May  2 00:01:07.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-bh5sj" in namespace "gc-8850"
    May  2 00:01:07.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-bp2n8" in namespace "gc-8850"
    May  2 00:01:07.497: INFO: Deleting pod "simpletest-rc-to-be-deleted-bw5cq" in namespace "gc-8850"
    May  2 00:01:07.610: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbqcn" in namespace "gc-8850"
    May  2 00:01:07.739: INFO: Deleting pod "simpletest-rc-to-be-deleted-czphk" in namespace "gc-8850"
    May  2 00:01:07.868: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5pnb" in namespace "gc-8850"
    May  2 00:01:07.990: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7vbd" in namespace "gc-8850"
    May  2 00:01:08.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-dgvcz" in namespace "gc-8850"
    May  2 00:01:08.224: INFO: Deleting pod "simpletest-rc-to-be-deleted-dn8jb" in namespace "gc-8850"
    May  2 00:01:08.336: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7jmg" in namespace "gc-8850"
    May  2 00:01:08.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9cs8" in namespace "gc-8850"
    May  2 00:01:08.576: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgslp" in namespace "gc-8850"
    May  2 00:01:08.693: INFO: Deleting pod "simpletest-rc-to-be-deleted-fx2cm" in namespace "gc-8850"
    May  2 00:01:08.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfvl5" in namespace "gc-8850"
    May  2 00:01:08.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-gnltj" in namespace "gc-8850"
    May  2 00:01:09.055: INFO: Deleting pod "simpletest-rc-to-be-deleted-gprk5" in namespace "gc-8850"
    May  2 00:01:09.166: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6d7w" in namespace "gc-8850"
    May  2 00:01:09.277: INFO: Deleting pod "simpletest-rc-to-be-deleted-h7xzq" in namespace "gc-8850"
    May  2 00:01:09.390: INFO: Deleting pod "simpletest-rc-to-be-deleted-hdmx4" in namespace "gc-8850"
    May  2 00:01:09.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-hm5cb" in namespace "gc-8850"
    May  2 00:01:09.617: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrjfj" in namespace "gc-8850"
    May  2 00:01:09.732: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrn68" in namespace "gc-8850"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  2 00:01:09.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8850" for this suite. 05/02/23 00:01:09.954
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:01:10.061
May  2 00:01:10.061: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sysctl 05/02/23 00:01:10.062
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:10.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:10.593
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 05/02/23 00:01:10.802
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
May  2 00:01:10.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5488" for this suite. 05/02/23 00:01:11.014
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":252,"skipped":4672,"failed":0}
------------------------------
• [1.060 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:01:10.061
    May  2 00:01:10.061: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sysctl 05/02/23 00:01:10.062
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:10.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:10.593
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 05/02/23 00:01:10.802
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    May  2 00:01:10.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5488" for this suite. 05/02/23 00:01:11.014
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:01:11.122
May  2 00:01:11.122: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/02/23 00:01:11.123
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:11.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:11.647
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/02/23 00:01:12.071
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:01:12.573
STEP: Deploying the webhook pod 05/02/23 00:01:12.681
STEP: Wait for the deployment to be ready 05/02/23 00:01:12.897
May  2 00:01:13.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/02/23 00:01:15.318
STEP: Verifying the service has paired with the endpoint 05/02/23 00:01:15.43
May  2 00:01:16.431: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 05/02/23 00:01:16.537
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 05/02/23 00:01:16.642
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 05/02/23 00:01:16.642
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 05/02/23 00:01:16.642
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 05/02/23 00:01:16.746
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 05/02/23 00:01:16.746
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 05/02/23 00:01:16.85
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:01:16.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4413" for this suite. 05/02/23 00:01:16.957
STEP: Destroying namespace "webhook-4413-markers" for this suite. 05/02/23 00:01:17.064
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":253,"skipped":4676,"failed":0}
------------------------------
• [SLOW TEST] [6.484 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:01:11.122
    May  2 00:01:11.122: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/02/23 00:01:11.123
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:11.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:11.647
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/02/23 00:01:12.071
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:01:12.573
    STEP: Deploying the webhook pod 05/02/23 00:01:12.681
    STEP: Wait for the deployment to be ready 05/02/23 00:01:12.897
    May  2 00:01:13.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 1, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/02/23 00:01:15.318
    STEP: Verifying the service has paired with the endpoint 05/02/23 00:01:15.43
    May  2 00:01:16.431: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 05/02/23 00:01:16.537
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 05/02/23 00:01:16.642
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 05/02/23 00:01:16.642
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 05/02/23 00:01:16.642
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 05/02/23 00:01:16.746
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 05/02/23 00:01:16.746
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 05/02/23 00:01:16.85
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:01:16.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4413" for this suite. 05/02/23 00:01:16.957
    STEP: Destroying namespace "webhook-4413-markers" for this suite. 05/02/23 00:01:17.064
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:01:17.609
May  2 00:01:17.609: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/02/23 00:01:17.61
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:17.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:18.134
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 05/02/23 00:01:18.342
STEP: Creating a ResourceQuota 05/02/23 00:01:23.45
STEP: Ensuring resource quota status is calculated 05/02/23 00:01:23.556
STEP: Creating a ReplicaSet 05/02/23 00:01:25.663
STEP: Ensuring resource quota status captures replicaset creation 05/02/23 00:01:25.774
STEP: Deleting a ReplicaSet 05/02/23 00:01:27.881
STEP: Ensuring resource quota status released usage 05/02/23 00:01:27.988
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  2 00:01:30.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7149" for this suite. 05/02/23 00:01:30.201
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":254,"skipped":4694,"failed":0}
------------------------------
• [SLOW TEST] [12.700 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:01:17.609
    May  2 00:01:17.609: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/02/23 00:01:17.61
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:17.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:18.134
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 05/02/23 00:01:18.342
    STEP: Creating a ResourceQuota 05/02/23 00:01:23.45
    STEP: Ensuring resource quota status is calculated 05/02/23 00:01:23.556
    STEP: Creating a ReplicaSet 05/02/23 00:01:25.663
    STEP: Ensuring resource quota status captures replicaset creation 05/02/23 00:01:25.774
    STEP: Deleting a ReplicaSet 05/02/23 00:01:27.881
    STEP: Ensuring resource quota status released usage 05/02/23 00:01:27.988
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  2 00:01:30.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7149" for this suite. 05/02/23 00:01:30.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:01:30.312
May  2 00:01:30.312: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment 05/02/23 00:01:30.313
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:30.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:30.839
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
May  2 00:01:31.048: INFO: Creating deployment "webserver-deployment"
May  2 00:01:31.155: INFO: Waiting for observed generation 1
May  2 00:01:31.277: INFO: Waiting for all required pods to come up
May  2 00:01:31.383: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 05/02/23 00:01:31.383
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zpdbn" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8dvj6" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8t6qp" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bg9g9" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-pmctb" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-sf7nd" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-srzv2" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tjgnx" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tx58p" in namespace "deployment-2627" to be "running"
May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vprlc" in namespace "deployment-2627" to be "running"
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-8t6qp": Phase="Pending", Reason="", readiness=false. Elapsed: 107.951086ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-tjgnx": Phase="Pending", Reason="", readiness=false. Elapsed: 107.713357ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-bg9g9": Phase="Pending", Reason="", readiness=false. Elapsed: 108.213916ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-srzv2": Phase="Pending", Reason="", readiness=false. Elapsed: 107.974247ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-8dvj6": Phase="Pending", Reason="", readiness=false. Elapsed: 108.14886ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-vprlc": Phase="Pending", Reason="", readiness=false. Elapsed: 107.497405ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-zpdbn": Phase="Pending", Reason="", readiness=false. Elapsed: 108.282236ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-sf7nd": Phase="Pending", Reason="", readiness=false. Elapsed: 108.227719ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-pmctb": Phase="Pending", Reason="", readiness=false. Elapsed: 108.350017ms
May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-tx58p": Phase="Pending", Reason="", readiness=false. Elapsed: 108.025306ms
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tx58p": Phase="Running", Reason="", readiness=true. Elapsed: 2.219251085s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tx58p" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-bg9g9": Phase="Running", Reason="", readiness=true. Elapsed: 2.219830178s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-bg9g9" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-sf7nd": Phase="Running", Reason="", readiness=true. Elapsed: 2.219861543s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-sf7nd" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8t6qp": Phase="Running", Reason="", readiness=true. Elapsed: 2.220179256s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8t6qp" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-srzv2": Phase="Running", Reason="", readiness=true. Elapsed: 2.219925829s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-srzv2" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tjgnx": Phase="Running", Reason="", readiness=true. Elapsed: 2.219986217s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tjgnx" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8dvj6": Phase="Running", Reason="", readiness=true. Elapsed: 2.220641609s
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8dvj6" satisfied condition "running"
May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-pmctb": Phase="Running", Reason="", readiness=true. Elapsed: 2.220469885s
May  2 00:01:33.605: INFO: Pod "webserver-deployment-845c8977d9-pmctb" satisfied condition "running"
May  2 00:01:33.605: INFO: Pod "webserver-deployment-845c8977d9-zpdbn": Phase="Running", Reason="", readiness=true. Elapsed: 2.221611437s
May  2 00:01:33.605: INFO: Pod "webserver-deployment-845c8977d9-zpdbn" satisfied condition "running"
May  2 00:01:33.606: INFO: Pod "webserver-deployment-845c8977d9-vprlc": Phase="Running", Reason="", readiness=true. Elapsed: 2.221593774s
May  2 00:01:33.606: INFO: Pod "webserver-deployment-845c8977d9-vprlc" satisfied condition "running"
May  2 00:01:33.606: INFO: Waiting for deployment "webserver-deployment" to complete
May  2 00:01:33.816: INFO: Updating deployment "webserver-deployment" with a non-existent image
May  2 00:01:34.028: INFO: Updating deployment webserver-deployment
May  2 00:01:34.028: INFO: Waiting for observed generation 2
May  2 00:01:34.149: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May  2 00:01:34.254: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May  2 00:01:34.359: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May  2 00:01:34.676: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May  2 00:01:34.676: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May  2 00:01:34.782: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May  2 00:01:35.001: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
May  2 00:01:35.001: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
May  2 00:01:35.215: INFO: Updating deployment webserver-deployment
May  2 00:01:35.215: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
May  2 00:01:35.471: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May  2 00:01:35.576: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
May  2 00:01:35.798: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2627  78164bc4-11dc-45fa-8428-ba487a1c42e0 30721 3 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f36a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-05-02 00:01:35 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-05-02 00:01:35 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

May  2 00:01:35.907: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-2627  f5ce533e-f21b-457d-b56d-ecaa3aaed03a 30718 3 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 78164bc4-11dc-45fa-8428-ba487a1c42e0 0xc0043f3a47 0xc0043f3a48}] [] [{kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78164bc4-11dc-45fa-8428-ba487a1c42e0\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f3ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  2 00:01:35.907: INFO: All old ReplicaSets of Deployment "webserver-deployment":
May  2 00:01:35.907: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-2627  1e8c62e2-5da0-48b5-abe7-65e21d29e799 30713 3 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 78164bc4-11dc-45fa-8428-ba487a1c42e0 0xc0043f3b47 0xc0043f3b48}] [] [{kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78164bc4-11dc-45fa-8428-ba487a1c42e0\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f3bd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
May  2 00:01:36.119: INFO: Pod "webserver-deployment-69b7448995-4ns62" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-4ns62 webserver-deployment-69b7448995- deployment-2627  960f06b9-d12e-40a6-885d-173b9b2861ba 30724 0 2023-05-02 00:01:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9468eb1b1ba8c269bd336cdf6c1fe158f43ca95315efd53e24bde6cb52173142 cni.projectcalico.org/podIP:100.123.145.197/32 cni.projectcalico.org/podIPs:100.123.145.197/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e80d7 0xc0057e80d8}] [] [{calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5fzpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5fzpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:100.123.145.197,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.123.145.197,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.119: INFO: Pod "webserver-deployment-69b7448995-cghsd" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-cghsd webserver-deployment-69b7448995- deployment-2627  cc8a5b43-0c49-475c-a1a1-1a35ab2b980f 30716 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e82f7 0xc0057e82f8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sz6jh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sz6jh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.119: INFO: Pod "webserver-deployment-69b7448995-d4z6p" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-d4z6p webserver-deployment-69b7448995- deployment-2627  9158c8b3-772f-45c2-93ca-56bedb5d84f3 30748 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b263b02a0f314c4c2f1cba591cf873b3ee57f9ecd8c46e38e369ddc5c034f7ab cni.projectcalico.org/podIP:100.105.72.161/32 cni.projectcalico.org/podIPs:100.105.72.161/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e84d7 0xc0057e84d8}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fc56z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fc56z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-djl98" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-djl98 webserver-deployment-69b7448995- deployment-2627  32d74ce9-2b4e-44a7-a039-20630659629b 30643 0 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5ed6fab5990c087c7907cbf055b1e8f100660d018fc65adac986cb10319236b0 cni.projectcalico.org/podIP:100.96.36.29/32 cni.projectcalico.org/podIPs:100.96.36.29/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e86e7 0xc0057e86e8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kckv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kckv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-fhd4g" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fhd4g webserver-deployment-69b7448995- deployment-2627  9953cb83-b58e-4c72-8c0f-221f1b169db8 30742 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2fb8345d39c0b9e6a735429c8c283e62ab73e26858f4a4430651d5c99d9e9759 cni.projectcalico.org/podIP:100.101.231.167/32 cni.projectcalico.org/podIPs:100.101.231.167/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e88e7 0xc0057e88e8}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ztl8s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ztl8s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-fq5k7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fq5k7 webserver-deployment-69b7448995- deployment-2627  52505ab5-9a34-4039-b010-6f29e59bf5f3 30699 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e8ad7 0xc0057e8ad8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55w44,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55w44,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-gc4qt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-gc4qt webserver-deployment-69b7448995- deployment-2627  f6d3d1fb-97b1-4250-94f6-72df2104ba23 30638 0 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:a1d6b2b7d2fb05aaef4e4198d39472a975893e458da2a1b6248b1a3d432cd814 cni.projectcalico.org/podIP:100.105.72.163/32 cni.projectcalico.org/podIPs:100.105.72.163/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e8c40 0xc0057e8c41}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-666cr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-666cr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-hn5gw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-hn5gw webserver-deployment-69b7448995- deployment-2627  9ed7610d-aec7-4847-b84e-91150fbd2ee4 30740 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:38aa43b282c6c68b426ab84cf7f37830dae14723c4000846f5a8f393d8eaa721 cni.projectcalico.org/podIP:100.123.145.208/32 cni.projectcalico.org/podIPs:100.123.145.208/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e8e37 0xc0057e8e38}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xdjfl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xdjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-jdss8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jdss8 webserver-deployment-69b7448995- deployment-2627  0c37d0b0-9922-41ff-a40a-580114030fa9 30726 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9027 0xc0057e9028}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h4jtg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h4jtg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-lzzxz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lzzxz webserver-deployment-69b7448995- deployment-2627  f049d506-033d-40f5-83e9-8485fe8d7bd6 30732 0 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:096d695530fd2a93b488084dada5ae59e25ced45797257f2dac72857db3c32c0 cni.projectcalico.org/podIP:100.101.231.148/32 cni.projectcalico.org/podIPs:100.101.231.148/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9207 0xc0057e9208}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.148\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4t26n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4t26n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:100.101.231.148,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.101.231.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-mjxh2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mjxh2 webserver-deployment-69b7448995- deployment-2627  6a733da6-0653-4f04-a952-233a61e4b9ce 30717 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9437 0xc0057e9438}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nc4sr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nc4sr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.122: INFO: Pod "webserver-deployment-69b7448995-qng7f" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qng7f webserver-deployment-69b7448995- deployment-2627  2b1455e7-8577-4e87-b287-c7c6921d49f7 30728 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9617 0xc0057e9618}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7q5tp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7q5tp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.122: INFO: Pod "webserver-deployment-69b7448995-wqh49" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wqh49 webserver-deployment-69b7448995- deployment-2627  7e2fb111-b9ae-4fbf-b9e1-f72f530793a5 30646 0 2023-05-02 00:01:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2e27f12631ee59b6d7740a4c206eddf6bac067856fd92f2b2ce0b2a9218b1d1c cni.projectcalico.org/podIP:100.96.36.30/32 cni.projectcalico.org/podIPs:100.96.36.30/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9817 0xc0057e9818}] [] [{calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l9rdf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l9rdf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.122: INFO: Pod "webserver-deployment-845c8977d9-8dvj6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8dvj6 webserver-deployment-845c8977d9- deployment-2627  48c3885e-4492-4757-8b74-d8f0d481a575 30578 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ef9a09e2c0b9879d6ce801961c1a4bcb62d655ddffc04e80a9a3e499fd3287d0 cni.projectcalico.org/podIP:100.101.231.149/32 cni.projectcalico.org/podIPs:100.101.231.149/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9a17 0xc0057e9a18}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.149\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q5s75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q5s75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:100.101.231.149,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e79619f14acea8403e5c9bef06a46447132b77528adada94096862649e2cd791,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.101.231.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.122: INFO: Pod "webserver-deployment-845c8977d9-8t6qp" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8t6qp webserver-deployment-845c8977d9- deployment-2627  d806d7db-7df5-49ba-9b8f-68f78765347b 30576 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:2b57b26e5ea261ba2e6144137ce29de8e156c938ca7b25d7f39c60379fee3178 cni.projectcalico.org/podIP:100.101.231.166/32 cni.projectcalico.org/podIPs:100.101.231.166/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9c07 0xc0057e9c08}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jkg94,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jkg94,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:100.101.231.166,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://62d903a9ef20dabbe3e41d1eb1d8cdff36eb92d3366c6ee219694979cf34b484,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.101.231.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.123: INFO: Pod "webserver-deployment-845c8977d9-9fd4l" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9fd4l webserver-deployment-845c8977d9- deployment-2627  8a3ada51-e0ca-4bef-a79a-21315013e142 30697 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9df7 0xc0057e9df8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lnk6w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lnk6w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.123: INFO: Pod "webserver-deployment-845c8977d9-9kgsx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9kgsx webserver-deployment-845c8977d9- deployment-2627  aaded8b6-7c2b-466b-a868-539fc2fc2d14 30695 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9f50 0xc0057e9f51}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zdx9k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zdx9k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.123: INFO: Pod "webserver-deployment-845c8977d9-fkzjc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fkzjc webserver-deployment-845c8977d9- deployment-2627  a96fbd5d-0ff7-4662-a3f9-5076beb22ad3 30701 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a107 0xc00630a108}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dxcbd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dxcbd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-gr9lh" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gr9lh webserver-deployment-845c8977d9- deployment-2627  9554e4d8-3008-433c-a81f-7311030e0eb1 30711 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a270 0xc00630a271}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pcl2q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pcl2q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-kbq4p" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kbq4p webserver-deployment-845c8977d9- deployment-2627  677656c8-ed47-4ad9-829e-49f78504e23a 30698 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a427 0xc00630a428}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvnsc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvnsc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-pgfnb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-pgfnb webserver-deployment-845c8977d9- deployment-2627  9698c0d8-7215-4f4d-a90e-ee5d1f16a10a 30712 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a580 0xc00630a581}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2xdjv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2xdjv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-pmctb" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-pmctb webserver-deployment-845c8977d9- deployment-2627  4fece679-7b6d-48e0-9b4c-1a232629eda3 30588 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4cb210fa6de6093afb253539f55e4888de830be1b20723415051cc1e6d7e9fa3 cni.projectcalico.org/podIP:100.105.72.164/32 cni.projectcalico.org/podIPs:100.105.72.164/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a737 0xc00630a738}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.164\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bxsrh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bxsrh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:100.105.72.164,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://26e43147c1e442da3bb24cf4420107c54ee4193b49674c0f74b1362370e01b58,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.105.72.164,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-qw5q2" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qw5q2 webserver-deployment-845c8977d9- deployment-2627  88c80a1c-6328-4190-b96e-aa1ee7593414 30707 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a927 0xc00630a928}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dc546,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dc546,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-rtgzk" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rtgzk webserver-deployment-845c8977d9- deployment-2627  84243f11-5785-4511-929d-ba9aff4cc40b 30747 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ee7a7f60a08c7d7f430c111557be094cbea090bb6f2a5b40d6d711ede1d366cf cni.projectcalico.org/podIP:100.101.231.168/32 cni.projectcalico.org/podIPs:100.101.231.168/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630aae7 0xc00630aae8}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j6bxf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j6bxf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-rzxm6" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rzxm6 webserver-deployment-845c8977d9- deployment-2627  2f85e838-d535-4bfb-9013-c8682952310f 30710 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630acc7 0xc00630acc8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mtw47,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mtw47,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-sf7nd" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-sf7nd webserver-deployment-845c8977d9- deployment-2627  518264d2-e71a-4f7d-b759-1edbc1dd5799 30563 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a715fc333162ed192e02632bb01c52eb6f4a8bdd10a01c069950ac70b2e04307 cni.projectcalico.org/podIP:100.123.145.204/32 cni.projectcalico.org/podIPs:100.123.145.204/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630ae87 0xc00630ae88}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.204\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4xtq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4xtq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:100.123.145.204,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f120b536d3d58c6294fdc6859db051a82758135bd922bdbc706ebb0ed9454ff4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.123.145.204,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.126: INFO: Pod "webserver-deployment-845c8977d9-t448r" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-t448r webserver-deployment-845c8977d9- deployment-2627  f7acef51-b05d-47d5-929a-60fab0f582b3 30709 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b077 0xc00630b078}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-94css,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-94css,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.127: INFO: Pod "webserver-deployment-845c8977d9-tjgnx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tjgnx webserver-deployment-845c8977d9- deployment-2627  c6466555-d95e-4a47-bc70-d0a8748aab49 30582 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6cfe063896c5315aa9a47e931d0612ccac507bc616a92c63a5de136451f9fef8 cni.projectcalico.org/podIP:100.105.72.166/32 cni.projectcalico.org/podIPs:100.105.72.166/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b237 0xc00630b238}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wgx8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wgx8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:100.105.72.166,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2865fe48ebcae4b9c753a15aa05b05318cc73ecbc33ddbbd733231fb89358687,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.105.72.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.127: INFO: Pod "webserver-deployment-845c8977d9-tx58p" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tx58p webserver-deployment-845c8977d9- deployment-2627  7db11480-44da-43cf-bd6f-7e9dbf138b2d 30584 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:173d8a06091cb174ba3957cef7fd5c9aea89e360559feabcf7bbe3762f787e80 cni.projectcalico.org/podIP:100.105.72.165/32 cni.projectcalico.org/podIPs:100.105.72.165/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b437 0xc00630b438}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.165\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ct8bq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ct8bq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:100.105.72.165,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d2935b3471c899fc4a7b39d8a4e596c4b25366e3c92e25991a9604c05a82aaf9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.105.72.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.127: INFO: Pod "webserver-deployment-845c8977d9-v9s8l" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-v9s8l webserver-deployment-845c8977d9- deployment-2627  aa71253c-d697-4299-ad6c-93c0668b8874 30741 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5a146668ad0075e038bc46c289b47f4a7cf5266d0763a1980758c309f052dd91 cni.projectcalico.org/podIP:100.105.72.167/32 cni.projectcalico.org/podIPs:100.105.72.167/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b637 0xc00630b638}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svn8d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svn8d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.128: INFO: Pod "webserver-deployment-845c8977d9-vprlc" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vprlc webserver-deployment-845c8977d9- deployment-2627  5d287828-068f-4fd6-9a42-f5ef7c3e2c79 30569 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:70d1241e6ac56e3b03ce104595d9de69a6bc9a94c46d4f1ac6c6903cc6b997d8 cni.projectcalico.org/podIP:100.96.36.28/32 cni.projectcalico.org/podIPs:100.96.36.28/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b827 0xc00630b828}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xn4d6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xn4d6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.28,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3989feedcbec39dd651f6baa95c5771a84e6c0ebc08905b0176bd2d9a7341848,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.128: INFO: Pod "webserver-deployment-845c8977d9-whkl9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-whkl9 webserver-deployment-845c8977d9- deployment-2627  2f279b96-5291-40fe-84d4-2ac14a468702 30666 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630ba27 0xc00630ba28}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvdxn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvdxn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  2 00:01:36.128: INFO: Pod "webserver-deployment-845c8977d9-zpdbn" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zpdbn webserver-deployment-845c8977d9- deployment-2627  ba85b7eb-2e68-40a3-8205-dc81276dbda4 30561 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1f2bcb5653658fef1a47d41e981f4a3feb933bb902fa9097c6672357b53d0cae cni.projectcalico.org/podIP:100.123.145.241/32 cni.projectcalico.org/podIPs:100.123.145.241/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630bbe7 0xc00630bbe8}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9txrp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9txrp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:100.123.145.241,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b6eba74dd31dd5934e27ea17b4d7222a10a972bec191bc11f73ee33fd7eba19b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.123.145.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
May  2 00:01:36.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2627" for this suite. 05/02/23 00:01:36.234
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":255,"skipped":4726,"failed":0}
------------------------------
• [SLOW TEST] [6.029 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:01:30.312
    May  2 00:01:30.312: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename deployment 05/02/23 00:01:30.313
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:30.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:30.839
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    May  2 00:01:31.048: INFO: Creating deployment "webserver-deployment"
    May  2 00:01:31.155: INFO: Waiting for observed generation 1
    May  2 00:01:31.277: INFO: Waiting for all required pods to come up
    May  2 00:01:31.383: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 05/02/23 00:01:31.383
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zpdbn" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8dvj6" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8t6qp" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bg9g9" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-pmctb" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-sf7nd" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-srzv2" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tjgnx" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-tx58p" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.384: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vprlc" in namespace "deployment-2627" to be "running"
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-8t6qp": Phase="Pending", Reason="", readiness=false. Elapsed: 107.951086ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-tjgnx": Phase="Pending", Reason="", readiness=false. Elapsed: 107.713357ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-bg9g9": Phase="Pending", Reason="", readiness=false. Elapsed: 108.213916ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-srzv2": Phase="Pending", Reason="", readiness=false. Elapsed: 107.974247ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-8dvj6": Phase="Pending", Reason="", readiness=false. Elapsed: 108.14886ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-vprlc": Phase="Pending", Reason="", readiness=false. Elapsed: 107.497405ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-zpdbn": Phase="Pending", Reason="", readiness=false. Elapsed: 108.282236ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-sf7nd": Phase="Pending", Reason="", readiness=false. Elapsed: 108.227719ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-pmctb": Phase="Pending", Reason="", readiness=false. Elapsed: 108.350017ms
    May  2 00:01:31.492: INFO: Pod "webserver-deployment-845c8977d9-tx58p": Phase="Pending", Reason="", readiness=false. Elapsed: 108.025306ms
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tx58p": Phase="Running", Reason="", readiness=true. Elapsed: 2.219251085s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tx58p" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-bg9g9": Phase="Running", Reason="", readiness=true. Elapsed: 2.219830178s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-bg9g9" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-sf7nd": Phase="Running", Reason="", readiness=true. Elapsed: 2.219861543s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-sf7nd" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8t6qp": Phase="Running", Reason="", readiness=true. Elapsed: 2.220179256s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8t6qp" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-srzv2": Phase="Running", Reason="", readiness=true. Elapsed: 2.219925829s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-srzv2" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tjgnx": Phase="Running", Reason="", readiness=true. Elapsed: 2.219986217s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-tjgnx" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8dvj6": Phase="Running", Reason="", readiness=true. Elapsed: 2.220641609s
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-8dvj6" satisfied condition "running"
    May  2 00:01:33.604: INFO: Pod "webserver-deployment-845c8977d9-pmctb": Phase="Running", Reason="", readiness=true. Elapsed: 2.220469885s
    May  2 00:01:33.605: INFO: Pod "webserver-deployment-845c8977d9-pmctb" satisfied condition "running"
    May  2 00:01:33.605: INFO: Pod "webserver-deployment-845c8977d9-zpdbn": Phase="Running", Reason="", readiness=true. Elapsed: 2.221611437s
    May  2 00:01:33.605: INFO: Pod "webserver-deployment-845c8977d9-zpdbn" satisfied condition "running"
    May  2 00:01:33.606: INFO: Pod "webserver-deployment-845c8977d9-vprlc": Phase="Running", Reason="", readiness=true. Elapsed: 2.221593774s
    May  2 00:01:33.606: INFO: Pod "webserver-deployment-845c8977d9-vprlc" satisfied condition "running"
    May  2 00:01:33.606: INFO: Waiting for deployment "webserver-deployment" to complete
    May  2 00:01:33.816: INFO: Updating deployment "webserver-deployment" with a non-existent image
    May  2 00:01:34.028: INFO: Updating deployment webserver-deployment
    May  2 00:01:34.028: INFO: Waiting for observed generation 2
    May  2 00:01:34.149: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    May  2 00:01:34.254: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    May  2 00:01:34.359: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    May  2 00:01:34.676: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    May  2 00:01:34.676: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    May  2 00:01:34.782: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    May  2 00:01:35.001: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    May  2 00:01:35.001: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    May  2 00:01:35.215: INFO: Updating deployment webserver-deployment
    May  2 00:01:35.215: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    May  2 00:01:35.471: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    May  2 00:01:35.576: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    May  2 00:01:35.798: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-2627  78164bc4-11dc-45fa-8428-ba487a1c42e0 30721 3 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f36a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-05-02 00:01:35 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-05-02 00:01:35 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    May  2 00:01:35.907: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-2627  f5ce533e-f21b-457d-b56d-ecaa3aaed03a 30718 3 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 78164bc4-11dc-45fa-8428-ba487a1c42e0 0xc0043f3a47 0xc0043f3a48}] [] [{kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78164bc4-11dc-45fa-8428-ba487a1c42e0\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f3ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    May  2 00:01:35.907: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    May  2 00:01:35.907: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-2627  1e8c62e2-5da0-48b5-abe7-65e21d29e799 30713 3 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 78164bc4-11dc-45fa-8428-ba487a1c42e0 0xc0043f3b47 0xc0043f3b48}] [] [{kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"78164bc4-11dc-45fa-8428-ba487a1c42e0\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043f3bd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    May  2 00:01:36.119: INFO: Pod "webserver-deployment-69b7448995-4ns62" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-4ns62 webserver-deployment-69b7448995- deployment-2627  960f06b9-d12e-40a6-885d-173b9b2861ba 30724 0 2023-05-02 00:01:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9468eb1b1ba8c269bd336cdf6c1fe158f43ca95315efd53e24bde6cb52173142 cni.projectcalico.org/podIP:100.123.145.197/32 cni.projectcalico.org/podIPs:100.123.145.197/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e80d7 0xc0057e80d8}] [] [{calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5fzpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5fzpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:100.123.145.197,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.123.145.197,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.119: INFO: Pod "webserver-deployment-69b7448995-cghsd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-cghsd webserver-deployment-69b7448995- deployment-2627  cc8a5b43-0c49-475c-a1a1-1a35ab2b980f 30716 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e82f7 0xc0057e82f8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sz6jh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sz6jh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.119: INFO: Pod "webserver-deployment-69b7448995-d4z6p" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-d4z6p webserver-deployment-69b7448995- deployment-2627  9158c8b3-772f-45c2-93ca-56bedb5d84f3 30748 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b263b02a0f314c4c2f1cba591cf873b3ee57f9ecd8c46e38e369ddc5c034f7ab cni.projectcalico.org/podIP:100.105.72.161/32 cni.projectcalico.org/podIPs:100.105.72.161/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e84d7 0xc0057e84d8}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fc56z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fc56z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-djl98" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-djl98 webserver-deployment-69b7448995- deployment-2627  32d74ce9-2b4e-44a7-a039-20630659629b 30643 0 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5ed6fab5990c087c7907cbf055b1e8f100660d018fc65adac986cb10319236b0 cni.projectcalico.org/podIP:100.96.36.29/32 cni.projectcalico.org/podIPs:100.96.36.29/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e86e7 0xc0057e86e8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kckv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kckv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-fhd4g" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fhd4g webserver-deployment-69b7448995- deployment-2627  9953cb83-b58e-4c72-8c0f-221f1b169db8 30742 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2fb8345d39c0b9e6a735429c8c283e62ab73e26858f4a4430651d5c99d9e9759 cni.projectcalico.org/podIP:100.101.231.167/32 cni.projectcalico.org/podIPs:100.101.231.167/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e88e7 0xc0057e88e8}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ztl8s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ztl8s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-fq5k7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fq5k7 webserver-deployment-69b7448995- deployment-2627  52505ab5-9a34-4039-b010-6f29e59bf5f3 30699 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e8ad7 0xc0057e8ad8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-55w44,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-55w44,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.120: INFO: Pod "webserver-deployment-69b7448995-gc4qt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-gc4qt webserver-deployment-69b7448995- deployment-2627  f6d3d1fb-97b1-4250-94f6-72df2104ba23 30638 0 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:a1d6b2b7d2fb05aaef4e4198d39472a975893e458da2a1b6248b1a3d432cd814 cni.projectcalico.org/podIP:100.105.72.163/32 cni.projectcalico.org/podIPs:100.105.72.163/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e8c40 0xc0057e8c41}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-666cr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-666cr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-hn5gw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-hn5gw webserver-deployment-69b7448995- deployment-2627  9ed7610d-aec7-4847-b84e-91150fbd2ee4 30740 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:38aa43b282c6c68b426ab84cf7f37830dae14723c4000846f5a8f393d8eaa721 cni.projectcalico.org/podIP:100.123.145.208/32 cni.projectcalico.org/podIPs:100.123.145.208/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e8e37 0xc0057e8e38}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xdjfl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xdjfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-jdss8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jdss8 webserver-deployment-69b7448995- deployment-2627  0c37d0b0-9922-41ff-a40a-580114030fa9 30726 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9027 0xc0057e9028}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h4jtg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h4jtg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-lzzxz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lzzxz webserver-deployment-69b7448995- deployment-2627  f049d506-033d-40f5-83e9-8485fe8d7bd6 30732 0 2023-05-02 00:01:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:096d695530fd2a93b488084dada5ae59e25ced45797257f2dac72857db3c32c0 cni.projectcalico.org/podIP:100.101.231.148/32 cni.projectcalico.org/podIPs:100.101.231.148/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9207 0xc0057e9208}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.148\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4t26n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4t26n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:100.101.231.148,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.101.231.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.121: INFO: Pod "webserver-deployment-69b7448995-mjxh2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mjxh2 webserver-deployment-69b7448995- deployment-2627  6a733da6-0653-4f04-a952-233a61e4b9ce 30717 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9437 0xc0057e9438}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nc4sr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nc4sr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.122: INFO: Pod "webserver-deployment-69b7448995-qng7f" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qng7f webserver-deployment-69b7448995- deployment-2627  2b1455e7-8577-4e87-b287-c7c6921d49f7 30728 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9617 0xc0057e9618}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7q5tp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7q5tp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.122: INFO: Pod "webserver-deployment-69b7448995-wqh49" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wqh49 webserver-deployment-69b7448995- deployment-2627  7e2fb111-b9ae-4fbf-b9e1-f72f530793a5 30646 0 2023-05-02 00:01:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2e27f12631ee59b6d7740a4c206eddf6bac067856fd92f2b2ce0b2a9218b1d1c cni.projectcalico.org/podIP:100.96.36.30/32 cni.projectcalico.org/podIPs:100.96.36.30/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 f5ce533e-f21b-457d-b56d-ecaa3aaed03a 0xc0057e9817 0xc0057e9818}] [] [{calico Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5ce533e-f21b-457d-b56d-ecaa3aaed03a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l9rdf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l9rdf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.122: INFO: Pod "webserver-deployment-845c8977d9-8dvj6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8dvj6 webserver-deployment-845c8977d9- deployment-2627  48c3885e-4492-4757-8b74-d8f0d481a575 30578 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ef9a09e2c0b9879d6ce801961c1a4bcb62d655ddffc04e80a9a3e499fd3287d0 cni.projectcalico.org/podIP:100.101.231.149/32 cni.projectcalico.org/podIPs:100.101.231.149/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9a17 0xc0057e9a18}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.149\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q5s75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q5s75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:100.101.231.149,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e79619f14acea8403e5c9bef06a46447132b77528adada94096862649e2cd791,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.101.231.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.122: INFO: Pod "webserver-deployment-845c8977d9-8t6qp" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8t6qp webserver-deployment-845c8977d9- deployment-2627  d806d7db-7df5-49ba-9b8f-68f78765347b 30576 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:2b57b26e5ea261ba2e6144137ce29de8e156c938ca7b25d7f39c60379fee3178 cni.projectcalico.org/podIP:100.101.231.166/32 cni.projectcalico.org/podIPs:100.101.231.166/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9c07 0xc0057e9c08}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.101.231.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jkg94,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jkg94,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:100.101.231.166,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://62d903a9ef20dabbe3e41d1eb1d8cdff36eb92d3366c6ee219694979cf34b484,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.101.231.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.123: INFO: Pod "webserver-deployment-845c8977d9-9fd4l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9fd4l webserver-deployment-845c8977d9- deployment-2627  8a3ada51-e0ca-4bef-a79a-21315013e142 30697 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9df7 0xc0057e9df8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lnk6w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lnk6w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.123: INFO: Pod "webserver-deployment-845c8977d9-9kgsx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9kgsx webserver-deployment-845c8977d9- deployment-2627  aaded8b6-7c2b-466b-a868-539fc2fc2d14 30695 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc0057e9f50 0xc0057e9f51}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zdx9k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zdx9k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.123: INFO: Pod "webserver-deployment-845c8977d9-fkzjc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fkzjc webserver-deployment-845c8977d9- deployment-2627  a96fbd5d-0ff7-4662-a3f9-5076beb22ad3 30701 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a107 0xc00630a108}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dxcbd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dxcbd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-gr9lh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gr9lh webserver-deployment-845c8977d9- deployment-2627  9554e4d8-3008-433c-a81f-7311030e0eb1 30711 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a270 0xc00630a271}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pcl2q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pcl2q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-kbq4p" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kbq4p webserver-deployment-845c8977d9- deployment-2627  677656c8-ed47-4ad9-829e-49f78504e23a 30698 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a427 0xc00630a428}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvnsc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvnsc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-pgfnb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-pgfnb webserver-deployment-845c8977d9- deployment-2627  9698c0d8-7215-4f4d-a90e-ee5d1f16a10a 30712 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a580 0xc00630a581}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2xdjv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2xdjv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.124: INFO: Pod "webserver-deployment-845c8977d9-pmctb" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-pmctb webserver-deployment-845c8977d9- deployment-2627  4fece679-7b6d-48e0-9b4c-1a232629eda3 30588 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4cb210fa6de6093afb253539f55e4888de830be1b20723415051cc1e6d7e9fa3 cni.projectcalico.org/podIP:100.105.72.164/32 cni.projectcalico.org/podIPs:100.105.72.164/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a737 0xc00630a738}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.164\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bxsrh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bxsrh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:100.105.72.164,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://26e43147c1e442da3bb24cf4420107c54ee4193b49674c0f74b1362370e01b58,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.105.72.164,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-qw5q2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qw5q2 webserver-deployment-845c8977d9- deployment-2627  88c80a1c-6328-4190-b96e-aa1ee7593414 30707 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630a927 0xc00630a928}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dc546,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dc546,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-rtgzk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rtgzk webserver-deployment-845c8977d9- deployment-2627  84243f11-5785-4511-929d-ba9aff4cc40b 30747 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ee7a7f60a08c7d7f430c111557be094cbea090bb6f2a5b40d6d711ede1d366cf cni.projectcalico.org/podIP:100.101.231.168/32 cni.projectcalico.org/podIPs:100.101.231.168/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630aae7 0xc00630aae8}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j6bxf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j6bxf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0aa263047c51ef669,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.39.145,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-rzxm6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rzxm6 webserver-deployment-845c8977d9- deployment-2627  2f85e838-d535-4bfb-9013-c8682952310f 30710 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630acc7 0xc00630acc8}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mtw47,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mtw47,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.125: INFO: Pod "webserver-deployment-845c8977d9-sf7nd" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-sf7nd webserver-deployment-845c8977d9- deployment-2627  518264d2-e71a-4f7d-b759-1edbc1dd5799 30563 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a715fc333162ed192e02632bb01c52eb6f4a8bdd10a01c069950ac70b2e04307 cni.projectcalico.org/podIP:100.123.145.204/32 cni.projectcalico.org/podIPs:100.123.145.204/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630ae87 0xc00630ae88}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.204\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4xtq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4xtq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:100.123.145.204,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f120b536d3d58c6294fdc6859db051a82758135bd922bdbc706ebb0ed9454ff4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.123.145.204,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.126: INFO: Pod "webserver-deployment-845c8977d9-t448r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-t448r webserver-deployment-845c8977d9- deployment-2627  f7acef51-b05d-47d5-929a-60fab0f582b3 30709 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b077 0xc00630b078}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-94css,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-94css,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.127: INFO: Pod "webserver-deployment-845c8977d9-tjgnx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tjgnx webserver-deployment-845c8977d9- deployment-2627  c6466555-d95e-4a47-bc70-d0a8748aab49 30582 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6cfe063896c5315aa9a47e931d0612ccac507bc616a92c63a5de136451f9fef8 cni.projectcalico.org/podIP:100.105.72.166/32 cni.projectcalico.org/podIPs:100.105.72.166/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b237 0xc00630b238}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wgx8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wgx8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:100.105.72.166,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2865fe48ebcae4b9c753a15aa05b05318cc73ecbc33ddbbd733231fb89358687,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.105.72.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.127: INFO: Pod "webserver-deployment-845c8977d9-tx58p" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tx58p webserver-deployment-845c8977d9- deployment-2627  7db11480-44da-43cf-bd6f-7e9dbf138b2d 30584 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:173d8a06091cb174ba3957cef7fd5c9aea89e360559feabcf7bbe3762f787e80 cni.projectcalico.org/podIP:100.105.72.165/32 cni.projectcalico.org/podIPs:100.105.72.165/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b437 0xc00630b438}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.105.72.165\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ct8bq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ct8bq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:100.105.72.165,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d2935b3471c899fc4a7b39d8a4e596c4b25366e3c92e25991a9604c05a82aaf9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.105.72.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.127: INFO: Pod "webserver-deployment-845c8977d9-v9s8l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-v9s8l webserver-deployment-845c8977d9- deployment-2627  aa71253c-d697-4299-ad6c-93c0668b8874 30741 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5a146668ad0075e038bc46c289b47f4a7cf5266d0763a1980758c309f052dd91 cni.projectcalico.org/podIP:100.105.72.167/32 cni.projectcalico.org/podIPs:100.105.72.167/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b637 0xc00630b638}] [] [{calico Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svn8d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svn8d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-0627b78ff917cf2ae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.62.149,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.128: INFO: Pod "webserver-deployment-845c8977d9-vprlc" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vprlc webserver-deployment-845c8977d9- deployment-2627  5d287828-068f-4fd6-9a42-f5ef7c3e2c79 30569 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:70d1241e6ac56e3b03ce104595d9de69a6bc9a94c46d4f1ac6c6903cc6b997d8 cni.projectcalico.org/podIP:100.96.36.28/32 cni.projectcalico.org/podIPs:100.96.36.28/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630b827 0xc00630b828}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.36.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xn4d6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xn4d6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:100.96.36.28,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3989feedcbec39dd651f6baa95c5771a84e6c0ebc08905b0176bd2d9a7341848,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.36.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.128: INFO: Pod "webserver-deployment-845c8977d9-whkl9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-whkl9 webserver-deployment-845c8977d9- deployment-2627  2f279b96-5291-40fe-84d4-2ac14a468702 30666 0 2023-05-02 00:01:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630ba27 0xc00630ba28}] [] [{kube-controller-manager Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvdxn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvdxn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-02d061b30635c230c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.48.211,PodIP:,StartTime:2023-05-02 00:01:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    May  2 00:01:36.128: INFO: Pod "webserver-deployment-845c8977d9-zpdbn" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zpdbn webserver-deployment-845c8977d9- deployment-2627  ba85b7eb-2e68-40a3-8205-dc81276dbda4 30561 0 2023-05-02 00:01:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1f2bcb5653658fef1a47d41e981f4a3feb933bb902fa9097c6672357b53d0cae cni.projectcalico.org/podIP:100.123.145.241/32 cni.projectcalico.org/podIPs:100.123.145.241/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 1e8c62e2-5da0-48b5-abe7-65e21d29e799 0xc00630bbe7 0xc00630bbe8}] [] [{calico Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2023-05-02 00:01:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e8c62e2-5da0-48b5-abe7-65e21d29e799\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-05-02 00:01:32 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.123.145.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9txrp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9txrp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-00fed7c0a42791aae,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-05-02 00:01:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.44.200,PodIP:100.123.145.241,StartTime:2023-05-02 00:01:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-05-02 00:01:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b6eba74dd31dd5934e27ea17b4d7222a10a972bec191bc11f73ee33fd7eba19b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.123.145.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    May  2 00:01:36.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2627" for this suite. 05/02/23 00:01:36.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:01:36.346
May  2 00:01:36.347: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename podtemplate 05/02/23 00:01:36.348
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:36.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:36.872
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 05/02/23 00:01:37.081
STEP: Replace a pod template 05/02/23 00:01:37.187
May  2 00:01:37.399: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
May  2 00:01:37.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8648" for this suite. 05/02/23 00:01:37.505
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":256,"skipped":4780,"failed":0}
------------------------------
• [1.266 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:01:36.346
    May  2 00:01:36.347: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename podtemplate 05/02/23 00:01:36.348
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:36.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:36.872
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 05/02/23 00:01:37.081
    STEP: Replace a pod template 05/02/23 00:01:37.187
    May  2 00:01:37.399: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    May  2 00:01:37.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-8648" for this suite. 05/02/23 00:01:37.505
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:01:37.613
May  2 00:01:37.613: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-preemption 05/02/23 00:01:37.614
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:37.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:38.147
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May  2 00:01:38.675: INFO: Waiting up to 1m0s for all nodes to be ready
May  2 00:02:39.429: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:02:39.534
May  2 00:02:39.534: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-preemption-path 05/02/23 00:02:39.535
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:02:39.851
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:02:40.06
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
May  2 00:02:40.589: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
May  2 00:02:40.695: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
May  2 00:02:41.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3267" for this suite. 05/02/23 00:02:41.33
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
May  2 00:02:41.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7686" for this suite. 05/02/23 00:02:41.652
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":257,"skipped":4786,"failed":0}
------------------------------
• [SLOW TEST] [64.916 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:01:37.613
    May  2 00:01:37.613: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-preemption 05/02/23 00:01:37.614
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:01:37.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:01:38.147
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    May  2 00:01:38.675: INFO: Waiting up to 1m0s for all nodes to be ready
    May  2 00:02:39.429: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:02:39.534
    May  2 00:02:39.534: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-preemption-path 05/02/23 00:02:39.535
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:02:39.851
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:02:40.06
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    May  2 00:02:40.589: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    May  2 00:02:40.695: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    May  2 00:02:41.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-3267" for this suite. 05/02/23 00:02:41.33
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:02:41.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7686" for this suite. 05/02/23 00:02:41.652
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:02:42.532
May  2 00:02:42.532: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/02/23 00:02:42.533
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:02:42.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:02:43.058
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1947 05/02/23 00:02:43.267
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-1947 05/02/23 00:02:43.482
May  2 00:02:43.696: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May  2 00:02:53.802: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 05/02/23 00:02:54.012
STEP: Getting /status 05/02/23 00:02:54.12
May  2 00:02:54.227: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 05/02/23 00:02:54.227
May  2 00:02:54.438: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 05/02/23 00:02:54.438
May  2 00:02:54.543: INFO: Observed &StatefulSet event: ADDED
May  2 00:02:54.543: INFO: Found Statefulset ss in namespace statefulset-1947 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
May  2 00:02:54.543: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 05/02/23 00:02:54.543
May  2 00:02:54.543: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
May  2 00:02:54.652: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 05/02/23 00:02:54.652
May  2 00:02:54.757: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  2 00:02:54.758: INFO: Deleting all statefulset in ns statefulset-1947
May  2 00:02:54.864: INFO: Scaling statefulset ss to 0
May  2 00:03:05.289: INFO: Waiting for statefulset status.replicas updated to 0
May  2 00:03:05.394: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  2 00:03:05.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1947" for this suite. 05/02/23 00:03:05.818
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":258,"skipped":4805,"failed":0}
------------------------------
• [SLOW TEST] [23.393 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:02:42.532
    May  2 00:02:42.532: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/02/23 00:02:42.533
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:02:42.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:02:43.058
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1947 05/02/23 00:02:43.267
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-1947 05/02/23 00:02:43.482
    May  2 00:02:43.696: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    May  2 00:02:53.802: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 05/02/23 00:02:54.012
    STEP: Getting /status 05/02/23 00:02:54.12
    May  2 00:02:54.227: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 05/02/23 00:02:54.227
    May  2 00:02:54.438: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 05/02/23 00:02:54.438
    May  2 00:02:54.543: INFO: Observed &StatefulSet event: ADDED
    May  2 00:02:54.543: INFO: Found Statefulset ss in namespace statefulset-1947 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    May  2 00:02:54.543: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 05/02/23 00:02:54.543
    May  2 00:02:54.543: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    May  2 00:02:54.652: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 05/02/23 00:02:54.652
    May  2 00:02:54.757: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  2 00:02:54.758: INFO: Deleting all statefulset in ns statefulset-1947
    May  2 00:02:54.864: INFO: Scaling statefulset ss to 0
    May  2 00:03:05.289: INFO: Waiting for statefulset status.replicas updated to 0
    May  2 00:03:05.394: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  2 00:03:05.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1947" for this suite. 05/02/23 00:03:05.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:03:05.926
May  2 00:03:05.926: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:03:05.927
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:03:06.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:03:06.454
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-8907b030-6e4d-41ba-a315-5f602d33dc09 05/02/23 00:03:06.662
STEP: Creating a pod to test consume secrets 05/02/23 00:03:06.769
May  2 00:03:06.879: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673" in namespace "projected-6806" to be "Succeeded or Failed"
May  2 00:03:06.984: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673": Phase="Pending", Reason="", readiness=false. Elapsed: 105.317677ms
May  2 00:03:09.090: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21155616s
May  2 00:03:11.090: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210987914s
STEP: Saw pod success 05/02/23 00:03:11.09
May  2 00:03:11.090: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673" satisfied condition "Succeeded or Failed"
May  2 00:03:11.195: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673 container secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:03:11.31
May  2 00:03:11.426: INFO: Waiting for pod pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673 to disappear
May  2 00:03:11.530: INFO: Pod pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  2 00:03:11.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6806" for this suite. 05/02/23 00:03:11.636
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":259,"skipped":4813,"failed":0}
------------------------------
• [SLOW TEST] [5.921 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:03:05.926
    May  2 00:03:05.926: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:03:05.927
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:03:06.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:03:06.454
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-8907b030-6e4d-41ba-a315-5f602d33dc09 05/02/23 00:03:06.662
    STEP: Creating a pod to test consume secrets 05/02/23 00:03:06.769
    May  2 00:03:06.879: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673" in namespace "projected-6806" to be "Succeeded or Failed"
    May  2 00:03:06.984: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673": Phase="Pending", Reason="", readiness=false. Elapsed: 105.317677ms
    May  2 00:03:09.090: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21155616s
    May  2 00:03:11.090: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210987914s
    STEP: Saw pod success 05/02/23 00:03:11.09
    May  2 00:03:11.090: INFO: Pod "pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673" satisfied condition "Succeeded or Failed"
    May  2 00:03:11.195: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673 container secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:03:11.31
    May  2 00:03:11.426: INFO: Waiting for pod pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673 to disappear
    May  2 00:03:11.530: INFO: Pod pod-projected-secrets-3861971c-e9a7-40c9-add8-886033a9c673 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  2 00:03:11.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6806" for this suite. 05/02/23 00:03:11.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:03:11.848
May  2 00:03:11.848: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename endpointslice 05/02/23 00:03:11.85
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:03:12.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:03:12.373
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
May  2 00:03:12.905: INFO: Endpoints addresses: [172.20.32.205] , ports: [443]
May  2 00:03:12.905: INFO: EndpointSlices addresses: [172.20.32.205] , ports: [443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
May  2 00:03:12.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3519" for this suite. 05/02/23 00:03:13.012
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":260,"skipped":4824,"failed":0}
------------------------------
• [1.271 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:03:11.848
    May  2 00:03:11.848: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename endpointslice 05/02/23 00:03:11.85
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:03:12.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:03:12.373
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    May  2 00:03:12.905: INFO: Endpoints addresses: [172.20.32.205] , ports: [443]
    May  2 00:03:12.905: INFO: EndpointSlices addresses: [172.20.32.205] , ports: [443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    May  2 00:03:12.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-3519" for this suite. 05/02/23 00:03:13.012
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:03:13.12
May  2 00:03:13.120: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/02/23 00:03:13.121
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:03:13.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:03:13.648
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 05/02/23 00:03:13.857
May  2 00:03:13.857: INFO: >>> kubeConfig: /root/.kube/config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 05/02/23 00:03:46.694
May  2 00:03:46.695: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:03:53.925: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:04:25.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-711" for this suite. 05/02/23 00:04:26.068
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":261,"skipped":4843,"failed":0}
------------------------------
• [SLOW TEST] [73.055 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:03:13.12
    May  2 00:03:13.120: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/02/23 00:03:13.121
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:03:13.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:03:13.648
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 05/02/23 00:03:13.857
    May  2 00:03:13.857: INFO: >>> kubeConfig: /root/.kube/config
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 05/02/23 00:03:46.694
    May  2 00:03:46.695: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:03:53.925: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:04:25.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-711" for this suite. 05/02/23 00:04:26.068
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:26.176
May  2 00:04:26.177: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/02/23 00:04:26.178
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:26.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:26.699
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 05/02/23 00:04:26.907
May  2 00:04:27.015: INFO: Waiting up to 5m0s for pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7" in namespace "emptydir-5036" to be "Succeeded or Failed"
May  2 00:04:27.120: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7": Phase="Pending", Reason="", readiness=false. Elapsed: 104.552966ms
May  2 00:04:29.225: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209784192s
May  2 00:04:31.225: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209551096s
STEP: Saw pod success 05/02/23 00:04:31.225
May  2 00:04:31.225: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7" satisfied condition "Succeeded or Failed"
May  2 00:04:31.330: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7 container test-container: <nil>
STEP: delete the pod 05/02/23 00:04:31.436
May  2 00:04:31.548: INFO: Waiting for pod pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7 to disappear
May  2 00:04:31.652: INFO: Pod pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  2 00:04:31.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5036" for this suite. 05/02/23 00:04:31.758
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":262,"skipped":4871,"failed":0}
------------------------------
• [SLOW TEST] [5.688 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:26.176
    May  2 00:04:26.177: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/02/23 00:04:26.178
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:26.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:26.699
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 05/02/23 00:04:26.907
    May  2 00:04:27.015: INFO: Waiting up to 5m0s for pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7" in namespace "emptydir-5036" to be "Succeeded or Failed"
    May  2 00:04:27.120: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7": Phase="Pending", Reason="", readiness=false. Elapsed: 104.552966ms
    May  2 00:04:29.225: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209784192s
    May  2 00:04:31.225: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209551096s
    STEP: Saw pod success 05/02/23 00:04:31.225
    May  2 00:04:31.225: INFO: Pod "pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7" satisfied condition "Succeeded or Failed"
    May  2 00:04:31.330: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7 container test-container: <nil>
    STEP: delete the pod 05/02/23 00:04:31.436
    May  2 00:04:31.548: INFO: Waiting for pod pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7 to disappear
    May  2 00:04:31.652: INFO: Pod pod-e3e2aa55-f85c-43e3-aefb-d00d90a6a1a7 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  2 00:04:31.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5036" for this suite. 05/02/23 00:04:31.758
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:31.865
May  2 00:04:31.865: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/02/23 00:04:31.867
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:32.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:32.389
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/02/23 00:04:32.809
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:04:33.257
STEP: Deploying the webhook pod 05/02/23 00:04:33.364
STEP: Wait for the deployment to be ready 05/02/23 00:04:33.581
May  2 00:04:33.894: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/02/23 00:04:35.999
STEP: Verifying the service has paired with the endpoint 05/02/23 00:04:36.109
May  2 00:04:37.109: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 05/02/23 00:04:38.286
STEP: Creating a configMap that should be mutated 05/02/23 00:04:38.501
STEP: Deleting the collection of validation webhooks 05/02/23 00:04:38.729
STEP: Creating a configMap that should not be mutated 05/02/23 00:04:38.856
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:04:39.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6376" for this suite. 05/02/23 00:04:39.173
STEP: Destroying namespace "webhook-6376-markers" for this suite. 05/02/23 00:04:39.28
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":263,"skipped":4873,"failed":0}
------------------------------
• [SLOW TEST] [7.959 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:31.865
    May  2 00:04:31.865: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/02/23 00:04:31.867
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:32.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:32.389
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/02/23 00:04:32.809
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:04:33.257
    STEP: Deploying the webhook pod 05/02/23 00:04:33.364
    STEP: Wait for the deployment to be ready 05/02/23 00:04:33.581
    May  2 00:04:33.894: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 4, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/02/23 00:04:35.999
    STEP: Verifying the service has paired with the endpoint 05/02/23 00:04:36.109
    May  2 00:04:37.109: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 05/02/23 00:04:38.286
    STEP: Creating a configMap that should be mutated 05/02/23 00:04:38.501
    STEP: Deleting the collection of validation webhooks 05/02/23 00:04:38.729
    STEP: Creating a configMap that should not be mutated 05/02/23 00:04:38.856
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:04:39.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6376" for this suite. 05/02/23 00:04:39.173
    STEP: Destroying namespace "webhook-6376-markers" for this suite. 05/02/23 00:04:39.28
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:39.825
May  2 00:04:39.825: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset 05/02/23 00:04:39.826
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:40.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:40.349
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 05/02/23 00:04:40.557
May  2 00:04:40.664: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-2194" to be "running and ready"
May  2 00:04:40.768: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 104.408017ms
May  2 00:04:40.769: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
May  2 00:04:42.873: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.209395362s
May  2 00:04:42.874: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
May  2 00:04:42.874: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 05/02/23 00:04:42.978
STEP: Then the orphan pod is adopted 05/02/23 00:04:43.084
STEP: When the matched label of one of its pods change 05/02/23 00:04:43.188
May  2 00:04:43.293: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 05/02/23 00:04:43.51
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
May  2 00:04:43.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2194" for this suite. 05/02/23 00:04:43.72
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":264,"skipped":4878,"failed":0}
------------------------------
• [4.102 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:39.825
    May  2 00:04:39.825: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replicaset 05/02/23 00:04:39.826
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:40.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:40.349
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 05/02/23 00:04:40.557
    May  2 00:04:40.664: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-2194" to be "running and ready"
    May  2 00:04:40.768: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 104.408017ms
    May  2 00:04:40.769: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:04:42.873: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.209395362s
    May  2 00:04:42.874: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    May  2 00:04:42.874: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 05/02/23 00:04:42.978
    STEP: Then the orphan pod is adopted 05/02/23 00:04:43.084
    STEP: When the matched label of one of its pods change 05/02/23 00:04:43.188
    May  2 00:04:43.293: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 05/02/23 00:04:43.51
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    May  2 00:04:43.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2194" for this suite. 05/02/23 00:04:43.72
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:43.928
May  2 00:04:43.928: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/02/23 00:04:43.93
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:44.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:44.449
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 05/02/23 00:04:44.656
May  2 00:04:44.763: INFO: Waiting up to 5m0s for pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76" in namespace "emptydir-2975" to be "Succeeded or Failed"
May  2 00:04:44.867: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76": Phase="Pending", Reason="", readiness=false. Elapsed: 104.506275ms
May  2 00:04:46.973: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76": Phase="Running", Reason="", readiness=false. Elapsed: 2.210376609s
May  2 00:04:48.978: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.214945787s
STEP: Saw pod success 05/02/23 00:04:48.978
May  2 00:04:48.978: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76" satisfied condition "Succeeded or Failed"
May  2 00:04:49.082: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-108081a5-c411-4fee-9ff3-ad24cedf9f76 container test-container: <nil>
STEP: delete the pod 05/02/23 00:04:49.19
May  2 00:04:49.305: INFO: Waiting for pod pod-108081a5-c411-4fee-9ff3-ad24cedf9f76 to disappear
May  2 00:04:49.409: INFO: Pod pod-108081a5-c411-4fee-9ff3-ad24cedf9f76 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  2 00:04:49.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2975" for this suite. 05/02/23 00:04:49.515
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":265,"skipped":4884,"failed":0}
------------------------------
• [SLOW TEST] [5.794 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:43.928
    May  2 00:04:43.928: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/02/23 00:04:43.93
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:44.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:44.449
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 05/02/23 00:04:44.656
    May  2 00:04:44.763: INFO: Waiting up to 5m0s for pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76" in namespace "emptydir-2975" to be "Succeeded or Failed"
    May  2 00:04:44.867: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76": Phase="Pending", Reason="", readiness=false. Elapsed: 104.506275ms
    May  2 00:04:46.973: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76": Phase="Running", Reason="", readiness=false. Elapsed: 2.210376609s
    May  2 00:04:48.978: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.214945787s
    STEP: Saw pod success 05/02/23 00:04:48.978
    May  2 00:04:48.978: INFO: Pod "pod-108081a5-c411-4fee-9ff3-ad24cedf9f76" satisfied condition "Succeeded or Failed"
    May  2 00:04:49.082: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-108081a5-c411-4fee-9ff3-ad24cedf9f76 container test-container: <nil>
    STEP: delete the pod 05/02/23 00:04:49.19
    May  2 00:04:49.305: INFO: Waiting for pod pod-108081a5-c411-4fee-9ff3-ad24cedf9f76 to disappear
    May  2 00:04:49.409: INFO: Pod pod-108081a5-c411-4fee-9ff3-ad24cedf9f76 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  2 00:04:49.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2975" for this suite. 05/02/23 00:04:49.515
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:49.723
May  2 00:04:49.723: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred 05/02/23 00:04:49.724
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:50.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:50.246
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May  2 00:04:50.453: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  2 00:04:50.671: INFO: Waiting for terminating namespaces to be deleted...
May  2 00:04:50.775: INFO: 
Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
May  2 00:04:50.883: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
May  2 00:04:50.883: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:04:50.883: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  2 00:04:50.883: INFO: 	Container coredns ready: true, restart count 0
May  2 00:04:50.883: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  2 00:04:50.883: INFO: 	Container autoscaler ready: true, restart count 0
May  2 00:04:50.883: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
May  2 00:04:50.883: INFO: 	Container csi-attacher ready: true, restart count 0
May  2 00:04:50.883: INFO: 	Container csi-provisioner ready: true, restart count 0
May  2 00:04:50.883: INFO: 	Container csi-resizer ready: true, restart count 0
May  2 00:04:50.883: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:04:50.883: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:04:50.883: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
May  2 00:04:50.883: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:04:50.883: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:04:50.883: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:04:50.883: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
May  2 00:04:50.883: INFO: 	Container kube-proxy ready: true, restart count 0
May  2 00:04:50.883: INFO: 
Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
May  2 00:04:50.991: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
May  2 00:04:50.991: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:04:50.991: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
May  2 00:04:50.991: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:04:50.991: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:04:50.991: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:04:50.991: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
May  2 00:04:50.991: INFO: 	Container kube-proxy ready: true, restart count 0
May  2 00:04:50.991: INFO: 
Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
May  2 00:04:51.099: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
May  2 00:04:51.099: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:04:51.099: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
May  2 00:04:51.099: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:04:51.099: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:04:51.099: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:04:51.099: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
May  2 00:04:51.099: INFO: 	Container kube-proxy ready: true, restart count 0
May  2 00:04:51.099: INFO: 
Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
May  2 00:04:51.207: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
May  2 00:04:51.207: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:04:51.207: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
May  2 00:04:51.208: INFO: 	Container coredns ready: true, restart count 0
May  2 00:04:51.208: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
May  2 00:04:51.208: INFO: 	Container csi-attacher ready: true, restart count 0
May  2 00:04:51.208: INFO: 	Container csi-provisioner ready: true, restart count 0
May  2 00:04:51.208: INFO: 	Container csi-resizer ready: true, restart count 0
May  2 00:04:51.208: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:04:51.208: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:04:51.208: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
May  2 00:04:51.208: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:04:51.208: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:04:51.208: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:04:51.208: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
May  2 00:04:51.208: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 05/02/23 00:04:51.208
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.175b2ac065d46722], Reason = [FailedScheduling], Message = [0/5 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 05/02/23 00:04:51.641
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
May  2 00:04:52.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-744" for this suite. 05/02/23 00:04:52.846
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":266,"skipped":4908,"failed":0}
------------------------------
• [3.229 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:49.723
    May  2 00:04:49.723: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-pred 05/02/23 00:04:49.724
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:50.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:50.246
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    May  2 00:04:50.453: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    May  2 00:04:50.671: INFO: Waiting for terminating namespaces to be deleted...
    May  2 00:04:50.775: INFO: 
    Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
    May  2 00:04:50.883: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
    May  2 00:04:50.883: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:04:50.883: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  2 00:04:50.883: INFO: 	Container coredns ready: true, restart count 0
    May  2 00:04:50.883: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  2 00:04:50.883: INFO: 	Container autoscaler ready: true, restart count 0
    May  2 00:04:50.883: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
    May  2 00:04:50.883: INFO: 	Container csi-attacher ready: true, restart count 0
    May  2 00:04:50.883: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  2 00:04:50.883: INFO: 	Container csi-resizer ready: true, restart count 0
    May  2 00:04:50.883: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:04:50.883: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:04:50.883: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
    May  2 00:04:50.883: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:04:50.883: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:04:50.883: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:04:50.883: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
    May  2 00:04:50.883: INFO: 	Container kube-proxy ready: true, restart count 0
    May  2 00:04:50.883: INFO: 
    Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
    May  2 00:04:50.991: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
    May  2 00:04:50.991: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:04:50.991: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
    May  2 00:04:50.991: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:04:50.991: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:04:50.991: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:04:50.991: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
    May  2 00:04:50.991: INFO: 	Container kube-proxy ready: true, restart count 0
    May  2 00:04:50.991: INFO: 
    Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
    May  2 00:04:51.099: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
    May  2 00:04:51.099: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:04:51.099: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
    May  2 00:04:51.099: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:04:51.099: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:04:51.099: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:04:51.099: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
    May  2 00:04:51.099: INFO: 	Container kube-proxy ready: true, restart count 0
    May  2 00:04:51.099: INFO: 
    Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
    May  2 00:04:51.207: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
    May  2 00:04:51.207: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:04:51.207: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
    May  2 00:04:51.208: INFO: 	Container coredns ready: true, restart count 0
    May  2 00:04:51.208: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
    May  2 00:04:51.208: INFO: 	Container csi-attacher ready: true, restart count 0
    May  2 00:04:51.208: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  2 00:04:51.208: INFO: 	Container csi-resizer ready: true, restart count 0
    May  2 00:04:51.208: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:04:51.208: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:04:51.208: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
    May  2 00:04:51.208: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:04:51.208: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:04:51.208: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:04:51.208: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
    May  2 00:04:51.208: INFO: 	Container kube-proxy ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 05/02/23 00:04:51.208
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.175b2ac065d46722], Reason = [FailedScheduling], Message = [0/5 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 05/02/23 00:04:51.641
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:04:52.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-744" for this suite. 05/02/23 00:04:52.846
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:52.954
May  2 00:04:52.954: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime 05/02/23 00:04:52.955
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:53.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:53.476
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 05/02/23 00:04:53.683
STEP: wait for the container to reach Succeeded 05/02/23 00:04:53.792
STEP: get the container status 05/02/23 00:04:57.213
STEP: the container should be terminated 05/02/23 00:04:57.318
STEP: the termination message should be set 05/02/23 00:04:57.318
May  2 00:04:57.318: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 05/02/23 00:04:57.318
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
May  2 00:04:57.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7983" for this suite. 05/02/23 00:04:57.64
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":267,"skipped":4949,"failed":0}
------------------------------
• [4.793 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:52.954
    May  2 00:04:52.954: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-runtime 05/02/23 00:04:52.955
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:53.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:53.476
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 05/02/23 00:04:53.683
    STEP: wait for the container to reach Succeeded 05/02/23 00:04:53.792
    STEP: get the container status 05/02/23 00:04:57.213
    STEP: the container should be terminated 05/02/23 00:04:57.318
    STEP: the termination message should be set 05/02/23 00:04:57.318
    May  2 00:04:57.318: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 05/02/23 00:04:57.318
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    May  2 00:04:57.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7983" for this suite. 05/02/23 00:04:57.64
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:57.749
May  2 00:04:57.749: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename events 05/02/23 00:04:57.75
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:58.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:58.27
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 05/02/23 00:04:58.478
STEP: get a list of Events with a label in the current namespace 05/02/23 00:04:58.797
STEP: delete a list of events 05/02/23 00:04:58.901
May  2 00:04:58.901: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 05/02/23 00:04:59.016
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
May  2 00:04:59.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-781" for this suite. 05/02/23 00:04:59.226
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":268,"skipped":4979,"failed":0}
------------------------------
• [1.583 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:57.749
    May  2 00:04:57.749: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename events 05/02/23 00:04:57.75
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:58.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:58.27
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 05/02/23 00:04:58.478
    STEP: get a list of Events with a label in the current namespace 05/02/23 00:04:58.797
    STEP: delete a list of events 05/02/23 00:04:58.901
    May  2 00:04:58.901: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 05/02/23 00:04:59.016
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    May  2 00:04:59.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-781" for this suite. 05/02/23 00:04:59.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:04:59.333
May  2 00:04:59.333: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/02/23 00:04:59.334
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:59.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:59.853
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
STEP: creating service in namespace services-3247 05/02/23 00:05:00.06
STEP: creating service affinity-clusterip-transition in namespace services-3247 05/02/23 00:05:00.061
STEP: creating replication controller affinity-clusterip-transition in namespace services-3247 05/02/23 00:05:00.17
I0502 00:05:00.277350    6969 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3247, replica count: 3
I0502 00:05:03.428421    6969 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 00:05:03.636: INFO: Creating new exec pod
May  2 00:05:03.742: INFO: Waiting up to 5m0s for pod "execpod-affinityjh5lv" in namespace "services-3247" to be "running"
May  2 00:05:03.846: INFO: Pod "execpod-affinityjh5lv": Phase="Pending", Reason="", readiness=false. Elapsed: 103.976237ms
May  2 00:05:05.950: INFO: Pod "execpod-affinityjh5lv": Phase="Running", Reason="", readiness=true. Elapsed: 2.20840335s
May  2 00:05:05.950: INFO: Pod "execpod-affinityjh5lv" satisfied condition "running"
May  2 00:05:06.951: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
May  2 00:05:08.099: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
May  2 00:05:08.099: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 00:05:08.099: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.37.1 80'
May  2 00:05:09.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.37.1 80\nConnection to 100.65.37.1 80 port [tcp/http] succeeded!\n"
May  2 00:05:09.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
May  2 00:05:09.447: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.65.37.1:80/ ; done'
May  2 00:05:10.753: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n"
May  2 00:05:10.753: INFO: stdout: "\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-dlvsl\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-dlvsl\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-dlvsl\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz"
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-dlvsl
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-dlvsl
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-dlvsl
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:10.964: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.65.37.1:80/ ; done'
May  2 00:05:12.204: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n"
May  2 00:05:12.204: INFO: stdout: "\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz"
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
May  2 00:05:12.204: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3247, will wait for the garbage collector to delete the pods 05/02/23 00:05:12.318
May  2 00:05:12.678: INFO: Deleting ReplicationController affinity-clusterip-transition took: 105.340507ms
May  2 00:05:12.779: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.794525ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  2 00:05:14.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3247" for this suite. 05/02/23 00:05:14.912
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":269,"skipped":4996,"failed":0}
------------------------------
• [SLOW TEST] [15.685 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:04:59.333
    May  2 00:04:59.333: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/02/23 00:04:59.334
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:04:59.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:04:59.853
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2179
    STEP: creating service in namespace services-3247 05/02/23 00:05:00.06
    STEP: creating service affinity-clusterip-transition in namespace services-3247 05/02/23 00:05:00.061
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3247 05/02/23 00:05:00.17
    I0502 00:05:00.277350    6969 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3247, replica count: 3
    I0502 00:05:03.428421    6969 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  2 00:05:03.636: INFO: Creating new exec pod
    May  2 00:05:03.742: INFO: Waiting up to 5m0s for pod "execpod-affinityjh5lv" in namespace "services-3247" to be "running"
    May  2 00:05:03.846: INFO: Pod "execpod-affinityjh5lv": Phase="Pending", Reason="", readiness=false. Elapsed: 103.976237ms
    May  2 00:05:05.950: INFO: Pod "execpod-affinityjh5lv": Phase="Running", Reason="", readiness=true. Elapsed: 2.20840335s
    May  2 00:05:05.950: INFO: Pod "execpod-affinityjh5lv" satisfied condition "running"
    May  2 00:05:06.951: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    May  2 00:05:08.099: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    May  2 00:05:08.099: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  2 00:05:08.099: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.37.1 80'
    May  2 00:05:09.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.37.1 80\nConnection to 100.65.37.1 80 port [tcp/http] succeeded!\n"
    May  2 00:05:09.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    May  2 00:05:09.447: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.65.37.1:80/ ; done'
    May  2 00:05:10.753: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n"
    May  2 00:05:10.753: INFO: stdout: "\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-dlvsl\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-dlvsl\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-dlvsl\naffinity-clusterip-transition-th2wc\naffinity-clusterip-transition-gt6bz"
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-dlvsl
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-dlvsl
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-dlvsl
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-th2wc
    May  2 00:05:10.753: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:10.964: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-3247 exec execpod-affinityjh5lv -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.65.37.1:80/ ; done'
    May  2 00:05:12.204: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.65.37.1:80/\n"
    May  2 00:05:12.204: INFO: stdout: "\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz\naffinity-clusterip-transition-gt6bz"
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Received response from host: affinity-clusterip-transition-gt6bz
    May  2 00:05:12.204: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3247, will wait for the garbage collector to delete the pods 05/02/23 00:05:12.318
    May  2 00:05:12.678: INFO: Deleting ReplicationController affinity-clusterip-transition took: 105.340507ms
    May  2 00:05:12.779: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.794525ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  2 00:05:14.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3247" for this suite. 05/02/23 00:05:14.912
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:05:15.021
May  2 00:05:15.021: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:05:15.022
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:15.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:15.543
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-9e8d01d0-54b3-4641-87d2-5337184d0e4a 05/02/23 00:05:15.75
STEP: Creating a pod to test consume secrets 05/02/23 00:05:15.859
May  2 00:05:15.968: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b" in namespace "projected-1453" to be "Succeeded or Failed"
May  2 00:05:16.072: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.457474ms
May  2 00:05:18.178: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210089243s
May  2 00:05:20.177: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20932726s
STEP: Saw pod success 05/02/23 00:05:20.177
May  2 00:05:20.177: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b" satisfied condition "Succeeded or Failed"
May  2 00:05:20.282: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b container projected-secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:05:20.397
May  2 00:05:20.509: INFO: Waiting for pod pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b to disappear
May  2 00:05:20.614: INFO: Pod pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  2 00:05:20.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1453" for this suite. 05/02/23 00:05:20.719
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":270,"skipped":5008,"failed":0}
------------------------------
• [SLOW TEST] [5.804 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:05:15.021
    May  2 00:05:15.021: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:05:15.022
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:15.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:15.543
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-9e8d01d0-54b3-4641-87d2-5337184d0e4a 05/02/23 00:05:15.75
    STEP: Creating a pod to test consume secrets 05/02/23 00:05:15.859
    May  2 00:05:15.968: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b" in namespace "projected-1453" to be "Succeeded or Failed"
    May  2 00:05:16.072: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.457474ms
    May  2 00:05:18.178: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210089243s
    May  2 00:05:20.177: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20932726s
    STEP: Saw pod success 05/02/23 00:05:20.177
    May  2 00:05:20.177: INFO: Pod "pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b" satisfied condition "Succeeded or Failed"
    May  2 00:05:20.282: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b container projected-secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:05:20.397
    May  2 00:05:20.509: INFO: Waiting for pod pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b to disappear
    May  2 00:05:20.614: INFO: Pod pod-projected-secrets-fc725f16-7802-4d64-ad51-09967067555b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  2 00:05:20.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1453" for this suite. 05/02/23 00:05:20.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:05:20.827
May  2 00:05:20.827: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/02/23 00:05:20.828
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:21.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:21.349
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-01e3b62d-50bd-462e-81a7-87c1cf894e34 05/02/23 00:05:21.557
STEP: Creating a pod to test consume configMaps 05/02/23 00:05:21.667
May  2 00:05:21.775: INFO: Waiting up to 5m0s for pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7" in namespace "configmap-4467" to be "Succeeded or Failed"
May  2 00:05:21.879: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7": Phase="Pending", Reason="", readiness=false. Elapsed: 104.466397ms
May  2 00:05:23.985: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209843531s
May  2 00:05:25.984: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209482691s
STEP: Saw pod success 05/02/23 00:05:25.984
May  2 00:05:25.984: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7" satisfied condition "Succeeded or Failed"
May  2 00:05:26.089: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7 container agnhost-container: <nil>
STEP: delete the pod 05/02/23 00:05:26.195
May  2 00:05:26.307: INFO: Waiting for pod pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7 to disappear
May  2 00:05:26.411: INFO: Pod pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  2 00:05:26.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4467" for this suite. 05/02/23 00:05:26.516
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":271,"skipped":5028,"failed":0}
------------------------------
• [SLOW TEST] [5.796 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:05:20.827
    May  2 00:05:20.827: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/02/23 00:05:20.828
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:21.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:21.349
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-01e3b62d-50bd-462e-81a7-87c1cf894e34 05/02/23 00:05:21.557
    STEP: Creating a pod to test consume configMaps 05/02/23 00:05:21.667
    May  2 00:05:21.775: INFO: Waiting up to 5m0s for pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7" in namespace "configmap-4467" to be "Succeeded or Failed"
    May  2 00:05:21.879: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7": Phase="Pending", Reason="", readiness=false. Elapsed: 104.466397ms
    May  2 00:05:23.985: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209843531s
    May  2 00:05:25.984: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209482691s
    STEP: Saw pod success 05/02/23 00:05:25.984
    May  2 00:05:25.984: INFO: Pod "pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7" satisfied condition "Succeeded or Failed"
    May  2 00:05:26.089: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7 container agnhost-container: <nil>
    STEP: delete the pod 05/02/23 00:05:26.195
    May  2 00:05:26.307: INFO: Waiting for pod pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7 to disappear
    May  2 00:05:26.411: INFO: Pod pod-configmaps-03ebd177-5639-4f1b-9ade-7d45dfc672c7 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  2 00:05:26.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4467" for this suite. 05/02/23 00:05:26.516
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:05:26.625
May  2 00:05:26.625: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/02/23 00:05:26.626
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:26.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:27.147
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 05/02/23 00:05:27.354
STEP: Creating a ResourceQuota 05/02/23 00:05:32.458
STEP: Ensuring resource quota status is calculated 05/02/23 00:05:32.564
STEP: Creating a Service 05/02/23 00:05:34.67
STEP: Creating a NodePort Service 05/02/23 00:05:34.785
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 05/02/23 00:05:34.904
STEP: Ensuring resource quota status captures service creation 05/02/23 00:05:35.02
STEP: Deleting Services 05/02/23 00:05:37.125
STEP: Ensuring resource quota status released usage 05/02/23 00:05:37.369
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  2 00:05:39.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5814" for this suite. 05/02/23 00:05:39.579
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":272,"skipped":5101,"failed":0}
------------------------------
• [SLOW TEST] [13.162 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:05:26.625
    May  2 00:05:26.625: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/02/23 00:05:26.626
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:26.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:27.147
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 05/02/23 00:05:27.354
    STEP: Creating a ResourceQuota 05/02/23 00:05:32.458
    STEP: Ensuring resource quota status is calculated 05/02/23 00:05:32.564
    STEP: Creating a Service 05/02/23 00:05:34.67
    STEP: Creating a NodePort Service 05/02/23 00:05:34.785
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 05/02/23 00:05:34.904
    STEP: Ensuring resource quota status captures service creation 05/02/23 00:05:35.02
    STEP: Deleting Services 05/02/23 00:05:37.125
    STEP: Ensuring resource quota status released usage 05/02/23 00:05:37.369
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  2 00:05:39.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5814" for this suite. 05/02/23 00:05:39.579
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:05:39.788
May  2 00:05:39.788: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/02/23 00:05:39.789
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:40.105
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:40.311
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 05/02/23 00:05:40.518
May  2 00:05:40.626: INFO: Waiting up to 5m0s for pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240" in namespace "emptydir-4887" to be "Succeeded or Failed"
May  2 00:05:40.730: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240": Phase="Pending", Reason="", readiness=false. Elapsed: 104.057071ms
May  2 00:05:42.835: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208726484s
May  2 00:05:44.835: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208994915s
STEP: Saw pod success 05/02/23 00:05:44.835
May  2 00:05:44.835: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240" satisfied condition "Succeeded or Failed"
May  2 00:05:44.940: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-a7ced879-0697-48ed-a80e-3fb33fcd9240 container test-container: <nil>
STEP: delete the pod 05/02/23 00:05:45.047
May  2 00:05:45.159: INFO: Waiting for pod pod-a7ced879-0697-48ed-a80e-3fb33fcd9240 to disappear
May  2 00:05:45.263: INFO: Pod pod-a7ced879-0697-48ed-a80e-3fb33fcd9240 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  2 00:05:45.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4887" for this suite. 05/02/23 00:05:45.368
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":273,"skipped":5118,"failed":0}
------------------------------
• [SLOW TEST] [5.793 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:05:39.788
    May  2 00:05:39.788: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/02/23 00:05:39.789
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:40.105
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:40.311
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 05/02/23 00:05:40.518
    May  2 00:05:40.626: INFO: Waiting up to 5m0s for pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240" in namespace "emptydir-4887" to be "Succeeded or Failed"
    May  2 00:05:40.730: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240": Phase="Pending", Reason="", readiness=false. Elapsed: 104.057071ms
    May  2 00:05:42.835: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208726484s
    May  2 00:05:44.835: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208994915s
    STEP: Saw pod success 05/02/23 00:05:44.835
    May  2 00:05:44.835: INFO: Pod "pod-a7ced879-0697-48ed-a80e-3fb33fcd9240" satisfied condition "Succeeded or Failed"
    May  2 00:05:44.940: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-a7ced879-0697-48ed-a80e-3fb33fcd9240 container test-container: <nil>
    STEP: delete the pod 05/02/23 00:05:45.047
    May  2 00:05:45.159: INFO: Waiting for pod pod-a7ced879-0697-48ed-a80e-3fb33fcd9240 to disappear
    May  2 00:05:45.263: INFO: Pod pod-a7ced879-0697-48ed-a80e-3fb33fcd9240 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  2 00:05:45.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4887" for this suite. 05/02/23 00:05:45.368
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:05:45.582
May  2 00:05:45.582: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/02/23 00:05:45.583
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:45.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:46.104
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 05/02/23 00:05:46.311
STEP: Ensuring ResourceQuota status is calculated 05/02/23 00:05:46.416
STEP: Creating a ResourceQuota with not terminating scope 05/02/23 00:05:48.522
STEP: Ensuring ResourceQuota status is calculated 05/02/23 00:05:48.633
STEP: Creating a long running pod 05/02/23 00:05:50.738
STEP: Ensuring resource quota with not terminating scope captures the pod usage 05/02/23 00:05:50.849
STEP: Ensuring resource quota with terminating scope ignored the pod usage 05/02/23 00:05:52.954
STEP: Deleting the pod 05/02/23 00:05:55.059
STEP: Ensuring resource quota status released the pod usage 05/02/23 00:05:55.172
STEP: Creating a terminating pod 05/02/23 00:05:57.276
STEP: Ensuring resource quota with terminating scope captures the pod usage 05/02/23 00:05:57.387
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 05/02/23 00:05:59.491
STEP: Deleting the pod 05/02/23 00:06:01.596
STEP: Ensuring resource quota status released the pod usage 05/02/23 00:06:01.709
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  2 00:06:03.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5243" for this suite. 05/02/23 00:06:03.919
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":274,"skipped":5125,"failed":0}
------------------------------
• [SLOW TEST] [18.443 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:05:45.582
    May  2 00:05:45.582: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/02/23 00:05:45.583
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:05:45.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:05:46.104
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 05/02/23 00:05:46.311
    STEP: Ensuring ResourceQuota status is calculated 05/02/23 00:05:46.416
    STEP: Creating a ResourceQuota with not terminating scope 05/02/23 00:05:48.522
    STEP: Ensuring ResourceQuota status is calculated 05/02/23 00:05:48.633
    STEP: Creating a long running pod 05/02/23 00:05:50.738
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 05/02/23 00:05:50.849
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 05/02/23 00:05:52.954
    STEP: Deleting the pod 05/02/23 00:05:55.059
    STEP: Ensuring resource quota status released the pod usage 05/02/23 00:05:55.172
    STEP: Creating a terminating pod 05/02/23 00:05:57.276
    STEP: Ensuring resource quota with terminating scope captures the pod usage 05/02/23 00:05:57.387
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 05/02/23 00:05:59.491
    STEP: Deleting the pod 05/02/23 00:06:01.596
    STEP: Ensuring resource quota status released the pod usage 05/02/23 00:06:01.709
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  2 00:06:03.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5243" for this suite. 05/02/23 00:06:03.919
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:04.025
May  2 00:06:04.025: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime 05/02/23 00:06:04.027
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:04.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:04.549
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 05/02/23 00:06:04.756
STEP: wait for the container to reach Failed 05/02/23 00:06:04.865
STEP: get the container status 05/02/23 00:06:09.388
STEP: the container should be terminated 05/02/23 00:06:09.492
STEP: the termination message should be set 05/02/23 00:06:09.492
May  2 00:06:09.493: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 05/02/23 00:06:09.493
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
May  2 00:06:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6185" for this suite. 05/02/23 00:06:09.821
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":275,"skipped":5128,"failed":0}
------------------------------
• [SLOW TEST] [6.002 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:04.025
    May  2 00:06:04.025: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-runtime 05/02/23 00:06:04.027
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:04.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:04.549
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 05/02/23 00:06:04.756
    STEP: wait for the container to reach Failed 05/02/23 00:06:04.865
    STEP: get the container status 05/02/23 00:06:09.388
    STEP: the container should be terminated 05/02/23 00:06:09.492
    STEP: the termination message should be set 05/02/23 00:06:09.492
    May  2 00:06:09.493: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 05/02/23 00:06:09.493
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    May  2 00:06:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6185" for this suite. 05/02/23 00:06:09.821
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:10.028
May  2 00:06:10.028: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/02/23 00:06:10.029
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:10.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:10.551
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 05/02/23 00:06:10.758
May  2 00:06:10.865: INFO: Waiting up to 5m0s for pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07" in namespace "var-expansion-5767" to be "Succeeded or Failed"
May  2 00:06:10.969: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07": Phase="Pending", Reason="", readiness=false. Elapsed: 104.180958ms
May  2 00:06:13.075: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20985299s
May  2 00:06:15.074: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208742875s
STEP: Saw pod success 05/02/23 00:06:15.074
May  2 00:06:15.074: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07" satisfied condition "Succeeded or Failed"
May  2 00:06:15.178: INFO: Trying to get logs from node i-02d061b30635c230c pod var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07 container dapi-container: <nil>
STEP: delete the pod 05/02/23 00:06:15.285
May  2 00:06:15.412: INFO: Waiting for pod var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07 to disappear
May  2 00:06:15.517: INFO: Pod var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  2 00:06:15.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5767" for this suite. 05/02/23 00:06:15.626
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":276,"skipped":5140,"failed":0}
------------------------------
• [SLOW TEST] [5.704 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:10.028
    May  2 00:06:10.028: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/02/23 00:06:10.029
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:10.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:10.551
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 05/02/23 00:06:10.758
    May  2 00:06:10.865: INFO: Waiting up to 5m0s for pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07" in namespace "var-expansion-5767" to be "Succeeded or Failed"
    May  2 00:06:10.969: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07": Phase="Pending", Reason="", readiness=false. Elapsed: 104.180958ms
    May  2 00:06:13.075: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20985299s
    May  2 00:06:15.074: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208742875s
    STEP: Saw pod success 05/02/23 00:06:15.074
    May  2 00:06:15.074: INFO: Pod "var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07" satisfied condition "Succeeded or Failed"
    May  2 00:06:15.178: INFO: Trying to get logs from node i-02d061b30635c230c pod var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07 container dapi-container: <nil>
    STEP: delete the pod 05/02/23 00:06:15.285
    May  2 00:06:15.412: INFO: Waiting for pod var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07 to disappear
    May  2 00:06:15.517: INFO: Pod var-expansion-3b99c091-e261-4717-b2f5-adf489d6eb07 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  2 00:06:15.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5767" for this suite. 05/02/23 00:06:15.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:15.733
May  2 00:06:15.733: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job 05/02/23 00:06:15.734
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:16.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:16.254
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 05/02/23 00:06:16.461
STEP: Ensuring job reaches completions 05/02/23 00:06:16.568
STEP: Ensuring pods with index for job exist 05/02/23 00:06:24.673
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
May  2 00:06:24.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3909" for this suite. 05/02/23 00:06:24.883
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":277,"skipped":5162,"failed":0}
------------------------------
• [SLOW TEST] [9.256 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:15.733
    May  2 00:06:15.733: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename job 05/02/23 00:06:15.734
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:16.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:16.254
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 05/02/23 00:06:16.461
    STEP: Ensuring job reaches completions 05/02/23 00:06:16.568
    STEP: Ensuring pods with index for job exist 05/02/23 00:06:24.673
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    May  2 00:06:24.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3909" for this suite. 05/02/23 00:06:24.883
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:24.99
May  2 00:06:24.990: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition 05/02/23 00:06:24.991
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:25.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:25.511
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
May  2 00:06:25.721: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:06:29.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8235" for this suite. 05/02/23 00:06:29.862
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":278,"skipped":5165,"failed":0}
------------------------------
• [4.978 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:24.99
    May  2 00:06:24.990: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename custom-resource-definition 05/02/23 00:06:24.991
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:25.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:25.511
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    May  2 00:06:25.721: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:06:29.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8235" for this suite. 05/02/23 00:06:29.862
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:29.969
May  2 00:06:29.969: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/02/23 00:06:29.97
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:30.287
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:30.496
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:06:30.703
May  2 00:06:30.810: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b" in namespace "downward-api-1975" to be "Succeeded or Failed"
May  2 00:06:30.914: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.263607ms
May  2 00:06:33.019: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209186574s
May  2 00:06:35.019: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209497987s
STEP: Saw pod success 05/02/23 00:06:35.019
May  2 00:06:35.019: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b" satisfied condition "Succeeded or Failed"
May  2 00:06:35.124: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b container client-container: <nil>
STEP: delete the pod 05/02/23 00:06:35.23
May  2 00:06:35.342: INFO: Waiting for pod downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b to disappear
May  2 00:06:35.447: INFO: Pod downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  2 00:06:35.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1975" for this suite. 05/02/23 00:06:35.553
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":279,"skipped":5167,"failed":0}
------------------------------
• [SLOW TEST] [5.794 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:29.969
    May  2 00:06:29.969: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/02/23 00:06:29.97
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:30.287
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:30.496
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:06:30.703
    May  2 00:06:30.810: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b" in namespace "downward-api-1975" to be "Succeeded or Failed"
    May  2 00:06:30.914: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.263607ms
    May  2 00:06:33.019: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209186574s
    May  2 00:06:35.019: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209497987s
    STEP: Saw pod success 05/02/23 00:06:35.019
    May  2 00:06:35.019: INFO: Pod "downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b" satisfied condition "Succeeded or Failed"
    May  2 00:06:35.124: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b container client-container: <nil>
    STEP: delete the pod 05/02/23 00:06:35.23
    May  2 00:06:35.342: INFO: Waiting for pod downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b to disappear
    May  2 00:06:35.447: INFO: Pod downwardapi-volume-b39d1d41-ef9c-4123-8db3-1994ec02003b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  2 00:06:35.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1975" for this suite. 05/02/23 00:06:35.553
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:35.763
May  2 00:06:35.763: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/02/23 00:06:35.764
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:36.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:36.285
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
May  2 00:06:36.492: INFO: >>> kubeConfig: /root/.kube/config
STEP: creating the pod 05/02/23 00:06:36.493
STEP: submitting the pod to kubernetes 05/02/23 00:06:36.493
May  2 00:06:36.601: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb" in namespace "pods-1505" to be "running and ready"
May  2 00:06:36.705: INFO: Pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 104.403553ms
May  2 00:06:36.706: INFO: The phase of Pod pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb is Pending, waiting for it to be Running (with Ready = true)
May  2 00:06:38.810: INFO: Pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb": Phase="Running", Reason="", readiness=true. Elapsed: 2.20912673s
May  2 00:06:38.810: INFO: The phase of Pod pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb is Running (Ready = true)
May  2 00:06:38.810: INFO: Pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  2 00:06:39.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1505" for this suite. 05/02/23 00:06:39.46
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":280,"skipped":5170,"failed":0}
------------------------------
• [3.804 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:35.763
    May  2 00:06:35.763: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/02/23 00:06:35.764
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:36.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:36.285
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    May  2 00:06:36.492: INFO: >>> kubeConfig: /root/.kube/config
    STEP: creating the pod 05/02/23 00:06:36.493
    STEP: submitting the pod to kubernetes 05/02/23 00:06:36.493
    May  2 00:06:36.601: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb" in namespace "pods-1505" to be "running and ready"
    May  2 00:06:36.705: INFO: Pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 104.403553ms
    May  2 00:06:36.706: INFO: The phase of Pod pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:06:38.810: INFO: Pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb": Phase="Running", Reason="", readiness=true. Elapsed: 2.20912673s
    May  2 00:06:38.810: INFO: The phase of Pod pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb is Running (Ready = true)
    May  2 00:06:38.810: INFO: Pod "pod-exec-websocket-81627c39-64ce-470d-85e7-951bd0090fbb" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  2 00:06:39.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1505" for this suite. 05/02/23 00:06:39.46
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:39.568
May  2 00:06:39.568: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook 05/02/23 00:06:39.569
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:39.883
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:40.089
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 05/02/23 00:06:40.405
May  2 00:06:40.515: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9530" to be "running and ready"
May  2 00:06:40.619: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 104.348825ms
May  2 00:06:40.619: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 00:06:42.725: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.209866048s
May  2 00:06:42.725: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
May  2 00:06:42.725: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 05/02/23 00:06:42.829
May  2 00:06:42.935: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-9530" to be "running and ready"
May  2 00:06:43.039: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 104.241129ms
May  2 00:06:43.039: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 00:06:45.145: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.209804256s
May  2 00:06:45.145: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
May  2 00:06:45.145: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 05/02/23 00:06:45.249
STEP: delete the pod with lifecycle hook 05/02/23 00:06:45.363
May  2 00:06:45.471: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  2 00:06:45.578: INFO: Pod pod-with-poststart-exec-hook still exists
May  2 00:06:47.579: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  2 00:06:47.684: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
May  2 00:06:47.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9530" for this suite. 05/02/23 00:06:47.79
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":281,"skipped":5173,"failed":0}
------------------------------
• [SLOW TEST] [8.328 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:39.568
    May  2 00:06:39.568: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-lifecycle-hook 05/02/23 00:06:39.569
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:39.883
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:40.089
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 05/02/23 00:06:40.405
    May  2 00:06:40.515: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9530" to be "running and ready"
    May  2 00:06:40.619: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 104.348825ms
    May  2 00:06:40.619: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:06:42.725: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.209866048s
    May  2 00:06:42.725: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    May  2 00:06:42.725: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 05/02/23 00:06:42.829
    May  2 00:06:42.935: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-9530" to be "running and ready"
    May  2 00:06:43.039: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 104.241129ms
    May  2 00:06:43.039: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:06:45.145: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.209804256s
    May  2 00:06:45.145: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    May  2 00:06:45.145: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 05/02/23 00:06:45.249
    STEP: delete the pod with lifecycle hook 05/02/23 00:06:45.363
    May  2 00:06:45.471: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    May  2 00:06:45.578: INFO: Pod pod-with-poststart-exec-hook still exists
    May  2 00:06:47.579: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    May  2 00:06:47.684: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    May  2 00:06:47.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9530" for this suite. 05/02/23 00:06:47.79
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:47.897
May  2 00:06:47.897: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces 05/02/23 00:06:47.898
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:48.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:48.418
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 05/02/23 00:06:48.626
May  2 00:06:48.730: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 05/02/23 00:06:48.73
May  2 00:06:48.837: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 05/02/23 00:06:48.837
May  2 00:06:49.048: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
May  2 00:06:49.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7585" for this suite. 05/02/23 00:06:49.153
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":282,"skipped":5186,"failed":0}
------------------------------
• [1.363 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:47.897
    May  2 00:06:47.897: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename namespaces 05/02/23 00:06:47.898
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:48.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:48.418
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 05/02/23 00:06:48.626
    May  2 00:06:48.730: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 05/02/23 00:06:48.73
    May  2 00:06:48.837: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 05/02/23 00:06:48.837
    May  2 00:06:49.048: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:06:49.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7585" for this suite. 05/02/23 00:06:49.153
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:06:49.26
May  2 00:06:49.260: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/02/23 00:06:49.261
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:49.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:49.782
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4739 05/02/23 00:06:49.989
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 05/02/23 00:06:50.103
STEP: creating service externalsvc in namespace services-4739 05/02/23 00:06:50.103
STEP: creating replication controller externalsvc in namespace services-4739 05/02/23 00:06:50.213
I0502 00:06:50.319687    6969 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4739, replica count: 2
I0502 00:06:53.471266    6969 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 05/02/23 00:06:53.576
May  2 00:06:53.792: INFO: Creating new exec pod
May  2 00:06:53.899: INFO: Waiting up to 5m0s for pod "execpod6tvhf" in namespace "services-4739" to be "running"
May  2 00:06:54.004: INFO: Pod "execpod6tvhf": Phase="Pending", Reason="", readiness=false. Elapsed: 104.439305ms
May  2 00:06:56.109: INFO: Pod "execpod6tvhf": Phase="Running", Reason="", readiness=true. Elapsed: 2.209175293s
May  2 00:06:56.109: INFO: Pod "execpod6tvhf" satisfied condition "running"
May  2 00:06:56.109: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4739 exec execpod6tvhf -- /bin/sh -x -c nslookup nodeport-service.services-4739.svc.cluster.local'
May  2 00:06:57.270: INFO: stderr: "+ nslookup nodeport-service.services-4739.svc.cluster.local\n"
May  2 00:06:57.270: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-4739.svc.cluster.local\tcanonical name = externalsvc.services-4739.svc.cluster.local.\nName:\texternalsvc.services-4739.svc.cluster.local\nAddress: 100.68.206.107\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4739, will wait for the garbage collector to delete the pods 05/02/23 00:06:57.27
May  2 00:06:57.631: INFO: Deleting ReplicationController externalsvc took: 106.50851ms
May  2 00:06:57.732: INFO: Terminating ReplicationController externalsvc pods took: 101.051879ms
May  2 00:07:00.048: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  2 00:07:00.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4739" for this suite. 05/02/23 00:07:00.266
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":283,"skipped":5186,"failed":0}
------------------------------
• [SLOW TEST] [11.112 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:06:49.26
    May  2 00:06:49.260: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/02/23 00:06:49.261
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:06:49.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:06:49.782
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-4739 05/02/23 00:06:49.989
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 05/02/23 00:06:50.103
    STEP: creating service externalsvc in namespace services-4739 05/02/23 00:06:50.103
    STEP: creating replication controller externalsvc in namespace services-4739 05/02/23 00:06:50.213
    I0502 00:06:50.319687    6969 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4739, replica count: 2
    I0502 00:06:53.471266    6969 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 05/02/23 00:06:53.576
    May  2 00:06:53.792: INFO: Creating new exec pod
    May  2 00:06:53.899: INFO: Waiting up to 5m0s for pod "execpod6tvhf" in namespace "services-4739" to be "running"
    May  2 00:06:54.004: INFO: Pod "execpod6tvhf": Phase="Pending", Reason="", readiness=false. Elapsed: 104.439305ms
    May  2 00:06:56.109: INFO: Pod "execpod6tvhf": Phase="Running", Reason="", readiness=true. Elapsed: 2.209175293s
    May  2 00:06:56.109: INFO: Pod "execpod6tvhf" satisfied condition "running"
    May  2 00:06:56.109: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4739 exec execpod6tvhf -- /bin/sh -x -c nslookup nodeport-service.services-4739.svc.cluster.local'
    May  2 00:06:57.270: INFO: stderr: "+ nslookup nodeport-service.services-4739.svc.cluster.local\n"
    May  2 00:06:57.270: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-4739.svc.cluster.local\tcanonical name = externalsvc.services-4739.svc.cluster.local.\nName:\texternalsvc.services-4739.svc.cluster.local\nAddress: 100.68.206.107\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4739, will wait for the garbage collector to delete the pods 05/02/23 00:06:57.27
    May  2 00:06:57.631: INFO: Deleting ReplicationController externalsvc took: 106.50851ms
    May  2 00:06:57.732: INFO: Terminating ReplicationController externalsvc pods took: 101.051879ms
    May  2 00:07:00.048: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  2 00:07:00.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4739" for this suite. 05/02/23 00:07:00.266
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:00.375
May  2 00:07:00.375: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/02/23 00:07:00.376
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:00.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:00.897
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 05/02/23 00:07:01.105
STEP: submitting the pod to kubernetes 05/02/23 00:07:01.105
STEP: verifying QOS class is set on the pod 05/02/23 00:07:01.212
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
May  2 00:07:01.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8474" for this suite. 05/02/23 00:07:01.422
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":284,"skipped":5228,"failed":0}
------------------------------
• [1.157 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:00.375
    May  2 00:07:00.375: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/02/23 00:07:00.376
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:00.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:00.897
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 05/02/23 00:07:01.105
    STEP: submitting the pod to kubernetes 05/02/23 00:07:01.105
    STEP: verifying QOS class is set on the pod 05/02/23 00:07:01.212
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    May  2 00:07:01.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8474" for this suite. 05/02/23 00:07:01.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:01.533
May  2 00:07:01.533: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset 05/02/23 00:07:01.534
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:01.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:02.055
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
May  2 00:07:02.262: INFO: Creating ReplicaSet my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb
May  2 00:07:02.473: INFO: Pod name my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb: Found 1 pods out of 1
May  2 00:07:02.474: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb" is running
May  2 00:07:02.474: INFO: Waiting up to 5m0s for pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96" in namespace "replicaset-6529" to be "running"
May  2 00:07:02.578: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96": Phase="Pending", Reason="", readiness=false. Elapsed: 104.360712ms
May  2 00:07:04.683: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96": Phase="Running", Reason="", readiness=true. Elapsed: 2.209422046s
May  2 00:07:04.683: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96" satisfied condition "running"
May  2 00:07:04.683: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason: Message:}])
May  2 00:07:04.683: INFO: Trying to dial the pod
May  2 00:07:09.998: INFO: Controller my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb: Got expected result from replica 1 [my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96]: "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
May  2 00:07:09.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6529" for this suite. 05/02/23 00:07:10.104
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":285,"skipped":5240,"failed":0}
------------------------------
• [SLOW TEST] [8.676 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:01.533
    May  2 00:07:01.533: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replicaset 05/02/23 00:07:01.534
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:01.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:02.055
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    May  2 00:07:02.262: INFO: Creating ReplicaSet my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb
    May  2 00:07:02.473: INFO: Pod name my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb: Found 1 pods out of 1
    May  2 00:07:02.474: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb" is running
    May  2 00:07:02.474: INFO: Waiting up to 5m0s for pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96" in namespace "replicaset-6529" to be "running"
    May  2 00:07:02.578: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96": Phase="Pending", Reason="", readiness=false. Elapsed: 104.360712ms
    May  2 00:07:04.683: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96": Phase="Running", Reason="", readiness=true. Elapsed: 2.209422046s
    May  2 00:07:04.683: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96" satisfied condition "running"
    May  2 00:07:04.683: INFO: Pod "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:07:02 +0000 UTC Reason: Message:}])
    May  2 00:07:04.683: INFO: Trying to dial the pod
    May  2 00:07:09.998: INFO: Controller my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb: Got expected result from replica 1 [my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96]: "my-hostname-basic-bcf77db8-a650-4142-940b-aab370142ccb-qws96", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    May  2 00:07:09.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6529" for this suite. 05/02/23 00:07:10.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:10.212
May  2 00:07:10.212: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/02/23 00:07:10.213
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:10.527
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:10.734
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 05/02/23 00:07:10.942
May  2 00:07:11.050: INFO: Waiting up to 5m0s for pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578" in namespace "emptydir-7478" to be "Succeeded or Failed"
May  2 00:07:11.155: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578": Phase="Pending", Reason="", readiness=false. Elapsed: 104.369691ms
May  2 00:07:13.260: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209596531s
May  2 00:07:15.260: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209608705s
STEP: Saw pod success 05/02/23 00:07:15.26
May  2 00:07:15.260: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578" satisfied condition "Succeeded or Failed"
May  2 00:07:15.364: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-fc0d635b-f3df-4192-8b47-fa67fc884578 container test-container: <nil>
STEP: delete the pod 05/02/23 00:07:15.471
May  2 00:07:15.594: INFO: Waiting for pod pod-fc0d635b-f3df-4192-8b47-fa67fc884578 to disappear
May  2 00:07:15.698: INFO: Pod pod-fc0d635b-f3df-4192-8b47-fa67fc884578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  2 00:07:15.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7478" for this suite. 05/02/23 00:07:15.803
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":286,"skipped":5298,"failed":0}
------------------------------
• [SLOW TEST] [5.799 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:10.212
    May  2 00:07:10.212: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/02/23 00:07:10.213
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:10.527
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:10.734
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 05/02/23 00:07:10.942
    May  2 00:07:11.050: INFO: Waiting up to 5m0s for pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578" in namespace "emptydir-7478" to be "Succeeded or Failed"
    May  2 00:07:11.155: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578": Phase="Pending", Reason="", readiness=false. Elapsed: 104.369691ms
    May  2 00:07:13.260: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209596531s
    May  2 00:07:15.260: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209608705s
    STEP: Saw pod success 05/02/23 00:07:15.26
    May  2 00:07:15.260: INFO: Pod "pod-fc0d635b-f3df-4192-8b47-fa67fc884578" satisfied condition "Succeeded or Failed"
    May  2 00:07:15.364: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-fc0d635b-f3df-4192-8b47-fa67fc884578 container test-container: <nil>
    STEP: delete the pod 05/02/23 00:07:15.471
    May  2 00:07:15.594: INFO: Waiting for pod pod-fc0d635b-f3df-4192-8b47-fa67fc884578 to disappear
    May  2 00:07:15.698: INFO: Pod pod-fc0d635b-f3df-4192-8b47-fa67fc884578 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  2 00:07:15.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7478" for this suite. 05/02/23 00:07:15.803
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:16.011
May  2 00:07:16.011: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers 05/02/23 00:07:16.012
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:16.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:16.533
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
May  2 00:07:16.848: INFO: Waiting up to 5m0s for pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690" in namespace "containers-1377" to be "running"
May  2 00:07:16.953: INFO: Pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690": Phase="Pending", Reason="", readiness=false. Elapsed: 104.135814ms
May  2 00:07:19.058: INFO: Pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690": Phase="Running", Reason="", readiness=true. Elapsed: 2.209227961s
May  2 00:07:19.058: INFO: Pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
May  2 00:07:19.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1377" for this suite. 05/02/23 00:07:19.275
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":287,"skipped":5303,"failed":0}
------------------------------
• [3.372 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:16.011
    May  2 00:07:16.011: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename containers 05/02/23 00:07:16.012
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:16.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:16.533
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    May  2 00:07:16.848: INFO: Waiting up to 5m0s for pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690" in namespace "containers-1377" to be "running"
    May  2 00:07:16.953: INFO: Pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690": Phase="Pending", Reason="", readiness=false. Elapsed: 104.135814ms
    May  2 00:07:19.058: INFO: Pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690": Phase="Running", Reason="", readiness=true. Elapsed: 2.209227961s
    May  2 00:07:19.058: INFO: Pod "client-containers-962abc39-3f7d-4e69-889b-2e672ce5c690" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    May  2 00:07:19.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1377" for this suite. 05/02/23 00:07:19.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:19.388
May  2 00:07:19.388: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:07:19.389
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:19.703
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:19.91
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/02/23 00:07:20.117
May  2 00:07:20.117: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
May  2 00:07:20.559: INFO: stderr: ""
May  2 00:07:20.559: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 05/02/23 00:07:20.559
STEP: verifying the pod e2e-test-httpd-pod was created 05/02/23 00:07:25.71
May  2 00:07:25.710: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 get pod e2e-test-httpd-pod -o json'
May  2 00:07:26.135: INFO: stderr: ""
May  2 00:07:26.135: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"275f03242fd5186ec65db78a2dca4856fbcb3e7e22d5f7fbd6f4b414fbf51708\",\n            \"cni.projectcalico.org/podIP\": \"100.96.36.47/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.96.36.47/32\"\n        },\n        \"creationTimestamp\": \"2023-05-02T00:07:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7076\",\n        \"resourceVersion\": \"33102\",\n        \"uid\": \"62d08f6d-bf77-4fd3-b686-4767b343c929\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-z4c2g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"i-02d061b30635c230c\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-z4c2g\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:21Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8725ce34079942bd1f62e4263c81b8c4b4304c41542f4bf797a7f0cc8eda515b\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-05-02T00:07:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.48.211\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.36.47\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.36.47\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-05-02T00:07:20Z\"\n    }\n}\n"
STEP: replace the image in the pod 05/02/23 00:07:26.136
May  2 00:07:26.136: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 replace -f -'
May  2 00:07:27.456: INFO: stderr: ""
May  2 00:07:27.456: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 05/02/23 00:07:27.456
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
May  2 00:07:27.560: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 delete pods e2e-test-httpd-pod'
May  2 00:07:30.714: INFO: stderr: ""
May  2 00:07:30.714: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:07:30.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7076" for this suite. 05/02/23 00:07:30.819
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":288,"skipped":5309,"failed":0}
------------------------------
• [SLOW TEST] [11.639 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:19.388
    May  2 00:07:19.388: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:07:19.389
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:19.703
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:19.91
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/02/23 00:07:20.117
    May  2 00:07:20.117: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    May  2 00:07:20.559: INFO: stderr: ""
    May  2 00:07:20.559: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 05/02/23 00:07:20.559
    STEP: verifying the pod e2e-test-httpd-pod was created 05/02/23 00:07:25.71
    May  2 00:07:25.710: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 get pod e2e-test-httpd-pod -o json'
    May  2 00:07:26.135: INFO: stderr: ""
    May  2 00:07:26.135: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"275f03242fd5186ec65db78a2dca4856fbcb3e7e22d5f7fbd6f4b414fbf51708\",\n            \"cni.projectcalico.org/podIP\": \"100.96.36.47/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.96.36.47/32\"\n        },\n        \"creationTimestamp\": \"2023-05-02T00:07:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7076\",\n        \"resourceVersion\": \"33102\",\n        \"uid\": \"62d08f6d-bf77-4fd3-b686-4767b343c929\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-z4c2g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"i-02d061b30635c230c\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-z4c2g\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:21Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-05-02T00:07:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8725ce34079942bd1f62e4263c81b8c4b4304c41542f4bf797a7f0cc8eda515b\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-05-02T00:07:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.48.211\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.36.47\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.36.47\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-05-02T00:07:20Z\"\n    }\n}\n"
    STEP: replace the image in the pod 05/02/23 00:07:26.136
    May  2 00:07:26.136: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 replace -f -'
    May  2 00:07:27.456: INFO: stderr: ""
    May  2 00:07:27.456: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 05/02/23 00:07:27.456
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    May  2 00:07:27.560: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7076 delete pods e2e-test-httpd-pod'
    May  2 00:07:30.714: INFO: stderr: ""
    May  2 00:07:30.714: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:07:30.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7076" for this suite. 05/02/23 00:07:30.819
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:31.028
May  2 00:07:31.029: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:07:31.031
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:31.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:31.552
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-223c03a9-d4dc-4f61-984b-793f40959b95 05/02/23 00:07:31.758
STEP: Creating a pod to test consume configMaps 05/02/23 00:07:31.864
May  2 00:07:31.975: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e" in namespace "projected-7025" to be "Succeeded or Failed"
May  2 00:07:32.079: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e": Phase="Pending", Reason="", readiness=false. Elapsed: 104.100843ms
May  2 00:07:34.184: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208981164s
May  2 00:07:36.184: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209440684s
STEP: Saw pod success 05/02/23 00:07:36.184
May  2 00:07:36.184: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e" satisfied condition "Succeeded or Failed"
May  2 00:07:36.289: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e container projected-configmap-volume-test: <nil>
STEP: delete the pod 05/02/23 00:07:36.395
May  2 00:07:36.506: INFO: Waiting for pod pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e to disappear
May  2 00:07:36.610: INFO: Pod pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  2 00:07:36.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7025" for this suite. 05/02/23 00:07:36.715
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":289,"skipped":5330,"failed":0}
------------------------------
• [SLOW TEST] [5.894 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:31.028
    May  2 00:07:31.029: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:07:31.031
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:31.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:31.552
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-223c03a9-d4dc-4f61-984b-793f40959b95 05/02/23 00:07:31.758
    STEP: Creating a pod to test consume configMaps 05/02/23 00:07:31.864
    May  2 00:07:31.975: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e" in namespace "projected-7025" to be "Succeeded or Failed"
    May  2 00:07:32.079: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e": Phase="Pending", Reason="", readiness=false. Elapsed: 104.100843ms
    May  2 00:07:34.184: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208981164s
    May  2 00:07:36.184: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209440684s
    STEP: Saw pod success 05/02/23 00:07:36.184
    May  2 00:07:36.184: INFO: Pod "pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e" satisfied condition "Succeeded or Failed"
    May  2 00:07:36.289: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e container projected-configmap-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:07:36.395
    May  2 00:07:36.506: INFO: Waiting for pod pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e to disappear
    May  2 00:07:36.610: INFO: Pod pod-projected-configmaps-06a965e5-cbc7-439e-a243-62d6e1d0614e no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  2 00:07:36.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7025" for this suite. 05/02/23 00:07:36.715
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:36.923
May  2 00:07:36.923: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/02/23 00:07:36.924
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:37.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:37.445
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 05/02/23 00:07:37.652
STEP: submitting the pod to kubernetes 05/02/23 00:07:37.652
May  2 00:07:37.759: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" in namespace "pods-2423" to be "running and ready"
May  2 00:07:37.864: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Pending", Reason="", readiness=false. Elapsed: 104.145475ms
May  2 00:07:37.864: INFO: The phase of Pod pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:07:39.969: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Running", Reason="", readiness=true. Elapsed: 2.20894278s
May  2 00:07:39.969: INFO: The phase of Pod pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99 is Running (Ready = true)
May  2 00:07:39.969: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 05/02/23 00:07:40.073
STEP: updating the pod 05/02/23 00:07:40.178
May  2 00:07:40.900: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99"
May  2 00:07:40.900: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" in namespace "pods-2423" to be "terminated with reason DeadlineExceeded"
May  2 00:07:41.004: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Running", Reason="", readiness=true. Elapsed: 104.156337ms
May  2 00:07:43.109: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Running", Reason="", readiness=false. Elapsed: 2.208956661s
May  2 00:07:45.109: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.209589451s
May  2 00:07:45.109: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  2 00:07:45.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2423" for this suite. 05/02/23 00:07:45.215
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":290,"skipped":5340,"failed":0}
------------------------------
• [SLOW TEST] [8.397 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:36.923
    May  2 00:07:36.923: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/02/23 00:07:36.924
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:37.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:37.445
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 05/02/23 00:07:37.652
    STEP: submitting the pod to kubernetes 05/02/23 00:07:37.652
    May  2 00:07:37.759: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" in namespace "pods-2423" to be "running and ready"
    May  2 00:07:37.864: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Pending", Reason="", readiness=false. Elapsed: 104.145475ms
    May  2 00:07:37.864: INFO: The phase of Pod pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:07:39.969: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Running", Reason="", readiness=true. Elapsed: 2.20894278s
    May  2 00:07:39.969: INFO: The phase of Pod pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99 is Running (Ready = true)
    May  2 00:07:39.969: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 05/02/23 00:07:40.073
    STEP: updating the pod 05/02/23 00:07:40.178
    May  2 00:07:40.900: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99"
    May  2 00:07:40.900: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" in namespace "pods-2423" to be "terminated with reason DeadlineExceeded"
    May  2 00:07:41.004: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Running", Reason="", readiness=true. Elapsed: 104.156337ms
    May  2 00:07:43.109: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Running", Reason="", readiness=false. Elapsed: 2.208956661s
    May  2 00:07:45.109: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.209589451s
    May  2 00:07:45.109: INFO: Pod "pod-update-activedeadlineseconds-4fc4d680-7d4a-44e3-8917-f4567cfced99" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  2 00:07:45.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2423" for this suite. 05/02/23 00:07:45.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:07:45.323
May  2 00:07:45.323: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job 05/02/23 00:07:45.324
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:45.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:45.847
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 05/02/23 00:07:46.054
STEP: Ensuring active pods == parallelism 05/02/23 00:07:46.162
STEP: delete a job 05/02/23 00:07:48.267
STEP: deleting Job.batch foo in namespace job-5987, will wait for the garbage collector to delete the pods 05/02/23 00:07:48.267
May  2 00:07:48.629: INFO: Deleting Job.batch foo took: 106.583196ms
May  2 00:07:48.729: INFO: Terminating Job.batch foo pods took: 100.488009ms
STEP: Ensuring job was deleted 05/02/23 00:08:20.93
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
May  2 00:08:21.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5987" for this suite. 05/02/23 00:08:21.141
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":291,"skipped":5389,"failed":0}
------------------------------
• [SLOW TEST] [35.924 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:07:45.323
    May  2 00:07:45.323: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename job 05/02/23 00:07:45.324
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:07:45.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:07:45.847
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 05/02/23 00:07:46.054
    STEP: Ensuring active pods == parallelism 05/02/23 00:07:46.162
    STEP: delete a job 05/02/23 00:07:48.267
    STEP: deleting Job.batch foo in namespace job-5987, will wait for the garbage collector to delete the pods 05/02/23 00:07:48.267
    May  2 00:07:48.629: INFO: Deleting Job.batch foo took: 106.583196ms
    May  2 00:07:48.729: INFO: Terminating Job.batch foo pods took: 100.488009ms
    STEP: Ensuring job was deleted 05/02/23 00:08:20.93
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    May  2 00:08:21.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5987" for this suite. 05/02/23 00:08:21.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:21.247
May  2 00:08:21.247: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/02/23 00:08:21.249
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:21.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:21.769
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 05/02/23 00:08:21.977
May  2 00:08:22.084: INFO: Waiting up to 5m0s for pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a" in namespace "emptydir-245" to be "Succeeded or Failed"
May  2 00:08:22.190: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a": Phase="Pending", Reason="", readiness=false. Elapsed: 105.868099ms
May  2 00:08:24.296: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.211187903s
May  2 00:08:26.295: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.21030487s
STEP: Saw pod success 05/02/23 00:08:26.295
May  2 00:08:26.295: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a" satisfied condition "Succeeded or Failed"
May  2 00:08:26.400: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-d472fabb-2477-4b40-9802-f676c7fe608a container test-container: <nil>
STEP: delete the pod 05/02/23 00:08:26.508
May  2 00:08:26.620: INFO: Waiting for pod pod-d472fabb-2477-4b40-9802-f676c7fe608a to disappear
May  2 00:08:26.724: INFO: Pod pod-d472fabb-2477-4b40-9802-f676c7fe608a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  2 00:08:26.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-245" for this suite. 05/02/23 00:08:26.83
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":292,"skipped":5394,"failed":0}
------------------------------
• [SLOW TEST] [5.790 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:21.247
    May  2 00:08:21.247: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/02/23 00:08:21.249
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:21.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:21.769
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 05/02/23 00:08:21.977
    May  2 00:08:22.084: INFO: Waiting up to 5m0s for pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a" in namespace "emptydir-245" to be "Succeeded or Failed"
    May  2 00:08:22.190: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a": Phase="Pending", Reason="", readiness=false. Elapsed: 105.868099ms
    May  2 00:08:24.296: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.211187903s
    May  2 00:08:26.295: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.21030487s
    STEP: Saw pod success 05/02/23 00:08:26.295
    May  2 00:08:26.295: INFO: Pod "pod-d472fabb-2477-4b40-9802-f676c7fe608a" satisfied condition "Succeeded or Failed"
    May  2 00:08:26.400: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-d472fabb-2477-4b40-9802-f676c7fe608a container test-container: <nil>
    STEP: delete the pod 05/02/23 00:08:26.508
    May  2 00:08:26.620: INFO: Waiting for pod pod-d472fabb-2477-4b40-9802-f676c7fe608a to disappear
    May  2 00:08:26.724: INFO: Pod pod-d472fabb-2477-4b40-9802-f676c7fe608a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  2 00:08:26.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-245" for this suite. 05/02/23 00:08:26.83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:27.039
May  2 00:08:27.039: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/02/23 00:08:27.04
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:27.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:27.56
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-ae0c26ad-a3bf-46c2-8226-7f3cd97369ef 05/02/23 00:08:27.767
STEP: Creating a pod to test consume secrets 05/02/23 00:08:27.872
May  2 00:08:27.981: INFO: Waiting up to 5m0s for pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98" in namespace "secrets-1311" to be "Succeeded or Failed"
May  2 00:08:28.085: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98": Phase="Pending", Reason="", readiness=false. Elapsed: 103.90846ms
May  2 00:08:30.190: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209339752s
May  2 00:08:32.191: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209563701s
STEP: Saw pod success 05/02/23 00:08:32.191
May  2 00:08:32.191: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98" satisfied condition "Succeeded or Failed"
May  2 00:08:32.295: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98 container secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:08:32.403
May  2 00:08:32.514: INFO: Waiting for pod pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98 to disappear
May  2 00:08:32.619: INFO: Pod pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  2 00:08:32.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1311" for this suite. 05/02/23 00:08:32.724
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":293,"skipped":5443,"failed":0}
------------------------------
• [SLOW TEST] [5.792 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:27.039
    May  2 00:08:27.039: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/02/23 00:08:27.04
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:27.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:27.56
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-ae0c26ad-a3bf-46c2-8226-7f3cd97369ef 05/02/23 00:08:27.767
    STEP: Creating a pod to test consume secrets 05/02/23 00:08:27.872
    May  2 00:08:27.981: INFO: Waiting up to 5m0s for pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98" in namespace "secrets-1311" to be "Succeeded or Failed"
    May  2 00:08:28.085: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98": Phase="Pending", Reason="", readiness=false. Elapsed: 103.90846ms
    May  2 00:08:30.190: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209339752s
    May  2 00:08:32.191: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209563701s
    STEP: Saw pod success 05/02/23 00:08:32.191
    May  2 00:08:32.191: INFO: Pod "pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98" satisfied condition "Succeeded or Failed"
    May  2 00:08:32.295: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98 container secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:08:32.403
    May  2 00:08:32.514: INFO: Waiting for pod pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98 to disappear
    May  2 00:08:32.619: INFO: Pod pod-secrets-50a17f19-e016-4e4e-9c39-99cf7f582e98 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  2 00:08:32.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1311" for this suite. 05/02/23 00:08:32.724
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:32.831
May  2 00:08:32.832: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/02/23 00:08:32.833
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:33.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:33.355
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-64ca6e92-a341-4b52-8345-6d078f9f10ed 05/02/23 00:08:33.562
STEP: Creating a pod to test consume secrets 05/02/23 00:08:33.668
May  2 00:08:33.776: INFO: Waiting up to 5m0s for pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8" in namespace "secrets-3818" to be "Succeeded or Failed"
May  2 00:08:33.880: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8": Phase="Pending", Reason="", readiness=false. Elapsed: 104.066839ms
May  2 00:08:35.985: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20905503s
May  2 00:08:37.986: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210143173s
STEP: Saw pod success 05/02/23 00:08:37.986
May  2 00:08:37.986: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8" satisfied condition "Succeeded or Failed"
May  2 00:08:38.090: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8 container secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:08:38.198
May  2 00:08:38.310: INFO: Waiting for pod pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8 to disappear
May  2 00:08:38.414: INFO: Pod pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  2 00:08:38.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3818" for this suite. 05/02/23 00:08:38.519
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":294,"skipped":5450,"failed":0}
------------------------------
• [SLOW TEST] [5.794 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:32.831
    May  2 00:08:32.832: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/02/23 00:08:32.833
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:33.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:33.355
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-64ca6e92-a341-4b52-8345-6d078f9f10ed 05/02/23 00:08:33.562
    STEP: Creating a pod to test consume secrets 05/02/23 00:08:33.668
    May  2 00:08:33.776: INFO: Waiting up to 5m0s for pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8" in namespace "secrets-3818" to be "Succeeded or Failed"
    May  2 00:08:33.880: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8": Phase="Pending", Reason="", readiness=false. Elapsed: 104.066839ms
    May  2 00:08:35.985: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20905503s
    May  2 00:08:37.986: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210143173s
    STEP: Saw pod success 05/02/23 00:08:37.986
    May  2 00:08:37.986: INFO: Pod "pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8" satisfied condition "Succeeded or Failed"
    May  2 00:08:38.090: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8 container secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:08:38.198
    May  2 00:08:38.310: INFO: Waiting for pod pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8 to disappear
    May  2 00:08:38.414: INFO: Pod pod-secrets-4359c1a2-386c-4355-b393-9bf9525c81f8 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  2 00:08:38.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3818" for this suite. 05/02/23 00:08:38.519
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:38.626
May  2 00:08:38.627: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns 05/02/23 00:08:38.628
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:38.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:39.15
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 05/02/23 00:08:39.357
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 05/02/23 00:08:39.462
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 05/02/23 00:08:39.463
STEP: creating a pod to probe DNS 05/02/23 00:08:39.463
STEP: submitting the pod to kubernetes 05/02/23 00:08:39.463
May  2 00:08:39.571: INFO: Waiting up to 15m0s for pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00" in namespace "dns-1394" to be "running"
May  2 00:08:39.676: INFO: Pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00": Phase="Pending", Reason="", readiness=false. Elapsed: 104.82428ms
May  2 00:08:41.782: INFO: Pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00": Phase="Running", Reason="", readiness=true. Elapsed: 2.210426619s
May  2 00:08:41.782: INFO: Pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00" satisfied condition "running"
STEP: retrieving the pod 05/02/23 00:08:41.782
STEP: looking for the results for each expected name from probers 05/02/23 00:08:41.886
May  2 00:08:42.306: INFO: DNS probes using dns-1394/dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00 succeeded

STEP: deleting the pod 05/02/23 00:08:42.306
STEP: deleting the test headless service 05/02/23 00:08:42.422
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
May  2 00:08:42.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1394" for this suite. 05/02/23 00:08:42.643
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":295,"skipped":5463,"failed":0}
------------------------------
• [4.123 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:38.626
    May  2 00:08:38.627: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename dns 05/02/23 00:08:38.628
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:38.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:39.15
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 05/02/23 00:08:39.357
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     05/02/23 00:08:39.462
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1394.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     05/02/23 00:08:39.463
    STEP: creating a pod to probe DNS 05/02/23 00:08:39.463
    STEP: submitting the pod to kubernetes 05/02/23 00:08:39.463
    May  2 00:08:39.571: INFO: Waiting up to 15m0s for pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00" in namespace "dns-1394" to be "running"
    May  2 00:08:39.676: INFO: Pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00": Phase="Pending", Reason="", readiness=false. Elapsed: 104.82428ms
    May  2 00:08:41.782: INFO: Pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00": Phase="Running", Reason="", readiness=true. Elapsed: 2.210426619s
    May  2 00:08:41.782: INFO: Pod "dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00" satisfied condition "running"
    STEP: retrieving the pod 05/02/23 00:08:41.782
    STEP: looking for the results for each expected name from probers 05/02/23 00:08:41.886
    May  2 00:08:42.306: INFO: DNS probes using dns-1394/dns-test-8240aae0-7e22-4595-8273-7b5ee10dbc00 succeeded

    STEP: deleting the pod 05/02/23 00:08:42.306
    STEP: deleting the test headless service 05/02/23 00:08:42.422
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    May  2 00:08:42.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1394" for this suite. 05/02/23 00:08:42.643
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:42.75
May  2 00:08:42.750: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:08:42.751
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:43.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:43.273
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:08:43.48
May  2 00:08:43.587: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1" in namespace "projected-6578" to be "Succeeded or Failed"
May  2 00:08:43.691: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.759652ms
May  2 00:08:45.796: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208970663s
May  2 00:08:47.796: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208827697s
STEP: Saw pod success 05/02/23 00:08:47.796
May  2 00:08:47.796: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1" satisfied condition "Succeeded or Failed"
May  2 00:08:47.900: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1 container client-container: <nil>
STEP: delete the pod 05/02/23 00:08:48.007
May  2 00:08:48.119: INFO: Waiting for pod downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1 to disappear
May  2 00:08:48.223: INFO: Pod downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  2 00:08:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6578" for this suite. 05/02/23 00:08:48.329
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":296,"skipped":5482,"failed":0}
------------------------------
• [SLOW TEST] [5.786 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:42.75
    May  2 00:08:42.750: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:08:42.751
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:43.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:43.273
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:08:43.48
    May  2 00:08:43.587: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1" in namespace "projected-6578" to be "Succeeded or Failed"
    May  2 00:08:43.691: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.759652ms
    May  2 00:08:45.796: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208970663s
    May  2 00:08:47.796: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208827697s
    STEP: Saw pod success 05/02/23 00:08:47.796
    May  2 00:08:47.796: INFO: Pod "downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1" satisfied condition "Succeeded or Failed"
    May  2 00:08:47.900: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1 container client-container: <nil>
    STEP: delete the pod 05/02/23 00:08:48.007
    May  2 00:08:48.119: INFO: Waiting for pod downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1 to disappear
    May  2 00:08:48.223: INFO: Pod downwardapi-volume-b078e94c-e7c0-442c-908d-3cb443b2f9f1 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  2 00:08:48.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6578" for this suite. 05/02/23 00:08:48.329
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:48.536
May  2 00:08:48.536: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/02/23 00:08:48.537
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:48.851
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:49.057
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 05/02/23 00:08:49.264
STEP: Wait for the Deployment to create new ReplicaSet 05/02/23 00:08:49.37
STEP: delete the deployment 05/02/23 00:08:49.579
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 05/02/23 00:08:49.685
STEP: Gathering metrics 05/02/23 00:08:50.206
May  2 00:08:50.431: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
May  2 00:08:50.535: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 104.232082ms
May  2 00:08:50.535: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
May  2 00:08:50.535: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
May  2 00:08:51.430: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  2 00:08:51.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9384" for this suite. 05/02/23 00:08:51.536
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":297,"skipped":5489,"failed":0}
------------------------------
• [3.105 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:48.536
    May  2 00:08:48.536: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/02/23 00:08:48.537
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:48.851
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:49.057
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 05/02/23 00:08:49.264
    STEP: Wait for the Deployment to create new ReplicaSet 05/02/23 00:08:49.37
    STEP: delete the deployment 05/02/23 00:08:49.579
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 05/02/23 00:08:49.685
    STEP: Gathering metrics 05/02/23 00:08:50.206
    May  2 00:08:50.431: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
    May  2 00:08:50.535: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 104.232082ms
    May  2 00:08:50.535: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
    May  2 00:08:50.535: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
    May  2 00:08:51.430: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  2 00:08:51.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9384" for this suite. 05/02/23 00:08:51.536
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:08:51.642
May  2 00:08:51.642: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred 05/02/23 00:08:51.643
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:51.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:52.164
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
May  2 00:08:52.371: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  2 00:08:52.581: INFO: Waiting for terminating namespaces to be deleted...
May  2 00:08:52.685: INFO: 
Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
May  2 00:08:52.793: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.793: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:08:52.793: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.793: INFO: 	Container coredns ready: true, restart count 0
May  2 00:08:52.793: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.793: INFO: 	Container autoscaler ready: true, restart count 0
May  2 00:08:52.793: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
May  2 00:08:52.793: INFO: 	Container csi-attacher ready: true, restart count 0
May  2 00:08:52.793: INFO: 	Container csi-provisioner ready: true, restart count 0
May  2 00:08:52.793: INFO: 	Container csi-resizer ready: true, restart count 0
May  2 00:08:52.793: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:08:52.793: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:08:52.793: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
May  2 00:08:52.793: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:08:52.793: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:08:52.793: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:08:52.793: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.793: INFO: 	Container kube-proxy ready: true, restart count 0
May  2 00:08:52.793: INFO: 
Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
May  2 00:08:52.901: INFO: simpletest.deployment-594f986645-8rjcv from gc-9384 started at 2023-05-02 00:08:49 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.901: INFO: 	Container nginx ready: true, restart count 0
May  2 00:08:52.901: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.901: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:08:52.901: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
May  2 00:08:52.901: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:08:52.901: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:08:52.901: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:08:52.901: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
May  2 00:08:52.901: INFO: 	Container kube-proxy ready: true, restart count 0
May  2 00:08:52.901: INFO: 
Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
May  2 00:08:53.008: INFO: simpletest.deployment-594f986645-rk2l9 from gc-9384 started at 2023-05-02 00:08:49 +0000 UTC (1 container statuses recorded)
May  2 00:08:53.008: INFO: 	Container nginx ready: true, restart count 0
May  2 00:08:53.008: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
May  2 00:08:53.008: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:08:53.008: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
May  2 00:08:53.008: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:08:53.008: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:08:53.008: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:08:53.008: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
May  2 00:08:53.008: INFO: 	Container kube-proxy ready: true, restart count 0
May  2 00:08:53.008: INFO: 
Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
May  2 00:08:53.117: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
May  2 00:08:53.117: INFO: 	Container calico-node ready: true, restart count 0
May  2 00:08:53.117: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
May  2 00:08:53.117: INFO: 	Container coredns ready: true, restart count 0
May  2 00:08:53.117: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
May  2 00:08:53.117: INFO: 	Container csi-attacher ready: true, restart count 0
May  2 00:08:53.117: INFO: 	Container csi-provisioner ready: true, restart count 0
May  2 00:08:53.117: INFO: 	Container csi-resizer ready: true, restart count 0
May  2 00:08:53.117: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:08:53.117: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:08:53.117: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
May  2 00:08:53.117: INFO: 	Container ebs-plugin ready: true, restart count 0
May  2 00:08:53.117: INFO: 	Container liveness-probe ready: true, restart count 0
May  2 00:08:53.117: INFO: 	Container node-driver-registrar ready: true, restart count 0
May  2 00:08:53.117: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
May  2 00:08:53.117: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 05/02/23 00:08:53.117
May  2 00:08:53.225: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-779" to be "running"
May  2 00:08:53.329: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 104.321176ms
May  2 00:08:55.435: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.209925874s
May  2 00:08:55.435: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 05/02/23 00:08:55.541
STEP: Trying to apply a random label on the found node. 05/02/23 00:08:55.761
STEP: verifying the node has the label kubernetes.io/e2e-f10a1690-f058-4155-801d-0303037e8cc5 95 05/02/23 00:08:55.871
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 05/02/23 00:08:55.975
May  2 00:08:56.081: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-779" to be "not pending"
May  2 00:08:56.185: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 104.150425ms
May  2 00:08:58.291: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.209665571s
May  2 00:08:58.291: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.20.48.211 on the node which pod4 resides and expect not scheduled 05/02/23 00:08:58.291
May  2 00:08:58.397: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-779" to be "not pending"
May  2 00:08:58.502: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 104.49257ms
May  2 00:09:00.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209882601s
May  2 00:09:02.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209454504s
May  2 00:09:04.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.208946496s
May  2 00:09:06.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209443601s
May  2 00:09:08.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.210955767s
May  2 00:09:10.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.208948858s
May  2 00:09:12.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.209328859s
May  2 00:09:14.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.211054098s
May  2 00:09:16.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.20978076s
May  2 00:09:18.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.208916705s
May  2 00:09:20.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.209036561s
May  2 00:09:22.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.209756124s
May  2 00:09:24.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.209524365s
May  2 00:09:26.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.209649005s
May  2 00:09:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.20904236s
May  2 00:09:30.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.20979304s
May  2 00:09:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.209157595s
May  2 00:09:34.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.210225449s
May  2 00:09:36.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.209297373s
May  2 00:09:38.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.209179937s
May  2 00:09:40.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.209699527s
May  2 00:09:42.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.210040531s
May  2 00:09:44.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.210355163s
May  2 00:09:46.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.209609058s
May  2 00:09:48.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.209035216s
May  2 00:09:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.209006584s
May  2 00:09:52.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.209943886s
May  2 00:09:54.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.209326087s
May  2 00:09:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.209259797s
May  2 00:09:58.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.209194322s
May  2 00:10:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.209393658s
May  2 00:10:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.209215623s
May  2 00:10:04.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.208870222s
May  2 00:10:06.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.208909915s
May  2 00:10:08.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.209689594s
May  2 00:10:10.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.209704289s
May  2 00:10:12.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.210277816s
May  2 00:10:14.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.209125926s
May  2 00:10:16.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.209461446s
May  2 00:10:18.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.20917549s
May  2 00:10:20.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.209828807s
May  2 00:10:22.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.20993796s
May  2 00:10:24.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.209196792s
May  2 00:10:26.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.210309644s
May  2 00:10:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.209082065s
May  2 00:10:30.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.209473903s
May  2 00:10:32.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.210546218s
May  2 00:10:34.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.211160543s
May  2 00:10:36.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.209023746s
May  2 00:10:38.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.209072403s
May  2 00:10:40.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.20960742s
May  2 00:10:42.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.210785333s
May  2 00:10:44.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.209020915s
May  2 00:10:46.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.211189438s
May  2 00:10:48.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.210837427s
May  2 00:10:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.209196125s
May  2 00:10:52.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.209216653s
May  2 00:10:54.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.209879661s
May  2 00:10:56.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.20943904s
May  2 00:10:58.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.209342973s
May  2 00:11:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.208940038s
May  2 00:11:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.209290241s
May  2 00:11:04.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.209437695s
May  2 00:11:06.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.209018831s
May  2 00:11:08.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.209050822s
May  2 00:11:10.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.209141179s
May  2 00:11:12.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.209066572s
May  2 00:11:14.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.209319835s
May  2 00:11:16.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.20895236s
May  2 00:11:18.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.209557924s
May  2 00:11:20.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.208905351s
May  2 00:11:22.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.209250174s
May  2 00:11:24.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.209905123s
May  2 00:11:26.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.209129729s
May  2 00:11:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.209011497s
May  2 00:11:30.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.210541436s
May  2 00:11:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.208981731s
May  2 00:11:34.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.21038781s
May  2 00:11:36.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.209013124s
May  2 00:11:38.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.209056713s
May  2 00:11:40.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.208768106s
May  2 00:11:42.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.209163298s
May  2 00:11:44.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.210762063s
May  2 00:11:46.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.209878812s
May  2 00:11:48.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.208969351s
May  2 00:11:50.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.209821642s
May  2 00:11:52.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.20893264s
May  2 00:11:54.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.209111563s
May  2 00:11:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.2092607s
May  2 00:11:58.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.20988917s
May  2 00:12:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.208990483s
May  2 00:12:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.209130923s
May  2 00:12:04.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.209021747s
May  2 00:12:06.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.209339519s
May  2 00:12:08.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.209092591s
May  2 00:12:10.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.209254501s
May  2 00:12:12.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.21031488s
May  2 00:12:14.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.210465199s
May  2 00:12:16.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.209197031s
May  2 00:12:18.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.209450196s
May  2 00:12:20.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.208770782s
May  2 00:12:22.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.209373409s
May  2 00:12:24.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.211681317s
May  2 00:12:26.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.21007215s
May  2 00:12:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.209227367s
May  2 00:12:30.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.20915874s
May  2 00:12:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.208885745s
May  2 00:12:34.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.209235016s
May  2 00:12:36.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.209959863s
May  2 00:12:38.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.210029921s
May  2 00:12:40.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.209425577s
May  2 00:12:42.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.209281094s
May  2 00:12:44.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.209012835s
May  2 00:12:46.610: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.2127056s
May  2 00:12:48.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.211176625s
May  2 00:12:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.209390422s
May  2 00:12:52.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.210163453s
May  2 00:12:54.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.209115483s
May  2 00:12:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.209253515s
May  2 00:12:58.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.210636431s
May  2 00:13:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.209342035s
May  2 00:13:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.20925114s
May  2 00:13:04.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.210763896s
May  2 00:13:06.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.209667138s
May  2 00:13:08.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.211022592s
May  2 00:13:10.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.209723772s
May  2 00:13:12.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.211415739s
May  2 00:13:14.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.21073977s
May  2 00:13:16.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.209508813s
May  2 00:13:18.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.209376386s
May  2 00:13:20.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.209583685s
May  2 00:13:22.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.209305815s
May  2 00:13:24.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.209148322s
May  2 00:13:26.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.20917646s
May  2 00:13:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.209120451s
May  2 00:13:30.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.20961638s
May  2 00:13:32.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.210809875s
May  2 00:13:34.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.209396277s
May  2 00:13:36.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.210316468s
May  2 00:13:38.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.210732271s
May  2 00:13:40.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.209213099s
May  2 00:13:42.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.210437094s
May  2 00:13:44.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.209039016s
May  2 00:13:46.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.209926852s
May  2 00:13:48.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.21011522s
May  2 00:13:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.209328438s
May  2 00:13:52.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.210101144s
May  2 00:13:54.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.209912651s
May  2 00:13:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.209390503s
May  2 00:13:58.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.209247855s
May  2 00:13:58.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.314959118s
STEP: removing the label kubernetes.io/e2e-f10a1690-f058-4155-801d-0303037e8cc5 off the node i-02d061b30635c230c 05/02/23 00:13:58.712
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f10a1690-f058-4155-801d-0303037e8cc5 05/02/23 00:13:58.927
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
May  2 00:13:59.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-779" for this suite. 05/02/23 00:13:59.137
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":298,"skipped":5489,"failed":0}
------------------------------
• [SLOW TEST] [307.602 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:08:51.642
    May  2 00:08:51.642: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-pred 05/02/23 00:08:51.643
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:08:51.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:08:52.164
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    May  2 00:08:52.371: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    May  2 00:08:52.581: INFO: Waiting for terminating namespaces to be deleted...
    May  2 00:08:52.685: INFO: 
    Logging pods the apiserver thinks is on node i-00fed7c0a42791aae before test
    May  2 00:08:52.793: INFO: calico-node-zd6l4 from kube-system started at 2023-05-01 22:31:34 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.793: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:08:52.793: INFO: coredns-6c7bddbb75-7b4g9 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.793: INFO: 	Container coredns ready: true, restart count 0
    May  2 00:08:52.793: INFO: coredns-autoscaler-db7b97744-xpnj5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.793: INFO: 	Container autoscaler ready: true, restart count 0
    May  2 00:08:52.793: INFO: ebs-csi-controller-f987fd46-c4wk5 from kube-system started at 2023-05-01 22:31:44 +0000 UTC (5 container statuses recorded)
    May  2 00:08:52.793: INFO: 	Container csi-attacher ready: true, restart count 0
    May  2 00:08:52.793: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  2 00:08:52.793: INFO: 	Container csi-resizer ready: true, restart count 0
    May  2 00:08:52.793: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:08:52.793: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:08:52.793: INFO: ebs-csi-node-4hblj from kube-system started at 2023-05-01 22:31:34 +0000 UTC (3 container statuses recorded)
    May  2 00:08:52.793: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:08:52.793: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:08:52.793: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:08:52.793: INFO: kube-proxy-i-00fed7c0a42791aae from kube-system started at 2023-05-01 22:31:04 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.793: INFO: 	Container kube-proxy ready: true, restart count 0
    May  2 00:08:52.793: INFO: 
    Logging pods the apiserver thinks is on node i-02d061b30635c230c before test
    May  2 00:08:52.901: INFO: simpletest.deployment-594f986645-8rjcv from gc-9384 started at 2023-05-02 00:08:49 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.901: INFO: 	Container nginx ready: true, restart count 0
    May  2 00:08:52.901: INFO: calico-node-lr44d from kube-system started at 2023-05-01 22:31:37 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.901: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:08:52.901: INFO: ebs-csi-node-s46d6 from kube-system started at 2023-05-01 22:31:37 +0000 UTC (3 container statuses recorded)
    May  2 00:08:52.901: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:08:52.901: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:08:52.901: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:08:52.901: INFO: kube-proxy-i-02d061b30635c230c from kube-system started at 2023-05-01 22:31:17 +0000 UTC (1 container statuses recorded)
    May  2 00:08:52.901: INFO: 	Container kube-proxy ready: true, restart count 0
    May  2 00:08:52.901: INFO: 
    Logging pods the apiserver thinks is on node i-0627b78ff917cf2ae before test
    May  2 00:08:53.008: INFO: simpletest.deployment-594f986645-rk2l9 from gc-9384 started at 2023-05-02 00:08:49 +0000 UTC (1 container statuses recorded)
    May  2 00:08:53.008: INFO: 	Container nginx ready: true, restart count 0
    May  2 00:08:53.008: INFO: calico-node-vtrp8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (1 container statuses recorded)
    May  2 00:08:53.008: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:08:53.008: INFO: ebs-csi-node-9zhf8 from kube-system started at 2023-05-01 22:31:36 +0000 UTC (3 container statuses recorded)
    May  2 00:08:53.008: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:08:53.008: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:08:53.008: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:08:53.008: INFO: kube-proxy-i-0627b78ff917cf2ae from kube-system started at 2023-05-01 22:31:16 +0000 UTC (1 container statuses recorded)
    May  2 00:08:53.008: INFO: 	Container kube-proxy ready: true, restart count 0
    May  2 00:08:53.008: INFO: 
    Logging pods the apiserver thinks is on node i-0aa263047c51ef669 before test
    May  2 00:08:53.117: INFO: calico-node-phdpj from kube-system started at 2023-05-01 22:31:39 +0000 UTC (1 container statuses recorded)
    May  2 00:08:53.117: INFO: 	Container calico-node ready: true, restart count 0
    May  2 00:08:53.117: INFO: coredns-6c7bddbb75-zv7nq from kube-system started at 2023-05-01 22:32:02 +0000 UTC (1 container statuses recorded)
    May  2 00:08:53.117: INFO: 	Container coredns ready: true, restart count 0
    May  2 00:08:53.117: INFO: ebs-csi-controller-f987fd46-vlkj2 from kube-system started at 2023-05-01 22:31:58 +0000 UTC (5 container statuses recorded)
    May  2 00:08:53.117: INFO: 	Container csi-attacher ready: true, restart count 0
    May  2 00:08:53.117: INFO: 	Container csi-provisioner ready: true, restart count 0
    May  2 00:08:53.117: INFO: 	Container csi-resizer ready: true, restart count 0
    May  2 00:08:53.117: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:08:53.117: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:08:53.117: INFO: ebs-csi-node-hvkck from kube-system started at 2023-05-01 22:31:39 +0000 UTC (3 container statuses recorded)
    May  2 00:08:53.117: INFO: 	Container ebs-plugin ready: true, restart count 0
    May  2 00:08:53.117: INFO: 	Container liveness-probe ready: true, restart count 0
    May  2 00:08:53.117: INFO: 	Container node-driver-registrar ready: true, restart count 0
    May  2 00:08:53.117: INFO: kube-proxy-i-0aa263047c51ef669 from kube-system started at 2023-05-01 22:31:08 +0000 UTC (1 container statuses recorded)
    May  2 00:08:53.117: INFO: 	Container kube-proxy ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 05/02/23 00:08:53.117
    May  2 00:08:53.225: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-779" to be "running"
    May  2 00:08:53.329: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 104.321176ms
    May  2 00:08:55.435: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.209925874s
    May  2 00:08:55.435: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 05/02/23 00:08:55.541
    STEP: Trying to apply a random label on the found node. 05/02/23 00:08:55.761
    STEP: verifying the node has the label kubernetes.io/e2e-f10a1690-f058-4155-801d-0303037e8cc5 95 05/02/23 00:08:55.871
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 05/02/23 00:08:55.975
    May  2 00:08:56.081: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-779" to be "not pending"
    May  2 00:08:56.185: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 104.150425ms
    May  2 00:08:58.291: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.209665571s
    May  2 00:08:58.291: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.20.48.211 on the node which pod4 resides and expect not scheduled 05/02/23 00:08:58.291
    May  2 00:08:58.397: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-779" to be "not pending"
    May  2 00:08:58.502: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 104.49257ms
    May  2 00:09:00.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209882601s
    May  2 00:09:02.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209454504s
    May  2 00:09:04.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.208946496s
    May  2 00:09:06.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209443601s
    May  2 00:09:08.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.210955767s
    May  2 00:09:10.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.208948858s
    May  2 00:09:12.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.209328859s
    May  2 00:09:14.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.211054098s
    May  2 00:09:16.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.20978076s
    May  2 00:09:18.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.208916705s
    May  2 00:09:20.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.209036561s
    May  2 00:09:22.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.209756124s
    May  2 00:09:24.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.209524365s
    May  2 00:09:26.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.209649005s
    May  2 00:09:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.20904236s
    May  2 00:09:30.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.20979304s
    May  2 00:09:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.209157595s
    May  2 00:09:34.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.210225449s
    May  2 00:09:36.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.209297373s
    May  2 00:09:38.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.209179937s
    May  2 00:09:40.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.209699527s
    May  2 00:09:42.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.210040531s
    May  2 00:09:44.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.210355163s
    May  2 00:09:46.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.209609058s
    May  2 00:09:48.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.209035216s
    May  2 00:09:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.209006584s
    May  2 00:09:52.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.209943886s
    May  2 00:09:54.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.209326087s
    May  2 00:09:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.209259797s
    May  2 00:09:58.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.209194322s
    May  2 00:10:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.209393658s
    May  2 00:10:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.209215623s
    May  2 00:10:04.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.208870222s
    May  2 00:10:06.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.208909915s
    May  2 00:10:08.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.209689594s
    May  2 00:10:10.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.209704289s
    May  2 00:10:12.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.210277816s
    May  2 00:10:14.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.209125926s
    May  2 00:10:16.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.209461446s
    May  2 00:10:18.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.20917549s
    May  2 00:10:20.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.209828807s
    May  2 00:10:22.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.20993796s
    May  2 00:10:24.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.209196792s
    May  2 00:10:26.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.210309644s
    May  2 00:10:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.209082065s
    May  2 00:10:30.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.209473903s
    May  2 00:10:32.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.210546218s
    May  2 00:10:34.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.211160543s
    May  2 00:10:36.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.209023746s
    May  2 00:10:38.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.209072403s
    May  2 00:10:40.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.20960742s
    May  2 00:10:42.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.210785333s
    May  2 00:10:44.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.209020915s
    May  2 00:10:46.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.211189438s
    May  2 00:10:48.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.210837427s
    May  2 00:10:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.209196125s
    May  2 00:10:52.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.209216653s
    May  2 00:10:54.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.209879661s
    May  2 00:10:56.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.20943904s
    May  2 00:10:58.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.209342973s
    May  2 00:11:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.208940038s
    May  2 00:11:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.209290241s
    May  2 00:11:04.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.209437695s
    May  2 00:11:06.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.209018831s
    May  2 00:11:08.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.209050822s
    May  2 00:11:10.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.209141179s
    May  2 00:11:12.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.209066572s
    May  2 00:11:14.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.209319835s
    May  2 00:11:16.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.20895236s
    May  2 00:11:18.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.209557924s
    May  2 00:11:20.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.208905351s
    May  2 00:11:22.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.209250174s
    May  2 00:11:24.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.209905123s
    May  2 00:11:26.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.209129729s
    May  2 00:11:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.209011497s
    May  2 00:11:30.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.210541436s
    May  2 00:11:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.208981731s
    May  2 00:11:34.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.21038781s
    May  2 00:11:36.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.209013124s
    May  2 00:11:38.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.209056713s
    May  2 00:11:40.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.208768106s
    May  2 00:11:42.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.209163298s
    May  2 00:11:44.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.210762063s
    May  2 00:11:46.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.209878812s
    May  2 00:11:48.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.208969351s
    May  2 00:11:50.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.209821642s
    May  2 00:11:52.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.20893264s
    May  2 00:11:54.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.209111563s
    May  2 00:11:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.2092607s
    May  2 00:11:58.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.20988917s
    May  2 00:12:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.208990483s
    May  2 00:12:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.209130923s
    May  2 00:12:04.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.209021747s
    May  2 00:12:06.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.209339519s
    May  2 00:12:08.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.209092591s
    May  2 00:12:10.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.209254501s
    May  2 00:12:12.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.21031488s
    May  2 00:12:14.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.210465199s
    May  2 00:12:16.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.209197031s
    May  2 00:12:18.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.209450196s
    May  2 00:12:20.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.208770782s
    May  2 00:12:22.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.209373409s
    May  2 00:12:24.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.211681317s
    May  2 00:12:26.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.21007215s
    May  2 00:12:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.209227367s
    May  2 00:12:30.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.20915874s
    May  2 00:12:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.208885745s
    May  2 00:12:34.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.209235016s
    May  2 00:12:36.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.209959863s
    May  2 00:12:38.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.210029921s
    May  2 00:12:40.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.209425577s
    May  2 00:12:42.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.209281094s
    May  2 00:12:44.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.209012835s
    May  2 00:12:46.610: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.2127056s
    May  2 00:12:48.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.211176625s
    May  2 00:12:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.209390422s
    May  2 00:12:52.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.210163453s
    May  2 00:12:54.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.209115483s
    May  2 00:12:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.209253515s
    May  2 00:12:58.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.210636431s
    May  2 00:13:00.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.209342035s
    May  2 00:13:02.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.20925114s
    May  2 00:13:04.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.210763896s
    May  2 00:13:06.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.209667138s
    May  2 00:13:08.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.211022592s
    May  2 00:13:10.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.209723772s
    May  2 00:13:12.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.211415739s
    May  2 00:13:14.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.21073977s
    May  2 00:13:16.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.209508813s
    May  2 00:13:18.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.209376386s
    May  2 00:13:20.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.209583685s
    May  2 00:13:22.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.209305815s
    May  2 00:13:24.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.209148322s
    May  2 00:13:26.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.20917646s
    May  2 00:13:28.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.209120451s
    May  2 00:13:30.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.20961638s
    May  2 00:13:32.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.210809875s
    May  2 00:13:34.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.209396277s
    May  2 00:13:36.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.210316468s
    May  2 00:13:38.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.210732271s
    May  2 00:13:40.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.209213099s
    May  2 00:13:42.608: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.210437094s
    May  2 00:13:44.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.209039016s
    May  2 00:13:46.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.209926852s
    May  2 00:13:48.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.21011522s
    May  2 00:13:50.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.209328438s
    May  2 00:13:52.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.210101144s
    May  2 00:13:54.607: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.209912651s
    May  2 00:13:56.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.209390503s
    May  2 00:13:58.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.209247855s
    May  2 00:13:58.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.314959118s
    STEP: removing the label kubernetes.io/e2e-f10a1690-f058-4155-801d-0303037e8cc5 off the node i-02d061b30635c230c 05/02/23 00:13:58.712
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-f10a1690-f058-4155-801d-0303037e8cc5 05/02/23 00:13:58.927
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:13:59.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-779" for this suite. 05/02/23 00:13:59.137
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:13:59.245
May  2 00:13:59.245: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:13:59.246
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:13:59.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:13:59.768
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:13:59.975
May  2 00:14:00.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b" in namespace "projected-8002" to be "Succeeded or Failed"
May  2 00:14:00.188: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.37947ms
May  2 00:14:02.294: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210413007s
May  2 00:14:04.295: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210915574s
STEP: Saw pod success 05/02/23 00:14:04.295
May  2 00:14:04.295: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b" satisfied condition "Succeeded or Failed"
May  2 00:14:04.399: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b container client-container: <nil>
STEP: delete the pod 05/02/23 00:14:04.514
May  2 00:14:04.628: INFO: Waiting for pod downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b to disappear
May  2 00:14:04.731: INFO: Pod downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  2 00:14:04.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8002" for this suite. 05/02/23 00:14:04.837
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":299,"skipped":5497,"failed":0}
------------------------------
• [SLOW TEST] [5.799 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:13:59.245
    May  2 00:13:59.245: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:13:59.246
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:13:59.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:13:59.768
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:13:59.975
    May  2 00:14:00.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b" in namespace "projected-8002" to be "Succeeded or Failed"
    May  2 00:14:00.188: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b": Phase="Pending", Reason="", readiness=false. Elapsed: 104.37947ms
    May  2 00:14:02.294: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210413007s
    May  2 00:14:04.295: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210915574s
    STEP: Saw pod success 05/02/23 00:14:04.295
    May  2 00:14:04.295: INFO: Pod "downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b" satisfied condition "Succeeded or Failed"
    May  2 00:14:04.399: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b container client-container: <nil>
    STEP: delete the pod 05/02/23 00:14:04.514
    May  2 00:14:04.628: INFO: Waiting for pod downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b to disappear
    May  2 00:14:04.731: INFO: Pod downwardapi-volume-f38b98b4-f1f2-427e-a134-abff44d99f9b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  2 00:14:04.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8002" for this suite. 05/02/23 00:14:04.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:14:05.047
May  2 00:14:05.047: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir 05/02/23 00:14:05.049
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:05.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:05.571
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 05/02/23 00:14:05.779
May  2 00:14:05.889: INFO: Waiting up to 5m0s for pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655" in namespace "emptydir-1447" to be "Succeeded or Failed"
May  2 00:14:05.993: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655": Phase="Pending", Reason="", readiness=false. Elapsed: 104.180778ms
May  2 00:14:08.099: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210026822s
May  2 00:14:10.098: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209341372s
STEP: Saw pod success 05/02/23 00:14:10.098
May  2 00:14:10.099: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655" satisfied condition "Succeeded or Failed"
May  2 00:14:10.203: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655 container test-container: <nil>
STEP: delete the pod 05/02/23 00:14:10.309
May  2 00:14:10.421: INFO: Waiting for pod pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655 to disappear
May  2 00:14:10.525: INFO: Pod pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
May  2 00:14:10.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1447" for this suite. 05/02/23 00:14:10.63
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":300,"skipped":5537,"failed":0}
------------------------------
• [SLOW TEST] [5.791 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:14:05.047
    May  2 00:14:05.047: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename emptydir 05/02/23 00:14:05.049
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:05.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:05.571
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 05/02/23 00:14:05.779
    May  2 00:14:05.889: INFO: Waiting up to 5m0s for pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655" in namespace "emptydir-1447" to be "Succeeded or Failed"
    May  2 00:14:05.993: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655": Phase="Pending", Reason="", readiness=false. Elapsed: 104.180778ms
    May  2 00:14:08.099: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210026822s
    May  2 00:14:10.098: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209341372s
    STEP: Saw pod success 05/02/23 00:14:10.098
    May  2 00:14:10.099: INFO: Pod "pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655" satisfied condition "Succeeded or Failed"
    May  2 00:14:10.203: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655 container test-container: <nil>
    STEP: delete the pod 05/02/23 00:14:10.309
    May  2 00:14:10.421: INFO: Waiting for pod pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655 to disappear
    May  2 00:14:10.525: INFO: Pod pod-7cb4cdfa-d011-4ba4-8593-01d795bb6655 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    May  2 00:14:10.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1447" for this suite. 05/02/23 00:14:10.63
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:14:10.839
May  2 00:14:10.839: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename endpointslice 05/02/23 00:14:10.84
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:11.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:11.361
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 05/02/23 00:14:11.567
STEP: getting /apis/discovery.k8s.io 05/02/23 00:14:11.774
STEP: getting /apis/discovery.k8s.iov1 05/02/23 00:14:11.877
STEP: creating 05/02/23 00:14:11.98
STEP: getting 05/02/23 00:14:12.297
STEP: listing 05/02/23 00:14:12.401
STEP: watching 05/02/23 00:14:12.506
May  2 00:14:12.506: INFO: starting watch
STEP: cluster-wide listing 05/02/23 00:14:12.609
STEP: cluster-wide watching 05/02/23 00:14:12.714
May  2 00:14:12.714: INFO: starting watch
STEP: patching 05/02/23 00:14:12.817
STEP: updating 05/02/23 00:14:12.923
May  2 00:14:13.133: INFO: waiting for watch events with expected annotations
May  2 00:14:13.133: INFO: saw patched and updated annotations
STEP: deleting 05/02/23 00:14:13.133
STEP: deleting a collection 05/02/23 00:14:13.447
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
May  2 00:14:13.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8470" for this suite. 05/02/23 00:14:13.768
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":301,"skipped":5559,"failed":0}
------------------------------
• [3.035 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:14:10.839
    May  2 00:14:10.839: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename endpointslice 05/02/23 00:14:10.84
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:11.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:11.361
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 05/02/23 00:14:11.567
    STEP: getting /apis/discovery.k8s.io 05/02/23 00:14:11.774
    STEP: getting /apis/discovery.k8s.iov1 05/02/23 00:14:11.877
    STEP: creating 05/02/23 00:14:11.98
    STEP: getting 05/02/23 00:14:12.297
    STEP: listing 05/02/23 00:14:12.401
    STEP: watching 05/02/23 00:14:12.506
    May  2 00:14:12.506: INFO: starting watch
    STEP: cluster-wide listing 05/02/23 00:14:12.609
    STEP: cluster-wide watching 05/02/23 00:14:12.714
    May  2 00:14:12.714: INFO: starting watch
    STEP: patching 05/02/23 00:14:12.817
    STEP: updating 05/02/23 00:14:12.923
    May  2 00:14:13.133: INFO: waiting for watch events with expected annotations
    May  2 00:14:13.133: INFO: saw patched and updated annotations
    STEP: deleting 05/02/23 00:14:13.133
    STEP: deleting a collection 05/02/23 00:14:13.447
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    May  2 00:14:13.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8470" for this suite. 05/02/23 00:14:13.768
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:14:13.875
May  2 00:14:13.875: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/02/23 00:14:13.876
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:14.191
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:14.398
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:14:14.605
May  2 00:14:14.713: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27" in namespace "downward-api-300" to be "Succeeded or Failed"
May  2 00:14:14.818: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27": Phase="Pending", Reason="", readiness=false. Elapsed: 104.598815ms
May  2 00:14:16.924: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210419501s
May  2 00:14:18.924: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210432311s
STEP: Saw pod success 05/02/23 00:14:18.924
May  2 00:14:18.924: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27" satisfied condition "Succeeded or Failed"
May  2 00:14:19.028: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27 container client-container: <nil>
STEP: delete the pod 05/02/23 00:14:19.142
May  2 00:14:19.254: INFO: Waiting for pod downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27 to disappear
May  2 00:14:19.358: INFO: Pod downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  2 00:14:19.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-300" for this suite. 05/02/23 00:14:19.463
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":302,"skipped":5564,"failed":0}
------------------------------
• [SLOW TEST] [5.695 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:14:13.875
    May  2 00:14:13.875: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/02/23 00:14:13.876
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:14.191
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:14.398
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:14:14.605
    May  2 00:14:14.713: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27" in namespace "downward-api-300" to be "Succeeded or Failed"
    May  2 00:14:14.818: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27": Phase="Pending", Reason="", readiness=false. Elapsed: 104.598815ms
    May  2 00:14:16.924: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210419501s
    May  2 00:14:18.924: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210432311s
    STEP: Saw pod success 05/02/23 00:14:18.924
    May  2 00:14:18.924: INFO: Pod "downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27" satisfied condition "Succeeded or Failed"
    May  2 00:14:19.028: INFO: Trying to get logs from node i-02d061b30635c230c pod downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27 container client-container: <nil>
    STEP: delete the pod 05/02/23 00:14:19.142
    May  2 00:14:19.254: INFO: Waiting for pod downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27 to disappear
    May  2 00:14:19.358: INFO: Pod downwardapi-volume-8286da27-04ef-41b2-94e7-0a89701cef27 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  2 00:14:19.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-300" for this suite. 05/02/23 00:14:19.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:14:19.57
May  2 00:14:19.570: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap 05/02/23 00:14:19.571
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:19.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:20.092
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-c6fd502c-58d3-4647-bf7f-b305eba2f235 05/02/23 00:14:20.3
STEP: Creating a pod to test consume configMaps 05/02/23 00:14:20.407
May  2 00:14:20.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9" in namespace "configmap-4550" to be "Succeeded or Failed"
May  2 00:14:20.620: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9": Phase="Pending", Reason="", readiness=false. Elapsed: 104.394672ms
May  2 00:14:22.726: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209780037s
May  2 00:14:24.726: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210053908s
STEP: Saw pod success 05/02/23 00:14:24.726
May  2 00:14:24.726: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9" satisfied condition "Succeeded or Failed"
May  2 00:14:24.831: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9 container agnhost-container: <nil>
STEP: delete the pod 05/02/23 00:14:24.938
May  2 00:14:25.049: INFO: Waiting for pod pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9 to disappear
May  2 00:14:25.153: INFO: Pod pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
May  2 00:14:25.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4550" for this suite. 05/02/23 00:14:25.259
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":303,"skipped":5573,"failed":0}
------------------------------
• [SLOW TEST] [5.795 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:14:19.57
    May  2 00:14:19.570: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename configmap 05/02/23 00:14:19.571
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:19.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:20.092
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-c6fd502c-58d3-4647-bf7f-b305eba2f235 05/02/23 00:14:20.3
    STEP: Creating a pod to test consume configMaps 05/02/23 00:14:20.407
    May  2 00:14:20.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9" in namespace "configmap-4550" to be "Succeeded or Failed"
    May  2 00:14:20.620: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9": Phase="Pending", Reason="", readiness=false. Elapsed: 104.394672ms
    May  2 00:14:22.726: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209780037s
    May  2 00:14:24.726: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.210053908s
    STEP: Saw pod success 05/02/23 00:14:24.726
    May  2 00:14:24.726: INFO: Pod "pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9" satisfied condition "Succeeded or Failed"
    May  2 00:14:24.831: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9 container agnhost-container: <nil>
    STEP: delete the pod 05/02/23 00:14:24.938
    May  2 00:14:25.049: INFO: Waiting for pod pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9 to disappear
    May  2 00:14:25.153: INFO: Pod pod-configmaps-ec5645da-c7af-44f2-b632-4b5b2c6709d9 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    May  2 00:14:25.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4550" for this suite. 05/02/23 00:14:25.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:14:25.367
May  2 00:14:25.367: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch 05/02/23 00:14:25.369
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:25.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:25.891
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 05/02/23 00:14:26.098
STEP: modifying the configmap once 05/02/23 00:14:26.205
STEP: modifying the configmap a second time 05/02/23 00:14:26.415
STEP: deleting the configmap 05/02/23 00:14:26.625
STEP: creating a watch on configmaps from the resource version returned by the first update 05/02/23 00:14:26.731
STEP: Expecting to observe notifications for all changes to the configmap after the first update 05/02/23 00:14:26.834
May  2 00:14:26.835: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9172  f025654a-5a8d-4ff3-99ac-e4052cea6104 34827 0 2023-05-02 00:14:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-05-02 00:14:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
May  2 00:14:26.835: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9172  f025654a-5a8d-4ff3-99ac-e4052cea6104 34828 0 2023-05-02 00:14:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-05-02 00:14:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
May  2 00:14:26.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9172" for this suite. 05/02/23 00:14:26.94
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":304,"skipped":5604,"failed":0}
------------------------------
• [1.679 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:14:25.367
    May  2 00:14:25.367: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename watch 05/02/23 00:14:25.369
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:25.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:25.891
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 05/02/23 00:14:26.098
    STEP: modifying the configmap once 05/02/23 00:14:26.205
    STEP: modifying the configmap a second time 05/02/23 00:14:26.415
    STEP: deleting the configmap 05/02/23 00:14:26.625
    STEP: creating a watch on configmaps from the resource version returned by the first update 05/02/23 00:14:26.731
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 05/02/23 00:14:26.834
    May  2 00:14:26.835: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9172  f025654a-5a8d-4ff3-99ac-e4052cea6104 34827 0 2023-05-02 00:14:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-05-02 00:14:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    May  2 00:14:26.835: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9172  f025654a-5a8d-4ff3-99ac-e4052cea6104 34828 0 2023-05-02 00:14:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-05-02 00:14:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    May  2 00:14:26.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9172" for this suite. 05/02/23 00:14:26.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:14:27.047
May  2 00:14:27.047: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/02/23 00:14:27.048
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:27.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:27.569
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7887 05/02/23 00:14:27.776
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 05/02/23 00:14:27.883
May  2 00:14:28.094: INFO: Found 1 stateful pods, waiting for 3
May  2 00:14:38.200: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:14:38.200: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:14:38.200: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 05/02/23 00:14:38.514
May  2 00:14:38.736: INFO: Updating stateful set ss2
STEP: Creating a new revision 05/02/23 00:14:38.736
STEP: Not applying an update when the partition is greater than the number of replicas 05/02/23 00:14:38.946
STEP: Performing a canary update 05/02/23 00:14:38.946
May  2 00:14:39.167: INFO: Updating stateful set ss2
May  2 00:14:39.377: INFO: Waiting for Pod statefulset-7887/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 05/02/23 00:14:49.587
May  2 00:14:49.928: INFO: Found 2 stateful pods, waiting for 3
May  2 00:15:00.033: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:15:00.033: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:15:00.033: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 05/02/23 00:15:00.242
May  2 00:15:00.463: INFO: Updating stateful set ss2
May  2 00:15:00.672: INFO: Waiting for Pod statefulset-7887/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
May  2 00:15:11.105: INFO: Updating stateful set ss2
May  2 00:15:11.314: INFO: Waiting for StatefulSet statefulset-7887/ss2 to complete update
May  2 00:15:11.315: INFO: Waiting for Pod statefulset-7887/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  2 00:15:21.526: INFO: Deleting all statefulset in ns statefulset-7887
May  2 00:15:21.630: INFO: Scaling statefulset ss2 to 0
May  2 00:15:32.052: INFO: Waiting for statefulset status.replicas updated to 0
May  2 00:15:32.157: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  2 00:15:32.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7887" for this suite. 05/02/23 00:15:32.576
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":305,"skipped":5626,"failed":0}
------------------------------
• [SLOW TEST] [65.738 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:14:27.047
    May  2 00:14:27.047: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/02/23 00:14:27.048
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:14:27.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:14:27.569
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7887 05/02/23 00:14:27.776
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 05/02/23 00:14:27.883
    May  2 00:14:28.094: INFO: Found 1 stateful pods, waiting for 3
    May  2 00:14:38.200: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:14:38.200: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:14:38.200: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 05/02/23 00:14:38.514
    May  2 00:14:38.736: INFO: Updating stateful set ss2
    STEP: Creating a new revision 05/02/23 00:14:38.736
    STEP: Not applying an update when the partition is greater than the number of replicas 05/02/23 00:14:38.946
    STEP: Performing a canary update 05/02/23 00:14:38.946
    May  2 00:14:39.167: INFO: Updating stateful set ss2
    May  2 00:14:39.377: INFO: Waiting for Pod statefulset-7887/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 05/02/23 00:14:49.587
    May  2 00:14:49.928: INFO: Found 2 stateful pods, waiting for 3
    May  2 00:15:00.033: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:15:00.033: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:15:00.033: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 05/02/23 00:15:00.242
    May  2 00:15:00.463: INFO: Updating stateful set ss2
    May  2 00:15:00.672: INFO: Waiting for Pod statefulset-7887/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    May  2 00:15:11.105: INFO: Updating stateful set ss2
    May  2 00:15:11.314: INFO: Waiting for StatefulSet statefulset-7887/ss2 to complete update
    May  2 00:15:11.315: INFO: Waiting for Pod statefulset-7887/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  2 00:15:21.526: INFO: Deleting all statefulset in ns statefulset-7887
    May  2 00:15:21.630: INFO: Scaling statefulset ss2 to 0
    May  2 00:15:32.052: INFO: Waiting for statefulset status.replicas updated to 0
    May  2 00:15:32.157: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  2 00:15:32.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7887" for this suite. 05/02/23 00:15:32.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:15:32.787
May  2 00:15:32.787: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename lease-test 05/02/23 00:15:32.788
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:15:33.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:15:33.31
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
May  2 00:15:34.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2340" for this suite. 05/02/23 00:15:34.99
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":306,"skipped":5652,"failed":0}
------------------------------
• [2.310 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:15:32.787
    May  2 00:15:32.787: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename lease-test 05/02/23 00:15:32.788
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:15:33.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:15:33.31
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    May  2 00:15:34.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-2340" for this suite. 05/02/23 00:15:34.99
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:15:35.098
May  2 00:15:35.098: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pod-network-test 05/02/23 00:15:35.099
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:15:35.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:15:35.623
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-5164 05/02/23 00:15:35.83
STEP: creating a selector 05/02/23 00:15:35.83
STEP: Creating the service pods in kubernetes 05/02/23 00:15:35.83
May  2 00:15:35.831: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  2 00:15:36.470: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5164" to be "running and ready"
May  2 00:15:36.574: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 104.351025ms
May  2 00:15:36.574: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:15:38.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.209357796s
May  2 00:15:38.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:15:40.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.209841227s
May  2 00:15:40.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:15:42.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.209397883s
May  2 00:15:42.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:15:44.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.210114103s
May  2 00:15:44.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:15:46.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 10.209772385s
May  2 00:15:46.680: INFO: The phase of Pod netserver-0 is Running (Ready = true)
May  2 00:15:46.680: INFO: Pod "netserver-0" satisfied condition "running and ready"
May  2 00:15:46.784: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5164" to be "running and ready"
May  2 00:15:46.889: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 104.610292ms
May  2 00:15:46.889: INFO: The phase of Pod netserver-1 is Running (Ready = true)
May  2 00:15:46.889: INFO: Pod "netserver-1" satisfied condition "running and ready"
May  2 00:15:46.994: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5164" to be "running and ready"
May  2 00:15:47.099: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 104.871333ms
May  2 00:15:47.099: INFO: The phase of Pod netserver-2 is Running (Ready = false)
May  2 00:15:49.205: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 2.211378686s
May  2 00:15:49.205: INFO: The phase of Pod netserver-2 is Running (Ready = false)
May  2 00:15:51.205: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 4.211011649s
May  2 00:15:51.205: INFO: The phase of Pod netserver-2 is Running (Ready = false)
May  2 00:15:53.204: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 6.210243021s
May  2 00:15:53.204: INFO: The phase of Pod netserver-2 is Running (Ready = false)
May  2 00:15:55.205: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 8.21098071s
May  2 00:15:55.205: INFO: The phase of Pod netserver-2 is Running (Ready = false)
May  2 00:15:57.204: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.210013861s
May  2 00:15:57.204: INFO: The phase of Pod netserver-2 is Running (Ready = true)
May  2 00:15:57.204: INFO: Pod "netserver-2" satisfied condition "running and ready"
May  2 00:15:57.308: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-5164" to be "running and ready"
May  2 00:15:57.413: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 104.527234ms
May  2 00:15:57.413: INFO: The phase of Pod netserver-3 is Running (Ready = true)
May  2 00:15:57.413: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 05/02/23 00:15:57.517
May  2 00:15:57.729: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5164" to be "running"
May  2 00:15:57.834: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.622375ms
May  2 00:15:59.939: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209692994s
May  2 00:15:59.939: INFO: Pod "test-container-pod" satisfied condition "running"
May  2 00:16:00.044: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5164" to be "running"
May  2 00:16:00.148: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 104.453923ms
May  2 00:16:00.149: INFO: Pod "host-test-container-pod" satisfied condition "running"
May  2 00:16:00.253: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
May  2 00:16:00.253: INFO: Going to poll 100.123.145.248 on port 8083 at least 0 times, with a maximum of 46 tries before failing
May  2 00:16:00.357: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.123.145.248:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:16:00.357: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:16:00.358: INFO: ExecWithOptions: Clientset creation
May  2 00:16:00.358: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.123.145.248%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  2 00:16:01.078: INFO: Found all 1 expected endpoints: [netserver-0]
May  2 00:16:01.078: INFO: Going to poll 100.96.36.16 on port 8083 at least 0 times, with a maximum of 46 tries before failing
May  2 00:16:01.182: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.36.16:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:16:01.182: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:16:01.183: INFO: ExecWithOptions: Clientset creation
May  2 00:16:01.183: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.36.16%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  2 00:16:01.906: INFO: Found all 1 expected endpoints: [netserver-1]
May  2 00:16:01.906: INFO: Going to poll 100.105.72.131 on port 8083 at least 0 times, with a maximum of 46 tries before failing
May  2 00:16:02.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.105.72.131:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:16:02.011: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:16:02.012: INFO: ExecWithOptions: Clientset creation
May  2 00:16:02.012: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.105.72.131%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  2 00:16:02.739: INFO: Found all 1 expected endpoints: [netserver-2]
May  2 00:16:02.739: INFO: Going to poll 100.101.231.186 on port 8083 at least 0 times, with a maximum of 46 tries before failing
May  2 00:16:02.843: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.101.231.186:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:16:02.843: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:16:02.844: INFO: ExecWithOptions: Clientset creation
May  2 00:16:02.844: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.101.231.186%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
May  2 00:16:03.541: INFO: Found all 1 expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
May  2 00:16:03.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5164" for this suite. 05/02/23 00:16:03.647
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":307,"skipped":5674,"failed":0}
------------------------------
• [SLOW TEST] [28.657 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:15:35.098
    May  2 00:15:35.098: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pod-network-test 05/02/23 00:15:35.099
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:15:35.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:15:35.623
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-5164 05/02/23 00:15:35.83
    STEP: creating a selector 05/02/23 00:15:35.83
    STEP: Creating the service pods in kubernetes 05/02/23 00:15:35.83
    May  2 00:15:35.831: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    May  2 00:15:36.470: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5164" to be "running and ready"
    May  2 00:15:36.574: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 104.351025ms
    May  2 00:15:36.574: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:15:38.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.209357796s
    May  2 00:15:38.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:15:40.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.209841227s
    May  2 00:15:40.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:15:42.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.209397883s
    May  2 00:15:42.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:15:44.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.210114103s
    May  2 00:15:44.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:15:46.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 10.209772385s
    May  2 00:15:46.680: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    May  2 00:15:46.680: INFO: Pod "netserver-0" satisfied condition "running and ready"
    May  2 00:15:46.784: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5164" to be "running and ready"
    May  2 00:15:46.889: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 104.610292ms
    May  2 00:15:46.889: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    May  2 00:15:46.889: INFO: Pod "netserver-1" satisfied condition "running and ready"
    May  2 00:15:46.994: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5164" to be "running and ready"
    May  2 00:15:47.099: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 104.871333ms
    May  2 00:15:47.099: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    May  2 00:15:49.205: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 2.211378686s
    May  2 00:15:49.205: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    May  2 00:15:51.205: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 4.211011649s
    May  2 00:15:51.205: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    May  2 00:15:53.204: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 6.210243021s
    May  2 00:15:53.204: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    May  2 00:15:55.205: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 8.21098071s
    May  2 00:15:55.205: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    May  2 00:15:57.204: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.210013861s
    May  2 00:15:57.204: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    May  2 00:15:57.204: INFO: Pod "netserver-2" satisfied condition "running and ready"
    May  2 00:15:57.308: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-5164" to be "running and ready"
    May  2 00:15:57.413: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 104.527234ms
    May  2 00:15:57.413: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    May  2 00:15:57.413: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 05/02/23 00:15:57.517
    May  2 00:15:57.729: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5164" to be "running"
    May  2 00:15:57.834: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.622375ms
    May  2 00:15:59.939: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209692994s
    May  2 00:15:59.939: INFO: Pod "test-container-pod" satisfied condition "running"
    May  2 00:16:00.044: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5164" to be "running"
    May  2 00:16:00.148: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 104.453923ms
    May  2 00:16:00.149: INFO: Pod "host-test-container-pod" satisfied condition "running"
    May  2 00:16:00.253: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    May  2 00:16:00.253: INFO: Going to poll 100.123.145.248 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    May  2 00:16:00.357: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.123.145.248:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:16:00.357: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:16:00.358: INFO: ExecWithOptions: Clientset creation
    May  2 00:16:00.358: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.123.145.248%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  2 00:16:01.078: INFO: Found all 1 expected endpoints: [netserver-0]
    May  2 00:16:01.078: INFO: Going to poll 100.96.36.16 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    May  2 00:16:01.182: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.36.16:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:16:01.182: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:16:01.183: INFO: ExecWithOptions: Clientset creation
    May  2 00:16:01.183: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.36.16%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  2 00:16:01.906: INFO: Found all 1 expected endpoints: [netserver-1]
    May  2 00:16:01.906: INFO: Going to poll 100.105.72.131 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    May  2 00:16:02.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.105.72.131:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:16:02.011: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:16:02.012: INFO: ExecWithOptions: Clientset creation
    May  2 00:16:02.012: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.105.72.131%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  2 00:16:02.739: INFO: Found all 1 expected endpoints: [netserver-2]
    May  2 00:16:02.739: INFO: Going to poll 100.101.231.186 on port 8083 at least 0 times, with a maximum of 46 tries before failing
    May  2 00:16:02.843: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.101.231.186:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5164 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:16:02.843: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:16:02.844: INFO: ExecWithOptions: Clientset creation
    May  2 00:16:02.844: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-5164/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.101.231.186%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    May  2 00:16:03.541: INFO: Found all 1 expected endpoints: [netserver-3]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    May  2 00:16:03.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5164" for this suite. 05/02/23 00:16:03.647
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:16:03.757
May  2 00:16:03.757: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts 05/02/23 00:16:03.758
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:04.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:04.279
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
May  2 00:16:04.805: INFO: created pod pod-service-account-defaultsa
May  2 00:16:04.805: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May  2 00:16:04.911: INFO: created pod pod-service-account-mountsa
May  2 00:16:04.911: INFO: pod pod-service-account-mountsa service account token volume mount: true
May  2 00:16:05.018: INFO: created pod pod-service-account-nomountsa
May  2 00:16:05.018: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May  2 00:16:05.124: INFO: created pod pod-service-account-defaultsa-mountspec
May  2 00:16:05.124: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May  2 00:16:05.230: INFO: created pod pod-service-account-mountsa-mountspec
May  2 00:16:05.230: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May  2 00:16:05.336: INFO: created pod pod-service-account-nomountsa-mountspec
May  2 00:16:05.336: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May  2 00:16:05.443: INFO: created pod pod-service-account-defaultsa-nomountspec
May  2 00:16:05.443: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May  2 00:16:05.557: INFO: created pod pod-service-account-mountsa-nomountspec
May  2 00:16:05.557: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May  2 00:16:05.671: INFO: created pod pod-service-account-nomountsa-nomountspec
May  2 00:16:05.671: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
May  2 00:16:05.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3247" for this suite. 05/02/23 00:16:05.777
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":308,"skipped":5735,"failed":0}
------------------------------
• [2.130 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:16:03.757
    May  2 00:16:03.757: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svcaccounts 05/02/23 00:16:03.758
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:04.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:04.279
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    May  2 00:16:04.805: INFO: created pod pod-service-account-defaultsa
    May  2 00:16:04.805: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    May  2 00:16:04.911: INFO: created pod pod-service-account-mountsa
    May  2 00:16:04.911: INFO: pod pod-service-account-mountsa service account token volume mount: true
    May  2 00:16:05.018: INFO: created pod pod-service-account-nomountsa
    May  2 00:16:05.018: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    May  2 00:16:05.124: INFO: created pod pod-service-account-defaultsa-mountspec
    May  2 00:16:05.124: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    May  2 00:16:05.230: INFO: created pod pod-service-account-mountsa-mountspec
    May  2 00:16:05.230: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    May  2 00:16:05.336: INFO: created pod pod-service-account-nomountsa-mountspec
    May  2 00:16:05.336: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    May  2 00:16:05.443: INFO: created pod pod-service-account-defaultsa-nomountspec
    May  2 00:16:05.443: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    May  2 00:16:05.557: INFO: created pod pod-service-account-mountsa-nomountspec
    May  2 00:16:05.557: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    May  2 00:16:05.671: INFO: created pod pod-service-account-nomountsa-nomountspec
    May  2 00:16:05.671: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    May  2 00:16:05.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3247" for this suite. 05/02/23 00:16:05.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:16:05.889
May  2 00:16:05.889: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/02/23 00:16:05.89
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:06.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:06.414
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
May  2 00:16:07.355: INFO: Create a RollingUpdate DaemonSet
May  2 00:16:07.461: INFO: Check that daemon pods launch on every node of the cluster
May  2 00:16:07.567: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:07.671: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  2 00:16:07.671: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  2 00:16:08.778: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:08.884: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May  2 00:16:08.884: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  2 00:16:09.777: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:09.884: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May  2 00:16:09.884: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  2 00:16:10.778: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:10.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  2 00:16:10.883: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
May  2 00:16:10.883: INFO: Update the DaemonSet to trigger a rollout
May  2 00:16:11.095: INFO: Updating DaemonSet daemon-set
May  2 00:16:13.522: INFO: Roll back the DaemonSet before rollout is complete
May  2 00:16:13.733: INFO: Updating DaemonSet daemon-set
May  2 00:16:13.733: INFO: Make sure DaemonSet rollback is complete
May  2 00:16:13.947: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:15.159: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:16.159: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:16:17.053: INFO: Pod daemon-set-nvrjb is not available
May  2 00:16:17.162: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 05/02/23 00:16:17.372
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9416, will wait for the garbage collector to delete the pods 05/02/23 00:16:17.372
May  2 00:16:17.734: INFO: Deleting DaemonSet.extensions daemon-set took: 106.005549ms
May  2 00:16:17.834: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.492292ms
May  2 00:16:20.139: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  2 00:16:20.139: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May  2 00:16:20.243: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35793"},"items":null}

May  2 00:16:20.347: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35793"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  2 00:16:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9416" for this suite. 05/02/23 00:16:20.977
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":309,"skipped":5780,"failed":0}
------------------------------
• [SLOW TEST] [15.195 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:16:05.889
    May  2 00:16:05.889: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/02/23 00:16:05.89
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:06.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:06.414
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    May  2 00:16:07.355: INFO: Create a RollingUpdate DaemonSet
    May  2 00:16:07.461: INFO: Check that daemon pods launch on every node of the cluster
    May  2 00:16:07.567: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:07.671: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  2 00:16:07.671: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  2 00:16:08.778: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:08.884: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    May  2 00:16:08.884: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  2 00:16:09.777: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:09.884: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    May  2 00:16:09.884: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  2 00:16:10.778: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:10.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  2 00:16:10.883: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    May  2 00:16:10.883: INFO: Update the DaemonSet to trigger a rollout
    May  2 00:16:11.095: INFO: Updating DaemonSet daemon-set
    May  2 00:16:13.522: INFO: Roll back the DaemonSet before rollout is complete
    May  2 00:16:13.733: INFO: Updating DaemonSet daemon-set
    May  2 00:16:13.733: INFO: Make sure DaemonSet rollback is complete
    May  2 00:16:13.947: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:15.159: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:16.159: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:16:17.053: INFO: Pod daemon-set-nvrjb is not available
    May  2 00:16:17.162: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 05/02/23 00:16:17.372
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9416, will wait for the garbage collector to delete the pods 05/02/23 00:16:17.372
    May  2 00:16:17.734: INFO: Deleting DaemonSet.extensions daemon-set took: 106.005549ms
    May  2 00:16:17.834: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.492292ms
    May  2 00:16:20.139: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  2 00:16:20.139: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    May  2 00:16:20.243: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35793"},"items":null}

    May  2 00:16:20.347: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35793"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:16:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9416" for this suite. 05/02/23 00:16:20.977
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:16:21.086
May  2 00:16:21.086: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller 05/02/23 00:16:21.087
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:21.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:21.609
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4 05/02/23 00:16:21.817
May  2 00:16:22.028: INFO: Pod name my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4: Found 1 pods out of 1
May  2 00:16:22.028: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4" are running
May  2 00:16:22.028: INFO: Waiting up to 5m0s for pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr" in namespace "replication-controller-4397" to be "running"
May  2 00:16:22.132: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr": Phase="Pending", Reason="", readiness=false. Elapsed: 104.382115ms
May  2 00:16:24.238: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr": Phase="Running", Reason="", readiness=true. Elapsed: 2.210040701s
May  2 00:16:24.238: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr" satisfied condition "running"
May  2 00:16:24.238: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason: Message:}])
May  2 00:16:24.238: INFO: Trying to dial the pod
May  2 00:16:29.552: INFO: Controller my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4: Got expected result from replica 1 [my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr]: "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
May  2 00:16:29.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4397" for this suite. 05/02/23 00:16:29.658
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":310,"skipped":5819,"failed":0}
------------------------------
• [SLOW TEST] [8.681 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:16:21.086
    May  2 00:16:21.086: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename replication-controller 05/02/23 00:16:21.087
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:21.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:21.609
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4 05/02/23 00:16:21.817
    May  2 00:16:22.028: INFO: Pod name my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4: Found 1 pods out of 1
    May  2 00:16:22.028: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4" are running
    May  2 00:16:22.028: INFO: Waiting up to 5m0s for pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr" in namespace "replication-controller-4397" to be "running"
    May  2 00:16:22.132: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr": Phase="Pending", Reason="", readiness=false. Elapsed: 104.382115ms
    May  2 00:16:24.238: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr": Phase="Running", Reason="", readiness=true. Elapsed: 2.210040701s
    May  2 00:16:24.238: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr" satisfied condition "running"
    May  2 00:16:24.238: INFO: Pod "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-05-02 00:16:21 +0000 UTC Reason: Message:}])
    May  2 00:16:24.238: INFO: Trying to dial the pod
    May  2 00:16:29.552: INFO: Controller my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4: Got expected result from replica 1 [my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr]: "my-hostname-basic-b2056779-4100-4734-81bb-b470996b46d4-cc8fr", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    May  2 00:16:29.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4397" for this suite. 05/02/23 00:16:29.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:16:29.767
May  2 00:16:29.767: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/02/23 00:16:29.768
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:30.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:30.289
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 05/02/23 00:16:30.497
May  2 00:16:30.614: INFO: Waiting up to 5m0s for pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084" in namespace "downward-api-5615" to be "Succeeded or Failed"
May  2 00:16:30.718: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084": Phase="Pending", Reason="", readiness=false. Elapsed: 104.298445ms
May  2 00:16:32.823: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209508486s
May  2 00:16:34.825: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211110231s
STEP: Saw pod success 05/02/23 00:16:34.825
May  2 00:16:34.825: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084" satisfied condition "Succeeded or Failed"
May  2 00:16:34.929: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084 container dapi-container: <nil>
STEP: delete the pod 05/02/23 00:16:35.042
May  2 00:16:35.155: INFO: Waiting for pod downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084 to disappear
May  2 00:16:35.259: INFO: Pod downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
May  2 00:16:35.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5615" for this suite. 05/02/23 00:16:35.365
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":311,"skipped":5826,"failed":0}
------------------------------
• [SLOW TEST] [5.816 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:16:29.767
    May  2 00:16:29.767: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/02/23 00:16:29.768
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:30.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:30.289
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 05/02/23 00:16:30.497
    May  2 00:16:30.614: INFO: Waiting up to 5m0s for pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084" in namespace "downward-api-5615" to be "Succeeded or Failed"
    May  2 00:16:30.718: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084": Phase="Pending", Reason="", readiness=false. Elapsed: 104.298445ms
    May  2 00:16:32.823: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209508486s
    May  2 00:16:34.825: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.211110231s
    STEP: Saw pod success 05/02/23 00:16:34.825
    May  2 00:16:34.825: INFO: Pod "downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084" satisfied condition "Succeeded or Failed"
    May  2 00:16:34.929: INFO: Trying to get logs from node i-02d061b30635c230c pod downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084 container dapi-container: <nil>
    STEP: delete the pod 05/02/23 00:16:35.042
    May  2 00:16:35.155: INFO: Waiting for pod downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084 to disappear
    May  2 00:16:35.259: INFO: Pod downward-api-e9c15c1c-6bbd-443d-af7a-5ea65c24a084 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    May  2 00:16:35.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5615" for this suite. 05/02/23 00:16:35.365
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:16:35.583
May  2 00:16:35.583: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pod-network-test 05/02/23 00:16:35.584
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:35.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:36.11
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-2820 05/02/23 00:16:36.317
STEP: creating a selector 05/02/23 00:16:36.317
STEP: Creating the service pods in kubernetes 05/02/23 00:16:36.317
May  2 00:16:36.317: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
May  2 00:16:36.954: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2820" to be "running and ready"
May  2 00:16:37.058: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 104.318517ms
May  2 00:16:37.058: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:16:39.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.210342609s
May  2 00:16:39.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:41.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.209870222s
May  2 00:16:41.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:43.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.209391425s
May  2 00:16:43.163: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:45.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.20988477s
May  2 00:16:45.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:47.165: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.210992239s
May  2 00:16:47.165: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:49.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.20940969s
May  2 00:16:49.163: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:51.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.209365648s
May  2 00:16:51.163: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:53.165: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.211047495s
May  2 00:16:53.165: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:55.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.210015672s
May  2 00:16:55.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
May  2 00:16:57.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 20.209174246s
May  2 00:16:57.163: INFO: The phase of Pod netserver-0 is Running (Ready = true)
May  2 00:16:57.163: INFO: Pod "netserver-0" satisfied condition "running and ready"
May  2 00:16:57.268: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2820" to be "running and ready"
May  2 00:16:57.372: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 104.364061ms
May  2 00:16:57.372: INFO: The phase of Pod netserver-1 is Running (Ready = true)
May  2 00:16:57.372: INFO: Pod "netserver-1" satisfied condition "running and ready"
May  2 00:16:57.477: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2820" to be "running and ready"
May  2 00:16:57.581: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 104.452072ms
May  2 00:16:57.581: INFO: The phase of Pod netserver-2 is Running (Ready = true)
May  2 00:16:57.581: INFO: Pod "netserver-2" satisfied condition "running and ready"
May  2 00:16:57.686: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-2820" to be "running and ready"
May  2 00:16:57.790: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 104.226138ms
May  2 00:16:57.790: INFO: The phase of Pod netserver-3 is Running (Ready = true)
May  2 00:16:57.790: INFO: Pod "netserver-3" satisfied condition "running and ready"
STEP: Creating test pods 05/02/23 00:16:57.895
May  2 00:16:58.001: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2820" to be "running"
May  2 00:16:58.106: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.583819ms
May  2 00:17:00.211: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209353987s
May  2 00:17:00.211: INFO: Pod "test-container-pod" satisfied condition "running"
May  2 00:17:00.315: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
May  2 00:17:00.315: INFO: Breadth first check of 100.123.145.245 on host 172.20.44.200...
May  2 00:17:00.420: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.123.145.245&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:17:00.420: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:17:00.421: INFO: ExecWithOptions: Clientset creation
May  2 00:17:00.421: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.123.145.245%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  2 00:17:01.143: INFO: Waiting for responses: map[]
May  2 00:17:01.143: INFO: reached 100.123.145.245 after 0/1 tries
May  2 00:17:01.143: INFO: Breadth first check of 100.96.36.24 on host 172.20.48.211...
May  2 00:17:01.248: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.96.36.24&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:17:01.248: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:17:01.249: INFO: ExecWithOptions: Clientset creation
May  2 00:17:01.249: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.36.24%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  2 00:17:01.969: INFO: Waiting for responses: map[]
May  2 00:17:01.969: INFO: reached 100.96.36.24 after 0/1 tries
May  2 00:17:01.969: INFO: Breadth first check of 100.105.72.187 on host 172.20.62.149...
May  2 00:17:02.074: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.105.72.187&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:17:02.074: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:17:02.075: INFO: ExecWithOptions: Clientset creation
May  2 00:17:02.075: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.105.72.187%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  2 00:17:02.798: INFO: Waiting for responses: map[]
May  2 00:17:02.798: INFO: reached 100.105.72.187 after 0/1 tries
May  2 00:17:02.798: INFO: Breadth first check of 100.101.231.179 on host 172.20.39.145...
May  2 00:17:02.902: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.101.231.179&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
May  2 00:17:02.902: INFO: >>> kubeConfig: /root/.kube/config
May  2 00:17:02.903: INFO: ExecWithOptions: Clientset creation
May  2 00:17:02.903: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.101.231.179%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
May  2 00:17:03.617: INFO: Waiting for responses: map[]
May  2 00:17:03.617: INFO: reached 100.101.231.179 after 0/1 tries
May  2 00:17:03.617: INFO: Going to retry 0 out of 4 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
May  2 00:17:03.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2820" for this suite. 05/02/23 00:17:03.723
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":312,"skipped":5834,"failed":0}
------------------------------
• [SLOW TEST] [28.347 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:16:35.583
    May  2 00:16:35.583: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pod-network-test 05/02/23 00:16:35.584
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:16:35.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:16:36.11
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-2820 05/02/23 00:16:36.317
    STEP: creating a selector 05/02/23 00:16:36.317
    STEP: Creating the service pods in kubernetes 05/02/23 00:16:36.317
    May  2 00:16:36.317: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    May  2 00:16:36.954: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2820" to be "running and ready"
    May  2 00:16:37.058: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 104.318517ms
    May  2 00:16:37.058: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:16:39.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.210342609s
    May  2 00:16:39.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:41.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.209870222s
    May  2 00:16:41.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:43.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.209391425s
    May  2 00:16:43.163: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:45.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.20988477s
    May  2 00:16:45.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:47.165: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.210992239s
    May  2 00:16:47.165: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:49.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.20940969s
    May  2 00:16:49.163: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:51.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.209365648s
    May  2 00:16:51.163: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:53.165: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.211047495s
    May  2 00:16:53.165: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:55.164: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.210015672s
    May  2 00:16:55.164: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    May  2 00:16:57.163: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 20.209174246s
    May  2 00:16:57.163: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    May  2 00:16:57.163: INFO: Pod "netserver-0" satisfied condition "running and ready"
    May  2 00:16:57.268: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2820" to be "running and ready"
    May  2 00:16:57.372: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 104.364061ms
    May  2 00:16:57.372: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    May  2 00:16:57.372: INFO: Pod "netserver-1" satisfied condition "running and ready"
    May  2 00:16:57.477: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2820" to be "running and ready"
    May  2 00:16:57.581: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 104.452072ms
    May  2 00:16:57.581: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    May  2 00:16:57.581: INFO: Pod "netserver-2" satisfied condition "running and ready"
    May  2 00:16:57.686: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-2820" to be "running and ready"
    May  2 00:16:57.790: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 104.226138ms
    May  2 00:16:57.790: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    May  2 00:16:57.790: INFO: Pod "netserver-3" satisfied condition "running and ready"
    STEP: Creating test pods 05/02/23 00:16:57.895
    May  2 00:16:58.001: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2820" to be "running"
    May  2 00:16:58.106: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 104.583819ms
    May  2 00:17:00.211: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.209353987s
    May  2 00:17:00.211: INFO: Pod "test-container-pod" satisfied condition "running"
    May  2 00:17:00.315: INFO: Setting MaxTries for pod polling to 46 for networking test based on endpoint count 4
    May  2 00:17:00.315: INFO: Breadth first check of 100.123.145.245 on host 172.20.44.200...
    May  2 00:17:00.420: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.123.145.245&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:17:00.420: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:17:00.421: INFO: ExecWithOptions: Clientset creation
    May  2 00:17:00.421: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.123.145.245%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  2 00:17:01.143: INFO: Waiting for responses: map[]
    May  2 00:17:01.143: INFO: reached 100.123.145.245 after 0/1 tries
    May  2 00:17:01.143: INFO: Breadth first check of 100.96.36.24 on host 172.20.48.211...
    May  2 00:17:01.248: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.96.36.24&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:17:01.248: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:17:01.249: INFO: ExecWithOptions: Clientset creation
    May  2 00:17:01.249: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.36.24%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  2 00:17:01.969: INFO: Waiting for responses: map[]
    May  2 00:17:01.969: INFO: reached 100.96.36.24 after 0/1 tries
    May  2 00:17:01.969: INFO: Breadth first check of 100.105.72.187 on host 172.20.62.149...
    May  2 00:17:02.074: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.105.72.187&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:17:02.074: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:17:02.075: INFO: ExecWithOptions: Clientset creation
    May  2 00:17:02.075: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.105.72.187%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  2 00:17:02.798: INFO: Waiting for responses: map[]
    May  2 00:17:02.798: INFO: reached 100.105.72.187 after 0/1 tries
    May  2 00:17:02.798: INFO: Breadth first check of 100.101.231.179 on host 172.20.39.145...
    May  2 00:17:02.902: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.36.22:9080/dial?request=hostname&protocol=http&host=100.101.231.179&port=8083&tries=1'] Namespace:pod-network-test-2820 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    May  2 00:17:02.902: INFO: >>> kubeConfig: /root/.kube/config
    May  2 00:17:02.903: INFO: ExecWithOptions: Clientset creation
    May  2 00:17:02.903: INFO: ExecWithOptions: execute(POST https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io/api/v1/namespaces/pod-network-test-2820/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.36.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.101.231.179%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    May  2 00:17:03.617: INFO: Waiting for responses: map[]
    May  2 00:17:03.617: INFO: reached 100.101.231.179 after 0/1 tries
    May  2 00:17:03.617: INFO: Going to retry 0 out of 4 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    May  2 00:17:03.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2820" for this suite. 05/02/23 00:17:03.723
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:17:03.931
May  2 00:17:03.931: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/02/23 00:17:03.932
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:17:04.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:17:04.454
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  2 00:17:05.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2210" for this suite. 05/02/23 00:17:05.72
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":313,"skipped":5858,"failed":0}
------------------------------
• [1.895 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:17:03.931
    May  2 00:17:03.931: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/02/23 00:17:03.932
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:17:04.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:17:04.454
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  2 00:17:05.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2210" for this suite. 05/02/23 00:17:05.72
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:17:05.827
May  2 00:17:05.827: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/02/23 00:17:05.828
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:17:06.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:17:06.349
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
May  2 00:17:06.556: INFO: >>> kubeConfig: /root/.kube/config
STEP: creating the pod 05/02/23 00:17:06.557
STEP: submitting the pod to kubernetes 05/02/23 00:17:06.557
May  2 00:17:06.665: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783" in namespace "pods-639" to be "running and ready"
May  2 00:17:06.769: INFO: Pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783": Phase="Pending", Reason="", readiness=false. Elapsed: 104.205575ms
May  2 00:17:06.769: INFO: The phase of Pod pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:17:08.874: INFO: Pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783": Phase="Running", Reason="", readiness=true. Elapsed: 2.209364157s
May  2 00:17:08.874: INFO: The phase of Pod pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783 is Running (Ready = true)
May  2 00:17:08.874: INFO: Pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  2 00:17:09.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-639" for this suite. 05/02/23 00:17:09.451
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":314,"skipped":5859,"failed":0}
------------------------------
• [3.730 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:17:05.827
    May  2 00:17:05.827: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/02/23 00:17:05.828
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:17:06.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:17:06.349
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    May  2 00:17:06.556: INFO: >>> kubeConfig: /root/.kube/config
    STEP: creating the pod 05/02/23 00:17:06.557
    STEP: submitting the pod to kubernetes 05/02/23 00:17:06.557
    May  2 00:17:06.665: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783" in namespace "pods-639" to be "running and ready"
    May  2 00:17:06.769: INFO: Pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783": Phase="Pending", Reason="", readiness=false. Elapsed: 104.205575ms
    May  2 00:17:06.769: INFO: The phase of Pod pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:17:08.874: INFO: Pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783": Phase="Running", Reason="", readiness=true. Elapsed: 2.209364157s
    May  2 00:17:08.874: INFO: The phase of Pod pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783 is Running (Ready = true)
    May  2 00:17:08.874: INFO: Pod "pod-logs-websocket-17fe2686-0de6-4304-942b-7f977613a783" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  2 00:17:09.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-639" for this suite. 05/02/23 00:17:09.451
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:17:09.559
May  2 00:17:09.559: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion 05/02/23 00:17:09.56
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:17:09.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:17:10.081
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 05/02/23 00:17:10.288
May  2 00:17:10.398: INFO: Waiting up to 2m0s for pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" in namespace "var-expansion-4534" to be "running"
May  2 00:17:10.502: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 104.239799ms
May  2 00:17:12.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20897328s
May  2 00:17:14.609: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210837203s
May  2 00:17:16.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 6.209681667s
May  2 00:17:18.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210131157s
May  2 00:17:20.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209685477s
May  2 00:17:22.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 12.210525348s
May  2 00:17:24.609: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 14.210952117s
May  2 00:17:26.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 16.209021162s
May  2 00:17:28.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 18.209088799s
May  2 00:17:30.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 20.209113198s
May  2 00:17:32.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 22.209706671s
May  2 00:17:34.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 24.209230256s
May  2 00:17:36.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 26.210390921s
May  2 00:17:38.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 28.209111755s
May  2 00:17:40.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 30.209201946s
May  2 00:17:42.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 32.209395904s
May  2 00:17:44.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 34.210300717s
May  2 00:17:46.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 36.21037977s
May  2 00:17:48.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 38.210728852s
May  2 00:17:50.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 40.209170256s
May  2 00:17:52.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 42.209255082s
May  2 00:17:54.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 44.208972317s
May  2 00:17:56.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 46.209157448s
May  2 00:17:58.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 48.210324486s
May  2 00:18:00.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 50.208946309s
May  2 00:18:02.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 52.209034935s
May  2 00:18:04.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 54.208801152s
May  2 00:18:06.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 56.20890793s
May  2 00:18:08.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 58.208804899s
May  2 00:18:10.610: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.212083117s
May  2 00:18:12.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.209193159s
May  2 00:18:14.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.208834116s
May  2 00:18:16.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.208530057s
May  2 00:18:18.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.210220032s
May  2 00:18:20.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.209221863s
May  2 00:18:22.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.209343861s
May  2 00:18:24.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.208959765s
May  2 00:18:26.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.208882985s
May  2 00:18:28.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.209358747s
May  2 00:18:30.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.209961916s
May  2 00:18:32.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.210206827s
May  2 00:18:34.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.210646276s
May  2 00:18:36.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.210217869s
May  2 00:18:38.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.210716095s
May  2 00:18:40.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.209379971s
May  2 00:18:42.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.209290718s
May  2 00:18:44.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.208891453s
May  2 00:18:46.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.210224326s
May  2 00:18:48.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.210411146s
May  2 00:18:50.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.210240003s
May  2 00:18:52.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.208938718s
May  2 00:18:54.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.209049107s
May  2 00:18:56.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.209199699s
May  2 00:18:58.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.209137569s
May  2 00:19:00.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.209102327s
May  2 00:19:02.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.209042392s
May  2 00:19:04.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.210294499s
May  2 00:19:06.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.20950589s
May  2 00:19:08.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.208807813s
May  2 00:19:10.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.209237214s
May  2 00:19:10.711: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.313810445s
STEP: updating the pod 05/02/23 00:19:10.712
May  2 00:19:11.426: INFO: Successfully updated pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00"
STEP: waiting for pod running 05/02/23 00:19:11.426
May  2 00:19:11.426: INFO: Waiting up to 2m0s for pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" in namespace "var-expansion-4534" to be "running"
May  2 00:19:11.531: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 104.429549ms
May  2 00:19:13.636: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Running", Reason="", readiness=true. Elapsed: 2.209708005s
May  2 00:19:13.636: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" satisfied condition "running"
STEP: deleting the pod gracefully 05/02/23 00:19:13.636
May  2 00:19:13.636: INFO: Deleting pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" in namespace "var-expansion-4534"
May  2 00:19:13.744: INFO: Wait up to 5m0s for pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
May  2 00:19:45.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4534" for this suite. 05/02/23 00:19:46.058
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":315,"skipped":5890,"failed":0}
------------------------------
• [SLOW TEST] [156.605 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:17:09.559
    May  2 00:17:09.559: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename var-expansion 05/02/23 00:17:09.56
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:17:09.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:17:10.081
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 05/02/23 00:17:10.288
    May  2 00:17:10.398: INFO: Waiting up to 2m0s for pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" in namespace "var-expansion-4534" to be "running"
    May  2 00:17:10.502: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 104.239799ms
    May  2 00:17:12.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20897328s
    May  2 00:17:14.609: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210837203s
    May  2 00:17:16.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 6.209681667s
    May  2 00:17:18.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210131157s
    May  2 00:17:20.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 10.209685477s
    May  2 00:17:22.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 12.210525348s
    May  2 00:17:24.609: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 14.210952117s
    May  2 00:17:26.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 16.209021162s
    May  2 00:17:28.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 18.209088799s
    May  2 00:17:30.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 20.209113198s
    May  2 00:17:32.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 22.209706671s
    May  2 00:17:34.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 24.209230256s
    May  2 00:17:36.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 26.210390921s
    May  2 00:17:38.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 28.209111755s
    May  2 00:17:40.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 30.209201946s
    May  2 00:17:42.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 32.209395904s
    May  2 00:17:44.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 34.210300717s
    May  2 00:17:46.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 36.21037977s
    May  2 00:17:48.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 38.210728852s
    May  2 00:17:50.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 40.209170256s
    May  2 00:17:52.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 42.209255082s
    May  2 00:17:54.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 44.208972317s
    May  2 00:17:56.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 46.209157448s
    May  2 00:17:58.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 48.210324486s
    May  2 00:18:00.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 50.208946309s
    May  2 00:18:02.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 52.209034935s
    May  2 00:18:04.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 54.208801152s
    May  2 00:18:06.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 56.20890793s
    May  2 00:18:08.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 58.208804899s
    May  2 00:18:10.610: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.212083117s
    May  2 00:18:12.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.209193159s
    May  2 00:18:14.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.208834116s
    May  2 00:18:16.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.208530057s
    May  2 00:18:18.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.210220032s
    May  2 00:18:20.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.209221863s
    May  2 00:18:22.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.209343861s
    May  2 00:18:24.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.208959765s
    May  2 00:18:26.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.208882985s
    May  2 00:18:28.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.209358747s
    May  2 00:18:30.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.209961916s
    May  2 00:18:32.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.210206827s
    May  2 00:18:34.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.210646276s
    May  2 00:18:36.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.210217869s
    May  2 00:18:38.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.210716095s
    May  2 00:18:40.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.209379971s
    May  2 00:18:42.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.209290718s
    May  2 00:18:44.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.208891453s
    May  2 00:18:46.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.210224326s
    May  2 00:18:48.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.210411146s
    May  2 00:18:50.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.210240003s
    May  2 00:18:52.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.208938718s
    May  2 00:18:54.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.209049107s
    May  2 00:18:56.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.209199699s
    May  2 00:18:58.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.209137569s
    May  2 00:19:00.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.209102327s
    May  2 00:19:02.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.209042392s
    May  2 00:19:04.608: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.210294499s
    May  2 00:19:06.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.20950589s
    May  2 00:19:08.606: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.208807813s
    May  2 00:19:10.607: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.209237214s
    May  2 00:19:10.711: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.313810445s
    STEP: updating the pod 05/02/23 00:19:10.712
    May  2 00:19:11.426: INFO: Successfully updated pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00"
    STEP: waiting for pod running 05/02/23 00:19:11.426
    May  2 00:19:11.426: INFO: Waiting up to 2m0s for pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" in namespace "var-expansion-4534" to be "running"
    May  2 00:19:11.531: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Pending", Reason="", readiness=false. Elapsed: 104.429549ms
    May  2 00:19:13.636: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00": Phase="Running", Reason="", readiness=true. Elapsed: 2.209708005s
    May  2 00:19:13.636: INFO: Pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" satisfied condition "running"
    STEP: deleting the pod gracefully 05/02/23 00:19:13.636
    May  2 00:19:13.636: INFO: Deleting pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" in namespace "var-expansion-4534"
    May  2 00:19:13.744: INFO: Wait up to 5m0s for pod "var-expansion-16e9f3b6-d34f-4a85-b2b7-72f73a73cd00" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    May  2 00:19:45.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4534" for this suite. 05/02/23 00:19:46.058
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:19:46.165
May  2 00:19:46.166: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi 05/02/23 00:19:46.167
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:19:46.48
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:19:46.687
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
May  2 00:19:46.897: INFO: >>> kubeConfig: /root/.kube/config
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 05/02/23 00:19:52.13
May  2 00:19:52.130: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
May  2 00:19:53.979: INFO: stderr: ""
May  2 00:19:53.979: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May  2 00:19:53.979: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 delete e2e-test-crd-publish-openapi-9166-crds test-foo'
May  2 00:19:54.479: INFO: stderr: ""
May  2 00:19:54.479: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
May  2 00:19:54.479: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 apply -f -'
May  2 00:19:55.383: INFO: stderr: ""
May  2 00:19:55.383: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May  2 00:19:55.383: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 delete e2e-test-crd-publish-openapi-9166-crds test-foo'
May  2 00:19:55.902: INFO: stderr: ""
May  2 00:19:55.902: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 05/02/23 00:19:55.902
May  2 00:19:55.903: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
May  2 00:19:56.567: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 05/02/23 00:19:56.567
May  2 00:19:56.568: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
May  2 00:19:57.252: INFO: rc: 1
May  2 00:19:57.252: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 apply -f -'
May  2 00:19:58.121: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 05/02/23 00:19:58.121
May  2 00:19:58.121: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
May  2 00:19:58.791: INFO: rc: 1
May  2 00:19:58.791: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 apply -f -'
May  2 00:19:59.669: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 05/02/23 00:19:59.669
May  2 00:19:59.669: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds'
May  2 00:20:00.219: INFO: stderr: ""
May  2 00:20:00.219: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 05/02/23 00:20:00.219
May  2 00:20:00.220: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.metadata'
May  2 00:20:00.763: INFO: stderr: ""
May  2 00:20:00.763: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
May  2 00:20:00.764: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.spec'
May  2 00:20:01.322: INFO: stderr: ""
May  2 00:20:01.322: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
May  2 00:20:01.322: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.spec.bars'
May  2 00:20:01.870: INFO: stderr: ""
May  2 00:20:01.870: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 05/02/23 00:20:01.87
May  2 00:20:01.870: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.spec.bars2'
May  2 00:20:02.414: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:20:07.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6804" for this suite. 05/02/23 00:20:08.333
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":316,"skipped":5927,"failed":0}
------------------------------
• [SLOW TEST] [22.273 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:19:46.165
    May  2 00:19:46.166: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename crd-publish-openapi 05/02/23 00:19:46.167
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:19:46.48
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:19:46.687
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    May  2 00:19:46.897: INFO: >>> kubeConfig: /root/.kube/config
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 05/02/23 00:19:52.13
    May  2 00:19:52.130: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
    May  2 00:19:53.979: INFO: stderr: ""
    May  2 00:19:53.979: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    May  2 00:19:53.979: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 delete e2e-test-crd-publish-openapi-9166-crds test-foo'
    May  2 00:19:54.479: INFO: stderr: ""
    May  2 00:19:54.479: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    May  2 00:19:54.479: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 apply -f -'
    May  2 00:19:55.383: INFO: stderr: ""
    May  2 00:19:55.383: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    May  2 00:19:55.383: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 delete e2e-test-crd-publish-openapi-9166-crds test-foo'
    May  2 00:19:55.902: INFO: stderr: ""
    May  2 00:19:55.902: INFO: stdout: "e2e-test-crd-publish-openapi-9166-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 05/02/23 00:19:55.902
    May  2 00:19:55.903: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
    May  2 00:19:56.567: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 05/02/23 00:19:56.567
    May  2 00:19:56.568: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
    May  2 00:19:57.252: INFO: rc: 1
    May  2 00:19:57.252: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 apply -f -'
    May  2 00:19:58.121: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 05/02/23 00:19:58.121
    May  2 00:19:58.121: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 create -f -'
    May  2 00:19:58.791: INFO: rc: 1
    May  2 00:19:58.791: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 --namespace=crd-publish-openapi-6804 apply -f -'
    May  2 00:19:59.669: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 05/02/23 00:19:59.669
    May  2 00:19:59.669: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds'
    May  2 00:20:00.219: INFO: stderr: ""
    May  2 00:20:00.219: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 05/02/23 00:20:00.219
    May  2 00:20:00.220: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.metadata'
    May  2 00:20:00.763: INFO: stderr: ""
    May  2 00:20:00.763: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    May  2 00:20:00.764: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.spec'
    May  2 00:20:01.322: INFO: stderr: ""
    May  2 00:20:01.322: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    May  2 00:20:01.322: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.spec.bars'
    May  2 00:20:01.870: INFO: stderr: ""
    May  2 00:20:01.870: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9166-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 05/02/23 00:20:01.87
    May  2 00:20:01.870: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-6804 explain e2e-test-crd-publish-openapi-9166-crds.spec.bars2'
    May  2 00:20:02.414: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:20:07.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6804" for this suite. 05/02/23 00:20:08.333
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:08.442
May  2 00:20:08.442: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job 05/02/23 00:20:08.444
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:08.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:08.96
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 05/02/23 00:20:09.166
STEP: Ensure pods equal to paralellism count is attached to the job 05/02/23 00:20:09.272
STEP: patching /status 05/02/23 00:20:11.377
STEP: updating /status 05/02/23 00:20:11.485
STEP: get /status 05/02/23 00:20:11.694
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
May  2 00:20:11.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8681" for this suite. 05/02/23 00:20:11.903
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":317,"skipped":5987,"failed":0}
------------------------------
• [3.667 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:08.442
    May  2 00:20:08.442: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename job 05/02/23 00:20:08.444
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:08.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:08.96
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 05/02/23 00:20:09.166
    STEP: Ensure pods equal to paralellism count is attached to the job 05/02/23 00:20:09.272
    STEP: patching /status 05/02/23 00:20:11.377
    STEP: updating /status 05/02/23 00:20:11.485
    STEP: get /status 05/02/23 00:20:11.694
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    May  2 00:20:11.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8681" for this suite. 05/02/23 00:20:11.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:12.112
May  2 00:20:12.112: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:20:12.113
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:12.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:12.63
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 05/02/23 00:20:12.836
May  2 00:20:12.836: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-292 create -f -'
May  2 00:20:14.279: INFO: stderr: ""
May  2 00:20:14.279: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 05/02/23 00:20:14.279
May  2 00:20:14.279: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-292 diff -f -'
May  2 00:20:15.045: INFO: rc: 1
May  2 00:20:15.045: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-292 delete -f -'
May  2 00:20:15.545: INFO: stderr: ""
May  2 00:20:15.545: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:20:15.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-292" for this suite. 05/02/23 00:20:15.655
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":318,"skipped":6035,"failed":0}
------------------------------
• [3.748 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:12.112
    May  2 00:20:12.112: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:20:12.113
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:12.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:12.63
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 05/02/23 00:20:12.836
    May  2 00:20:12.836: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-292 create -f -'
    May  2 00:20:14.279: INFO: stderr: ""
    May  2 00:20:14.279: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 05/02/23 00:20:14.279
    May  2 00:20:14.279: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-292 diff -f -'
    May  2 00:20:15.045: INFO: rc: 1
    May  2 00:20:15.045: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-292 delete -f -'
    May  2 00:20:15.545: INFO: stderr: ""
    May  2 00:20:15.545: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:20:15.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-292" for this suite. 05/02/23 00:20:15.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:15.861
May  2 00:20:15.862: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/02/23 00:20:15.863
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:16.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:16.38
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/02/23 00:20:16.797
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:20:17.332
STEP: Deploying the webhook pod 05/02/23 00:20:17.438
STEP: Wait for the deployment to be ready 05/02/23 00:20:17.652
May  2 00:20:17.963: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/02/23 00:20:20.068
STEP: Verifying the service has paired with the endpoint 05/02/23 00:20:20.176
May  2 00:20:21.177: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 05/02/23 00:20:22.343
STEP: Creating a configMap that does not comply to the validation webhook rules 05/02/23 00:20:22.591
STEP: Deleting the collection of validation webhooks 05/02/23 00:20:22.751
STEP: Creating a configMap that does not comply to the validation webhook rules 05/02/23 00:20:22.88
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:20:23.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3688" for this suite. 05/02/23 00:20:23.196
STEP: Destroying namespace "webhook-3688-markers" for this suite. 05/02/23 00:20:23.301
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":319,"skipped":6060,"failed":0}
------------------------------
• [SLOW TEST] [8.001 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:15.861
    May  2 00:20:15.862: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/02/23 00:20:15.863
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:16.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:16.38
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/02/23 00:20:16.797
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:20:17.332
    STEP: Deploying the webhook pod 05/02/23 00:20:17.438
    STEP: Wait for the deployment to be ready 05/02/23 00:20:17.652
    May  2 00:20:17.963: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 20, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/02/23 00:20:20.068
    STEP: Verifying the service has paired with the endpoint 05/02/23 00:20:20.176
    May  2 00:20:21.177: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 05/02/23 00:20:22.343
    STEP: Creating a configMap that does not comply to the validation webhook rules 05/02/23 00:20:22.591
    STEP: Deleting the collection of validation webhooks 05/02/23 00:20:22.751
    STEP: Creating a configMap that does not comply to the validation webhook rules 05/02/23 00:20:22.88
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:20:23.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3688" for this suite. 05/02/23 00:20:23.196
    STEP: Destroying namespace "webhook-3688-markers" for this suite. 05/02/23 00:20:23.301
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:23.864
May  2 00:20:23.864: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers 05/02/23 00:20:23.865
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:24.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:24.382
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 05/02/23 00:20:24.588
May  2 00:20:24.695: INFO: Waiting up to 5m0s for pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e" in namespace "containers-9601" to be "Succeeded or Failed"
May  2 00:20:24.798: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e": Phase="Pending", Reason="", readiness=false. Elapsed: 103.464629ms
May  2 00:20:26.904: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e": Phase="Running", Reason="", readiness=false. Elapsed: 2.20855166s
May  2 00:20:28.905: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209564674s
STEP: Saw pod success 05/02/23 00:20:28.905
May  2 00:20:28.905: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e" satisfied condition "Succeeded or Failed"
May  2 00:20:29.009: INFO: Trying to get logs from node i-02d061b30635c230c pod client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e container agnhost-container: <nil>
STEP: delete the pod 05/02/23 00:20:29.122
May  2 00:20:29.232: INFO: Waiting for pod client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e to disappear
May  2 00:20:29.335: INFO: Pod client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
May  2 00:20:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9601" for this suite. 05/02/23 00:20:29.44
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":320,"skipped":6067,"failed":0}
------------------------------
• [SLOW TEST] [5.782 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:23.864
    May  2 00:20:23.864: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename containers 05/02/23 00:20:23.865
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:24.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:24.382
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 05/02/23 00:20:24.588
    May  2 00:20:24.695: INFO: Waiting up to 5m0s for pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e" in namespace "containers-9601" to be "Succeeded or Failed"
    May  2 00:20:24.798: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e": Phase="Pending", Reason="", readiness=false. Elapsed: 103.464629ms
    May  2 00:20:26.904: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e": Phase="Running", Reason="", readiness=false. Elapsed: 2.20855166s
    May  2 00:20:28.905: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209564674s
    STEP: Saw pod success 05/02/23 00:20:28.905
    May  2 00:20:28.905: INFO: Pod "client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e" satisfied condition "Succeeded or Failed"
    May  2 00:20:29.009: INFO: Trying to get logs from node i-02d061b30635c230c pod client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e container agnhost-container: <nil>
    STEP: delete the pod 05/02/23 00:20:29.122
    May  2 00:20:29.232: INFO: Waiting for pod client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e to disappear
    May  2 00:20:29.335: INFO: Pod client-containers-671f6f9d-4dbb-4c1c-965a-13723e03751e no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    May  2 00:20:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9601" for this suite. 05/02/23 00:20:29.44
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:29.647
May  2 00:20:29.647: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota 05/02/23 00:20:29.648
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:29.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:30.165
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 05/02/23 00:20:30.371
STEP: Creating a ResourceQuota 05/02/23 00:20:35.475
STEP: Ensuring resource quota status is calculated 05/02/23 00:20:35.591
STEP: Creating a Pod that fits quota 05/02/23 00:20:37.695
STEP: Ensuring ResourceQuota status captures the pod usage 05/02/23 00:20:37.808
STEP: Not allowing a pod to be created that exceeds remaining quota 05/02/23 00:20:39.913
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 05/02/23 00:20:40.016
STEP: Ensuring a pod cannot update its resource requirements 05/02/23 00:20:40.12
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 05/02/23 00:20:40.225
STEP: Deleting the pod 05/02/23 00:20:42.33
STEP: Ensuring resource quota status released the pod usage 05/02/23 00:20:42.443
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
May  2 00:20:44.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9105" for this suite. 05/02/23 00:20:44.654
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":321,"skipped":6094,"failed":0}
------------------------------
• [SLOW TEST] [15.112 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:29.647
    May  2 00:20:29.647: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename resourcequota 05/02/23 00:20:29.648
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:29.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:30.165
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 05/02/23 00:20:30.371
    STEP: Creating a ResourceQuota 05/02/23 00:20:35.475
    STEP: Ensuring resource quota status is calculated 05/02/23 00:20:35.591
    STEP: Creating a Pod that fits quota 05/02/23 00:20:37.695
    STEP: Ensuring ResourceQuota status captures the pod usage 05/02/23 00:20:37.808
    STEP: Not allowing a pod to be created that exceeds remaining quota 05/02/23 00:20:39.913
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 05/02/23 00:20:40.016
    STEP: Ensuring a pod cannot update its resource requirements 05/02/23 00:20:40.12
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 05/02/23 00:20:40.225
    STEP: Deleting the pod 05/02/23 00:20:42.33
    STEP: Ensuring resource quota status released the pod usage 05/02/23 00:20:42.443
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    May  2 00:20:44.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9105" for this suite. 05/02/23 00:20:44.654
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:44.761
May  2 00:20:44.761: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition 05/02/23 00:20:44.762
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:45.074
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:45.28
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
May  2 00:20:45.485: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:20:48.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5954" for this suite. 05/02/23 00:20:48.706
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":322,"skipped":6111,"failed":0}
------------------------------
• [4.051 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:44.761
    May  2 00:20:44.761: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename custom-resource-definition 05/02/23 00:20:44.762
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:45.074
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:45.28
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    May  2 00:20:45.485: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:20:48.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5954" for this suite. 05/02/23 00:20:48.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:48.812
May  2 00:20:48.813: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test 05/02/23 00:20:48.814
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:49.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:49.331
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
May  2 00:20:49.643: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b" in namespace "security-context-test-3473" to be "Succeeded or Failed"
May  2 00:20:49.746: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Pending", Reason="", readiness=false. Elapsed: 103.445205ms
May  2 00:20:51.851: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208432808s
May  2 00:20:53.854: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210579819s
May  2 00:20:55.851: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.208279484s
May  2 00:20:55.851: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b" satisfied condition "Succeeded or Failed"
May  2 00:20:55.965: INFO: Got logs for pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
May  2 00:20:55.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3473" for this suite. 05/02/23 00:20:56.07
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":323,"skipped":6120,"failed":0}
------------------------------
• [SLOW TEST] [7.465 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:48.812
    May  2 00:20:48.813: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename security-context-test 05/02/23 00:20:48.814
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:49.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:49.331
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    May  2 00:20:49.643: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b" in namespace "security-context-test-3473" to be "Succeeded or Failed"
    May  2 00:20:49.746: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Pending", Reason="", readiness=false. Elapsed: 103.445205ms
    May  2 00:20:51.851: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208432808s
    May  2 00:20:53.854: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210579819s
    May  2 00:20:55.851: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.208279484s
    May  2 00:20:55.851: INFO: Pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b" satisfied condition "Succeeded or Failed"
    May  2 00:20:55.965: INFO: Got logs for pod "busybox-privileged-false-a3694121-88ad-45b4-b111-0f68ff7e136b": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    May  2 00:20:55.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-3473" for this suite. 05/02/23 00:20:56.07
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:56.282
May  2 00:20:56.282: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename events 05/02/23 00:20:56.283
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:56.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:56.799
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 05/02/23 00:20:57.005
STEP: listing events in all namespaces 05/02/23 00:20:57.112
STEP: listing events in test namespace 05/02/23 00:20:57.216
STEP: listing events with field selection filtering on source 05/02/23 00:20:57.319
STEP: listing events with field selection filtering on reportingController 05/02/23 00:20:57.423
STEP: getting the test event 05/02/23 00:20:57.527
STEP: patching the test event 05/02/23 00:20:57.631
STEP: getting the test event 05/02/23 00:20:57.741
STEP: updating the test event 05/02/23 00:20:57.844
STEP: getting the test event 05/02/23 00:20:57.95
STEP: deleting the test event 05/02/23 00:20:58.054
STEP: listing events in all namespaces 05/02/23 00:20:58.159
STEP: listing events in test namespace 05/02/23 00:20:58.263
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
May  2 00:20:58.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9087" for this suite. 05/02/23 00:20:58.471
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":324,"skipped":6200,"failed":0}
------------------------------
• [2.295 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:56.282
    May  2 00:20:56.282: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename events 05/02/23 00:20:56.283
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:56.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:56.799
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 05/02/23 00:20:57.005
    STEP: listing events in all namespaces 05/02/23 00:20:57.112
    STEP: listing events in test namespace 05/02/23 00:20:57.216
    STEP: listing events with field selection filtering on source 05/02/23 00:20:57.319
    STEP: listing events with field selection filtering on reportingController 05/02/23 00:20:57.423
    STEP: getting the test event 05/02/23 00:20:57.527
    STEP: patching the test event 05/02/23 00:20:57.631
    STEP: getting the test event 05/02/23 00:20:57.741
    STEP: updating the test event 05/02/23 00:20:57.844
    STEP: getting the test event 05/02/23 00:20:57.95
    STEP: deleting the test event 05/02/23 00:20:58.054
    STEP: listing events in all namespaces 05/02/23 00:20:58.159
    STEP: listing events in test namespace 05/02/23 00:20:58.263
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    May  2 00:20:58.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9087" for this suite. 05/02/23 00:20:58.471
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:20:58.577
May  2 00:20:58.577: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test 05/02/23 00:20:58.578
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:58.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:59.095
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
May  2 00:20:59.407: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb" in namespace "security-context-test-7950" to be "Succeeded or Failed"
May  2 00:20:59.510: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb": Phase="Pending", Reason="", readiness=false. Elapsed: 103.543214ms
May  2 00:21:01.615: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207742394s
May  2 00:21:03.614: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207244652s
May  2 00:21:03.614: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
May  2 00:21:03.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7950" for this suite. 05/02/23 00:21:03.719
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":325,"skipped":6205,"failed":0}
------------------------------
• [SLOW TEST] [5.248 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:20:58.577
    May  2 00:20:58.577: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename security-context-test 05/02/23 00:20:58.578
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:20:58.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:20:59.095
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    May  2 00:20:59.407: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb" in namespace "security-context-test-7950" to be "Succeeded or Failed"
    May  2 00:20:59.510: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb": Phase="Pending", Reason="", readiness=false. Elapsed: 103.543214ms
    May  2 00:21:01.615: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207742394s
    May  2 00:21:03.614: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207244652s
    May  2 00:21:03.614: INFO: Pod "busybox-readonly-false-86ccec99-a061-4c44-b16a-423af8dcecfb" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    May  2 00:21:03.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7950" for this suite. 05/02/23 00:21:03.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:21:03.828
May  2 00:21:03.828: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:21:03.829
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:04.141
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:04.347
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 05/02/23 00:21:04.553
May  2 00:21:04.553: INFO: Asynchronously running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7120 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 05/02/23 00:21:04.619
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:21:04.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7120" for this suite. 05/02/23 00:21:05.084
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":326,"skipped":6283,"failed":0}
------------------------------
• [1.462 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:21:03.828
    May  2 00:21:03.828: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:21:03.829
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:04.141
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:04.347
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 05/02/23 00:21:04.553
    May  2 00:21:04.553: INFO: Asynchronously running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-7120 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 05/02/23 00:21:04.619
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:21:04.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7120" for this suite. 05/02/23 00:21:05.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:21:05.292
May  2 00:21:05.292: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:21:05.294
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:05.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:05.812
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:21:06.018
May  2 00:21:06.125: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab" in namespace "projected-1946" to be "Succeeded or Failed"
May  2 00:21:06.228: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab": Phase="Pending", Reason="", readiness=false. Elapsed: 103.569737ms
May  2 00:21:08.333: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab": Phase="Running", Reason="", readiness=false. Elapsed: 2.207786215s
May  2 00:21:10.333: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208046236s
STEP: Saw pod success 05/02/23 00:21:10.333
May  2 00:21:10.333: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab" satisfied condition "Succeeded or Failed"
May  2 00:21:10.436: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab container client-container: <nil>
STEP: delete the pod 05/02/23 00:21:10.542
May  2 00:21:10.656: INFO: Waiting for pod downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab to disappear
May  2 00:21:10.759: INFO: Pod downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  2 00:21:10.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1946" for this suite. 05/02/23 00:21:10.863
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":327,"skipped":6347,"failed":0}
------------------------------
• [SLOW TEST] [5.679 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:21:05.292
    May  2 00:21:05.292: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:21:05.294
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:05.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:05.812
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:21:06.018
    May  2 00:21:06.125: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab" in namespace "projected-1946" to be "Succeeded or Failed"
    May  2 00:21:06.228: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab": Phase="Pending", Reason="", readiness=false. Elapsed: 103.569737ms
    May  2 00:21:08.333: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab": Phase="Running", Reason="", readiness=false. Elapsed: 2.207786215s
    May  2 00:21:10.333: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208046236s
    STEP: Saw pod success 05/02/23 00:21:10.333
    May  2 00:21:10.333: INFO: Pod "downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab" satisfied condition "Succeeded or Failed"
    May  2 00:21:10.436: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab container client-container: <nil>
    STEP: delete the pod 05/02/23 00:21:10.542
    May  2 00:21:10.656: INFO: Waiting for pod downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab to disappear
    May  2 00:21:10.759: INFO: Pod downwardapi-volume-9f17fa38-54d8-4966-a555-e38918bca4ab no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  2 00:21:10.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1946" for this suite. 05/02/23 00:21:10.863
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:21:10.972
May  2 00:21:10.972: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svc-latency 05/02/23 00:21:10.973
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:11.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:11.49
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
May  2 00:21:11.696: INFO: >>> kubeConfig: /root/.kube/config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-378 05/02/23 00:21:11.697
I0502 00:21:11.803518    6969 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-378, replica count: 1
I0502 00:21:12.954361    6969 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 00:21:13.265: INFO: Created: latency-svc-4cdcg
May  2 00:21:13.275: INFO: Got endpoints: latency-svc-4cdcg [119.513556ms]
May  2 00:21:13.388: INFO: Created: latency-svc-xlqdv
May  2 00:21:13.396: INFO: Got endpoints: latency-svc-xlqdv [121.008616ms]
May  2 00:21:13.398: INFO: Created: latency-svc-jn4mv
May  2 00:21:13.403: INFO: Got endpoints: latency-svc-jn4mv [128.323535ms]
May  2 00:21:13.406: INFO: Created: latency-svc-l8qdz
May  2 00:21:13.414: INFO: Created: latency-svc-djvtd
May  2 00:21:13.418: INFO: Got endpoints: latency-svc-l8qdz [143.592228ms]
May  2 00:21:13.421: INFO: Got endpoints: latency-svc-djvtd [146.719443ms]
May  2 00:21:13.423: INFO: Created: latency-svc-s7gw5
May  2 00:21:13.427: INFO: Got endpoints: latency-svc-s7gw5 [152.414594ms]
May  2 00:21:13.494: INFO: Created: latency-svc-6xzkb
May  2 00:21:13.499: INFO: Got endpoints: latency-svc-6xzkb [223.941627ms]
May  2 00:21:13.506: INFO: Created: latency-svc-mxbl9
May  2 00:21:13.510: INFO: Got endpoints: latency-svc-mxbl9 [234.808586ms]
May  2 00:21:13.515: INFO: Created: latency-svc-lvggg
May  2 00:21:13.524: INFO: Got endpoints: latency-svc-lvggg [248.735562ms]
May  2 00:21:13.532: INFO: Created: latency-svc-rnswn
May  2 00:21:13.534: INFO: Created: latency-svc-ckv4m
May  2 00:21:13.541: INFO: Got endpoints: latency-svc-rnswn [266.364029ms]
May  2 00:21:13.559: INFO: Got endpoints: latency-svc-ckv4m [284.344854ms]
May  2 00:21:13.562: INFO: Created: latency-svc-5hxnr
May  2 00:21:13.569: INFO: Got endpoints: latency-svc-5hxnr [294.204586ms]
May  2 00:21:13.571: INFO: Created: latency-svc-t5hfd
May  2 00:21:13.586: INFO: Created: latency-svc-v787c
May  2 00:21:13.591: INFO: Got endpoints: latency-svc-t5hfd [316.252984ms]
May  2 00:21:13.595: INFO: Got endpoints: latency-svc-v787c [319.618328ms]
May  2 00:21:13.597: INFO: Created: latency-svc-hrx2t
May  2 00:21:13.608: INFO: Got endpoints: latency-svc-hrx2t [332.929344ms]
May  2 00:21:13.613: INFO: Created: latency-svc-fbkqk
May  2 00:21:13.619: INFO: Got endpoints: latency-svc-fbkqk [344.342971ms]
May  2 00:21:13.621: INFO: Created: latency-svc-76mmc
May  2 00:21:13.632: INFO: Got endpoints: latency-svc-76mmc [235.468281ms]
May  2 00:21:13.634: INFO: Created: latency-svc-m7kl6
May  2 00:21:13.640: INFO: Got endpoints: latency-svc-m7kl6 [236.824741ms]
May  2 00:21:13.642: INFO: Created: latency-svc-4v9qk
May  2 00:21:13.651: INFO: Got endpoints: latency-svc-4v9qk [233.122133ms]
May  2 00:21:13.652: INFO: Created: latency-svc-n7b74
May  2 00:21:13.661: INFO: Got endpoints: latency-svc-n7b74 [239.654187ms]
May  2 00:21:13.661: INFO: Created: latency-svc-nxzhr
May  2 00:21:13.671: INFO: Got endpoints: latency-svc-nxzhr [243.907346ms]
May  2 00:21:13.675: INFO: Created: latency-svc-glzlf
May  2 00:21:13.682: INFO: Got endpoints: latency-svc-glzlf [182.792892ms]
May  2 00:21:13.684: INFO: Created: latency-svc-wf8sf
May  2 00:21:13.693: INFO: Created: latency-svc-8rcd9
May  2 00:21:13.702: INFO: Got endpoints: latency-svc-wf8sf [191.958852ms]
May  2 00:21:13.713: INFO: Got endpoints: latency-svc-8rcd9 [188.756548ms]
May  2 00:21:13.716: INFO: Created: latency-svc-7nw2d
May  2 00:21:13.724: INFO: Got endpoints: latency-svc-7nw2d [182.482595ms]
May  2 00:21:13.724: INFO: Created: latency-svc-xpjqd
May  2 00:21:13.734: INFO: Got endpoints: latency-svc-xpjqd [174.132356ms]
May  2 00:21:13.738: INFO: Created: latency-svc-vw6z5
May  2 00:21:13.743: INFO: Got endpoints: latency-svc-vw6z5 [173.215419ms]
May  2 00:21:13.747: INFO: Created: latency-svc-hftlb
May  2 00:21:13.753: INFO: Got endpoints: latency-svc-hftlb [161.686744ms]
May  2 00:21:13.759: INFO: Created: latency-svc-dmp77
May  2 00:21:13.765: INFO: Got endpoints: latency-svc-dmp77 [170.160951ms]
May  2 00:21:13.769: INFO: Created: latency-svc-7dq52
May  2 00:21:13.775: INFO: Got endpoints: latency-svc-7dq52 [166.611379ms]
May  2 00:21:13.779: INFO: Created: latency-svc-sd2l9
May  2 00:21:13.787: INFO: Created: latency-svc-cqs6f
May  2 00:21:13.790: INFO: Got endpoints: latency-svc-sd2l9 [170.301019ms]
May  2 00:21:13.794: INFO: Got endpoints: latency-svc-cqs6f [162.728788ms]
May  2 00:21:13.802: INFO: Created: latency-svc-6xnhl
May  2 00:21:13.808: INFO: Got endpoints: latency-svc-6xnhl [167.348072ms]
May  2 00:21:13.813: INFO: Created: latency-svc-562st
May  2 00:21:13.821: INFO: Got endpoints: latency-svc-562st [169.877252ms]
May  2 00:21:13.824: INFO: Created: latency-svc-48t5t
May  2 00:21:13.832: INFO: Created: latency-svc-x8dc5
May  2 00:21:13.837: INFO: Got endpoints: latency-svc-48t5t [175.52168ms]
May  2 00:21:13.844: INFO: Got endpoints: latency-svc-x8dc5 [172.774716ms]
May  2 00:21:13.853: INFO: Created: latency-svc-tjw88
May  2 00:21:13.861: INFO: Got endpoints: latency-svc-tjw88 [178.603859ms]
May  2 00:21:13.874: INFO: Created: latency-svc-dljcm
May  2 00:21:13.884: INFO: Got endpoints: latency-svc-dljcm [182.02971ms]
May  2 00:21:13.892: INFO: Created: latency-svc-lw79p
May  2 00:21:13.896: INFO: Got endpoints: latency-svc-lw79p [183.031014ms]
May  2 00:21:13.898: INFO: Created: latency-svc-m5hhb
May  2 00:21:13.916: INFO: Got endpoints: latency-svc-m5hhb [192.257993ms]
May  2 00:21:13.919: INFO: Created: latency-svc-ndhf4
May  2 00:21:13.932: INFO: Got endpoints: latency-svc-ndhf4 [198.60625ms]
May  2 00:21:13.933: INFO: Created: latency-svc-whzkm
May  2 00:21:13.944: INFO: Created: latency-svc-nmg4z
May  2 00:21:13.949: INFO: Got endpoints: latency-svc-whzkm [206.681842ms]
May  2 00:21:13.953: INFO: Created: latency-svc-np8vg
May  2 00:21:13.960: INFO: Created: latency-svc-8kbxx
May  2 00:21:13.967: INFO: Created: latency-svc-lfxc4
May  2 00:21:13.977: INFO: Created: latency-svc-6fw86
May  2 00:21:13.983: INFO: Created: latency-svc-8srkr
May  2 00:21:13.991: INFO: Created: latency-svc-pvgj5
May  2 00:21:13.998: INFO: Got endpoints: latency-svc-nmg4z [245.368114ms]
May  2 00:21:14.004: INFO: Created: latency-svc-lbvm9
May  2 00:21:14.010: INFO: Created: latency-svc-vdpkq
May  2 00:21:14.019: INFO: Created: latency-svc-7ll58
May  2 00:21:14.025: INFO: Created: latency-svc-nzq5r
May  2 00:21:14.038: INFO: Created: latency-svc-qdzwx
May  2 00:21:14.043: INFO: Created: latency-svc-pqrcd
May  2 00:21:14.046: INFO: Got endpoints: latency-svc-np8vg [281.137227ms]
May  2 00:21:14.052: INFO: Created: latency-svc-9dfk5
May  2 00:21:14.061: INFO: Created: latency-svc-4jdbx
May  2 00:21:14.093: INFO: Got endpoints: latency-svc-8kbxx [318.601847ms]
May  2 00:21:14.111: INFO: Created: latency-svc-dqqfn
May  2 00:21:14.146: INFO: Got endpoints: latency-svc-lfxc4 [355.782566ms]
May  2 00:21:14.156: INFO: Created: latency-svc-jqq7q
May  2 00:21:14.193: INFO: Got endpoints: latency-svc-6fw86 [398.933586ms]
May  2 00:21:14.205: INFO: Created: latency-svc-gc64t
May  2 00:21:14.245: INFO: Got endpoints: latency-svc-8srkr [437.695183ms]
May  2 00:21:14.256: INFO: Created: latency-svc-hzsp4
May  2 00:21:14.295: INFO: Got endpoints: latency-svc-pvgj5 [473.157443ms]
May  2 00:21:14.308: INFO: Created: latency-svc-kn2pw
May  2 00:21:14.349: INFO: Got endpoints: latency-svc-lbvm9 [511.316223ms]
May  2 00:21:14.363: INFO: Created: latency-svc-wcbk7
May  2 00:21:14.393: INFO: Got endpoints: latency-svc-vdpkq [548.749328ms]
May  2 00:21:14.404: INFO: Created: latency-svc-jgs4w
May  2 00:21:14.444: INFO: Got endpoints: latency-svc-7ll58 [583.000277ms]
May  2 00:21:14.459: INFO: Created: latency-svc-pxxsj
May  2 00:21:14.494: INFO: Got endpoints: latency-svc-nzq5r [610.045965ms]
May  2 00:21:14.504: INFO: Created: latency-svc-vgtht
May  2 00:21:14.544: INFO: Got endpoints: latency-svc-qdzwx [648.709838ms]
May  2 00:21:14.554: INFO: Created: latency-svc-wwdp8
May  2 00:21:14.597: INFO: Got endpoints: latency-svc-pqrcd [680.362007ms]
May  2 00:21:14.608: INFO: Created: latency-svc-tfp69
May  2 00:21:14.643: INFO: Got endpoints: latency-svc-9dfk5 [710.800027ms]
May  2 00:21:14.658: INFO: Created: latency-svc-lqmxd
May  2 00:21:14.694: INFO: Got endpoints: latency-svc-4jdbx [744.376543ms]
May  2 00:21:14.706: INFO: Created: latency-svc-hw5wz
May  2 00:21:14.743: INFO: Got endpoints: latency-svc-dqqfn [744.408183ms]
May  2 00:21:14.756: INFO: Created: latency-svc-75crw
May  2 00:21:14.796: INFO: Got endpoints: latency-svc-jqq7q [749.472587ms]
May  2 00:21:14.804: INFO: Created: latency-svc-8bs9x
May  2 00:21:14.845: INFO: Got endpoints: latency-svc-gc64t [751.651919ms]
May  2 00:21:14.858: INFO: Created: latency-svc-mhnr5
May  2 00:21:14.895: INFO: Got endpoints: latency-svc-hzsp4 [749.786039ms]
May  2 00:21:14.907: INFO: Created: latency-svc-78v9m
May  2 00:21:14.946: INFO: Got endpoints: latency-svc-kn2pw [752.343629ms]
May  2 00:21:14.956: INFO: Created: latency-svc-4qrff
May  2 00:21:14.995: INFO: Got endpoints: latency-svc-wcbk7 [749.676076ms]
May  2 00:21:15.006: INFO: Created: latency-svc-nmdxc
May  2 00:21:15.043: INFO: Got endpoints: latency-svc-jgs4w [748.594543ms]
May  2 00:21:15.057: INFO: Created: latency-svc-lrfzl
May  2 00:21:15.093: INFO: Got endpoints: latency-svc-pxxsj [744.690852ms]
May  2 00:21:15.107: INFO: Created: latency-svc-nf494
May  2 00:21:15.147: INFO: Got endpoints: latency-svc-vgtht [754.025502ms]
May  2 00:21:15.156: INFO: Created: latency-svc-qkbnr
May  2 00:21:15.195: INFO: Got endpoints: latency-svc-wwdp8 [751.810522ms]
May  2 00:21:15.206: INFO: Created: latency-svc-5k5wh
May  2 00:21:15.243: INFO: Got endpoints: latency-svc-tfp69 [749.169309ms]
May  2 00:21:15.258: INFO: Created: latency-svc-zm4rg
May  2 00:21:15.295: INFO: Got endpoints: latency-svc-lqmxd [750.393007ms]
May  2 00:21:15.311: INFO: Created: latency-svc-sg8g6
May  2 00:21:15.348: INFO: Got endpoints: latency-svc-hw5wz [751.342905ms]
May  2 00:21:15.363: INFO: Created: latency-svc-txtzn
May  2 00:21:15.394: INFO: Got endpoints: latency-svc-75crw [750.786252ms]
May  2 00:21:15.406: INFO: Created: latency-svc-dpkph
May  2 00:21:15.447: INFO: Got endpoints: latency-svc-8bs9x [752.777245ms]
May  2 00:21:15.460: INFO: Created: latency-svc-p8rsx
May  2 00:21:15.495: INFO: Got endpoints: latency-svc-mhnr5 [751.589604ms]
May  2 00:21:15.505: INFO: Created: latency-svc-msz8k
May  2 00:21:15.545: INFO: Got endpoints: latency-svc-78v9m [749.528998ms]
May  2 00:21:15.562: INFO: Created: latency-svc-t2gqz
May  2 00:21:15.610: INFO: Got endpoints: latency-svc-4qrff [765.088228ms]
May  2 00:21:15.620: INFO: Created: latency-svc-ggnpb
May  2 00:21:15.648: INFO: Got endpoints: latency-svc-nmdxc [752.345754ms]
May  2 00:21:15.675: INFO: Created: latency-svc-nbktx
May  2 00:21:15.695: INFO: Got endpoints: latency-svc-lrfzl [748.778578ms]
May  2 00:21:15.725: INFO: Created: latency-svc-gkc98
May  2 00:21:15.743: INFO: Got endpoints: latency-svc-nf494 [748.104168ms]
May  2 00:21:15.758: INFO: Created: latency-svc-r56kn
May  2 00:21:15.795: INFO: Got endpoints: latency-svc-qkbnr [751.792064ms]
May  2 00:21:15.805: INFO: Created: latency-svc-8b2mf
May  2 00:21:15.851: INFO: Got endpoints: latency-svc-5k5wh [757.810096ms]
May  2 00:21:15.881: INFO: Created: latency-svc-5rjh4
May  2 00:21:15.907: INFO: Got endpoints: latency-svc-zm4rg [760.354372ms]
May  2 00:21:15.922: INFO: Created: latency-svc-xm4hr
May  2 00:21:15.958: INFO: Got endpoints: latency-svc-sg8g6 [762.110423ms]
May  2 00:21:15.985: INFO: Created: latency-svc-p9msq
May  2 00:21:16.010: INFO: Got endpoints: latency-svc-txtzn [766.3465ms]
May  2 00:21:16.026: INFO: Created: latency-svc-8fgs8
May  2 00:21:16.043: INFO: Got endpoints: latency-svc-dpkph [747.930392ms]
May  2 00:21:16.067: INFO: Created: latency-svc-grlgp
May  2 00:21:16.094: INFO: Got endpoints: latency-svc-p8rsx [746.230006ms]
May  2 00:21:16.122: INFO: Created: latency-svc-2k8x5
May  2 00:21:16.146: INFO: Got endpoints: latency-svc-msz8k [752.419892ms]
May  2 00:21:16.155: INFO: Created: latency-svc-fvz4x
May  2 00:21:16.194: INFO: Got endpoints: latency-svc-t2gqz [747.130331ms]
May  2 00:21:16.206: INFO: Created: latency-svc-mhf5d
May  2 00:21:16.244: INFO: Got endpoints: latency-svc-ggnpb [749.53742ms]
May  2 00:21:16.257: INFO: Created: latency-svc-z9gf8
May  2 00:21:16.295: INFO: Got endpoints: latency-svc-nbktx [749.41005ms]
May  2 00:21:16.311: INFO: Created: latency-svc-shtcv
May  2 00:21:16.348: INFO: Got endpoints: latency-svc-gkc98 [737.87982ms]
May  2 00:21:16.358: INFO: Created: latency-svc-w2cc5
May  2 00:21:16.395: INFO: Got endpoints: latency-svc-r56kn [747.427063ms]
May  2 00:21:16.406: INFO: Created: latency-svc-d6rvv
May  2 00:21:16.444: INFO: Got endpoints: latency-svc-8b2mf [749.435757ms]
May  2 00:21:16.459: INFO: Created: latency-svc-b4zvj
May  2 00:21:16.495: INFO: Got endpoints: latency-svc-5rjh4 [751.293288ms]
May  2 00:21:16.508: INFO: Created: latency-svc-vm6nx
May  2 00:21:16.543: INFO: Got endpoints: latency-svc-xm4hr [747.664101ms]
May  2 00:21:16.570: INFO: Created: latency-svc-d8ph2
May  2 00:21:16.598: INFO: Got endpoints: latency-svc-p9msq [746.518108ms]
May  2 00:21:16.606: INFO: Created: latency-svc-cntmn
May  2 00:21:16.643: INFO: Got endpoints: latency-svc-8fgs8 [735.691545ms]
May  2 00:21:16.654: INFO: Created: latency-svc-lrdfd
May  2 00:21:16.695: INFO: Got endpoints: latency-svc-grlgp [737.260709ms]
May  2 00:21:16.708: INFO: Created: latency-svc-l8jss
May  2 00:21:16.745: INFO: Got endpoints: latency-svc-2k8x5 [735.827406ms]
May  2 00:21:16.754: INFO: Created: latency-svc-nscfv
May  2 00:21:16.796: INFO: Got endpoints: latency-svc-fvz4x [752.822649ms]
May  2 00:21:16.805: INFO: Created: latency-svc-wr2w6
May  2 00:21:16.846: INFO: Got endpoints: latency-svc-mhf5d [751.119043ms]
May  2 00:21:16.856: INFO: Created: latency-svc-nltsc
May  2 00:21:16.894: INFO: Got endpoints: latency-svc-z9gf8 [747.723452ms]
May  2 00:21:16.908: INFO: Created: latency-svc-sx77m
May  2 00:21:16.943: INFO: Got endpoints: latency-svc-shtcv [748.981585ms]
May  2 00:21:16.956: INFO: Created: latency-svc-kml25
May  2 00:21:16.993: INFO: Got endpoints: latency-svc-w2cc5 [748.926164ms]
May  2 00:21:17.004: INFO: Created: latency-svc-nphwg
May  2 00:21:17.043: INFO: Got endpoints: latency-svc-d6rvv [748.491253ms]
May  2 00:21:17.054: INFO: Created: latency-svc-vkq9d
May  2 00:21:17.093: INFO: Got endpoints: latency-svc-b4zvj [744.69127ms]
May  2 00:21:17.104: INFO: Created: latency-svc-xfr5j
May  2 00:21:17.146: INFO: Got endpoints: latency-svc-vm6nx [751.040767ms]
May  2 00:21:17.154: INFO: Created: latency-svc-h5hvs
May  2 00:21:17.193: INFO: Got endpoints: latency-svc-d8ph2 [748.929388ms]
May  2 00:21:17.204: INFO: Created: latency-svc-sv7r8
May  2 00:21:17.243: INFO: Got endpoints: latency-svc-cntmn [748.355956ms]
May  2 00:21:17.257: INFO: Created: latency-svc-x6pqq
May  2 00:21:17.297: INFO: Got endpoints: latency-svc-lrdfd [753.729501ms]
May  2 00:21:17.310: INFO: Created: latency-svc-nm86s
May  2 00:21:17.354: INFO: Got endpoints: latency-svc-l8jss [756.583968ms]
May  2 00:21:17.361: INFO: Created: latency-svc-f6tc5
May  2 00:21:17.395: INFO: Got endpoints: latency-svc-nscfv [751.426342ms]
May  2 00:21:17.407: INFO: Created: latency-svc-c5bwz
May  2 00:21:17.443: INFO: Got endpoints: latency-svc-wr2w6 [747.801406ms]
May  2 00:21:17.469: INFO: Created: latency-svc-fghhh
May  2 00:21:17.496: INFO: Got endpoints: latency-svc-nltsc [750.248218ms]
May  2 00:21:17.505: INFO: Created: latency-svc-4qllh
May  2 00:21:17.543: INFO: Got endpoints: latency-svc-sx77m [747.411164ms]
May  2 00:21:17.553: INFO: Created: latency-svc-68l7k
May  2 00:21:17.595: INFO: Got endpoints: latency-svc-kml25 [749.102319ms]
May  2 00:21:17.606: INFO: Created: latency-svc-hjc8m
May  2 00:21:17.646: INFO: Got endpoints: latency-svc-nphwg [751.450487ms]
May  2 00:21:17.655: INFO: Created: latency-svc-m89vs
May  2 00:21:17.695: INFO: Got endpoints: latency-svc-vkq9d [751.897839ms]
May  2 00:21:17.704: INFO: Created: latency-svc-zzdp6
May  2 00:21:17.744: INFO: Got endpoints: latency-svc-xfr5j [750.65293ms]
May  2 00:21:17.755: INFO: Created: latency-svc-k9wzp
May  2 00:21:17.793: INFO: Got endpoints: latency-svc-h5hvs [749.277867ms]
May  2 00:21:17.807: INFO: Created: latency-svc-pdb5q
May  2 00:21:17.843: INFO: Got endpoints: latency-svc-sv7r8 [750.16855ms]
May  2 00:21:17.853: INFO: Created: latency-svc-tkgxf
May  2 00:21:17.893: INFO: Got endpoints: latency-svc-x6pqq [746.899172ms]
May  2 00:21:17.903: INFO: Created: latency-svc-cx27v
May  2 00:21:17.945: INFO: Got endpoints: latency-svc-nm86s [752.114597ms]
May  2 00:21:17.955: INFO: Created: latency-svc-p9w4n
May  2 00:21:17.993: INFO: Got endpoints: latency-svc-f6tc5 [749.956816ms]
May  2 00:21:18.004: INFO: Created: latency-svc-chxwz
May  2 00:21:18.047: INFO: Got endpoints: latency-svc-c5bwz [749.734695ms]
May  2 00:21:18.057: INFO: Created: latency-svc-8b2kj
May  2 00:21:18.094: INFO: Got endpoints: latency-svc-fghhh [739.063907ms]
May  2 00:21:18.104: INFO: Created: latency-svc-kv58q
May  2 00:21:18.143: INFO: Got endpoints: latency-svc-4qllh [747.891052ms]
May  2 00:21:18.157: INFO: Created: latency-svc-62svs
May  2 00:21:18.197: INFO: Got endpoints: latency-svc-68l7k [754.026204ms]
May  2 00:21:18.205: INFO: Created: latency-svc-l9jvr
May  2 00:21:18.246: INFO: Got endpoints: latency-svc-hjc8m [750.13548ms]
May  2 00:21:18.255: INFO: Created: latency-svc-nn5p9
May  2 00:21:18.299: INFO: Got endpoints: latency-svc-m89vs [755.657887ms]
May  2 00:21:18.311: INFO: Created: latency-svc-5sl5t
May  2 00:21:18.348: INFO: Got endpoints: latency-svc-zzdp6 [753.364447ms]
May  2 00:21:18.359: INFO: Created: latency-svc-bmpvh
May  2 00:21:18.393: INFO: Got endpoints: latency-svc-k9wzp [747.419137ms]
May  2 00:21:18.410: INFO: Created: latency-svc-4llml
May  2 00:21:18.444: INFO: Got endpoints: latency-svc-pdb5q [748.754162ms]
May  2 00:21:18.458: INFO: Created: latency-svc-f2k5q
May  2 00:21:18.494: INFO: Got endpoints: latency-svc-tkgxf [750.2058ms]
May  2 00:21:18.506: INFO: Created: latency-svc-g2mhr
May  2 00:21:18.545: INFO: Got endpoints: latency-svc-cx27v [752.411836ms]
May  2 00:21:18.557: INFO: Created: latency-svc-m9m6x
May  2 00:21:18.594: INFO: Got endpoints: latency-svc-p9w4n [750.539381ms]
May  2 00:21:18.608: INFO: Created: latency-svc-zqbv9
May  2 00:21:18.645: INFO: Got endpoints: latency-svc-chxwz [751.07764ms]
May  2 00:21:18.658: INFO: Created: latency-svc-zm4ng
May  2 00:21:18.693: INFO: Got endpoints: latency-svc-8b2kj [747.375524ms]
May  2 00:21:18.704: INFO: Created: latency-svc-wtv7m
May  2 00:21:18.747: INFO: Got endpoints: latency-svc-kv58q [753.577475ms]
May  2 00:21:18.757: INFO: Created: latency-svc-rd9nn
May  2 00:21:18.794: INFO: Got endpoints: latency-svc-62svs [747.066236ms]
May  2 00:21:18.804: INFO: Created: latency-svc-znfjn
May  2 00:21:18.844: INFO: Got endpoints: latency-svc-l9jvr [750.888733ms]
May  2 00:21:18.856: INFO: Created: latency-svc-vtd86
May  2 00:21:18.896: INFO: Got endpoints: latency-svc-nn5p9 [753.352829ms]
May  2 00:21:18.905: INFO: Created: latency-svc-pdtxw
May  2 00:21:18.943: INFO: Got endpoints: latency-svc-5sl5t [746.356276ms]
May  2 00:21:18.954: INFO: Created: latency-svc-7bjjp
May  2 00:21:18.994: INFO: Got endpoints: latency-svc-bmpvh [748.378095ms]
May  2 00:21:19.006: INFO: Created: latency-svc-rq2p9
May  2 00:21:19.043: INFO: Got endpoints: latency-svc-4llml [743.765377ms]
May  2 00:21:19.056: INFO: Created: latency-svc-hxbsf
May  2 00:21:19.094: INFO: Got endpoints: latency-svc-f2k5q [745.509293ms]
May  2 00:21:19.105: INFO: Created: latency-svc-6csjg
May  2 00:21:19.144: INFO: Got endpoints: latency-svc-g2mhr [750.679222ms]
May  2 00:21:19.154: INFO: Created: latency-svc-5bhsg
May  2 00:21:19.193: INFO: Got endpoints: latency-svc-m9m6x [749.283132ms]
May  2 00:21:19.206: INFO: Created: latency-svc-vn7dk
May  2 00:21:19.246: INFO: Got endpoints: latency-svc-zqbv9 [752.016859ms]
May  2 00:21:19.255: INFO: Created: latency-svc-nrcqb
May  2 00:21:19.294: INFO: Got endpoints: latency-svc-zm4ng [748.485878ms]
May  2 00:21:19.314: INFO: Created: latency-svc-777xj
May  2 00:21:19.348: INFO: Got endpoints: latency-svc-wtv7m [753.793028ms]
May  2 00:21:19.361: INFO: Created: latency-svc-m64mt
May  2 00:21:19.401: INFO: Got endpoints: latency-svc-rd9nn [755.881086ms]
May  2 00:21:19.407: INFO: Created: latency-svc-p79wx
May  2 00:21:19.446: INFO: Got endpoints: latency-svc-znfjn [753.019151ms]
May  2 00:21:19.458: INFO: Created: latency-svc-fgdgj
May  2 00:21:19.496: INFO: Got endpoints: latency-svc-vtd86 [748.997407ms]
May  2 00:21:19.512: INFO: Created: latency-svc-dq9tr
May  2 00:21:19.548: INFO: Got endpoints: latency-svc-pdtxw [754.092793ms]
May  2 00:21:19.558: INFO: Created: latency-svc-vr4wt
May  2 00:21:19.596: INFO: Got endpoints: latency-svc-7bjjp [751.110315ms]
May  2 00:21:19.606: INFO: Created: latency-svc-tf9rz
May  2 00:21:19.644: INFO: Got endpoints: latency-svc-rq2p9 [747.8828ms]
May  2 00:21:19.658: INFO: Created: latency-svc-psfwc
May  2 00:21:19.693: INFO: Got endpoints: latency-svc-hxbsf [749.520809ms]
May  2 00:21:19.705: INFO: Created: latency-svc-rkhcc
May  2 00:21:19.745: INFO: Got endpoints: latency-svc-6csjg [750.908009ms]
May  2 00:21:19.759: INFO: Created: latency-svc-jqh5x
May  2 00:21:19.793: INFO: Got endpoints: latency-svc-5bhsg [749.842471ms]
May  2 00:21:19.803: INFO: Created: latency-svc-qsqjs
May  2 00:21:19.843: INFO: Got endpoints: latency-svc-vn7dk [748.759796ms]
May  2 00:21:19.855: INFO: Created: latency-svc-zbgdj
May  2 00:21:19.896: INFO: Got endpoints: latency-svc-nrcqb [751.584155ms]
May  2 00:21:19.905: INFO: Created: latency-svc-wrk7w
May  2 00:21:19.943: INFO: Got endpoints: latency-svc-777xj [750.043256ms]
May  2 00:21:19.954: INFO: Created: latency-svc-kj7dt
May  2 00:21:19.997: INFO: Got endpoints: latency-svc-m64mt [750.299167ms]
May  2 00:21:20.006: INFO: Created: latency-svc-xcqgg
May  2 00:21:20.045: INFO: Got endpoints: latency-svc-p79wx [750.78075ms]
May  2 00:21:20.056: INFO: Created: latency-svc-rjxd4
May  2 00:21:20.095: INFO: Got endpoints: latency-svc-fgdgj [747.818885ms]
May  2 00:21:20.106: INFO: Created: latency-svc-vcpzw
May  2 00:21:20.143: INFO: Got endpoints: latency-svc-dq9tr [742.399528ms]
May  2 00:21:20.161: INFO: Created: latency-svc-5696g
May  2 00:21:20.193: INFO: Got endpoints: latency-svc-vr4wt [746.977771ms]
May  2 00:21:20.206: INFO: Created: latency-svc-d5qw2
May  2 00:21:20.243: INFO: Got endpoints: latency-svc-tf9rz [746.825505ms]
May  2 00:21:20.252: INFO: Created: latency-svc-rclpw
May  2 00:21:20.293: INFO: Got endpoints: latency-svc-psfwc [745.336844ms]
May  2 00:21:20.306: INFO: Created: latency-svc-c6wg8
May  2 00:21:20.354: INFO: Got endpoints: latency-svc-rkhcc [757.992818ms]
May  2 00:21:20.366: INFO: Created: latency-svc-zmh9l
May  2 00:21:20.402: INFO: Got endpoints: latency-svc-jqh5x [757.642518ms]
May  2 00:21:20.408: INFO: Created: latency-svc-f6qgl
May  2 00:21:20.446: INFO: Got endpoints: latency-svc-qsqjs [752.58374ms]
May  2 00:21:20.463: INFO: Created: latency-svc-j76xt
May  2 00:21:20.493: INFO: Got endpoints: latency-svc-zbgdj [747.851791ms]
May  2 00:21:20.514: INFO: Created: latency-svc-f8k45
May  2 00:21:20.545: INFO: Got endpoints: latency-svc-wrk7w [752.595031ms]
May  2 00:21:20.555: INFO: Created: latency-svc-cklnq
May  2 00:21:20.596: INFO: Got endpoints: latency-svc-kj7dt [753.096042ms]
May  2 00:21:20.603: INFO: Created: latency-svc-jbx2t
May  2 00:21:20.645: INFO: Got endpoints: latency-svc-xcqgg [749.609315ms]
May  2 00:21:20.657: INFO: Created: latency-svc-8bglz
May  2 00:21:20.693: INFO: Got endpoints: latency-svc-rjxd4 [749.640987ms]
May  2 00:21:20.706: INFO: Created: latency-svc-bvmg2
May  2 00:21:20.745: INFO: Got endpoints: latency-svc-vcpzw [748.100494ms]
May  2 00:21:20.755: INFO: Created: latency-svc-zr92w
May  2 00:21:20.797: INFO: Got endpoints: latency-svc-5696g [752.452427ms]
May  2 00:21:20.808: INFO: Created: latency-svc-ntdfk
May  2 00:21:20.845: INFO: Got endpoints: latency-svc-d5qw2 [749.540628ms]
May  2 00:21:20.856: INFO: Created: latency-svc-tmnvw
May  2 00:21:20.894: INFO: Got endpoints: latency-svc-rclpw [750.705223ms]
May  2 00:21:20.911: INFO: Created: latency-svc-2q9dv
May  2 00:21:20.944: INFO: Got endpoints: latency-svc-c6wg8 [750.958033ms]
May  2 00:21:20.955: INFO: Created: latency-svc-spk5w
May  2 00:21:20.997: INFO: Got endpoints: latency-svc-zmh9l [753.928357ms]
May  2 00:21:21.005: INFO: Created: latency-svc-5d6j6
May  2 00:21:21.046: INFO: Got endpoints: latency-svc-f6qgl [752.606072ms]
May  2 00:21:21.055: INFO: Created: latency-svc-q85tq
May  2 00:21:21.097: INFO: Got endpoints: latency-svc-j76xt [743.403868ms]
May  2 00:21:21.108: INFO: Created: latency-svc-kn6j2
May  2 00:21:21.143: INFO: Got endpoints: latency-svc-f8k45 [741.071862ms]
May  2 00:21:21.156: INFO: Created: latency-svc-vqwpr
May  2 00:21:21.195: INFO: Got endpoints: latency-svc-cklnq [749.684567ms]
May  2 00:21:21.207: INFO: Created: latency-svc-m829f
May  2 00:21:21.244: INFO: Got endpoints: latency-svc-jbx2t [750.540749ms]
May  2 00:21:21.253: INFO: Created: latency-svc-9fhxl
May  2 00:21:21.301: INFO: Got endpoints: latency-svc-8bglz [755.86769ms]
May  2 00:21:21.348: INFO: Got endpoints: latency-svc-bvmg2 [751.837319ms]
May  2 00:21:21.398: INFO: Got endpoints: latency-svc-zr92w [752.732155ms]
May  2 00:21:21.444: INFO: Got endpoints: latency-svc-ntdfk [750.714709ms]
May  2 00:21:21.499: INFO: Got endpoints: latency-svc-tmnvw [753.872639ms]
May  2 00:21:21.545: INFO: Got endpoints: latency-svc-2q9dv [748.223122ms]
May  2 00:21:21.596: INFO: Got endpoints: latency-svc-spk5w [750.818477ms]
May  2 00:21:21.646: INFO: Got endpoints: latency-svc-5d6j6 [752.089036ms]
May  2 00:21:21.693: INFO: Got endpoints: latency-svc-q85tq [749.549181ms]
May  2 00:21:21.743: INFO: Got endpoints: latency-svc-kn6j2 [746.398881ms]
May  2 00:21:21.793: INFO: Got endpoints: latency-svc-vqwpr [747.122388ms]
May  2 00:21:21.844: INFO: Got endpoints: latency-svc-m829f [747.012008ms]
May  2 00:21:21.893: INFO: Got endpoints: latency-svc-9fhxl [750.213001ms]
May  2 00:21:21.893: INFO: Latencies: [121.008616ms 128.323535ms 143.592228ms 146.719443ms 152.414594ms 161.686744ms 162.728788ms 166.611379ms 167.348072ms 169.877252ms 170.160951ms 170.301019ms 172.774716ms 173.215419ms 174.132356ms 175.52168ms 178.603859ms 182.02971ms 182.482595ms 182.792892ms 183.031014ms 188.756548ms 191.958852ms 192.257993ms 198.60625ms 206.681842ms 223.941627ms 233.122133ms 234.808586ms 235.468281ms 236.824741ms 239.654187ms 243.907346ms 245.368114ms 248.735562ms 266.364029ms 281.137227ms 284.344854ms 294.204586ms 316.252984ms 318.601847ms 319.618328ms 332.929344ms 344.342971ms 355.782566ms 398.933586ms 437.695183ms 473.157443ms 511.316223ms 548.749328ms 583.000277ms 610.045965ms 648.709838ms 680.362007ms 710.800027ms 735.691545ms 735.827406ms 737.260709ms 737.87982ms 739.063907ms 741.071862ms 742.399528ms 743.403868ms 743.765377ms 744.376543ms 744.408183ms 744.690852ms 744.69127ms 745.336844ms 745.509293ms 746.230006ms 746.356276ms 746.398881ms 746.518108ms 746.825505ms 746.899172ms 746.977771ms 747.012008ms 747.066236ms 747.122388ms 747.130331ms 747.375524ms 747.411164ms 747.419137ms 747.427063ms 747.664101ms 747.723452ms 747.801406ms 747.818885ms 747.851791ms 747.8828ms 747.891052ms 747.930392ms 748.100494ms 748.104168ms 748.223122ms 748.355956ms 748.378095ms 748.485878ms 748.491253ms 748.594543ms 748.754162ms 748.759796ms 748.778578ms 748.926164ms 748.929388ms 748.981585ms 748.997407ms 749.102319ms 749.169309ms 749.277867ms 749.283132ms 749.41005ms 749.435757ms 749.472587ms 749.520809ms 749.528998ms 749.53742ms 749.540628ms 749.549181ms 749.609315ms 749.640987ms 749.676076ms 749.684567ms 749.734695ms 749.786039ms 749.842471ms 749.956816ms 750.043256ms 750.13548ms 750.16855ms 750.2058ms 750.213001ms 750.248218ms 750.299167ms 750.393007ms 750.539381ms 750.540749ms 750.65293ms 750.679222ms 750.705223ms 750.714709ms 750.78075ms 750.786252ms 750.818477ms 750.888733ms 750.908009ms 750.958033ms 751.040767ms 751.07764ms 751.110315ms 751.119043ms 751.293288ms 751.342905ms 751.426342ms 751.450487ms 751.584155ms 751.589604ms 751.651919ms 751.792064ms 751.810522ms 751.837319ms 751.897839ms 752.016859ms 752.089036ms 752.114597ms 752.343629ms 752.345754ms 752.411836ms 752.419892ms 752.452427ms 752.58374ms 752.595031ms 752.606072ms 752.732155ms 752.777245ms 752.822649ms 753.019151ms 753.096042ms 753.352829ms 753.364447ms 753.577475ms 753.729501ms 753.793028ms 753.872639ms 753.928357ms 754.025502ms 754.026204ms 754.092793ms 755.657887ms 755.86769ms 755.881086ms 756.583968ms 757.642518ms 757.810096ms 757.992818ms 760.354372ms 762.110423ms 765.088228ms 766.3465ms]
May  2 00:21:21.893: INFO: 50 %ile: 748.594543ms
May  2 00:21:21.893: INFO: 90 %ile: 753.364447ms
May  2 00:21:21.893: INFO: 99 %ile: 765.088228ms
May  2 00:21:21.893: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
May  2 00:21:21.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-378" for this suite. 05/02/23 00:21:22.001
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":328,"skipped":6348,"failed":0}
------------------------------
• [SLOW TEST] [11.136 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:21:10.972
    May  2 00:21:10.972: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svc-latency 05/02/23 00:21:10.973
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:11.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:11.49
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    May  2 00:21:11.696: INFO: >>> kubeConfig: /root/.kube/config
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-378 05/02/23 00:21:11.697
    I0502 00:21:11.803518    6969 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-378, replica count: 1
    I0502 00:21:12.954361    6969 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  2 00:21:13.265: INFO: Created: latency-svc-4cdcg
    May  2 00:21:13.275: INFO: Got endpoints: latency-svc-4cdcg [119.513556ms]
    May  2 00:21:13.388: INFO: Created: latency-svc-xlqdv
    May  2 00:21:13.396: INFO: Got endpoints: latency-svc-xlqdv [121.008616ms]
    May  2 00:21:13.398: INFO: Created: latency-svc-jn4mv
    May  2 00:21:13.403: INFO: Got endpoints: latency-svc-jn4mv [128.323535ms]
    May  2 00:21:13.406: INFO: Created: latency-svc-l8qdz
    May  2 00:21:13.414: INFO: Created: latency-svc-djvtd
    May  2 00:21:13.418: INFO: Got endpoints: latency-svc-l8qdz [143.592228ms]
    May  2 00:21:13.421: INFO: Got endpoints: latency-svc-djvtd [146.719443ms]
    May  2 00:21:13.423: INFO: Created: latency-svc-s7gw5
    May  2 00:21:13.427: INFO: Got endpoints: latency-svc-s7gw5 [152.414594ms]
    May  2 00:21:13.494: INFO: Created: latency-svc-6xzkb
    May  2 00:21:13.499: INFO: Got endpoints: latency-svc-6xzkb [223.941627ms]
    May  2 00:21:13.506: INFO: Created: latency-svc-mxbl9
    May  2 00:21:13.510: INFO: Got endpoints: latency-svc-mxbl9 [234.808586ms]
    May  2 00:21:13.515: INFO: Created: latency-svc-lvggg
    May  2 00:21:13.524: INFO: Got endpoints: latency-svc-lvggg [248.735562ms]
    May  2 00:21:13.532: INFO: Created: latency-svc-rnswn
    May  2 00:21:13.534: INFO: Created: latency-svc-ckv4m
    May  2 00:21:13.541: INFO: Got endpoints: latency-svc-rnswn [266.364029ms]
    May  2 00:21:13.559: INFO: Got endpoints: latency-svc-ckv4m [284.344854ms]
    May  2 00:21:13.562: INFO: Created: latency-svc-5hxnr
    May  2 00:21:13.569: INFO: Got endpoints: latency-svc-5hxnr [294.204586ms]
    May  2 00:21:13.571: INFO: Created: latency-svc-t5hfd
    May  2 00:21:13.586: INFO: Created: latency-svc-v787c
    May  2 00:21:13.591: INFO: Got endpoints: latency-svc-t5hfd [316.252984ms]
    May  2 00:21:13.595: INFO: Got endpoints: latency-svc-v787c [319.618328ms]
    May  2 00:21:13.597: INFO: Created: latency-svc-hrx2t
    May  2 00:21:13.608: INFO: Got endpoints: latency-svc-hrx2t [332.929344ms]
    May  2 00:21:13.613: INFO: Created: latency-svc-fbkqk
    May  2 00:21:13.619: INFO: Got endpoints: latency-svc-fbkqk [344.342971ms]
    May  2 00:21:13.621: INFO: Created: latency-svc-76mmc
    May  2 00:21:13.632: INFO: Got endpoints: latency-svc-76mmc [235.468281ms]
    May  2 00:21:13.634: INFO: Created: latency-svc-m7kl6
    May  2 00:21:13.640: INFO: Got endpoints: latency-svc-m7kl6 [236.824741ms]
    May  2 00:21:13.642: INFO: Created: latency-svc-4v9qk
    May  2 00:21:13.651: INFO: Got endpoints: latency-svc-4v9qk [233.122133ms]
    May  2 00:21:13.652: INFO: Created: latency-svc-n7b74
    May  2 00:21:13.661: INFO: Got endpoints: latency-svc-n7b74 [239.654187ms]
    May  2 00:21:13.661: INFO: Created: latency-svc-nxzhr
    May  2 00:21:13.671: INFO: Got endpoints: latency-svc-nxzhr [243.907346ms]
    May  2 00:21:13.675: INFO: Created: latency-svc-glzlf
    May  2 00:21:13.682: INFO: Got endpoints: latency-svc-glzlf [182.792892ms]
    May  2 00:21:13.684: INFO: Created: latency-svc-wf8sf
    May  2 00:21:13.693: INFO: Created: latency-svc-8rcd9
    May  2 00:21:13.702: INFO: Got endpoints: latency-svc-wf8sf [191.958852ms]
    May  2 00:21:13.713: INFO: Got endpoints: latency-svc-8rcd9 [188.756548ms]
    May  2 00:21:13.716: INFO: Created: latency-svc-7nw2d
    May  2 00:21:13.724: INFO: Got endpoints: latency-svc-7nw2d [182.482595ms]
    May  2 00:21:13.724: INFO: Created: latency-svc-xpjqd
    May  2 00:21:13.734: INFO: Got endpoints: latency-svc-xpjqd [174.132356ms]
    May  2 00:21:13.738: INFO: Created: latency-svc-vw6z5
    May  2 00:21:13.743: INFO: Got endpoints: latency-svc-vw6z5 [173.215419ms]
    May  2 00:21:13.747: INFO: Created: latency-svc-hftlb
    May  2 00:21:13.753: INFO: Got endpoints: latency-svc-hftlb [161.686744ms]
    May  2 00:21:13.759: INFO: Created: latency-svc-dmp77
    May  2 00:21:13.765: INFO: Got endpoints: latency-svc-dmp77 [170.160951ms]
    May  2 00:21:13.769: INFO: Created: latency-svc-7dq52
    May  2 00:21:13.775: INFO: Got endpoints: latency-svc-7dq52 [166.611379ms]
    May  2 00:21:13.779: INFO: Created: latency-svc-sd2l9
    May  2 00:21:13.787: INFO: Created: latency-svc-cqs6f
    May  2 00:21:13.790: INFO: Got endpoints: latency-svc-sd2l9 [170.301019ms]
    May  2 00:21:13.794: INFO: Got endpoints: latency-svc-cqs6f [162.728788ms]
    May  2 00:21:13.802: INFO: Created: latency-svc-6xnhl
    May  2 00:21:13.808: INFO: Got endpoints: latency-svc-6xnhl [167.348072ms]
    May  2 00:21:13.813: INFO: Created: latency-svc-562st
    May  2 00:21:13.821: INFO: Got endpoints: latency-svc-562st [169.877252ms]
    May  2 00:21:13.824: INFO: Created: latency-svc-48t5t
    May  2 00:21:13.832: INFO: Created: latency-svc-x8dc5
    May  2 00:21:13.837: INFO: Got endpoints: latency-svc-48t5t [175.52168ms]
    May  2 00:21:13.844: INFO: Got endpoints: latency-svc-x8dc5 [172.774716ms]
    May  2 00:21:13.853: INFO: Created: latency-svc-tjw88
    May  2 00:21:13.861: INFO: Got endpoints: latency-svc-tjw88 [178.603859ms]
    May  2 00:21:13.874: INFO: Created: latency-svc-dljcm
    May  2 00:21:13.884: INFO: Got endpoints: latency-svc-dljcm [182.02971ms]
    May  2 00:21:13.892: INFO: Created: latency-svc-lw79p
    May  2 00:21:13.896: INFO: Got endpoints: latency-svc-lw79p [183.031014ms]
    May  2 00:21:13.898: INFO: Created: latency-svc-m5hhb
    May  2 00:21:13.916: INFO: Got endpoints: latency-svc-m5hhb [192.257993ms]
    May  2 00:21:13.919: INFO: Created: latency-svc-ndhf4
    May  2 00:21:13.932: INFO: Got endpoints: latency-svc-ndhf4 [198.60625ms]
    May  2 00:21:13.933: INFO: Created: latency-svc-whzkm
    May  2 00:21:13.944: INFO: Created: latency-svc-nmg4z
    May  2 00:21:13.949: INFO: Got endpoints: latency-svc-whzkm [206.681842ms]
    May  2 00:21:13.953: INFO: Created: latency-svc-np8vg
    May  2 00:21:13.960: INFO: Created: latency-svc-8kbxx
    May  2 00:21:13.967: INFO: Created: latency-svc-lfxc4
    May  2 00:21:13.977: INFO: Created: latency-svc-6fw86
    May  2 00:21:13.983: INFO: Created: latency-svc-8srkr
    May  2 00:21:13.991: INFO: Created: latency-svc-pvgj5
    May  2 00:21:13.998: INFO: Got endpoints: latency-svc-nmg4z [245.368114ms]
    May  2 00:21:14.004: INFO: Created: latency-svc-lbvm9
    May  2 00:21:14.010: INFO: Created: latency-svc-vdpkq
    May  2 00:21:14.019: INFO: Created: latency-svc-7ll58
    May  2 00:21:14.025: INFO: Created: latency-svc-nzq5r
    May  2 00:21:14.038: INFO: Created: latency-svc-qdzwx
    May  2 00:21:14.043: INFO: Created: latency-svc-pqrcd
    May  2 00:21:14.046: INFO: Got endpoints: latency-svc-np8vg [281.137227ms]
    May  2 00:21:14.052: INFO: Created: latency-svc-9dfk5
    May  2 00:21:14.061: INFO: Created: latency-svc-4jdbx
    May  2 00:21:14.093: INFO: Got endpoints: latency-svc-8kbxx [318.601847ms]
    May  2 00:21:14.111: INFO: Created: latency-svc-dqqfn
    May  2 00:21:14.146: INFO: Got endpoints: latency-svc-lfxc4 [355.782566ms]
    May  2 00:21:14.156: INFO: Created: latency-svc-jqq7q
    May  2 00:21:14.193: INFO: Got endpoints: latency-svc-6fw86 [398.933586ms]
    May  2 00:21:14.205: INFO: Created: latency-svc-gc64t
    May  2 00:21:14.245: INFO: Got endpoints: latency-svc-8srkr [437.695183ms]
    May  2 00:21:14.256: INFO: Created: latency-svc-hzsp4
    May  2 00:21:14.295: INFO: Got endpoints: latency-svc-pvgj5 [473.157443ms]
    May  2 00:21:14.308: INFO: Created: latency-svc-kn2pw
    May  2 00:21:14.349: INFO: Got endpoints: latency-svc-lbvm9 [511.316223ms]
    May  2 00:21:14.363: INFO: Created: latency-svc-wcbk7
    May  2 00:21:14.393: INFO: Got endpoints: latency-svc-vdpkq [548.749328ms]
    May  2 00:21:14.404: INFO: Created: latency-svc-jgs4w
    May  2 00:21:14.444: INFO: Got endpoints: latency-svc-7ll58 [583.000277ms]
    May  2 00:21:14.459: INFO: Created: latency-svc-pxxsj
    May  2 00:21:14.494: INFO: Got endpoints: latency-svc-nzq5r [610.045965ms]
    May  2 00:21:14.504: INFO: Created: latency-svc-vgtht
    May  2 00:21:14.544: INFO: Got endpoints: latency-svc-qdzwx [648.709838ms]
    May  2 00:21:14.554: INFO: Created: latency-svc-wwdp8
    May  2 00:21:14.597: INFO: Got endpoints: latency-svc-pqrcd [680.362007ms]
    May  2 00:21:14.608: INFO: Created: latency-svc-tfp69
    May  2 00:21:14.643: INFO: Got endpoints: latency-svc-9dfk5 [710.800027ms]
    May  2 00:21:14.658: INFO: Created: latency-svc-lqmxd
    May  2 00:21:14.694: INFO: Got endpoints: latency-svc-4jdbx [744.376543ms]
    May  2 00:21:14.706: INFO: Created: latency-svc-hw5wz
    May  2 00:21:14.743: INFO: Got endpoints: latency-svc-dqqfn [744.408183ms]
    May  2 00:21:14.756: INFO: Created: latency-svc-75crw
    May  2 00:21:14.796: INFO: Got endpoints: latency-svc-jqq7q [749.472587ms]
    May  2 00:21:14.804: INFO: Created: latency-svc-8bs9x
    May  2 00:21:14.845: INFO: Got endpoints: latency-svc-gc64t [751.651919ms]
    May  2 00:21:14.858: INFO: Created: latency-svc-mhnr5
    May  2 00:21:14.895: INFO: Got endpoints: latency-svc-hzsp4 [749.786039ms]
    May  2 00:21:14.907: INFO: Created: latency-svc-78v9m
    May  2 00:21:14.946: INFO: Got endpoints: latency-svc-kn2pw [752.343629ms]
    May  2 00:21:14.956: INFO: Created: latency-svc-4qrff
    May  2 00:21:14.995: INFO: Got endpoints: latency-svc-wcbk7 [749.676076ms]
    May  2 00:21:15.006: INFO: Created: latency-svc-nmdxc
    May  2 00:21:15.043: INFO: Got endpoints: latency-svc-jgs4w [748.594543ms]
    May  2 00:21:15.057: INFO: Created: latency-svc-lrfzl
    May  2 00:21:15.093: INFO: Got endpoints: latency-svc-pxxsj [744.690852ms]
    May  2 00:21:15.107: INFO: Created: latency-svc-nf494
    May  2 00:21:15.147: INFO: Got endpoints: latency-svc-vgtht [754.025502ms]
    May  2 00:21:15.156: INFO: Created: latency-svc-qkbnr
    May  2 00:21:15.195: INFO: Got endpoints: latency-svc-wwdp8 [751.810522ms]
    May  2 00:21:15.206: INFO: Created: latency-svc-5k5wh
    May  2 00:21:15.243: INFO: Got endpoints: latency-svc-tfp69 [749.169309ms]
    May  2 00:21:15.258: INFO: Created: latency-svc-zm4rg
    May  2 00:21:15.295: INFO: Got endpoints: latency-svc-lqmxd [750.393007ms]
    May  2 00:21:15.311: INFO: Created: latency-svc-sg8g6
    May  2 00:21:15.348: INFO: Got endpoints: latency-svc-hw5wz [751.342905ms]
    May  2 00:21:15.363: INFO: Created: latency-svc-txtzn
    May  2 00:21:15.394: INFO: Got endpoints: latency-svc-75crw [750.786252ms]
    May  2 00:21:15.406: INFO: Created: latency-svc-dpkph
    May  2 00:21:15.447: INFO: Got endpoints: latency-svc-8bs9x [752.777245ms]
    May  2 00:21:15.460: INFO: Created: latency-svc-p8rsx
    May  2 00:21:15.495: INFO: Got endpoints: latency-svc-mhnr5 [751.589604ms]
    May  2 00:21:15.505: INFO: Created: latency-svc-msz8k
    May  2 00:21:15.545: INFO: Got endpoints: latency-svc-78v9m [749.528998ms]
    May  2 00:21:15.562: INFO: Created: latency-svc-t2gqz
    May  2 00:21:15.610: INFO: Got endpoints: latency-svc-4qrff [765.088228ms]
    May  2 00:21:15.620: INFO: Created: latency-svc-ggnpb
    May  2 00:21:15.648: INFO: Got endpoints: latency-svc-nmdxc [752.345754ms]
    May  2 00:21:15.675: INFO: Created: latency-svc-nbktx
    May  2 00:21:15.695: INFO: Got endpoints: latency-svc-lrfzl [748.778578ms]
    May  2 00:21:15.725: INFO: Created: latency-svc-gkc98
    May  2 00:21:15.743: INFO: Got endpoints: latency-svc-nf494 [748.104168ms]
    May  2 00:21:15.758: INFO: Created: latency-svc-r56kn
    May  2 00:21:15.795: INFO: Got endpoints: latency-svc-qkbnr [751.792064ms]
    May  2 00:21:15.805: INFO: Created: latency-svc-8b2mf
    May  2 00:21:15.851: INFO: Got endpoints: latency-svc-5k5wh [757.810096ms]
    May  2 00:21:15.881: INFO: Created: latency-svc-5rjh4
    May  2 00:21:15.907: INFO: Got endpoints: latency-svc-zm4rg [760.354372ms]
    May  2 00:21:15.922: INFO: Created: latency-svc-xm4hr
    May  2 00:21:15.958: INFO: Got endpoints: latency-svc-sg8g6 [762.110423ms]
    May  2 00:21:15.985: INFO: Created: latency-svc-p9msq
    May  2 00:21:16.010: INFO: Got endpoints: latency-svc-txtzn [766.3465ms]
    May  2 00:21:16.026: INFO: Created: latency-svc-8fgs8
    May  2 00:21:16.043: INFO: Got endpoints: latency-svc-dpkph [747.930392ms]
    May  2 00:21:16.067: INFO: Created: latency-svc-grlgp
    May  2 00:21:16.094: INFO: Got endpoints: latency-svc-p8rsx [746.230006ms]
    May  2 00:21:16.122: INFO: Created: latency-svc-2k8x5
    May  2 00:21:16.146: INFO: Got endpoints: latency-svc-msz8k [752.419892ms]
    May  2 00:21:16.155: INFO: Created: latency-svc-fvz4x
    May  2 00:21:16.194: INFO: Got endpoints: latency-svc-t2gqz [747.130331ms]
    May  2 00:21:16.206: INFO: Created: latency-svc-mhf5d
    May  2 00:21:16.244: INFO: Got endpoints: latency-svc-ggnpb [749.53742ms]
    May  2 00:21:16.257: INFO: Created: latency-svc-z9gf8
    May  2 00:21:16.295: INFO: Got endpoints: latency-svc-nbktx [749.41005ms]
    May  2 00:21:16.311: INFO: Created: latency-svc-shtcv
    May  2 00:21:16.348: INFO: Got endpoints: latency-svc-gkc98 [737.87982ms]
    May  2 00:21:16.358: INFO: Created: latency-svc-w2cc5
    May  2 00:21:16.395: INFO: Got endpoints: latency-svc-r56kn [747.427063ms]
    May  2 00:21:16.406: INFO: Created: latency-svc-d6rvv
    May  2 00:21:16.444: INFO: Got endpoints: latency-svc-8b2mf [749.435757ms]
    May  2 00:21:16.459: INFO: Created: latency-svc-b4zvj
    May  2 00:21:16.495: INFO: Got endpoints: latency-svc-5rjh4 [751.293288ms]
    May  2 00:21:16.508: INFO: Created: latency-svc-vm6nx
    May  2 00:21:16.543: INFO: Got endpoints: latency-svc-xm4hr [747.664101ms]
    May  2 00:21:16.570: INFO: Created: latency-svc-d8ph2
    May  2 00:21:16.598: INFO: Got endpoints: latency-svc-p9msq [746.518108ms]
    May  2 00:21:16.606: INFO: Created: latency-svc-cntmn
    May  2 00:21:16.643: INFO: Got endpoints: latency-svc-8fgs8 [735.691545ms]
    May  2 00:21:16.654: INFO: Created: latency-svc-lrdfd
    May  2 00:21:16.695: INFO: Got endpoints: latency-svc-grlgp [737.260709ms]
    May  2 00:21:16.708: INFO: Created: latency-svc-l8jss
    May  2 00:21:16.745: INFO: Got endpoints: latency-svc-2k8x5 [735.827406ms]
    May  2 00:21:16.754: INFO: Created: latency-svc-nscfv
    May  2 00:21:16.796: INFO: Got endpoints: latency-svc-fvz4x [752.822649ms]
    May  2 00:21:16.805: INFO: Created: latency-svc-wr2w6
    May  2 00:21:16.846: INFO: Got endpoints: latency-svc-mhf5d [751.119043ms]
    May  2 00:21:16.856: INFO: Created: latency-svc-nltsc
    May  2 00:21:16.894: INFO: Got endpoints: latency-svc-z9gf8 [747.723452ms]
    May  2 00:21:16.908: INFO: Created: latency-svc-sx77m
    May  2 00:21:16.943: INFO: Got endpoints: latency-svc-shtcv [748.981585ms]
    May  2 00:21:16.956: INFO: Created: latency-svc-kml25
    May  2 00:21:16.993: INFO: Got endpoints: latency-svc-w2cc5 [748.926164ms]
    May  2 00:21:17.004: INFO: Created: latency-svc-nphwg
    May  2 00:21:17.043: INFO: Got endpoints: latency-svc-d6rvv [748.491253ms]
    May  2 00:21:17.054: INFO: Created: latency-svc-vkq9d
    May  2 00:21:17.093: INFO: Got endpoints: latency-svc-b4zvj [744.69127ms]
    May  2 00:21:17.104: INFO: Created: latency-svc-xfr5j
    May  2 00:21:17.146: INFO: Got endpoints: latency-svc-vm6nx [751.040767ms]
    May  2 00:21:17.154: INFO: Created: latency-svc-h5hvs
    May  2 00:21:17.193: INFO: Got endpoints: latency-svc-d8ph2 [748.929388ms]
    May  2 00:21:17.204: INFO: Created: latency-svc-sv7r8
    May  2 00:21:17.243: INFO: Got endpoints: latency-svc-cntmn [748.355956ms]
    May  2 00:21:17.257: INFO: Created: latency-svc-x6pqq
    May  2 00:21:17.297: INFO: Got endpoints: latency-svc-lrdfd [753.729501ms]
    May  2 00:21:17.310: INFO: Created: latency-svc-nm86s
    May  2 00:21:17.354: INFO: Got endpoints: latency-svc-l8jss [756.583968ms]
    May  2 00:21:17.361: INFO: Created: latency-svc-f6tc5
    May  2 00:21:17.395: INFO: Got endpoints: latency-svc-nscfv [751.426342ms]
    May  2 00:21:17.407: INFO: Created: latency-svc-c5bwz
    May  2 00:21:17.443: INFO: Got endpoints: latency-svc-wr2w6 [747.801406ms]
    May  2 00:21:17.469: INFO: Created: latency-svc-fghhh
    May  2 00:21:17.496: INFO: Got endpoints: latency-svc-nltsc [750.248218ms]
    May  2 00:21:17.505: INFO: Created: latency-svc-4qllh
    May  2 00:21:17.543: INFO: Got endpoints: latency-svc-sx77m [747.411164ms]
    May  2 00:21:17.553: INFO: Created: latency-svc-68l7k
    May  2 00:21:17.595: INFO: Got endpoints: latency-svc-kml25 [749.102319ms]
    May  2 00:21:17.606: INFO: Created: latency-svc-hjc8m
    May  2 00:21:17.646: INFO: Got endpoints: latency-svc-nphwg [751.450487ms]
    May  2 00:21:17.655: INFO: Created: latency-svc-m89vs
    May  2 00:21:17.695: INFO: Got endpoints: latency-svc-vkq9d [751.897839ms]
    May  2 00:21:17.704: INFO: Created: latency-svc-zzdp6
    May  2 00:21:17.744: INFO: Got endpoints: latency-svc-xfr5j [750.65293ms]
    May  2 00:21:17.755: INFO: Created: latency-svc-k9wzp
    May  2 00:21:17.793: INFO: Got endpoints: latency-svc-h5hvs [749.277867ms]
    May  2 00:21:17.807: INFO: Created: latency-svc-pdb5q
    May  2 00:21:17.843: INFO: Got endpoints: latency-svc-sv7r8 [750.16855ms]
    May  2 00:21:17.853: INFO: Created: latency-svc-tkgxf
    May  2 00:21:17.893: INFO: Got endpoints: latency-svc-x6pqq [746.899172ms]
    May  2 00:21:17.903: INFO: Created: latency-svc-cx27v
    May  2 00:21:17.945: INFO: Got endpoints: latency-svc-nm86s [752.114597ms]
    May  2 00:21:17.955: INFO: Created: latency-svc-p9w4n
    May  2 00:21:17.993: INFO: Got endpoints: latency-svc-f6tc5 [749.956816ms]
    May  2 00:21:18.004: INFO: Created: latency-svc-chxwz
    May  2 00:21:18.047: INFO: Got endpoints: latency-svc-c5bwz [749.734695ms]
    May  2 00:21:18.057: INFO: Created: latency-svc-8b2kj
    May  2 00:21:18.094: INFO: Got endpoints: latency-svc-fghhh [739.063907ms]
    May  2 00:21:18.104: INFO: Created: latency-svc-kv58q
    May  2 00:21:18.143: INFO: Got endpoints: latency-svc-4qllh [747.891052ms]
    May  2 00:21:18.157: INFO: Created: latency-svc-62svs
    May  2 00:21:18.197: INFO: Got endpoints: latency-svc-68l7k [754.026204ms]
    May  2 00:21:18.205: INFO: Created: latency-svc-l9jvr
    May  2 00:21:18.246: INFO: Got endpoints: latency-svc-hjc8m [750.13548ms]
    May  2 00:21:18.255: INFO: Created: latency-svc-nn5p9
    May  2 00:21:18.299: INFO: Got endpoints: latency-svc-m89vs [755.657887ms]
    May  2 00:21:18.311: INFO: Created: latency-svc-5sl5t
    May  2 00:21:18.348: INFO: Got endpoints: latency-svc-zzdp6 [753.364447ms]
    May  2 00:21:18.359: INFO: Created: latency-svc-bmpvh
    May  2 00:21:18.393: INFO: Got endpoints: latency-svc-k9wzp [747.419137ms]
    May  2 00:21:18.410: INFO: Created: latency-svc-4llml
    May  2 00:21:18.444: INFO: Got endpoints: latency-svc-pdb5q [748.754162ms]
    May  2 00:21:18.458: INFO: Created: latency-svc-f2k5q
    May  2 00:21:18.494: INFO: Got endpoints: latency-svc-tkgxf [750.2058ms]
    May  2 00:21:18.506: INFO: Created: latency-svc-g2mhr
    May  2 00:21:18.545: INFO: Got endpoints: latency-svc-cx27v [752.411836ms]
    May  2 00:21:18.557: INFO: Created: latency-svc-m9m6x
    May  2 00:21:18.594: INFO: Got endpoints: latency-svc-p9w4n [750.539381ms]
    May  2 00:21:18.608: INFO: Created: latency-svc-zqbv9
    May  2 00:21:18.645: INFO: Got endpoints: latency-svc-chxwz [751.07764ms]
    May  2 00:21:18.658: INFO: Created: latency-svc-zm4ng
    May  2 00:21:18.693: INFO: Got endpoints: latency-svc-8b2kj [747.375524ms]
    May  2 00:21:18.704: INFO: Created: latency-svc-wtv7m
    May  2 00:21:18.747: INFO: Got endpoints: latency-svc-kv58q [753.577475ms]
    May  2 00:21:18.757: INFO: Created: latency-svc-rd9nn
    May  2 00:21:18.794: INFO: Got endpoints: latency-svc-62svs [747.066236ms]
    May  2 00:21:18.804: INFO: Created: latency-svc-znfjn
    May  2 00:21:18.844: INFO: Got endpoints: latency-svc-l9jvr [750.888733ms]
    May  2 00:21:18.856: INFO: Created: latency-svc-vtd86
    May  2 00:21:18.896: INFO: Got endpoints: latency-svc-nn5p9 [753.352829ms]
    May  2 00:21:18.905: INFO: Created: latency-svc-pdtxw
    May  2 00:21:18.943: INFO: Got endpoints: latency-svc-5sl5t [746.356276ms]
    May  2 00:21:18.954: INFO: Created: latency-svc-7bjjp
    May  2 00:21:18.994: INFO: Got endpoints: latency-svc-bmpvh [748.378095ms]
    May  2 00:21:19.006: INFO: Created: latency-svc-rq2p9
    May  2 00:21:19.043: INFO: Got endpoints: latency-svc-4llml [743.765377ms]
    May  2 00:21:19.056: INFO: Created: latency-svc-hxbsf
    May  2 00:21:19.094: INFO: Got endpoints: latency-svc-f2k5q [745.509293ms]
    May  2 00:21:19.105: INFO: Created: latency-svc-6csjg
    May  2 00:21:19.144: INFO: Got endpoints: latency-svc-g2mhr [750.679222ms]
    May  2 00:21:19.154: INFO: Created: latency-svc-5bhsg
    May  2 00:21:19.193: INFO: Got endpoints: latency-svc-m9m6x [749.283132ms]
    May  2 00:21:19.206: INFO: Created: latency-svc-vn7dk
    May  2 00:21:19.246: INFO: Got endpoints: latency-svc-zqbv9 [752.016859ms]
    May  2 00:21:19.255: INFO: Created: latency-svc-nrcqb
    May  2 00:21:19.294: INFO: Got endpoints: latency-svc-zm4ng [748.485878ms]
    May  2 00:21:19.314: INFO: Created: latency-svc-777xj
    May  2 00:21:19.348: INFO: Got endpoints: latency-svc-wtv7m [753.793028ms]
    May  2 00:21:19.361: INFO: Created: latency-svc-m64mt
    May  2 00:21:19.401: INFO: Got endpoints: latency-svc-rd9nn [755.881086ms]
    May  2 00:21:19.407: INFO: Created: latency-svc-p79wx
    May  2 00:21:19.446: INFO: Got endpoints: latency-svc-znfjn [753.019151ms]
    May  2 00:21:19.458: INFO: Created: latency-svc-fgdgj
    May  2 00:21:19.496: INFO: Got endpoints: latency-svc-vtd86 [748.997407ms]
    May  2 00:21:19.512: INFO: Created: latency-svc-dq9tr
    May  2 00:21:19.548: INFO: Got endpoints: latency-svc-pdtxw [754.092793ms]
    May  2 00:21:19.558: INFO: Created: latency-svc-vr4wt
    May  2 00:21:19.596: INFO: Got endpoints: latency-svc-7bjjp [751.110315ms]
    May  2 00:21:19.606: INFO: Created: latency-svc-tf9rz
    May  2 00:21:19.644: INFO: Got endpoints: latency-svc-rq2p9 [747.8828ms]
    May  2 00:21:19.658: INFO: Created: latency-svc-psfwc
    May  2 00:21:19.693: INFO: Got endpoints: latency-svc-hxbsf [749.520809ms]
    May  2 00:21:19.705: INFO: Created: latency-svc-rkhcc
    May  2 00:21:19.745: INFO: Got endpoints: latency-svc-6csjg [750.908009ms]
    May  2 00:21:19.759: INFO: Created: latency-svc-jqh5x
    May  2 00:21:19.793: INFO: Got endpoints: latency-svc-5bhsg [749.842471ms]
    May  2 00:21:19.803: INFO: Created: latency-svc-qsqjs
    May  2 00:21:19.843: INFO: Got endpoints: latency-svc-vn7dk [748.759796ms]
    May  2 00:21:19.855: INFO: Created: latency-svc-zbgdj
    May  2 00:21:19.896: INFO: Got endpoints: latency-svc-nrcqb [751.584155ms]
    May  2 00:21:19.905: INFO: Created: latency-svc-wrk7w
    May  2 00:21:19.943: INFO: Got endpoints: latency-svc-777xj [750.043256ms]
    May  2 00:21:19.954: INFO: Created: latency-svc-kj7dt
    May  2 00:21:19.997: INFO: Got endpoints: latency-svc-m64mt [750.299167ms]
    May  2 00:21:20.006: INFO: Created: latency-svc-xcqgg
    May  2 00:21:20.045: INFO: Got endpoints: latency-svc-p79wx [750.78075ms]
    May  2 00:21:20.056: INFO: Created: latency-svc-rjxd4
    May  2 00:21:20.095: INFO: Got endpoints: latency-svc-fgdgj [747.818885ms]
    May  2 00:21:20.106: INFO: Created: latency-svc-vcpzw
    May  2 00:21:20.143: INFO: Got endpoints: latency-svc-dq9tr [742.399528ms]
    May  2 00:21:20.161: INFO: Created: latency-svc-5696g
    May  2 00:21:20.193: INFO: Got endpoints: latency-svc-vr4wt [746.977771ms]
    May  2 00:21:20.206: INFO: Created: latency-svc-d5qw2
    May  2 00:21:20.243: INFO: Got endpoints: latency-svc-tf9rz [746.825505ms]
    May  2 00:21:20.252: INFO: Created: latency-svc-rclpw
    May  2 00:21:20.293: INFO: Got endpoints: latency-svc-psfwc [745.336844ms]
    May  2 00:21:20.306: INFO: Created: latency-svc-c6wg8
    May  2 00:21:20.354: INFO: Got endpoints: latency-svc-rkhcc [757.992818ms]
    May  2 00:21:20.366: INFO: Created: latency-svc-zmh9l
    May  2 00:21:20.402: INFO: Got endpoints: latency-svc-jqh5x [757.642518ms]
    May  2 00:21:20.408: INFO: Created: latency-svc-f6qgl
    May  2 00:21:20.446: INFO: Got endpoints: latency-svc-qsqjs [752.58374ms]
    May  2 00:21:20.463: INFO: Created: latency-svc-j76xt
    May  2 00:21:20.493: INFO: Got endpoints: latency-svc-zbgdj [747.851791ms]
    May  2 00:21:20.514: INFO: Created: latency-svc-f8k45
    May  2 00:21:20.545: INFO: Got endpoints: latency-svc-wrk7w [752.595031ms]
    May  2 00:21:20.555: INFO: Created: latency-svc-cklnq
    May  2 00:21:20.596: INFO: Got endpoints: latency-svc-kj7dt [753.096042ms]
    May  2 00:21:20.603: INFO: Created: latency-svc-jbx2t
    May  2 00:21:20.645: INFO: Got endpoints: latency-svc-xcqgg [749.609315ms]
    May  2 00:21:20.657: INFO: Created: latency-svc-8bglz
    May  2 00:21:20.693: INFO: Got endpoints: latency-svc-rjxd4 [749.640987ms]
    May  2 00:21:20.706: INFO: Created: latency-svc-bvmg2
    May  2 00:21:20.745: INFO: Got endpoints: latency-svc-vcpzw [748.100494ms]
    May  2 00:21:20.755: INFO: Created: latency-svc-zr92w
    May  2 00:21:20.797: INFO: Got endpoints: latency-svc-5696g [752.452427ms]
    May  2 00:21:20.808: INFO: Created: latency-svc-ntdfk
    May  2 00:21:20.845: INFO: Got endpoints: latency-svc-d5qw2 [749.540628ms]
    May  2 00:21:20.856: INFO: Created: latency-svc-tmnvw
    May  2 00:21:20.894: INFO: Got endpoints: latency-svc-rclpw [750.705223ms]
    May  2 00:21:20.911: INFO: Created: latency-svc-2q9dv
    May  2 00:21:20.944: INFO: Got endpoints: latency-svc-c6wg8 [750.958033ms]
    May  2 00:21:20.955: INFO: Created: latency-svc-spk5w
    May  2 00:21:20.997: INFO: Got endpoints: latency-svc-zmh9l [753.928357ms]
    May  2 00:21:21.005: INFO: Created: latency-svc-5d6j6
    May  2 00:21:21.046: INFO: Got endpoints: latency-svc-f6qgl [752.606072ms]
    May  2 00:21:21.055: INFO: Created: latency-svc-q85tq
    May  2 00:21:21.097: INFO: Got endpoints: latency-svc-j76xt [743.403868ms]
    May  2 00:21:21.108: INFO: Created: latency-svc-kn6j2
    May  2 00:21:21.143: INFO: Got endpoints: latency-svc-f8k45 [741.071862ms]
    May  2 00:21:21.156: INFO: Created: latency-svc-vqwpr
    May  2 00:21:21.195: INFO: Got endpoints: latency-svc-cklnq [749.684567ms]
    May  2 00:21:21.207: INFO: Created: latency-svc-m829f
    May  2 00:21:21.244: INFO: Got endpoints: latency-svc-jbx2t [750.540749ms]
    May  2 00:21:21.253: INFO: Created: latency-svc-9fhxl
    May  2 00:21:21.301: INFO: Got endpoints: latency-svc-8bglz [755.86769ms]
    May  2 00:21:21.348: INFO: Got endpoints: latency-svc-bvmg2 [751.837319ms]
    May  2 00:21:21.398: INFO: Got endpoints: latency-svc-zr92w [752.732155ms]
    May  2 00:21:21.444: INFO: Got endpoints: latency-svc-ntdfk [750.714709ms]
    May  2 00:21:21.499: INFO: Got endpoints: latency-svc-tmnvw [753.872639ms]
    May  2 00:21:21.545: INFO: Got endpoints: latency-svc-2q9dv [748.223122ms]
    May  2 00:21:21.596: INFO: Got endpoints: latency-svc-spk5w [750.818477ms]
    May  2 00:21:21.646: INFO: Got endpoints: latency-svc-5d6j6 [752.089036ms]
    May  2 00:21:21.693: INFO: Got endpoints: latency-svc-q85tq [749.549181ms]
    May  2 00:21:21.743: INFO: Got endpoints: latency-svc-kn6j2 [746.398881ms]
    May  2 00:21:21.793: INFO: Got endpoints: latency-svc-vqwpr [747.122388ms]
    May  2 00:21:21.844: INFO: Got endpoints: latency-svc-m829f [747.012008ms]
    May  2 00:21:21.893: INFO: Got endpoints: latency-svc-9fhxl [750.213001ms]
    May  2 00:21:21.893: INFO: Latencies: [121.008616ms 128.323535ms 143.592228ms 146.719443ms 152.414594ms 161.686744ms 162.728788ms 166.611379ms 167.348072ms 169.877252ms 170.160951ms 170.301019ms 172.774716ms 173.215419ms 174.132356ms 175.52168ms 178.603859ms 182.02971ms 182.482595ms 182.792892ms 183.031014ms 188.756548ms 191.958852ms 192.257993ms 198.60625ms 206.681842ms 223.941627ms 233.122133ms 234.808586ms 235.468281ms 236.824741ms 239.654187ms 243.907346ms 245.368114ms 248.735562ms 266.364029ms 281.137227ms 284.344854ms 294.204586ms 316.252984ms 318.601847ms 319.618328ms 332.929344ms 344.342971ms 355.782566ms 398.933586ms 437.695183ms 473.157443ms 511.316223ms 548.749328ms 583.000277ms 610.045965ms 648.709838ms 680.362007ms 710.800027ms 735.691545ms 735.827406ms 737.260709ms 737.87982ms 739.063907ms 741.071862ms 742.399528ms 743.403868ms 743.765377ms 744.376543ms 744.408183ms 744.690852ms 744.69127ms 745.336844ms 745.509293ms 746.230006ms 746.356276ms 746.398881ms 746.518108ms 746.825505ms 746.899172ms 746.977771ms 747.012008ms 747.066236ms 747.122388ms 747.130331ms 747.375524ms 747.411164ms 747.419137ms 747.427063ms 747.664101ms 747.723452ms 747.801406ms 747.818885ms 747.851791ms 747.8828ms 747.891052ms 747.930392ms 748.100494ms 748.104168ms 748.223122ms 748.355956ms 748.378095ms 748.485878ms 748.491253ms 748.594543ms 748.754162ms 748.759796ms 748.778578ms 748.926164ms 748.929388ms 748.981585ms 748.997407ms 749.102319ms 749.169309ms 749.277867ms 749.283132ms 749.41005ms 749.435757ms 749.472587ms 749.520809ms 749.528998ms 749.53742ms 749.540628ms 749.549181ms 749.609315ms 749.640987ms 749.676076ms 749.684567ms 749.734695ms 749.786039ms 749.842471ms 749.956816ms 750.043256ms 750.13548ms 750.16855ms 750.2058ms 750.213001ms 750.248218ms 750.299167ms 750.393007ms 750.539381ms 750.540749ms 750.65293ms 750.679222ms 750.705223ms 750.714709ms 750.78075ms 750.786252ms 750.818477ms 750.888733ms 750.908009ms 750.958033ms 751.040767ms 751.07764ms 751.110315ms 751.119043ms 751.293288ms 751.342905ms 751.426342ms 751.450487ms 751.584155ms 751.589604ms 751.651919ms 751.792064ms 751.810522ms 751.837319ms 751.897839ms 752.016859ms 752.089036ms 752.114597ms 752.343629ms 752.345754ms 752.411836ms 752.419892ms 752.452427ms 752.58374ms 752.595031ms 752.606072ms 752.732155ms 752.777245ms 752.822649ms 753.019151ms 753.096042ms 753.352829ms 753.364447ms 753.577475ms 753.729501ms 753.793028ms 753.872639ms 753.928357ms 754.025502ms 754.026204ms 754.092793ms 755.657887ms 755.86769ms 755.881086ms 756.583968ms 757.642518ms 757.810096ms 757.992818ms 760.354372ms 762.110423ms 765.088228ms 766.3465ms]
    May  2 00:21:21.893: INFO: 50 %ile: 748.594543ms
    May  2 00:21:21.893: INFO: 90 %ile: 753.364447ms
    May  2 00:21:21.893: INFO: 99 %ile: 765.088228ms
    May  2 00:21:21.893: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    May  2 00:21:21.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-378" for this suite. 05/02/23 00:21:22.001
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:21:22.109
May  2 00:21:22.109: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/02/23 00:21:22.111
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:22.423
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:22.629
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e in namespace container-probe-833 05/02/23 00:21:22.835
May  2 00:21:22.943: INFO: Waiting up to 5m0s for pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e" in namespace "container-probe-833" to be "not pending"
May  2 00:21:23.047: INFO: Pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e": Phase="Pending", Reason="", readiness=false. Elapsed: 103.631506ms
May  2 00:21:25.151: INFO: Pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.208474321s
May  2 00:21:25.151: INFO: Pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e" satisfied condition "not pending"
May  2 00:21:25.152: INFO: Started pod busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e in namespace container-probe-833
STEP: checking the pod's current state and verifying that restartCount is present 05/02/23 00:21:25.152
May  2 00:21:25.255: INFO: Initial restart count of pod busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e is 0
May  2 00:22:13.771: INFO: Restart count of pod container-probe-833/busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e is now 1 (48.515389646s elapsed)
STEP: deleting the pod 05/02/23 00:22:13.771
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  2 00:22:13.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-833" for this suite. 05/02/23 00:22:13.985
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":329,"skipped":6368,"failed":0}
------------------------------
• [SLOW TEST] [52.081 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:21:22.109
    May  2 00:21:22.109: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/02/23 00:21:22.111
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:21:22.423
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:21:22.629
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e in namespace container-probe-833 05/02/23 00:21:22.835
    May  2 00:21:22.943: INFO: Waiting up to 5m0s for pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e" in namespace "container-probe-833" to be "not pending"
    May  2 00:21:23.047: INFO: Pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e": Phase="Pending", Reason="", readiness=false. Elapsed: 103.631506ms
    May  2 00:21:25.151: INFO: Pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.208474321s
    May  2 00:21:25.151: INFO: Pod "busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e" satisfied condition "not pending"
    May  2 00:21:25.152: INFO: Started pod busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e in namespace container-probe-833
    STEP: checking the pod's current state and verifying that restartCount is present 05/02/23 00:21:25.152
    May  2 00:21:25.255: INFO: Initial restart count of pod busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e is 0
    May  2 00:22:13.771: INFO: Restart count of pod container-probe-833/busybox-0f035437-499f-46af-9dc7-0a08fc6dfa6e is now 1 (48.515389646s elapsed)
    STEP: deleting the pod 05/02/23 00:22:13.771
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  2 00:22:13.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-833" for this suite. 05/02/23 00:22:13.985
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:22:14.191
May  2 00:22:14.191: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:22:14.193
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:22:14.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:22:14.711
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 05/02/23 00:22:14.917
May  2 00:22:15.026: INFO: Waiting up to 5m0s for pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7" in namespace "projected-317" to be "running and ready"
May  2 00:22:15.129: INFO: Pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.430034ms
May  2 00:22:15.129: INFO: The phase of Pod labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:22:17.234: INFO: Pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7": Phase="Running", Reason="", readiness=true. Elapsed: 2.20845345s
May  2 00:22:17.234: INFO: The phase of Pod labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7 is Running (Ready = true)
May  2 00:22:17.234: INFO: Pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7" satisfied condition "running and ready"
May  2 00:22:18.155: INFO: Successfully updated pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  2 00:22:20.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-317" for this suite. 05/02/23 00:22:20.473
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":330,"skipped":6385,"failed":0}
------------------------------
• [SLOW TEST] [6.387 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:22:14.191
    May  2 00:22:14.191: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:22:14.193
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:22:14.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:22:14.711
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 05/02/23 00:22:14.917
    May  2 00:22:15.026: INFO: Waiting up to 5m0s for pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7" in namespace "projected-317" to be "running and ready"
    May  2 00:22:15.129: INFO: Pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.430034ms
    May  2 00:22:15.129: INFO: The phase of Pod labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:22:17.234: INFO: Pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7": Phase="Running", Reason="", readiness=true. Elapsed: 2.20845345s
    May  2 00:22:17.234: INFO: The phase of Pod labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7 is Running (Ready = true)
    May  2 00:22:17.234: INFO: Pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7" satisfied condition "running and ready"
    May  2 00:22:18.155: INFO: Successfully updated pod "labelsupdate1644725a-4121-4b0e-9f9d-04c740b995f7"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  2 00:22:20.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-317" for this suite. 05/02/23 00:22:20.473
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:22:20.578
May  2 00:22:20.579: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-preemption 05/02/23 00:22:20.579
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:22:20.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:22:21.097
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May  2 00:22:21.618: INFO: Waiting up to 1m0s for all nodes to be ready
May  2 00:23:22.358: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:23:22.462
May  2 00:23:22.462: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-preemption-path 05/02/23 00:23:22.463
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:23:22.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:23:22.981
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 05/02/23 00:23:23.187
STEP: Trying to launch a pod without a label to get a node which can launch it. 05/02/23 00:23:23.187
May  2 00:23:23.295: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8088" to be "running"
May  2 00:23:23.399: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 104.010159ms
May  2 00:23:25.503: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.208070066s
May  2 00:23:25.503: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 05/02/23 00:23:25.609
May  2 00:23:25.721: INFO: found a healthy node: i-02d061b30635c230c
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
May  2 00:23:37.297: INFO: pods created so far: [1 1 1]
May  2 00:23:37.297: INFO: length of pods created so far: 3
May  2 00:23:39.508: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
May  2 00:23:46.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8088" for this suite. 05/02/23 00:23:46.615
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
May  2 00:23:47.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5868" for this suite. 05/02/23 00:23:47.358
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":331,"skipped":6386,"failed":0}
------------------------------
• [SLOW TEST] [87.634 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:22:20.578
    May  2 00:22:20.579: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-preemption 05/02/23 00:22:20.579
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:22:20.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:22:21.097
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    May  2 00:22:21.618: INFO: Waiting up to 1m0s for all nodes to be ready
    May  2 00:23:22.358: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:23:22.462
    May  2 00:23:22.462: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-preemption-path 05/02/23 00:23:22.463
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:23:22.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:23:22.981
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 05/02/23 00:23:23.187
    STEP: Trying to launch a pod without a label to get a node which can launch it. 05/02/23 00:23:23.187
    May  2 00:23:23.295: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8088" to be "running"
    May  2 00:23:23.399: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 104.010159ms
    May  2 00:23:25.503: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.208070066s
    May  2 00:23:25.503: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 05/02/23 00:23:25.609
    May  2 00:23:25.721: INFO: found a healthy node: i-02d061b30635c230c
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    May  2 00:23:37.297: INFO: pods created so far: [1 1 1]
    May  2 00:23:37.297: INFO: length of pods created so far: 3
    May  2 00:23:39.508: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    May  2 00:23:46.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-8088" for this suite. 05/02/23 00:23:46.615
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:23:47.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5868" for this suite. 05/02/23 00:23:47.358
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:23:48.214
May  2 00:23:48.215: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/02/23 00:23:48.216
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:23:48.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:23:48.734
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-2640fa0a-d506-4a13-be7a-f2bbd58e5e40 05/02/23 00:23:48.939
STEP: Creating a pod to test consume secrets 05/02/23 00:23:49.045
May  2 00:23:49.152: INFO: Waiting up to 5m0s for pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07" in namespace "secrets-8887" to be "Succeeded or Failed"
May  2 00:23:49.256: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07": Phase="Pending", Reason="", readiness=false. Elapsed: 103.807765ms
May  2 00:23:51.359: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207739019s
May  2 00:23:53.360: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207947715s
STEP: Saw pod success 05/02/23 00:23:53.36
May  2 00:23:53.360: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07" satisfied condition "Succeeded or Failed"
May  2 00:23:53.463: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07 container secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:23:53.574
May  2 00:23:53.687: INFO: Waiting for pod pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07 to disappear
May  2 00:23:53.790: INFO: Pod pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  2 00:23:53.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8887" for this suite. 05/02/23 00:23:53.895
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":332,"skipped":6404,"failed":0}
------------------------------
• [SLOW TEST] [5.886 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:23:48.214
    May  2 00:23:48.215: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/02/23 00:23:48.216
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:23:48.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:23:48.734
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-2640fa0a-d506-4a13-be7a-f2bbd58e5e40 05/02/23 00:23:48.939
    STEP: Creating a pod to test consume secrets 05/02/23 00:23:49.045
    May  2 00:23:49.152: INFO: Waiting up to 5m0s for pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07" in namespace "secrets-8887" to be "Succeeded or Failed"
    May  2 00:23:49.256: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07": Phase="Pending", Reason="", readiness=false. Elapsed: 103.807765ms
    May  2 00:23:51.359: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207739019s
    May  2 00:23:53.360: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207947715s
    STEP: Saw pod success 05/02/23 00:23:53.36
    May  2 00:23:53.360: INFO: Pod "pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07" satisfied condition "Succeeded or Failed"
    May  2 00:23:53.463: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07 container secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:23:53.574
    May  2 00:23:53.687: INFO: Waiting for pod pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07 to disappear
    May  2 00:23:53.790: INFO: Pod pod-secrets-c9f3cb8a-2852-485e-ae31-960114ebbb07 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  2 00:23:53.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8887" for this suite. 05/02/23 00:23:53.895
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:23:54.101
May  2 00:23:54.101: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook 05/02/23 00:23:54.102
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:23:54.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:23:54.621
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 05/02/23 00:23:54.932
May  2 00:23:55.038: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9252" to be "running and ready"
May  2 00:23:55.141: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 103.495347ms
May  2 00:23:55.141: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
May  2 00:23:57.246: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.208315886s
May  2 00:23:57.246: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
May  2 00:23:57.246: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 05/02/23 00:23:57.35
May  2 00:23:57.457: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-9252" to be "running and ready"
May  2 00:23:57.560: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 103.615001ms
May  2 00:23:57.561: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
May  2 00:23:59.666: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.209129685s
May  2 00:23:59.666: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
May  2 00:23:59.666: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 05/02/23 00:23:59.77
STEP: delete the pod with lifecycle hook 05/02/23 00:23:59.883
May  2 00:23:59.989: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  2 00:24:00.093: INFO: Pod pod-with-poststart-http-hook still exists
May  2 00:24:02.094: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  2 00:24:02.198: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
May  2 00:24:02.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9252" for this suite. 05/02/23 00:24:02.303
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":333,"skipped":6404,"failed":0}
------------------------------
• [SLOW TEST] [8.308 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:23:54.101
    May  2 00:23:54.101: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-lifecycle-hook 05/02/23 00:23:54.102
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:23:54.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:23:54.621
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 05/02/23 00:23:54.932
    May  2 00:23:55.038: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9252" to be "running and ready"
    May  2 00:23:55.141: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 103.495347ms
    May  2 00:23:55.141: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:23:57.246: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.208315886s
    May  2 00:23:57.246: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    May  2 00:23:57.246: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 05/02/23 00:23:57.35
    May  2 00:23:57.457: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-9252" to be "running and ready"
    May  2 00:23:57.560: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 103.615001ms
    May  2 00:23:57.561: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:23:59.666: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.209129685s
    May  2 00:23:59.666: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    May  2 00:23:59.666: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 05/02/23 00:23:59.77
    STEP: delete the pod with lifecycle hook 05/02/23 00:23:59.883
    May  2 00:23:59.989: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    May  2 00:24:00.093: INFO: Pod pod-with-poststart-http-hook still exists
    May  2 00:24:02.094: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    May  2 00:24:02.198: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    May  2 00:24:02.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9252" for this suite. 05/02/23 00:24:02.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:24:02.41
May  2 00:24:02.410: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset 05/02/23 00:24:02.411
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:24:02.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:24:02.929
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9828 05/02/23 00:24:03.135
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 05/02/23 00:24:03.24
May  2 00:24:03.449: INFO: Found 1 stateful pods, waiting for 3
May  2 00:24:13.555: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:24:13.555: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:24:13.556: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May  2 00:24:13.867: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 00:24:15.019: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 00:24:15.019: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 00:24:15.019: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 05/02/23 00:24:25.435
May  2 00:24:25.659: INFO: Updating stateful set ss2
STEP: Creating a new revision 05/02/23 00:24:25.659
STEP: Updating Pods in reverse ordinal order 05/02/23 00:24:25.867
May  2 00:24:25.972: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 00:24:27.148: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 00:24:27.148: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 00:24:27.148: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  2 00:24:27.565: INFO: Waiting for StatefulSet statefulset-9828/ss2 to complete update
May  2 00:24:27.565: INFO: Waiting for Pod statefulset-9828/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
May  2 00:24:27.565: INFO: Waiting for Pod statefulset-9828/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
May  2 00:24:27.565: INFO: Waiting for Pod statefulset-9828/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Rolling back to a previous revision 05/02/23 00:24:37.777
May  2 00:24:37.777: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  2 00:24:38.902: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  2 00:24:38.902: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  2 00:24:38.902: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  2 00:24:49.539: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 05/02/23 00:24:49.747
May  2 00:24:49.851: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  2 00:24:50.982: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  2 00:24:50.982: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  2 00:24:50.982: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
May  2 00:25:01.607: INFO: Deleting all statefulset in ns statefulset-9828
May  2 00:25:01.710: INFO: Scaling statefulset ss2 to 0
May  2 00:25:12.127: INFO: Waiting for statefulset status.replicas updated to 0
May  2 00:25:12.230: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
May  2 00:25:12.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9828" for this suite. 05/02/23 00:25:12.646
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":334,"skipped":6411,"failed":0}
------------------------------
• [SLOW TEST] [70.342 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:24:02.41
    May  2 00:24:02.410: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename statefulset 05/02/23 00:24:02.411
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:24:02.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:24:02.929
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9828 05/02/23 00:24:03.135
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 05/02/23 00:24:03.24
    May  2 00:24:03.449: INFO: Found 1 stateful pods, waiting for 3
    May  2 00:24:13.555: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:24:13.555: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:24:13.556: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    May  2 00:24:13.867: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  2 00:24:15.019: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  2 00:24:15.019: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  2 00:24:15.019: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 05/02/23 00:24:25.435
    May  2 00:24:25.659: INFO: Updating stateful set ss2
    STEP: Creating a new revision 05/02/23 00:24:25.659
    STEP: Updating Pods in reverse ordinal order 05/02/23 00:24:25.867
    May  2 00:24:25.972: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  2 00:24:27.148: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    May  2 00:24:27.148: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  2 00:24:27.148: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    May  2 00:24:27.565: INFO: Waiting for StatefulSet statefulset-9828/ss2 to complete update
    May  2 00:24:27.565: INFO: Waiting for Pod statefulset-9828/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    May  2 00:24:27.565: INFO: Waiting for Pod statefulset-9828/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    May  2 00:24:27.565: INFO: Waiting for Pod statefulset-9828/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Rolling back to a previous revision 05/02/23 00:24:37.777
    May  2 00:24:37.777: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    May  2 00:24:38.902: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    May  2 00:24:38.902: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    May  2 00:24:38.902: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    May  2 00:24:49.539: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 05/02/23 00:24:49.747
    May  2 00:24:49.851: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=statefulset-9828 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    May  2 00:24:50.982: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    May  2 00:24:50.982: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    May  2 00:24:50.982: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    May  2 00:25:01.607: INFO: Deleting all statefulset in ns statefulset-9828
    May  2 00:25:01.710: INFO: Scaling statefulset ss2 to 0
    May  2 00:25:12.127: INFO: Waiting for statefulset status.replicas updated to 0
    May  2 00:25:12.230: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    May  2 00:25:12.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9828" for this suite. 05/02/23 00:25:12.646
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:25:12.753
May  2 00:25:12.753: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/02/23 00:25:12.754
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:25:13.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:25:13.271
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee in namespace container-probe-2455 05/02/23 00:25:13.477
May  2 00:25:13.586: INFO: Waiting up to 5m0s for pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee" in namespace "container-probe-2455" to be "not pending"
May  2 00:25:13.689: INFO: Pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee": Phase="Pending", Reason="", readiness=false. Elapsed: 103.363543ms
May  2 00:25:15.793: INFO: Pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee": Phase="Running", Reason="", readiness=true. Elapsed: 2.2075352s
May  2 00:25:15.793: INFO: Pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee" satisfied condition "not pending"
May  2 00:25:15.793: INFO: Started pod liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee in namespace container-probe-2455
STEP: checking the pod's current state and verifying that restartCount is present 05/02/23 00:25:15.793
May  2 00:25:15.897: INFO: Initial restart count of pod liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is 0
May  2 00:25:34.944: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 1 (19.046524312s elapsed)
May  2 00:25:55.986: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 2 (40.088540402s elapsed)
May  2 00:26:14.925: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 3 (59.028380963s elapsed)
May  2 00:26:35.967: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 4 (1m20.070464037s elapsed)
May  2 00:27:45.414: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 5 (2m29.516995228s elapsed)
STEP: deleting the pod 05/02/23 00:27:45.414
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  2 00:27:45.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2455" for this suite. 05/02/23 00:27:45.633
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":335,"skipped":6427,"failed":0}
------------------------------
• [SLOW TEST] [152.986 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:25:12.753
    May  2 00:25:12.753: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/02/23 00:25:12.754
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:25:13.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:25:13.271
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee in namespace container-probe-2455 05/02/23 00:25:13.477
    May  2 00:25:13.586: INFO: Waiting up to 5m0s for pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee" in namespace "container-probe-2455" to be "not pending"
    May  2 00:25:13.689: INFO: Pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee": Phase="Pending", Reason="", readiness=false. Elapsed: 103.363543ms
    May  2 00:25:15.793: INFO: Pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee": Phase="Running", Reason="", readiness=true. Elapsed: 2.2075352s
    May  2 00:25:15.793: INFO: Pod "liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee" satisfied condition "not pending"
    May  2 00:25:15.793: INFO: Started pod liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee in namespace container-probe-2455
    STEP: checking the pod's current state and verifying that restartCount is present 05/02/23 00:25:15.793
    May  2 00:25:15.897: INFO: Initial restart count of pod liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is 0
    May  2 00:25:34.944: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 1 (19.046524312s elapsed)
    May  2 00:25:55.986: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 2 (40.088540402s elapsed)
    May  2 00:26:14.925: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 3 (59.028380963s elapsed)
    May  2 00:26:35.967: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 4 (1m20.070464037s elapsed)
    May  2 00:27:45.414: INFO: Restart count of pod container-probe-2455/liveness-54675105-3a0d-4491-8755-5cfe0b73b6ee is now 5 (2m29.516995228s elapsed)
    STEP: deleting the pod 05/02/23 00:27:45.414
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  2 00:27:45.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2455" for this suite. 05/02/23 00:27:45.633
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:27:45.739
May  2 00:27:45.739: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:27:45.74
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:46.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:46.257
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 05/02/23 00:27:46.47
May  2 00:27:46.470: INFO: Asynchronously running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-1150 proxy --unix-socket=/tmp/kubectl-proxy-unix4138844561/test'
STEP: retrieving proxy /api/ output 05/02/23 00:27:46.533
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:27:46.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1150" for this suite. 05/02/23 00:27:46.639
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":336,"skipped":6428,"failed":0}
------------------------------
• [1.006 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:27:45.739
    May  2 00:27:45.739: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:27:45.74
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:46.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:46.257
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 05/02/23 00:27:46.47
    May  2 00:27:46.470: INFO: Asynchronously running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl /home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-1150 proxy --unix-socket=/tmp/kubectl-proxy-unix4138844561/test'
    STEP: retrieving proxy /api/ output 05/02/23 00:27:46.533
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:27:46.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1150" for this suite. 05/02/23 00:27:46.639
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:27:46.745
May  2 00:27:46.745: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:27:46.746
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:47.058
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:47.264
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-a68fb805-2d4d-4176-a7da-e87d45ac53fa 05/02/23 00:27:47.47
STEP: Creating a pod to test consume configMaps 05/02/23 00:27:47.575
May  2 00:27:47.682: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a" in namespace "projected-4647" to be "Succeeded or Failed"
May  2 00:27:47.786: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a": Phase="Pending", Reason="", readiness=false. Elapsed: 103.521816ms
May  2 00:27:49.890: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207462736s
May  2 00:27:51.892: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209426194s
STEP: Saw pod success 05/02/23 00:27:51.892
May  2 00:27:51.892: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a" satisfied condition "Succeeded or Failed"
May  2 00:27:51.996: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a container agnhost-container: <nil>
STEP: delete the pod 05/02/23 00:27:52.109
May  2 00:27:52.219: INFO: Waiting for pod pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a to disappear
May  2 00:27:52.322: INFO: Pod pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  2 00:27:52.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4647" for this suite. 05/02/23 00:27:52.427
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":337,"skipped":6432,"failed":0}
------------------------------
• [SLOW TEST] [5.787 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:27:46.745
    May  2 00:27:46.745: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:27:46.746
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:47.058
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:47.264
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-a68fb805-2d4d-4176-a7da-e87d45ac53fa 05/02/23 00:27:47.47
    STEP: Creating a pod to test consume configMaps 05/02/23 00:27:47.575
    May  2 00:27:47.682: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a" in namespace "projected-4647" to be "Succeeded or Failed"
    May  2 00:27:47.786: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a": Phase="Pending", Reason="", readiness=false. Elapsed: 103.521816ms
    May  2 00:27:49.890: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207462736s
    May  2 00:27:51.892: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.209426194s
    STEP: Saw pod success 05/02/23 00:27:51.892
    May  2 00:27:51.892: INFO: Pod "pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a" satisfied condition "Succeeded or Failed"
    May  2 00:27:51.996: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a container agnhost-container: <nil>
    STEP: delete the pod 05/02/23 00:27:52.109
    May  2 00:27:52.219: INFO: Waiting for pod pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a to disappear
    May  2 00:27:52.322: INFO: Pod pod-projected-configmaps-1d2f8834-95e4-48c2-ac97-39d8bb47970a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  2 00:27:52.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4647" for this suite. 05/02/23 00:27:52.427
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:27:52.533
May  2 00:27:52.533: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition 05/02/23 00:27:52.534
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:52.846
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:53.051
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
May  2 00:27:53.257: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:27:53.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1094" for this suite. 05/02/23 00:27:54.099
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":338,"skipped":6445,"failed":0}
------------------------------
• [1.672 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:27:52.533
    May  2 00:27:52.533: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename custom-resource-definition 05/02/23 00:27:52.534
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:52.846
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:53.051
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    May  2 00:27:53.257: INFO: >>> kubeConfig: /root/.kube/config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:27:53.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1094" for this suite. 05/02/23 00:27:54.099
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:27:54.205
May  2 00:27:54.205: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods 05/02/23 00:27:54.206
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:54.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:54.723
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
May  2 00:27:55.035: INFO: Waiting up to 5m0s for pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc" in namespace "pods-7994" to be "running and ready"
May  2 00:27:55.138: INFO: Pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 103.448765ms
May  2 00:27:55.138: INFO: The phase of Pod server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc is Pending, waiting for it to be Running (with Ready = true)
May  2 00:27:57.243: INFO: Pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc": Phase="Running", Reason="", readiness=true. Elapsed: 2.207967848s
May  2 00:27:57.243: INFO: The phase of Pod server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc is Running (Ready = true)
May  2 00:27:57.243: INFO: Pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc" satisfied condition "running and ready"
May  2 00:27:57.564: INFO: Waiting up to 5m0s for pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466" in namespace "pods-7994" to be "Succeeded or Failed"
May  2 00:27:57.667: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466": Phase="Pending", Reason="", readiness=false. Elapsed: 103.650577ms
May  2 00:27:59.773: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209018532s
May  2 00:28:01.771: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20775859s
STEP: Saw pod success 05/02/23 00:28:01.771
May  2 00:28:01.772: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466" satisfied condition "Succeeded or Failed"
May  2 00:28:01.875: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466 container env3cont: <nil>
STEP: delete the pod 05/02/23 00:28:01.984
May  2 00:28:02.095: INFO: Waiting for pod client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466 to disappear
May  2 00:28:02.198: INFO: Pod client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
May  2 00:28:02.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7994" for this suite. 05/02/23 00:28:02.303
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":339,"skipped":6450,"failed":0}
------------------------------
• [SLOW TEST] [8.304 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:27:54.205
    May  2 00:27:54.205: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename pods 05/02/23 00:27:54.206
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:27:54.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:27:54.723
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    May  2 00:27:55.035: INFO: Waiting up to 5m0s for pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc" in namespace "pods-7994" to be "running and ready"
    May  2 00:27:55.138: INFO: Pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 103.448765ms
    May  2 00:27:55.138: INFO: The phase of Pod server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:27:57.243: INFO: Pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc": Phase="Running", Reason="", readiness=true. Elapsed: 2.207967848s
    May  2 00:27:57.243: INFO: The phase of Pod server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc is Running (Ready = true)
    May  2 00:27:57.243: INFO: Pod "server-envvars-3eb8a510-866a-4a84-babd-9b0136cb3ddc" satisfied condition "running and ready"
    May  2 00:27:57.564: INFO: Waiting up to 5m0s for pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466" in namespace "pods-7994" to be "Succeeded or Failed"
    May  2 00:27:57.667: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466": Phase="Pending", Reason="", readiness=false. Elapsed: 103.650577ms
    May  2 00:27:59.773: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209018532s
    May  2 00:28:01.771: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.20775859s
    STEP: Saw pod success 05/02/23 00:28:01.771
    May  2 00:28:01.772: INFO: Pod "client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466" satisfied condition "Succeeded or Failed"
    May  2 00:28:01.875: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466 container env3cont: <nil>
    STEP: delete the pod 05/02/23 00:28:01.984
    May  2 00:28:02.095: INFO: Waiting for pod client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466 to disappear
    May  2 00:28:02.198: INFO: Pod client-envvars-089e41b9-97a2-4bc0-bf0e-63ec2bf27466 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    May  2 00:28:02.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7994" for this suite. 05/02/23 00:28:02.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:02.509
May  2 00:28:02.509: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/02/23 00:28:02.51
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:02.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:03.027
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:28:03.233
May  2 00:28:03.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1" in namespace "downward-api-6589" to be "Succeeded or Failed"
May  2 00:28:03.444: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.511585ms
May  2 00:28:05.551: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210108741s
May  2 00:28:07.555: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.214525908s
STEP: Saw pod success 05/02/23 00:28:07.556
May  2 00:28:07.556: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1" satisfied condition "Succeeded or Failed"
May  2 00:28:07.661: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1 container client-container: <nil>
STEP: delete the pod 05/02/23 00:28:07.768
May  2 00:28:07.885: INFO: Waiting for pod downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1 to disappear
May  2 00:28:07.988: INFO: Pod downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  2 00:28:07.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6589" for this suite. 05/02/23 00:28:08.093
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":340,"skipped":6455,"failed":0}
------------------------------
• [SLOW TEST] [5.690 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:02.509
    May  2 00:28:02.509: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/02/23 00:28:02.51
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:02.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:03.027
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:28:03.233
    May  2 00:28:03.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1" in namespace "downward-api-6589" to be "Succeeded or Failed"
    May  2 00:28:03.444: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1": Phase="Pending", Reason="", readiness=false. Elapsed: 103.511585ms
    May  2 00:28:05.551: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.210108741s
    May  2 00:28:07.555: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.214525908s
    STEP: Saw pod success 05/02/23 00:28:07.556
    May  2 00:28:07.556: INFO: Pod "downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1" satisfied condition "Succeeded or Failed"
    May  2 00:28:07.661: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1 container client-container: <nil>
    STEP: delete the pod 05/02/23 00:28:07.768
    May  2 00:28:07.885: INFO: Waiting for pod downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1 to disappear
    May  2 00:28:07.988: INFO: Pod downwardapi-volume-c6a3239f-22a2-45fd-988e-1bc17c076ee1 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  2 00:28:07.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6589" for this suite. 05/02/23 00:28:08.093
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:08.201
May  2 00:28:08.201: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:28:08.203
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:08.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:08.72
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 05/02/23 00:28:08.925
May  2 00:28:09.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7" in namespace "projected-407" to be "Succeeded or Failed"
May  2 00:28:09.135: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.308517ms
May  2 00:28:11.240: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20860235s
May  2 00:28:13.240: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208388494s
STEP: Saw pod success 05/02/23 00:28:13.24
May  2 00:28:13.241: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7" satisfied condition "Succeeded or Failed"
May  2 00:28:13.345: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7 container client-container: <nil>
STEP: delete the pod 05/02/23 00:28:13.451
May  2 00:28:13.563: INFO: Waiting for pod downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7 to disappear
May  2 00:28:13.666: INFO: Pod downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  2 00:28:13.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-407" for this suite. 05/02/23 00:28:13.771
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":341,"skipped":6488,"failed":0}
------------------------------
• [SLOW TEST] [5.775 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:08.201
    May  2 00:28:08.201: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:28:08.203
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:08.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:08.72
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 05/02/23 00:28:08.925
    May  2 00:28:09.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7" in namespace "projected-407" to be "Succeeded or Failed"
    May  2 00:28:09.135: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.308517ms
    May  2 00:28:11.240: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20860235s
    May  2 00:28:13.240: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208388494s
    STEP: Saw pod success 05/02/23 00:28:13.24
    May  2 00:28:13.241: INFO: Pod "downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7" satisfied condition "Succeeded or Failed"
    May  2 00:28:13.345: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7 container client-container: <nil>
    STEP: delete the pod 05/02/23 00:28:13.451
    May  2 00:28:13.563: INFO: Waiting for pod downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7 to disappear
    May  2 00:28:13.666: INFO: Pod downwardapi-volume-03cf3fb9-a719-4522-b994-383c5cef46b7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  2 00:28:13.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-407" for this suite. 05/02/23 00:28:13.771
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:13.977
May  2 00:28:13.977: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers 05/02/23 00:28:13.978
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:14.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:14.496
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 05/02/23 00:28:14.701
May  2 00:28:14.808: INFO: Waiting up to 5m0s for pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a" in namespace "containers-3186" to be "Succeeded or Failed"
May  2 00:28:14.911: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a": Phase="Pending", Reason="", readiness=false. Elapsed: 103.238331ms
May  2 00:28:17.015: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207418969s
May  2 00:28:19.015: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207236688s
STEP: Saw pod success 05/02/23 00:28:19.015
May  2 00:28:19.015: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a" satisfied condition "Succeeded or Failed"
May  2 00:28:19.119: INFO: Trying to get logs from node i-02d061b30635c230c pod client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a container agnhost-container: <nil>
STEP: delete the pod 05/02/23 00:28:19.231
May  2 00:28:19.343: INFO: Waiting for pod client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a to disappear
May  2 00:28:19.446: INFO: Pod client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
May  2 00:28:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3186" for this suite. 05/02/23 00:28:19.551
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":342,"skipped":6495,"failed":0}
------------------------------
• [SLOW TEST] [5.680 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:13.977
    May  2 00:28:13.977: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename containers 05/02/23 00:28:13.978
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:14.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:14.496
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 05/02/23 00:28:14.701
    May  2 00:28:14.808: INFO: Waiting up to 5m0s for pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a" in namespace "containers-3186" to be "Succeeded or Failed"
    May  2 00:28:14.911: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a": Phase="Pending", Reason="", readiness=false. Elapsed: 103.238331ms
    May  2 00:28:17.015: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207418969s
    May  2 00:28:19.015: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207236688s
    STEP: Saw pod success 05/02/23 00:28:19.015
    May  2 00:28:19.015: INFO: Pod "client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a" satisfied condition "Succeeded or Failed"
    May  2 00:28:19.119: INFO: Trying to get logs from node i-02d061b30635c230c pod client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a container agnhost-container: <nil>
    STEP: delete the pod 05/02/23 00:28:19.231
    May  2 00:28:19.343: INFO: Waiting for pod client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a to disappear
    May  2 00:28:19.446: INFO: Pod client-containers-8d126408-8c38-4268-89c9-d14e01ae0c1a no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    May  2 00:28:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3186" for this suite. 05/02/23 00:28:19.551
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:19.659
May  2 00:28:19.659: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/02/23 00:28:19.66
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:19.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:20.177
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-75429312-63ae-4cc1-89bf-d92a73a1f0b1 05/02/23 00:28:20.382
STEP: Creating a pod to test consume secrets 05/02/23 00:28:20.487
May  2 00:28:20.594: INFO: Waiting up to 5m0s for pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de" in namespace "secrets-8060" to be "Succeeded or Failed"
May  2 00:28:20.698: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de": Phase="Pending", Reason="", readiness=false. Elapsed: 103.388384ms
May  2 00:28:22.802: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207394001s
May  2 00:28:24.802: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207766091s
STEP: Saw pod success 05/02/23 00:28:24.802
May  2 00:28:24.802: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de" satisfied condition "Succeeded or Failed"
May  2 00:28:24.906: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de container secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:28:25.012
May  2 00:28:25.122: INFO: Waiting for pod pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de to disappear
May  2 00:28:25.225: INFO: Pod pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
May  2 00:28:25.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8060" for this suite. 05/02/23 00:28:25.33
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":343,"skipped":6537,"failed":0}
------------------------------
• [SLOW TEST] [5.776 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:19.659
    May  2 00:28:19.659: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/02/23 00:28:19.66
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:19.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:20.177
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-75429312-63ae-4cc1-89bf-d92a73a1f0b1 05/02/23 00:28:20.382
    STEP: Creating a pod to test consume secrets 05/02/23 00:28:20.487
    May  2 00:28:20.594: INFO: Waiting up to 5m0s for pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de" in namespace "secrets-8060" to be "Succeeded or Failed"
    May  2 00:28:20.698: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de": Phase="Pending", Reason="", readiness=false. Elapsed: 103.388384ms
    May  2 00:28:22.802: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207394001s
    May  2 00:28:24.802: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207766091s
    STEP: Saw pod success 05/02/23 00:28:24.802
    May  2 00:28:24.802: INFO: Pod "pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de" satisfied condition "Succeeded or Failed"
    May  2 00:28:24.906: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de container secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:28:25.012
    May  2 00:28:25.122: INFO: Waiting for pod pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de to disappear
    May  2 00:28:25.225: INFO: Pod pod-secrets-1815f4cc-23a5-42cf-9197-4421e1b831de no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    May  2 00:28:25.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8060" for this suite. 05/02/23 00:28:25.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:25.436
May  2 00:28:25.436: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:28:25.437
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:25.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:25.961
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-957b6009-7d11-457c-afcc-bd65bbd8c1b8 05/02/23 00:28:26.167
STEP: Creating a pod to test consume configMaps 05/02/23 00:28:26.272
May  2 00:28:26.381: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783" in namespace "projected-4294" to be "Succeeded or Failed"
May  2 00:28:26.485: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783": Phase="Pending", Reason="", readiness=false. Elapsed: 103.705013ms
May  2 00:28:28.590: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20806973s
May  2 00:28:30.589: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207626554s
STEP: Saw pod success 05/02/23 00:28:30.589
May  2 00:28:30.589: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783" satisfied condition "Succeeded or Failed"
May  2 00:28:30.692: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783 container agnhost-container: <nil>
STEP: delete the pod 05/02/23 00:28:30.798
May  2 00:28:30.910: INFO: Waiting for pod pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783 to disappear
May  2 00:28:31.013: INFO: Pod pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
May  2 00:28:31.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4294" for this suite. 05/02/23 00:28:31.118
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":344,"skipped":6542,"failed":0}
------------------------------
• [SLOW TEST] [5.787 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:25.436
    May  2 00:28:25.436: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:28:25.437
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:25.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:25.961
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-957b6009-7d11-457c-afcc-bd65bbd8c1b8 05/02/23 00:28:26.167
    STEP: Creating a pod to test consume configMaps 05/02/23 00:28:26.272
    May  2 00:28:26.381: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783" in namespace "projected-4294" to be "Succeeded or Failed"
    May  2 00:28:26.485: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783": Phase="Pending", Reason="", readiness=false. Elapsed: 103.705013ms
    May  2 00:28:28.590: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20806973s
    May  2 00:28:30.589: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207626554s
    STEP: Saw pod success 05/02/23 00:28:30.589
    May  2 00:28:30.589: INFO: Pod "pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783" satisfied condition "Succeeded or Failed"
    May  2 00:28:30.692: INFO: Trying to get logs from node i-02d061b30635c230c pod pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783 container agnhost-container: <nil>
    STEP: delete the pod 05/02/23 00:28:30.798
    May  2 00:28:30.910: INFO: Waiting for pod pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783 to disappear
    May  2 00:28:31.013: INFO: Pod pod-projected-configmaps-57d25484-146f-4026-a7a7-8c847b0db783 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    May  2 00:28:31.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4294" for this suite. 05/02/23 00:28:31.118
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:31.224
May  2 00:28:31.224: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename cronjob 05/02/23 00:28:31.225
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:31.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:31.743
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 05/02/23 00:28:31.948
STEP: creating 05/02/23 00:28:31.948
STEP: getting 05/02/23 00:28:32.054
STEP: listing 05/02/23 00:28:32.157
STEP: watching 05/02/23 00:28:32.261
May  2 00:28:32.261: INFO: starting watch
STEP: cluster-wide listing 05/02/23 00:28:32.363
STEP: cluster-wide watching 05/02/23 00:28:32.467
May  2 00:28:32.467: INFO: starting watch
STEP: patching 05/02/23 00:28:32.57
STEP: updating 05/02/23 00:28:32.678
May  2 00:28:32.887: INFO: waiting for watch events with expected annotations
May  2 00:28:32.888: INFO: saw patched and updated annotations
STEP: patching /status 05/02/23 00:28:32.888
STEP: updating /status 05/02/23 00:28:32.993
STEP: get /status 05/02/23 00:28:33.202
STEP: deleting 05/02/23 00:28:33.306
STEP: deleting a collection 05/02/23 00:28:33.621
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
May  2 00:28:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3615" for this suite. 05/02/23 00:28:33.936
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":345,"skipped":6561,"failed":0}
------------------------------
• [2.818 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:31.224
    May  2 00:28:31.224: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename cronjob 05/02/23 00:28:31.225
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:31.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:31.743
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 05/02/23 00:28:31.948
    STEP: creating 05/02/23 00:28:31.948
    STEP: getting 05/02/23 00:28:32.054
    STEP: listing 05/02/23 00:28:32.157
    STEP: watching 05/02/23 00:28:32.261
    May  2 00:28:32.261: INFO: starting watch
    STEP: cluster-wide listing 05/02/23 00:28:32.363
    STEP: cluster-wide watching 05/02/23 00:28:32.467
    May  2 00:28:32.467: INFO: starting watch
    STEP: patching 05/02/23 00:28:32.57
    STEP: updating 05/02/23 00:28:32.678
    May  2 00:28:32.887: INFO: waiting for watch events with expected annotations
    May  2 00:28:32.888: INFO: saw patched and updated annotations
    STEP: patching /status 05/02/23 00:28:32.888
    STEP: updating /status 05/02/23 00:28:32.993
    STEP: get /status 05/02/23 00:28:33.202
    STEP: deleting 05/02/23 00:28:33.306
    STEP: deleting a collection 05/02/23 00:28:33.621
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    May  2 00:28:33.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3615" for this suite. 05/02/23 00:28:33.936
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:34.044
May  2 00:28:34.044: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:28:34.045
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:34.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:34.562
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 05/02/23 00:28:34.767
May  2 00:28:34.768: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

May  2 00:28:34.768: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
May  2 00:28:36.126: INFO: stderr: ""
May  2 00:28:36.126: INFO: stdout: "service/agnhost-replica created\n"
May  2 00:28:36.126: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

May  2 00:28:36.126: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
May  2 00:28:36.804: INFO: stderr: ""
May  2 00:28:36.804: INFO: stdout: "service/agnhost-primary created\n"
May  2 00:28:36.804: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May  2 00:28:36.804: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
May  2 00:28:37.474: INFO: stderr: ""
May  2 00:28:37.474: INFO: stdout: "service/frontend created\n"
May  2 00:28:37.474: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

May  2 00:28:37.474: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
May  2 00:28:38.136: INFO: stderr: ""
May  2 00:28:38.136: INFO: stdout: "deployment.apps/frontend created\n"
May  2 00:28:38.136: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  2 00:28:38.136: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
May  2 00:28:38.786: INFO: stderr: ""
May  2 00:28:38.786: INFO: stdout: "deployment.apps/agnhost-primary created\n"
May  2 00:28:38.786: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  2 00:28:38.786: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
May  2 00:28:39.433: INFO: stderr: ""
May  2 00:28:39.434: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 05/02/23 00:28:39.434
May  2 00:28:39.434: INFO: Waiting for all frontend pods to be Running.
May  2 00:28:44.584: INFO: Waiting for frontend to serve content.
May  2 00:28:44.692: INFO: Trying to add a new entry to the guestbook.
May  2 00:28:44.803: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 05/02/23 00:28:44.91
May  2 00:28:44.910: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
May  2 00:28:45.436: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 00:28:45.437: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 05/02/23 00:28:45.437
May  2 00:28:45.437: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
May  2 00:28:45.976: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 00:28:45.976: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 05/02/23 00:28:45.976
May  2 00:28:45.976: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
May  2 00:28:46.499: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 00:28:46.499: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 05/02/23 00:28:46.5
May  2 00:28:46.500: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
May  2 00:28:47.021: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 00:28:47.021: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 05/02/23 00:28:47.021
May  2 00:28:47.021: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
May  2 00:28:47.534: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 00:28:47.534: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 05/02/23 00:28:47.534
May  2 00:28:47.534: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
May  2 00:28:48.051: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  2 00:28:48.051: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:28:48.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8437" for this suite. 05/02/23 00:28:48.155
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":346,"skipped":6593,"failed":0}
------------------------------
• [SLOW TEST] [14.223 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:34.044
    May  2 00:28:34.044: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:28:34.045
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:34.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:34.562
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 05/02/23 00:28:34.767
    May  2 00:28:34.768: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    May  2 00:28:34.768: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
    May  2 00:28:36.126: INFO: stderr: ""
    May  2 00:28:36.126: INFO: stdout: "service/agnhost-replica created\n"
    May  2 00:28:36.126: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    May  2 00:28:36.126: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
    May  2 00:28:36.804: INFO: stderr: ""
    May  2 00:28:36.804: INFO: stdout: "service/agnhost-primary created\n"
    May  2 00:28:36.804: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    May  2 00:28:36.804: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
    May  2 00:28:37.474: INFO: stderr: ""
    May  2 00:28:37.474: INFO: stdout: "service/frontend created\n"
    May  2 00:28:37.474: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    May  2 00:28:37.474: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
    May  2 00:28:38.136: INFO: stderr: ""
    May  2 00:28:38.136: INFO: stdout: "deployment.apps/frontend created\n"
    May  2 00:28:38.136: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    May  2 00:28:38.136: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
    May  2 00:28:38.786: INFO: stderr: ""
    May  2 00:28:38.786: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    May  2 00:28:38.786: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    May  2 00:28:38.786: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 create -f -'
    May  2 00:28:39.433: INFO: stderr: ""
    May  2 00:28:39.434: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 05/02/23 00:28:39.434
    May  2 00:28:39.434: INFO: Waiting for all frontend pods to be Running.
    May  2 00:28:44.584: INFO: Waiting for frontend to serve content.
    May  2 00:28:44.692: INFO: Trying to add a new entry to the guestbook.
    May  2 00:28:44.803: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 05/02/23 00:28:44.91
    May  2 00:28:44.910: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
    May  2 00:28:45.436: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  2 00:28:45.437: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 05/02/23 00:28:45.437
    May  2 00:28:45.437: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
    May  2 00:28:45.976: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  2 00:28:45.976: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 05/02/23 00:28:45.976
    May  2 00:28:45.976: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
    May  2 00:28:46.499: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  2 00:28:46.499: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 05/02/23 00:28:46.5
    May  2 00:28:46.500: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
    May  2 00:28:47.021: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  2 00:28:47.021: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 05/02/23 00:28:47.021
    May  2 00:28:47.021: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
    May  2 00:28:47.534: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  2 00:28:47.534: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 05/02/23 00:28:47.534
    May  2 00:28:47.534: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-8437 delete --grace-period=0 --force -f -'
    May  2 00:28:48.051: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    May  2 00:28:48.051: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:28:48.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8437" for this suite. 05/02/23 00:28:48.155
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:48.267
May  2 00:28:48.268: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets 05/02/23 00:28:48.269
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:48.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:48.785
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-5622/secret-test-f86c9900-7103-4b08-bdea-6c6018b18fce 05/02/23 00:28:48.991
STEP: Creating a pod to test consume secrets 05/02/23 00:28:49.096
May  2 00:28:49.204: INFO: Waiting up to 5m0s for pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07" in namespace "secrets-5622" to be "Succeeded or Failed"
May  2 00:28:49.308: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07": Phase="Pending", Reason="", readiness=false. Elapsed: 103.274775ms
May  2 00:28:51.412: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20740304s
May  2 00:28:53.411: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207032921s
STEP: Saw pod success 05/02/23 00:28:53.412
May  2 00:28:53.412: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07" satisfied condition "Succeeded or Failed"
May  2 00:28:53.515: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07 container env-test: <nil>
STEP: delete the pod 05/02/23 00:28:53.622
May  2 00:28:53.732: INFO: Waiting for pod pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07 to disappear
May  2 00:28:53.836: INFO: Pod pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
May  2 00:28:53.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5622" for this suite. 05/02/23 00:28:53.941
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":347,"skipped":6601,"failed":0}
------------------------------
• [SLOW TEST] [5.779 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:48.267
    May  2 00:28:48.268: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename secrets 05/02/23 00:28:48.269
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:48.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:48.785
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-5622/secret-test-f86c9900-7103-4b08-bdea-6c6018b18fce 05/02/23 00:28:48.991
    STEP: Creating a pod to test consume secrets 05/02/23 00:28:49.096
    May  2 00:28:49.204: INFO: Waiting up to 5m0s for pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07" in namespace "secrets-5622" to be "Succeeded or Failed"
    May  2 00:28:49.308: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07": Phase="Pending", Reason="", readiness=false. Elapsed: 103.274775ms
    May  2 00:28:51.412: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20740304s
    May  2 00:28:53.411: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.207032921s
    STEP: Saw pod success 05/02/23 00:28:53.412
    May  2 00:28:53.412: INFO: Pod "pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07" satisfied condition "Succeeded or Failed"
    May  2 00:28:53.515: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07 container env-test: <nil>
    STEP: delete the pod 05/02/23 00:28:53.622
    May  2 00:28:53.732: INFO: Waiting for pod pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07 to disappear
    May  2 00:28:53.836: INFO: Pod pod-configmaps-8804242e-2e5a-453e-b64e-42a45808ea07 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    May  2 00:28:53.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5622" for this suite. 05/02/23 00:28:53.941
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:28:54.047
May  2 00:28:54.047: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:28:54.049
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:54.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:54.568
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 05/02/23 00:28:54.773
May  2 00:28:54.882: INFO: Waiting up to 5m0s for pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc" in namespace "projected-2982" to be "running and ready"
May  2 00:28:54.986: INFO: Pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc": Phase="Pending", Reason="", readiness=false. Elapsed: 103.72191ms
May  2 00:28:54.986: INFO: The phase of Pod annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc is Pending, waiting for it to be Running (with Ready = true)
May  2 00:28:57.091: INFO: Pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc": Phase="Running", Reason="", readiness=true. Elapsed: 2.208397473s
May  2 00:28:57.091: INFO: The phase of Pod annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc is Running (Ready = true)
May  2 00:28:57.091: INFO: Pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc" satisfied condition "running and ready"
May  2 00:28:58.013: INFO: Successfully updated pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
May  2 00:29:00.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2982" for this suite. 05/02/23 00:29:00.33
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":348,"skipped":6606,"failed":0}
------------------------------
• [SLOW TEST] [6.388 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:28:54.047
    May  2 00:28:54.047: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:28:54.049
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:28:54.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:28:54.568
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 05/02/23 00:28:54.773
    May  2 00:28:54.882: INFO: Waiting up to 5m0s for pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc" in namespace "projected-2982" to be "running and ready"
    May  2 00:28:54.986: INFO: Pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc": Phase="Pending", Reason="", readiness=false. Elapsed: 103.72191ms
    May  2 00:28:54.986: INFO: The phase of Pod annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:28:57.091: INFO: Pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc": Phase="Running", Reason="", readiness=true. Elapsed: 2.208397473s
    May  2 00:28:57.091: INFO: The phase of Pod annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc is Running (Ready = true)
    May  2 00:28:57.091: INFO: Pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc" satisfied condition "running and ready"
    May  2 00:28:58.013: INFO: Successfully updated pod "annotationupdate9c20ad4d-56b5-4427-b4b9-b51a075411bc"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    May  2 00:29:00.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2982" for this suite. 05/02/23 00:29:00.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:00.436
May  2 00:29:00.436: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook 05/02/23 00:29:00.438
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:00.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:00.96
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 05/02/23 00:29:01.377
STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:29:01.666
STEP: Deploying the webhook pod 05/02/23 00:29:01.772
STEP: Wait for the deployment to be ready 05/02/23 00:29:01.984
May  2 00:29:02.297: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 05/02/23 00:29:04.401
STEP: Verifying the service has paired with the endpoint 05/02/23 00:29:04.511
May  2 00:29:05.512: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 05/02/23 00:29:05.618
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 05/02/23 00:29:05.834
STEP: Creating a dummy validating-webhook-configuration object 05/02/23 00:29:06.049
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 05/02/23 00:29:06.259
STEP: Creating a dummy mutating-webhook-configuration object 05/02/23 00:29:06.365
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 05/02/23 00:29:06.575
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
May  2 00:29:06.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4942" for this suite. 05/02/23 00:29:07.004
STEP: Destroying namespace "webhook-4942-markers" for this suite. 05/02/23 00:29:07.109
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":349,"skipped":6614,"failed":0}
------------------------------
• [SLOW TEST] [7.225 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:00.436
    May  2 00:29:00.436: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename webhook 05/02/23 00:29:00.438
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:00.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:00.96
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 05/02/23 00:29:01.377
    STEP: Create role binding to let webhook read extension-apiserver-authentication 05/02/23 00:29:01.666
    STEP: Deploying the webhook pod 05/02/23 00:29:01.772
    STEP: Wait for the deployment to be ready 05/02/23 00:29:01.984
    May  2 00:29:02.297: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), LastTransitionTime:time.Date(2023, time.May, 2, 0, 29, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 05/02/23 00:29:04.401
    STEP: Verifying the service has paired with the endpoint 05/02/23 00:29:04.511
    May  2 00:29:05.512: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 05/02/23 00:29:05.618
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 05/02/23 00:29:05.834
    STEP: Creating a dummy validating-webhook-configuration object 05/02/23 00:29:06.049
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 05/02/23 00:29:06.259
    STEP: Creating a dummy mutating-webhook-configuration object 05/02/23 00:29:06.365
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 05/02/23 00:29:06.575
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    May  2 00:29:06.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4942" for this suite. 05/02/23 00:29:07.004
    STEP: Destroying namespace "webhook-4942-markers" for this suite. 05/02/23 00:29:07.109
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:07.663
May  2 00:29:07.663: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services 05/02/23 00:29:07.664
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:07.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:08.182
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4119 05/02/23 00:29:08.388
STEP: changing the ExternalName service to type=NodePort 05/02/23 00:29:08.492
STEP: creating replication controller externalname-service in namespace services-4119 05/02/23 00:29:08.708
I0502 00:29:08.814419    6969 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4119, replica count: 2
I0502 00:29:11.965183    6969 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  2 00:29:11.965: INFO: Creating new exec pod
May  2 00:29:12.070: INFO: Waiting up to 5m0s for pod "execpodwnbmx" in namespace "services-4119" to be "running"
May  2 00:29:12.174: INFO: Pod "execpodwnbmx": Phase="Pending", Reason="", readiness=false. Elapsed: 103.954882ms
May  2 00:29:14.279: INFO: Pod "execpodwnbmx": Phase="Running", Reason="", readiness=true. Elapsed: 2.208586566s
May  2 00:29:14.279: INFO: Pod "execpodwnbmx" satisfied condition "running"
May  2 00:29:15.385: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 00:29:16.525: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 00:29:16.525: INFO: stdout: ""
May  2 00:29:17.525: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 00:29:18.675: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 00:29:18.675: INFO: stdout: ""
May  2 00:29:19.526: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 00:29:20.655: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 00:29:20.655: INFO: stdout: ""
May  2 00:29:21.525: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
May  2 00:29:22.683: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  2 00:29:22.683: INFO: stdout: "externalname-service-j6ht5"
May  2 00:29:22.683: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.80.154 80'
May  2 00:29:23.797: INFO: stderr: "+ nc -v -t -w 2 100.65.80.154 80\n+ echo hostName\nConnection to 100.65.80.154 80 port [tcp/http] succeeded!\n"
May  2 00:29:23.797: INFO: stdout: "externalname-service-j6ht5"
May  2 00:29:23.797: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 31857'
May  2 00:29:24.934: INFO: stderr: "+ nc -v -t -w 2 172.20.39.145 31857\n+ echo hostName\nConnection to 172.20.39.145 31857 port [tcp/*] succeeded!\n"
May  2 00:29:24.934: INFO: stdout: "externalname-service-pggll"
May  2 00:29:24.934: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.44.200 31857'
May  2 00:29:26.065: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.44.200 31857\nConnection to 172.20.44.200 31857 port [tcp/*] succeeded!\n"
May  2 00:29:26.065: INFO: stdout: ""
May  2 00:29:27.065: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.44.200 31857'
May  2 00:29:28.159: INFO: stderr: "+ nc -v -t -w 2 172.20.44.200 31857\n+ echo hostName\nConnection to 172.20.44.200 31857 port [tcp/*] succeeded!\n"
May  2 00:29:28.159: INFO: stdout: "externalname-service-pggll"
May  2 00:29:28.159: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
May  2 00:29:28.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4119" for this suite. 05/02/23 00:29:28.389
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":350,"skipped":6632,"failed":0}
------------------------------
• [SLOW TEST] [20.932 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:07.663
    May  2 00:29:07.663: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename services 05/02/23 00:29:07.664
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:07.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:08.182
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-4119 05/02/23 00:29:08.388
    STEP: changing the ExternalName service to type=NodePort 05/02/23 00:29:08.492
    STEP: creating replication controller externalname-service in namespace services-4119 05/02/23 00:29:08.708
    I0502 00:29:08.814419    6969 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4119, replica count: 2
    I0502 00:29:11.965183    6969 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    May  2 00:29:11.965: INFO: Creating new exec pod
    May  2 00:29:12.070: INFO: Waiting up to 5m0s for pod "execpodwnbmx" in namespace "services-4119" to be "running"
    May  2 00:29:12.174: INFO: Pod "execpodwnbmx": Phase="Pending", Reason="", readiness=false. Elapsed: 103.954882ms
    May  2 00:29:14.279: INFO: Pod "execpodwnbmx": Phase="Running", Reason="", readiness=true. Elapsed: 2.208586566s
    May  2 00:29:14.279: INFO: Pod "execpodwnbmx" satisfied condition "running"
    May  2 00:29:15.385: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    May  2 00:29:16.525: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    May  2 00:29:16.525: INFO: stdout: ""
    May  2 00:29:17.525: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    May  2 00:29:18.675: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    May  2 00:29:18.675: INFO: stdout: ""
    May  2 00:29:19.526: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    May  2 00:29:20.655: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    May  2 00:29:20.655: INFO: stdout: ""
    May  2 00:29:21.525: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    May  2 00:29:22.683: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    May  2 00:29:22.683: INFO: stdout: "externalname-service-j6ht5"
    May  2 00:29:22.683: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.80.154 80'
    May  2 00:29:23.797: INFO: stderr: "+ nc -v -t -w 2 100.65.80.154 80\n+ echo hostName\nConnection to 100.65.80.154 80 port [tcp/http] succeeded!\n"
    May  2 00:29:23.797: INFO: stdout: "externalname-service-j6ht5"
    May  2 00:29:23.797: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.39.145 31857'
    May  2 00:29:24.934: INFO: stderr: "+ nc -v -t -w 2 172.20.39.145 31857\n+ echo hostName\nConnection to 172.20.39.145 31857 port [tcp/*] succeeded!\n"
    May  2 00:29:24.934: INFO: stdout: "externalname-service-pggll"
    May  2 00:29:24.934: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.44.200 31857'
    May  2 00:29:26.065: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.44.200 31857\nConnection to 172.20.44.200 31857 port [tcp/*] succeeded!\n"
    May  2 00:29:26.065: INFO: stdout: ""
    May  2 00:29:27.065: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=services-4119 exec execpodwnbmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.44.200 31857'
    May  2 00:29:28.159: INFO: stderr: "+ nc -v -t -w 2 172.20.44.200 31857\n+ echo hostName\nConnection to 172.20.44.200 31857 port [tcp/*] succeeded!\n"
    May  2 00:29:28.159: INFO: stdout: "externalname-service-pggll"
    May  2 00:29:28.159: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    May  2 00:29:28.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4119" for this suite. 05/02/23 00:29:28.389
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:28.596
May  2 00:29:28.596: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts 05/02/23 00:29:28.597
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:28.912
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:29.117
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
May  2 00:29:29.534: INFO: Waiting up to 5m0s for pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c" in namespace "svcaccounts-466" to be "running"
May  2 00:29:29.638: INFO: Pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c": Phase="Pending", Reason="", readiness=false. Elapsed: 104.012863ms
May  2 00:29:31.742: INFO: Pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c": Phase="Running", Reason="", readiness=true. Elapsed: 2.20805167s
May  2 00:29:31.742: INFO: Pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c" satisfied condition "running"
STEP: reading a file in the container 05/02/23 00:29:31.742
May  2 00:29:31.742: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl exec --namespace=svcaccounts-466 pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 05/02/23 00:29:32.825
May  2 00:29:32.825: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl exec --namespace=svcaccounts-466 pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 05/02/23 00:29:33.909
May  2 00:29:33.909: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl exec --namespace=svcaccounts-466 pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
May  2 00:29:35.139: INFO: Got root ca configmap in namespace "svcaccounts-466"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
May  2 00:29:35.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-466" for this suite. 05/02/23 00:29:35.347
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":351,"skipped":6654,"failed":0}
------------------------------
• [SLOW TEST] [6.856 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:28.596
    May  2 00:29:28.596: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svcaccounts 05/02/23 00:29:28.597
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:28.912
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:29.117
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    May  2 00:29:29.534: INFO: Waiting up to 5m0s for pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c" in namespace "svcaccounts-466" to be "running"
    May  2 00:29:29.638: INFO: Pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c": Phase="Pending", Reason="", readiness=false. Elapsed: 104.012863ms
    May  2 00:29:31.742: INFO: Pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c": Phase="Running", Reason="", readiness=true. Elapsed: 2.20805167s
    May  2 00:29:31.742: INFO: Pod "pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c" satisfied condition "running"
    STEP: reading a file in the container 05/02/23 00:29:31.742
    May  2 00:29:31.742: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl exec --namespace=svcaccounts-466 pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 05/02/23 00:29:32.825
    May  2 00:29:32.825: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl exec --namespace=svcaccounts-466 pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 05/02/23 00:29:33.909
    May  2 00:29:33.909: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl exec --namespace=svcaccounts-466 pod-service-account-a9c27694-5f55-453c-922c-a0f310739a3c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    May  2 00:29:35.139: INFO: Got root ca configmap in namespace "svcaccounts-466"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    May  2 00:29:35.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-466" for this suite. 05/02/23 00:29:35.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:35.452
May  2 00:29:35.452: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:29:35.454
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:35.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:35.977
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
May  2 00:29:36.182: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 create -f -'
May  2 00:29:36.835: INFO: stderr: ""
May  2 00:29:36.835: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
May  2 00:29:36.835: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 create -f -'
May  2 00:29:37.484: INFO: stderr: ""
May  2 00:29:37.484: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 05/02/23 00:29:37.485
May  2 00:29:38.589: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 00:29:38.589: INFO: Found 1 / 1
May  2 00:29:38.589: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  2 00:29:38.693: INFO: Selector matched 1 pods for map[app:agnhost]
May  2 00:29:38.693: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  2 00:29:38.693: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe pod agnhost-primary-h8mb6'
May  2 00:29:39.308: INFO: stderr: ""
May  2 00:29:39.308: INFO: stdout: "Name:             agnhost-primary-h8mb6\nNamespace:        kubectl-3552\nPriority:         0\nService Account:  default\nNode:             i-0627b78ff917cf2ae/172.20.62.149\nStart Time:       Tue, 02 May 2023 00:29:36 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: c1fb1732c82722466925a3df453f96497b49514f1c62d7ca1a0060f0793fb23c\n                  cni.projectcalico.org/podIP: 100.105.72.158/32\n                  cni.projectcalico.org/podIPs: 100.105.72.158/32\nStatus:           Running\nIP:               100.105.72.158\nIPs:\n  IP:           100.105.72.158\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://9da4c71561e128e335a2ebae6cc53fb557d1c89e4ad471125421ea8562332f0e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 02 May 2023 00:29:37 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-95z9t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-95z9t:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-3552/agnhost-primary-h8mb6 to i-0627b78ff917cf2ae\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
May  2 00:29:39.308: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe rc agnhost-primary'
May  2 00:29:40.026: INFO: stderr: ""
May  2 00:29:40.026: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-3552\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-primary-h8mb6\n"
May  2 00:29:40.026: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe service agnhost-primary'
May  2 00:29:40.735: INFO: stderr: ""
May  2 00:29:40.735: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-3552\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.65.242.155\nIPs:               100.65.242.155\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.105.72.158:6379\nSession Affinity:  None\nEvents:            <none>\n"
May  2 00:29:40.839: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe node i-00fed7c0a42791aae'
May  2 00:29:42.075: INFO: stderr: ""
May  2 00:29:42.075: INFO: stdout: "Name:               i-00fed7c0a42791aae\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-3\n                    failure-domain.beta.kubernetes.io/zone=eu-west-3a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=i-00fed7c0a42791aae\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/node=\n                    node.kubernetes.io/instance-type=t3.medium\n                    topology.ebs.csi.aws.com/zone=eu-west-3a\n                    topology.kubernetes.io/region=eu-west-3\n                    topology.kubernetes.io/zone=eu-west-3a\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"ebs.csi.aws.com\":\"i-00fed7c0a42791aae\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 172.20.44.200/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.123.145.192\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 01 May 2023 22:31:34 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  i-00fed7c0a42791aae\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 02 May 2023 00:29:36 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 01 May 2023 22:31:50 +0000   Mon, 01 May 2023 22:31:50 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:33 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:44 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   172.20.44.200\n  ExternalIP:   13.36.176.163\n  InternalDNS:  i-00fed7c0a42791aae.eu-west-3.compute.internal\n  Hostname:     i-00fed7c0a42791aae.eu-west-3.compute.internal\n  ExternalDNS:  ec2-13-36-176-163.eu-west-3.compute.amazonaws.com\nCapacity:\n  cpu:                2\n  ephemeral-storage:  48587704Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3956272Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  44778427933\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3853872Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2643b9d98a9e31592205a04b225bd0\n  System UUID:                ec2643b9-d98a-9e31-5922-05a04b225bd0\n  Boot ID:                    af57a60c-686c-40ba-9130-c7191bd26455\n  Kernel Version:             5.19.0-1023-aws\n  OS Image:                   Ubuntu 22.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.18\n  Kubelet Version:            v1.25.9\n  Kube-Proxy Version:         v1.25.9\nPodCIDR:                      100.96.1.0/24\nPodCIDRs:                     100.96.1.0/24\nProviderID:                   aws:///eu-west-3a/i-00fed7c0a42791aae\nNon-terminated Pods:          (6 in total)\n  Namespace                   Name                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                  ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-zd6l4                     100m (5%)     0 (0%)      0 (0%)           0 (0%)         118m\n  kube-system                 coredns-6c7bddbb75-7b4g9              100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     119m\n  kube-system                 coredns-autoscaler-db7b97744-xpnj5    20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         119m\n  kube-system                 ebs-csi-controller-f987fd46-c4wk5     0 (0%)        0 (0%)      0 (0%)           0 (0%)         119m\n  kube-system                 ebs-csi-node-4hblj                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         118m\n  kube-system                 kube-proxy-i-00fed7c0a42791aae        100m (5%)     0 (0%)      0 (0%)           0 (0%)         117m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                320m (16%)  0 (0%)\n  memory             80Mi (2%)   170Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
May  2 00:29:42.075: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe namespace kubectl-3552'
May  2 00:29:42.790: INFO: stderr: ""
May  2 00:29:42.790: INFO: stdout: "Name:         kubectl-3552\nLabels:       e2e-framework=kubectl\n              e2e-run=b85640b9-2efa-42a1-8547-7793d843b8be\n              kubernetes.io/metadata.name=kubectl-3552\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:29:42.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3552" for this suite. 05/02/23 00:29:42.895
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":352,"skipped":6661,"failed":0}
------------------------------
• [SLOW TEST] [7.548 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:35.452
    May  2 00:29:35.452: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:29:35.454
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:35.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:35.977
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    May  2 00:29:36.182: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 create -f -'
    May  2 00:29:36.835: INFO: stderr: ""
    May  2 00:29:36.835: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    May  2 00:29:36.835: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 create -f -'
    May  2 00:29:37.484: INFO: stderr: ""
    May  2 00:29:37.484: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 05/02/23 00:29:37.485
    May  2 00:29:38.589: INFO: Selector matched 1 pods for map[app:agnhost]
    May  2 00:29:38.589: INFO: Found 1 / 1
    May  2 00:29:38.589: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    May  2 00:29:38.693: INFO: Selector matched 1 pods for map[app:agnhost]
    May  2 00:29:38.693: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    May  2 00:29:38.693: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe pod agnhost-primary-h8mb6'
    May  2 00:29:39.308: INFO: stderr: ""
    May  2 00:29:39.308: INFO: stdout: "Name:             agnhost-primary-h8mb6\nNamespace:        kubectl-3552\nPriority:         0\nService Account:  default\nNode:             i-0627b78ff917cf2ae/172.20.62.149\nStart Time:       Tue, 02 May 2023 00:29:36 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: c1fb1732c82722466925a3df453f96497b49514f1c62d7ca1a0060f0793fb23c\n                  cni.projectcalico.org/podIP: 100.105.72.158/32\n                  cni.projectcalico.org/podIPs: 100.105.72.158/32\nStatus:           Running\nIP:               100.105.72.158\nIPs:\n  IP:           100.105.72.158\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://9da4c71561e128e335a2ebae6cc53fb557d1c89e4ad471125421ea8562332f0e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 02 May 2023 00:29:37 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-95z9t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-95z9t:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-3552/agnhost-primary-h8mb6 to i-0627b78ff917cf2ae\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
    May  2 00:29:39.308: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe rc agnhost-primary'
    May  2 00:29:40.026: INFO: stderr: ""
    May  2 00:29:40.026: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-3552\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: agnhost-primary-h8mb6\n"
    May  2 00:29:40.026: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe service agnhost-primary'
    May  2 00:29:40.735: INFO: stderr: ""
    May  2 00:29:40.735: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-3552\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.65.242.155\nIPs:               100.65.242.155\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.105.72.158:6379\nSession Affinity:  None\nEvents:            <none>\n"
    May  2 00:29:40.839: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe node i-00fed7c0a42791aae'
    May  2 00:29:42.075: INFO: stderr: ""
    May  2 00:29:42.075: INFO: stdout: "Name:               i-00fed7c0a42791aae\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-west-3\n                    failure-domain.beta.kubernetes.io/zone=eu-west-3a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=i-00fed7c0a42791aae\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/node=\n                    node.kubernetes.io/instance-type=t3.medium\n                    topology.ebs.csi.aws.com/zone=eu-west-3a\n                    topology.kubernetes.io/region=eu-west-3\n                    topology.kubernetes.io/zone=eu-west-3a\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"ebs.csi.aws.com\":\"i-00fed7c0a42791aae\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 172.20.44.200/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.123.145.192\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 01 May 2023 22:31:34 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  i-00fed7c0a42791aae\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 02 May 2023 00:29:36 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 01 May 2023 22:31:50 +0000   Mon, 01 May 2023 22:31:50 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:33 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 02 May 2023 00:25:15 +0000   Mon, 01 May 2023 22:31:44 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   172.20.44.200\n  ExternalIP:   13.36.176.163\n  InternalDNS:  i-00fed7c0a42791aae.eu-west-3.compute.internal\n  Hostname:     i-00fed7c0a42791aae.eu-west-3.compute.internal\n  ExternalDNS:  ec2-13-36-176-163.eu-west-3.compute.amazonaws.com\nCapacity:\n  cpu:                2\n  ephemeral-storage:  48587704Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3956272Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  44778427933\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3853872Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec2643b9d98a9e31592205a04b225bd0\n  System UUID:                ec2643b9-d98a-9e31-5922-05a04b225bd0\n  Boot ID:                    af57a60c-686c-40ba-9130-c7191bd26455\n  Kernel Version:             5.19.0-1023-aws\n  OS Image:                   Ubuntu 22.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.18\n  Kubelet Version:            v1.25.9\n  Kube-Proxy Version:         v1.25.9\nPodCIDR:                      100.96.1.0/24\nPodCIDRs:                     100.96.1.0/24\nProviderID:                   aws:///eu-west-3a/i-00fed7c0a42791aae\nNon-terminated Pods:          (6 in total)\n  Namespace                   Name                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                  ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-zd6l4                     100m (5%)     0 (0%)      0 (0%)           0 (0%)         118m\n  kube-system                 coredns-6c7bddbb75-7b4g9              100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     119m\n  kube-system                 coredns-autoscaler-db7b97744-xpnj5    20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         119m\n  kube-system                 ebs-csi-controller-f987fd46-c4wk5     0 (0%)        0 (0%)      0 (0%)           0 (0%)         119m\n  kube-system                 ebs-csi-node-4hblj                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         118m\n  kube-system                 kube-proxy-i-00fed7c0a42791aae        100m (5%)     0 (0%)      0 (0%)           0 (0%)         117m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                320m (16%)  0 (0%)\n  memory             80Mi (2%)   170Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
    May  2 00:29:42.075: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-3552 describe namespace kubectl-3552'
    May  2 00:29:42.790: INFO: stderr: ""
    May  2 00:29:42.790: INFO: stdout: "Name:         kubectl-3552\nLabels:       e2e-framework=kubectl\n              e2e-run=b85640b9-2efa-42a1-8547-7793d843b8be\n              kubernetes.io/metadata.name=kubectl-3552\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:29:42.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3552" for this suite. 05/02/23 00:29:42.895
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:43.002
May  2 00:29:43.002: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc 05/02/23 00:29:43.004
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:43.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:43.523
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 05/02/23 00:29:43.729
STEP: Wait for the Deployment to create new ReplicaSet 05/02/23 00:29:43.835
STEP: delete the deployment 05/02/23 00:29:43.939
STEP: wait for all rs to be garbage collected 05/02/23 00:29:44.047
STEP: Gathering metrics 05/02/23 00:29:44.359
May  2 00:29:44.581: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
May  2 00:29:44.685: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 104.040257ms
May  2 00:29:44.685: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
May  2 00:29:44.685: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
May  2 00:29:45.560: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
May  2 00:29:45.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6137" for this suite. 05/02/23 00:29:45.666
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":353,"skipped":6689,"failed":0}
------------------------------
• [2.769 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:43.002
    May  2 00:29:43.002: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename gc 05/02/23 00:29:43.004
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:43.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:43.523
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 05/02/23 00:29:43.729
    STEP: Wait for the Deployment to create new ReplicaSet 05/02/23 00:29:43.835
    STEP: delete the deployment 05/02/23 00:29:43.939
    STEP: wait for all rs to be garbage collected 05/02/23 00:29:44.047
    STEP: Gathering metrics 05/02/23 00:29:44.359
    May  2 00:29:44.581: INFO: Waiting up to 5m0s for pod "kube-controller-manager-i-017bcfba82c7d20ff" in namespace "kube-system" to be "running and ready"
    May  2 00:29:44.685: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff": Phase="Running", Reason="", readiness=true. Elapsed: 104.040257ms
    May  2 00:29:44.685: INFO: The phase of Pod kube-controller-manager-i-017bcfba82c7d20ff is Running (Ready = true)
    May  2 00:29:44.685: INFO: Pod "kube-controller-manager-i-017bcfba82c7d20ff" satisfied condition "running and ready"
    May  2 00:29:45.560: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    May  2 00:29:45.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6137" for this suite. 05/02/23 00:29:45.666
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:45.773
May  2 00:29:45.773: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts 05/02/23 00:29:45.774
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:46.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:46.291
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 05/02/23 00:29:46.496
STEP: watching for the ServiceAccount to be added 05/02/23 00:29:46.705
STEP: patching the ServiceAccount 05/02/23 00:29:46.808
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 05/02/23 00:29:46.914
STEP: deleting the ServiceAccount 05/02/23 00:29:47.018
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
May  2 00:29:47.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9864" for this suite. 05/02/23 00:29:47.233
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":354,"skipped":6715,"failed":0}
------------------------------
• [1.567 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:45.773
    May  2 00:29:45.773: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename svcaccounts 05/02/23 00:29:45.774
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:46.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:46.291
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 05/02/23 00:29:46.496
    STEP: watching for the ServiceAccount to be added 05/02/23 00:29:46.705
    STEP: patching the ServiceAccount 05/02/23 00:29:46.808
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 05/02/23 00:29:46.914
    STEP: deleting the ServiceAccount 05/02/23 00:29:47.018
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    May  2 00:29:47.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9864" for this suite. 05/02/23 00:29:47.233
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:29:47.341
May  2 00:29:47.341: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets 05/02/23 00:29:47.342
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:47.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:47.859
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
May  2 00:29:48.696: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 05/02/23 00:29:48.803
May  2 00:29:48.907: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:49.011: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  2 00:29:49.011: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  2 00:29:50.117: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:50.221: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  2 00:29:50.221: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  2 00:29:51.116: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:51.220: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
May  2 00:29:51.220: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
May  2 00:29:52.117: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:52.222: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  2 00:29:52.222: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Update daemon pods image. 05/02/23 00:29:52.638
STEP: Check that daemon pods images are updated. 05/02/23 00:29:52.849
May  2 00:29:52.954: INFO: Wrong image for pod: daemon-set-5qf7j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:52.954: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:52.954: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:53.059: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:54.163: INFO: Wrong image for pod: daemon-set-5qf7j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:54.163: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:54.163: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:54.267: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:55.163: INFO: Wrong image for pod: daemon-set-5qf7j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:55.164: INFO: Pod daemon-set-bc2hq is not available
May  2 00:29:55.164: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:55.164: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:55.268: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:56.163: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:56.163: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:56.269: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:57.164: INFO: Pod daemon-set-6zcp7 is not available
May  2 00:29:57.165: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:57.165: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:57.269: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:58.164: INFO: Pod daemon-set-btxzw is not available
May  2 00:29:58.164: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
May  2 00:29:58.268: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:29:59.268: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:30:00.164: INFO: Pod daemon-set-kxsc9 is not available
May  2 00:30:00.269: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 05/02/23 00:30:00.269
May  2 00:30:00.374: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:30:00.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
May  2 00:30:00.478: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
May  2 00:30:01.583: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  2 00:30:01.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
May  2 00:30:01.688: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 05/02/23 00:30:02.208
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9884, will wait for the garbage collector to delete the pods 05/02/23 00:30:02.208
May  2 00:30:02.568: INFO: Deleting DaemonSet.extensions daemon-set took: 105.681038ms
May  2 00:30:02.669: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.612694ms
May  2 00:30:04.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
May  2 00:30:04.273: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
May  2 00:30:04.377: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41819"},"items":null}

May  2 00:30:04.481: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41819"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
May  2 00:30:05.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9884" for this suite. 05/02/23 00:30:05.105
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":355,"skipped":6738,"failed":0}
------------------------------
• [SLOW TEST] [17.870 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:29:47.341
    May  2 00:29:47.341: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename daemonsets 05/02/23 00:29:47.342
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:29:47.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:29:47.859
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    May  2 00:29:48.696: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 05/02/23 00:29:48.803
    May  2 00:29:48.907: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:49.011: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  2 00:29:49.011: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  2 00:29:50.117: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:50.221: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  2 00:29:50.221: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  2 00:29:51.116: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:51.220: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    May  2 00:29:51.220: INFO: Node i-02d061b30635c230c is running 0 daemon pod, expected 1
    May  2 00:29:52.117: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:52.222: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  2 00:29:52.222: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Update daemon pods image. 05/02/23 00:29:52.638
    STEP: Check that daemon pods images are updated. 05/02/23 00:29:52.849
    May  2 00:29:52.954: INFO: Wrong image for pod: daemon-set-5qf7j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:52.954: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:52.954: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:53.059: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:54.163: INFO: Wrong image for pod: daemon-set-5qf7j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:54.163: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:54.163: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:54.267: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:55.163: INFO: Wrong image for pod: daemon-set-5qf7j. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:55.164: INFO: Pod daemon-set-bc2hq is not available
    May  2 00:29:55.164: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:55.164: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:55.268: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:56.163: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:56.163: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:56.269: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:57.164: INFO: Pod daemon-set-6zcp7 is not available
    May  2 00:29:57.165: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:57.165: INFO: Wrong image for pod: daemon-set-kqsvd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:57.269: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:58.164: INFO: Pod daemon-set-btxzw is not available
    May  2 00:29:58.164: INFO: Wrong image for pod: daemon-set-dr54s. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    May  2 00:29:58.268: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:29:59.268: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:30:00.164: INFO: Pod daemon-set-kxsc9 is not available
    May  2 00:30:00.269: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 05/02/23 00:30:00.269
    May  2 00:30:00.374: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:30:00.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    May  2 00:30:00.478: INFO: Node i-00fed7c0a42791aae is running 0 daemon pod, expected 1
    May  2 00:30:01.583: INFO: DaemonSet pods can't tolerate node i-017bcfba82c7d20ff with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    May  2 00:30:01.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    May  2 00:30:01.688: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 05/02/23 00:30:02.208
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9884, will wait for the garbage collector to delete the pods 05/02/23 00:30:02.208
    May  2 00:30:02.568: INFO: Deleting DaemonSet.extensions daemon-set took: 105.681038ms
    May  2 00:30:02.669: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.612694ms
    May  2 00:30:04.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    May  2 00:30:04.273: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    May  2 00:30:04.377: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41819"},"items":null}

    May  2 00:30:04.481: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41819"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:30:05.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9884" for this suite. 05/02/23 00:30:05.105
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:30:05.211
May  2 00:30:05.211: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe 05/02/23 00:30:05.212
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:05.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:05.73
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf in namespace container-probe-3634 05/02/23 00:30:05.936
May  2 00:30:06.044: INFO: Waiting up to 5m0s for pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf" in namespace "container-probe-3634" to be "not pending"
May  2 00:30:06.147: INFO: Pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf": Phase="Pending", Reason="", readiness=false. Elapsed: 103.46726ms
May  2 00:30:08.252: INFO: Pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.20780859s
May  2 00:30:08.252: INFO: Pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf" satisfied condition "not pending"
May  2 00:30:08.252: INFO: Started pod liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf in namespace container-probe-3634
STEP: checking the pod's current state and verifying that restartCount is present 05/02/23 00:30:08.252
May  2 00:30:08.355: INFO: Initial restart count of pod liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf is 0
May  2 00:30:27.405: INFO: Restart count of pod container-probe-3634/liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf is now 1 (19.049961807s elapsed)
STEP: deleting the pod 05/02/23 00:30:27.406
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
May  2 00:30:27.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3634" for this suite. 05/02/23 00:30:27.622
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":356,"skipped":6738,"failed":0}
------------------------------
• [SLOW TEST] [22.616 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:30:05.211
    May  2 00:30:05.211: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename container-probe 05/02/23 00:30:05.212
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:05.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:05.73
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf in namespace container-probe-3634 05/02/23 00:30:05.936
    May  2 00:30:06.044: INFO: Waiting up to 5m0s for pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf" in namespace "container-probe-3634" to be "not pending"
    May  2 00:30:06.147: INFO: Pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf": Phase="Pending", Reason="", readiness=false. Elapsed: 103.46726ms
    May  2 00:30:08.252: INFO: Pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.20780859s
    May  2 00:30:08.252: INFO: Pod "liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf" satisfied condition "not pending"
    May  2 00:30:08.252: INFO: Started pod liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf in namespace container-probe-3634
    STEP: checking the pod's current state and verifying that restartCount is present 05/02/23 00:30:08.252
    May  2 00:30:08.355: INFO: Initial restart count of pod liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf is 0
    May  2 00:30:27.405: INFO: Restart count of pod container-probe-3634/liveness-0dbfc4e6-e825-4a57-8d9c-a3e53e0cb7cf is now 1 (19.049961807s elapsed)
    STEP: deleting the pod 05/02/23 00:30:27.406
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    May  2 00:30:27.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3634" for this suite. 05/02/23 00:30:27.622
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:30:27.828
May  2 00:30:27.828: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected 05/02/23 00:30:27.829
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:28.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:28.346
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-4f6bcb44-a99b-4ebc-b568-a744c9cffb01 05/02/23 00:30:28.551
STEP: Creating a pod to test consume secrets 05/02/23 00:30:28.656
May  2 00:30:28.764: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38" in namespace "projected-7228" to be "Succeeded or Failed"
May  2 00:30:28.867: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38": Phase="Pending", Reason="", readiness=false. Elapsed: 103.258684ms
May  2 00:30:30.972: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208616901s
May  2 00:30:32.972: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208037428s
STEP: Saw pod success 05/02/23 00:30:32.972
May  2 00:30:32.972: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38" satisfied condition "Succeeded or Failed"
May  2 00:30:33.076: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38 container projected-secret-volume-test: <nil>
STEP: delete the pod 05/02/23 00:30:33.187
May  2 00:30:33.298: INFO: Waiting for pod pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38 to disappear
May  2 00:30:33.401: INFO: Pod pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
May  2 00:30:33.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7228" for this suite. 05/02/23 00:30:33.512
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":357,"skipped":6738,"failed":0}
------------------------------
• [SLOW TEST] [5.792 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:30:27.828
    May  2 00:30:27.828: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename projected 05/02/23 00:30:27.829
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:28.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:28.346
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-4f6bcb44-a99b-4ebc-b568-a744c9cffb01 05/02/23 00:30:28.551
    STEP: Creating a pod to test consume secrets 05/02/23 00:30:28.656
    May  2 00:30:28.764: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38" in namespace "projected-7228" to be "Succeeded or Failed"
    May  2 00:30:28.867: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38": Phase="Pending", Reason="", readiness=false. Elapsed: 103.258684ms
    May  2 00:30:30.972: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208616901s
    May  2 00:30:32.972: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.208037428s
    STEP: Saw pod success 05/02/23 00:30:32.972
    May  2 00:30:32.972: INFO: Pod "pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38" satisfied condition "Succeeded or Failed"
    May  2 00:30:33.076: INFO: Trying to get logs from node i-0627b78ff917cf2ae pod pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38 container projected-secret-volume-test: <nil>
    STEP: delete the pod 05/02/23 00:30:33.187
    May  2 00:30:33.298: INFO: Waiting for pod pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38 to disappear
    May  2 00:30:33.401: INFO: Pod pod-projected-secrets-6d601563-793a-454b-94b8-5421043b5b38 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    May  2 00:30:33.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7228" for this suite. 05/02/23 00:30:33.512
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:30:33.632
May  2 00:30:33.632: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl 05/02/23 00:30:33.633
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:33.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:34.152
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/02/23 00:30:34.358
May  2 00:30:34.358: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-4932 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
May  2 00:30:34.788: INFO: stderr: ""
May  2 00:30:34.788: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 05/02/23 00:30:34.788
May  2 00:30:34.788: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-4932 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
May  2 00:30:35.568: INFO: stderr: ""
May  2 00:30:35.568: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/02/23 00:30:35.568
May  2 00:30:35.672: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-4932 delete pods e2e-test-httpd-pod'
May  2 00:30:38.208: INFO: stderr: ""
May  2 00:30:38.208: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
May  2 00:30:38.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4932" for this suite. 05/02/23 00:30:38.313
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":358,"skipped":6878,"failed":0}
------------------------------
• [4.786 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:30:33.632
    May  2 00:30:33.632: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename kubectl 05/02/23 00:30:33.633
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:33.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:34.152
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/02/23 00:30:34.358
    May  2 00:30:34.358: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-4932 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    May  2 00:30:34.788: INFO: stderr: ""
    May  2 00:30:34.788: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 05/02/23 00:30:34.788
    May  2 00:30:34.788: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-4932 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    May  2 00:30:35.568: INFO: stderr: ""
    May  2 00:30:35.568: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 05/02/23 00:30:35.568
    May  2 00:30:35.672: INFO: Running '/home/prow/go/src/k8s.io/kops/_rundir/f9c87f7f-e86e-11ed-ad38-e6285af20ff4/kubectl --server=https://api.e2e-e2e-kops-aws-conformance-1-25.test-cncf-aws.k8s.io --kubeconfig=/root/.kube/config --namespace=kubectl-4932 delete pods e2e-test-httpd-pod'
    May  2 00:30:38.208: INFO: stderr: ""
    May  2 00:30:38.208: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    May  2 00:30:38.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4932" for this suite. 05/02/23 00:30:38.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:30:38.42
May  2 00:30:38.421: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api 05/02/23 00:30:38.422
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:38.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:38.939
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 05/02/23 00:30:39.144
May  2 00:30:39.253: INFO: Waiting up to 5m0s for pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5" in namespace "downward-api-5425" to be "running and ready"
May  2 00:30:39.357: INFO: Pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5": Phase="Pending", Reason="", readiness=false. Elapsed: 103.815279ms
May  2 00:30:39.357: INFO: The phase of Pod annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5 is Pending, waiting for it to be Running (with Ready = true)
May  2 00:30:41.461: INFO: Pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5": Phase="Running", Reason="", readiness=true. Elapsed: 2.208067466s
May  2 00:30:41.461: INFO: The phase of Pod annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5 is Running (Ready = true)
May  2 00:30:41.461: INFO: Pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5" satisfied condition "running and ready"
May  2 00:30:42.397: INFO: Successfully updated pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
May  2 00:30:44.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5425" for this suite. 05/02/23 00:30:44.715
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":359,"skipped":6940,"failed":0}
------------------------------
• [SLOW TEST] [6.400 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:30:38.42
    May  2 00:30:38.421: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename downward-api 05/02/23 00:30:38.422
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:38.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:38.939
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 05/02/23 00:30:39.144
    May  2 00:30:39.253: INFO: Waiting up to 5m0s for pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5" in namespace "downward-api-5425" to be "running and ready"
    May  2 00:30:39.357: INFO: Pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5": Phase="Pending", Reason="", readiness=false. Elapsed: 103.815279ms
    May  2 00:30:39.357: INFO: The phase of Pod annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5 is Pending, waiting for it to be Running (with Ready = true)
    May  2 00:30:41.461: INFO: Pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5": Phase="Running", Reason="", readiness=true. Elapsed: 2.208067466s
    May  2 00:30:41.461: INFO: The phase of Pod annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5 is Running (Ready = true)
    May  2 00:30:41.461: INFO: Pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5" satisfied condition "running and ready"
    May  2 00:30:42.397: INFO: Successfully updated pod "annotationupdatecea5b4c8-fd97-440f-a79c-1fcf982fbfb5"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    May  2 00:30:44.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5425" for this suite. 05/02/23 00:30:44.715
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 05/02/23 00:30:44.823
May  2 00:30:44.823: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-preemption 05/02/23 00:30:44.825
STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:45.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:45.343
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
May  2 00:30:45.864: INFO: Waiting up to 1m0s for all nodes to be ready
May  2 00:31:46.618: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 05/02/23 00:31:46.722
May  2 00:31:46.941: INFO: Created pod: pod0-0-sched-preemption-low-priority
May  2 00:31:47.046: INFO: Created pod: pod0-1-sched-preemption-medium-priority
May  2 00:31:47.262: INFO: Created pod: pod1-0-sched-preemption-medium-priority
May  2 00:31:47.367: INFO: Created pod: pod1-1-sched-preemption-medium-priority
May  2 00:31:47.584: INFO: Created pod: pod2-0-sched-preemption-medium-priority
May  2 00:31:47.691: INFO: Created pod: pod2-1-sched-preemption-medium-priority
May  2 00:31:47.908: INFO: Created pod: pod3-0-sched-preemption-medium-priority
May  2 00:31:48.021: INFO: Created pod: pod3-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 05/02/23 00:31:48.021
May  2 00:31:48.021: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:48.125: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 104.120486ms
May  2 00:31:50.229: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207989941s
May  2 00:31:52.231: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209678342s
May  2 00:31:54.230: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.209317019s
May  2 00:31:56.230: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.208474188s
May  2 00:31:58.230: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.20903563s
May  2 00:31:58.231: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
May  2 00:31:58.231: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.334: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.763608ms
May  2 00:31:58.334: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
May  2 00:31:58.334: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.438: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.619814ms
May  2 00:31:58.438: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
May  2 00:31:58.438: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.545: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 106.954005ms
May  2 00:31:58.545: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
May  2 00:31:58.545: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.649: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.926984ms
May  2 00:31:58.649: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
May  2 00:31:58.649: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.753: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.687042ms
May  2 00:31:58.753: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
May  2 00:31:58.753: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.856: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.536377ms
May  2 00:31:58.857: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
May  2 00:31:58.857: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:58.960: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.769821ms
May  2 00:31:58.960: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 05/02/23 00:31:58.96
May  2 00:31:59.067: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-2348" to be "running"
May  2 00:31:59.170: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.437007ms
May  2 00:32:01.275: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.20821338s
May  2 00:32:01.275: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
May  2 00:32:02.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2348" for this suite. 05/02/23 00:32:02.313
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":360,"skipped":6971,"failed":0}
------------------------------
• [SLOW TEST] [78.446 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 05/02/23 00:30:44.823
    May  2 00:30:44.823: INFO: >>> kubeConfig: /root/.kube/config
    STEP: Building a namespace api object, basename sched-preemption 05/02/23 00:30:44.825
    STEP: Waiting for a default service account to be provisioned in namespace 05/02/23 00:30:45.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 05/02/23 00:30:45.343
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    May  2 00:30:45.864: INFO: Waiting up to 1m0s for all nodes to be ready
    May  2 00:31:46.618: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 05/02/23 00:31:46.722
    May  2 00:31:46.941: INFO: Created pod: pod0-0-sched-preemption-low-priority
    May  2 00:31:47.046: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    May  2 00:31:47.262: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    May  2 00:31:47.367: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    May  2 00:31:47.584: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    May  2 00:31:47.691: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    May  2 00:31:47.908: INFO: Created pod: pod3-0-sched-preemption-medium-priority
    May  2 00:31:48.021: INFO: Created pod: pod3-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 05/02/23 00:31:48.021
    May  2 00:31:48.021: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:48.125: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 104.120486ms
    May  2 00:31:50.229: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.207989941s
    May  2 00:31:52.231: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209678342s
    May  2 00:31:54.230: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.209317019s
    May  2 00:31:56.230: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.208474188s
    May  2 00:31:58.230: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.20903563s
    May  2 00:31:58.231: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    May  2 00:31:58.231: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.334: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.763608ms
    May  2 00:31:58.334: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    May  2 00:31:58.334: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.438: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.619814ms
    May  2 00:31:58.438: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    May  2 00:31:58.438: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.545: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 106.954005ms
    May  2 00:31:58.545: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    May  2 00:31:58.545: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.649: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.926984ms
    May  2 00:31:58.649: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    May  2 00:31:58.649: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.753: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.687042ms
    May  2 00:31:58.753: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    May  2 00:31:58.753: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.856: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.536377ms
    May  2 00:31:58.857: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
    May  2 00:31:58.857: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:58.960: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 103.769821ms
    May  2 00:31:58.960: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 05/02/23 00:31:58.96
    May  2 00:31:59.067: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-2348" to be "running"
    May  2 00:31:59.170: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 103.437007ms
    May  2 00:32:01.275: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.20821338s
    May  2 00:32:01.275: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    May  2 00:32:02.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2348" for this suite. 05/02/23 00:32:02.313
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":360,"skipped":6972,"failed":0}
May  2 00:32:03.270: INFO: Running AfterSuite actions on all nodes
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
May  2 00:32:03.270: INFO: Running AfterSuite actions on node 1
May  2 00:32:03.270: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    May  2 00:32:03.270: INFO: Running AfterSuite actions on all nodes
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    May  2 00:32:03.270: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    May  2 00:32:03.270: INFO: Running AfterSuite actions on node 1
    May  2 00:32:03.270: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------set
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.080 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 360 of 7332 Specs in 7028.389 seconds
SUCCESS! -- 360 Passed | 0 Failed | 0 Pending | 6972 Skipped
PASS

Ginkgo ran 1 suite in 1h57m8.752987335s
Test Suite Passed
