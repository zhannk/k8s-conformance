I0827 05:29:40.934433      19 e2e.go:116] Starting e2e run "2182355c-f2a3-4ab8-bbc3-0d6edf17ebec" on Ginkgo node 1
Aug 27 05:29:40.945: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1661578180 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Aug 27 05:29:41.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:29:41.095: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 27 05:29:41.114: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 27 05:29:41.135: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 27 05:29:41.135: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Aug 27 05:29:41.135: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 27 05:29:41.140: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 27 05:29:41.140: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug 27 05:29:41.140: INFO: e2e test version: v1.25.0
Aug 27 05:29:41.142: INFO: kube-apiserver version: v1.25.0
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Aug 27 05:29:41.142: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:29:41.147: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.054 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Aug 27 05:29:41.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:29:41.095: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Aug 27 05:29:41.114: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Aug 27 05:29:41.135: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Aug 27 05:29:41.135: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
    Aug 27 05:29:41.135: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Aug 27 05:29:41.140: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Aug 27 05:29:41.140: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
    Aug 27 05:29:41.140: INFO: e2e test version: v1.25.0
    Aug 27 05:29:41.142: INFO: kube-apiserver version: v1.25.0
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Aug 27 05:29:41.142: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:29:41.147: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:29:41.181
Aug 27 05:29:41.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename ephemeral-containers-test 08/27/22 05:29:41.182
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:41.203
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:41.207
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 08/27/22 05:29:41.21
Aug 27 05:29:41.219: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-7253" to be "running and ready"
Aug 27 05:29:41.222: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.680437ms
Aug 27 05:29:41.222: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:29:43.227: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007769361s
Aug 27 05:29:43.227: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:29:45.228: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009563678s
Aug 27 05:29:45.228: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Aug 27 05:29:45.228: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 08/27/22 05:29:45.231
Aug 27 05:29:45.244: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-7253" to be "container debugger running"
Aug 27 05:29:45.249: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.756796ms
Aug 27 05:29:47.254: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009274059s
Aug 27 05:29:47.254: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 08/27/22 05:29:47.254
Aug 27 05:29:47.254: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-7253 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:29:47.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:29:47.254: INFO: ExecWithOptions: Clientset creation
Aug 27 05:29:47.254: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/ephemeral-containers-test-7253/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Aug 27 05:29:47.359: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 05:29:47.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-7253" for this suite. 08/27/22 05:29:47.385
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":1,"skipped":6,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.211 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:29:41.181
    Aug 27 05:29:41.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename ephemeral-containers-test 08/27/22 05:29:41.182
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:41.203
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:41.207
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 08/27/22 05:29:41.21
    Aug 27 05:29:41.219: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-7253" to be "running and ready"
    Aug 27 05:29:41.222: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.680437ms
    Aug 27 05:29:41.222: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:29:43.227: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007769361s
    Aug 27 05:29:43.227: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:29:45.228: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009563678s
    Aug 27 05:29:45.228: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Aug 27 05:29:45.228: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 08/27/22 05:29:45.231
    Aug 27 05:29:45.244: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-7253" to be "container debugger running"
    Aug 27 05:29:45.249: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.756796ms
    Aug 27 05:29:47.254: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009274059s
    Aug 27 05:29:47.254: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 08/27/22 05:29:47.254
    Aug 27 05:29:47.254: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-7253 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:29:47.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:29:47.254: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:29:47.254: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/ephemeral-containers-test-7253/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Aug 27 05:29:47.359: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 05:29:47.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-7253" for this suite. 08/27/22 05:29:47.385
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:29:47.398
Aug 27 05:29:47.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 05:29:47.404
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:47.423
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:47.429
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 08/27/22 05:29:47.434
Aug 27 05:29:47.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5372 api-versions'
Aug 27 05:29:47.644: INFO: stderr: ""
Aug 27 05:29:47.644: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 05:29:47.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5372" for this suite. 08/27/22 05:29:47.649
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":2,"skipped":22,"failed":0}
------------------------------
â€¢ [0.257 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:29:47.398
    Aug 27 05:29:47.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 05:29:47.404
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:47.423
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:47.429
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 08/27/22 05:29:47.434
    Aug 27 05:29:47.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5372 api-versions'
    Aug 27 05:29:47.644: INFO: stderr: ""
    Aug 27 05:29:47.644: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 05:29:47.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5372" for this suite. 08/27/22 05:29:47.649
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:29:47.657
Aug 27 05:29:47.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:29:47.658
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:47.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:47.718
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:29:47.766
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:29:48.237
STEP: Deploying the webhook pod 08/27/22 05:29:48.243
STEP: Wait for the deployment to be ready 08/27/22 05:29:48.253
Aug 27 05:29:48.259: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Aug 27 05:29:50.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 05:29:52.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/27/22 05:29:54.284
STEP: Verifying the service has paired with the endpoint 08/27/22 05:29:54.293
Aug 27 05:29:55.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 08/27/22 05:29:55.297
STEP: Creating a custom resource definition that should be denied by the webhook 08/27/22 05:29:55.334
Aug 27 05:29:55.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:29:55.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4840" for this suite. 08/27/22 05:29:55.361
STEP: Destroying namespace "webhook-4840-markers" for this suite. 08/27/22 05:29:55.367
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":3,"skipped":23,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.797 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:29:47.657
    Aug 27 05:29:47.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:29:47.658
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:47.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:47.718
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:29:47.766
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:29:48.237
    STEP: Deploying the webhook pod 08/27/22 05:29:48.243
    STEP: Wait for the deployment to be ready 08/27/22 05:29:48.253
    Aug 27 05:29:48.259: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Aug 27 05:29:50.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 05:29:52.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 29, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/27/22 05:29:54.284
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:29:54.293
    Aug 27 05:29:55.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 08/27/22 05:29:55.297
    STEP: Creating a custom resource definition that should be denied by the webhook 08/27/22 05:29:55.334
    Aug 27 05:29:55.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:29:55.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4840" for this suite. 08/27/22 05:29:55.361
    STEP: Destroying namespace "webhook-4840-markers" for this suite. 08/27/22 05:29:55.367
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:29:55.455
Aug 27 05:29:55.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 05:29:55.457
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:55.527
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:55.545
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2091 08/27/22 05:29:55.586
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 08/27/22 05:29:55.599
STEP: Creating pod with conflicting port in namespace statefulset-2091 08/27/22 05:29:55.632
STEP: Waiting until pod test-pod will start running in namespace statefulset-2091 08/27/22 05:29:55.666
Aug 27 05:29:55.666: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2091" to be "running"
Aug 27 05:29:55.686: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 20.088993ms
Aug 27 05:29:57.695: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028910769s
Aug 27 05:29:59.691: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024553593s
Aug 27 05:30:01.690: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.023729129s
Aug 27 05:30:01.690: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-2091 08/27/22 05:30:01.69
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2091 08/27/22 05:30:01.715
Aug 27 05:30:01.831: INFO: Observed stateful pod in namespace: statefulset-2091, name: ss-0, uid: 4bf01083-a7db-4745-a8d6-0e797dc92449, status phase: Pending. Waiting for statefulset controller to delete.
Aug 27 05:30:01.883: INFO: Observed stateful pod in namespace: statefulset-2091, name: ss-0, uid: 4bf01083-a7db-4745-a8d6-0e797dc92449, status phase: Failed. Waiting for statefulset controller to delete.
Aug 27 05:30:01.908: INFO: Observed stateful pod in namespace: statefulset-2091, name: ss-0, uid: 4bf01083-a7db-4745-a8d6-0e797dc92449, status phase: Failed. Waiting for statefulset controller to delete.
Aug 27 05:30:01.928: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2091
STEP: Removing pod with conflicting port in namespace statefulset-2091 08/27/22 05:30:01.929
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2091 and will be in running state 08/27/22 05:30:02.009
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 05:30:06.054: INFO: Deleting all statefulset in ns statefulset-2091
Aug 27 05:30:06.057: INFO: Scaling statefulset ss to 0
Aug 27 05:30:16.080: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 05:30:16.084: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 05:30:16.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2091" for this suite. 08/27/22 05:30:16.111
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":4,"skipped":33,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.661 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:29:55.455
    Aug 27 05:29:55.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 05:29:55.457
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:29:55.527
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:29:55.545
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2091 08/27/22 05:29:55.586
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 08/27/22 05:29:55.599
    STEP: Creating pod with conflicting port in namespace statefulset-2091 08/27/22 05:29:55.632
    STEP: Waiting until pod test-pod will start running in namespace statefulset-2091 08/27/22 05:29:55.666
    Aug 27 05:29:55.666: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2091" to be "running"
    Aug 27 05:29:55.686: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 20.088993ms
    Aug 27 05:29:57.695: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028910769s
    Aug 27 05:29:59.691: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024553593s
    Aug 27 05:30:01.690: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.023729129s
    Aug 27 05:30:01.690: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-2091 08/27/22 05:30:01.69
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2091 08/27/22 05:30:01.715
    Aug 27 05:30:01.831: INFO: Observed stateful pod in namespace: statefulset-2091, name: ss-0, uid: 4bf01083-a7db-4745-a8d6-0e797dc92449, status phase: Pending. Waiting for statefulset controller to delete.
    Aug 27 05:30:01.883: INFO: Observed stateful pod in namespace: statefulset-2091, name: ss-0, uid: 4bf01083-a7db-4745-a8d6-0e797dc92449, status phase: Failed. Waiting for statefulset controller to delete.
    Aug 27 05:30:01.908: INFO: Observed stateful pod in namespace: statefulset-2091, name: ss-0, uid: 4bf01083-a7db-4745-a8d6-0e797dc92449, status phase: Failed. Waiting for statefulset controller to delete.
    Aug 27 05:30:01.928: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2091
    STEP: Removing pod with conflicting port in namespace statefulset-2091 08/27/22 05:30:01.929
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2091 and will be in running state 08/27/22 05:30:02.009
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 05:30:06.054: INFO: Deleting all statefulset in ns statefulset-2091
    Aug 27 05:30:06.057: INFO: Scaling statefulset ss to 0
    Aug 27 05:30:16.080: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 05:30:16.084: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 05:30:16.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2091" for this suite. 08/27/22 05:30:16.111
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:30:16.117
Aug 27 05:30:16.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 05:30:16.122
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:16.143
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:16.148
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 08/27/22 05:30:16.188
STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:30:16.194
Aug 27 05:30:16.216: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:16.232: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:30:16.232: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:17.237: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:17.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:30:17.243: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:18.238: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:18.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:18.244: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:19.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:19.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:19.240: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:20.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:20.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:20.242: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:21.238: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:21.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:21.243: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:22.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:22.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:22.239: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:23.237: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:23.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:23.240: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:24.238: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:24.249: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:24.249: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:25.237: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:25.241: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:25.241: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:26.241: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:26.248: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:26.248: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:27.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:27.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 05:30:27.240: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status 08/27/22 05:30:27.244
Aug 27 05:30:27.248: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 08/27/22 05:30:27.248
Aug 27 05:30:27.259: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 08/27/22 05:30:27.259
Aug 27 05:30:27.263: INFO: Observed &DaemonSet event: ADDED
Aug 27 05:30:27.263: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.263: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.264: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.264: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.264: INFO: Found daemon set daemon-set in namespace daemonsets-2770 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 27 05:30:27.264: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 08/27/22 05:30:27.264
STEP: watching for the daemon set status to be patched 08/27/22 05:30:27.278
Aug 27 05:30:27.285: INFO: Observed &DaemonSet event: ADDED
Aug 27 05:30:27.285: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.286: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.286: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.286: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.286: INFO: Observed daemon set daemon-set in namespace daemonsets-2770 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 27 05:30:27.290: INFO: Observed &DaemonSet event: MODIFIED
Aug 27 05:30:27.290: INFO: Found daemon set daemon-set in namespace daemonsets-2770 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Aug 27 05:30:27.291: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/27/22 05:30:27.295
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2770, will wait for the garbage collector to delete the pods 08/27/22 05:30:27.295
Aug 27 05:30:27.355: INFO: Deleting DaemonSet.extensions daemon-set took: 5.131466ms
Aug 27 05:30:27.455: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.730575ms
Aug 27 05:30:29.960: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:30:29.960: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 27 05:30:29.963: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1265"},"items":null}

Aug 27 05:30:29.973: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1265"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:30:30.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2770" for this suite. 08/27/22 05:30:30.007
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":5,"skipped":40,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.896 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:30:16.117
    Aug 27 05:30:16.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 05:30:16.122
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:16.143
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:16.148
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 08/27/22 05:30:16.188
    STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:30:16.194
    Aug 27 05:30:16.216: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:16.232: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:30:16.232: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:17.237: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:17.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:30:17.243: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:18.238: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:18.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:18.244: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:19.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:19.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:19.240: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:20.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:20.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:20.242: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:21.238: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:21.243: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:21.243: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:22.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:22.239: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:22.239: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:23.237: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:23.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:23.240: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:24.238: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:24.249: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:24.249: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:25.237: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:25.241: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:25.241: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:26.241: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:26.248: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:26.248: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:27.236: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:27.240: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 05:30:27.240: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Getting /status 08/27/22 05:30:27.244
    Aug 27 05:30:27.248: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 08/27/22 05:30:27.248
    Aug 27 05:30:27.259: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 08/27/22 05:30:27.259
    Aug 27 05:30:27.263: INFO: Observed &DaemonSet event: ADDED
    Aug 27 05:30:27.263: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.263: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.264: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.264: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.264: INFO: Found daemon set daemon-set in namespace daemonsets-2770 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 27 05:30:27.264: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 08/27/22 05:30:27.264
    STEP: watching for the daemon set status to be patched 08/27/22 05:30:27.278
    Aug 27 05:30:27.285: INFO: Observed &DaemonSet event: ADDED
    Aug 27 05:30:27.285: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.286: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.286: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.286: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.286: INFO: Observed daemon set daemon-set in namespace daemonsets-2770 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 27 05:30:27.290: INFO: Observed &DaemonSet event: MODIFIED
    Aug 27 05:30:27.290: INFO: Found daemon set daemon-set in namespace daemonsets-2770 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Aug 27 05:30:27.291: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/27/22 05:30:27.295
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2770, will wait for the garbage collector to delete the pods 08/27/22 05:30:27.295
    Aug 27 05:30:27.355: INFO: Deleting DaemonSet.extensions daemon-set took: 5.131466ms
    Aug 27 05:30:27.455: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.730575ms
    Aug 27 05:30:29.960: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:30:29.960: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 27 05:30:29.963: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1265"},"items":null}

    Aug 27 05:30:29.973: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1265"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:30:30.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2770" for this suite. 08/27/22 05:30:30.007
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:30:30.013
Aug 27 05:30:30.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 05:30:30.014
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:30.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:30.068
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 08/27/22 05:30:30.075
STEP: submitting the pod to kubernetes 08/27/22 05:30:30.076
Aug 27 05:30:30.086: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" in namespace "pods-4751" to be "running and ready"
Aug 27 05:30:30.092: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Pending", Reason="", readiness=false. Elapsed: 5.801335ms
Aug 27 05:30:30.092: INFO: The phase of Pod pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:30:32.096: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00930542s
Aug 27 05:30:32.096: INFO: The phase of Pod pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:30:34.099: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Running", Reason="", readiness=true. Elapsed: 4.012527958s
Aug 27 05:30:34.099: INFO: The phase of Pod pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86 is Running (Ready = true)
Aug 27 05:30:34.099: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 08/27/22 05:30:34.102
STEP: updating the pod 08/27/22 05:30:34.106
Aug 27 05:30:34.615: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86"
Aug 27 05:30:34.615: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" in namespace "pods-4751" to be "terminated with reason DeadlineExceeded"
Aug 27 05:30:34.619: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Running", Reason="", readiness=true. Elapsed: 3.511019ms
Aug 27 05:30:36.624: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Running", Reason="", readiness=false. Elapsed: 2.008438292s
Aug 27 05:30:38.624: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008768173s
Aug 27 05:30:38.624: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 05:30:38.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4751" for this suite. 08/27/22 05:30:38.628
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":6,"skipped":43,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.620 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:30:30.013
    Aug 27 05:30:30.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 05:30:30.014
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:30.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:30.068
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 08/27/22 05:30:30.075
    STEP: submitting the pod to kubernetes 08/27/22 05:30:30.076
    Aug 27 05:30:30.086: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" in namespace "pods-4751" to be "running and ready"
    Aug 27 05:30:30.092: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Pending", Reason="", readiness=false. Elapsed: 5.801335ms
    Aug 27 05:30:30.092: INFO: The phase of Pod pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:30:32.096: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00930542s
    Aug 27 05:30:32.096: INFO: The phase of Pod pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:30:34.099: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Running", Reason="", readiness=true. Elapsed: 4.012527958s
    Aug 27 05:30:34.099: INFO: The phase of Pod pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86 is Running (Ready = true)
    Aug 27 05:30:34.099: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 08/27/22 05:30:34.102
    STEP: updating the pod 08/27/22 05:30:34.106
    Aug 27 05:30:34.615: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86"
    Aug 27 05:30:34.615: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" in namespace "pods-4751" to be "terminated with reason DeadlineExceeded"
    Aug 27 05:30:34.619: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Running", Reason="", readiness=true. Elapsed: 3.511019ms
    Aug 27 05:30:36.624: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Running", Reason="", readiness=false. Elapsed: 2.008438292s
    Aug 27 05:30:38.624: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008768173s
    Aug 27 05:30:38.624: INFO: Pod "pod-update-activedeadlineseconds-a145ae2c-3402-44f4-b71b-c7ef7d087e86" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 05:30:38.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4751" for this suite. 08/27/22 05:30:38.628
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:30:38.639
Aug 27 05:30:38.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename controllerrevisions 08/27/22 05:30:38.639
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:38.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:38.663
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-spp84-daemon-set" 08/27/22 05:30:38.686
STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:30:38.69
Aug 27 05:30:38.695: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:38.699: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 0
Aug 27 05:30:38.699: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:39.704: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:39.707: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 0
Aug 27 05:30:39.707: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:40.705: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:40.709: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 2
Aug 27 05:30:40.709: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-spp84-daemon-set
STEP: Confirm DaemonSet "e2e-spp84-daemon-set" successfully created with "daemonset-name=e2e-spp84-daemon-set" label 08/27/22 05:30:40.717
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-spp84-daemon-set" 08/27/22 05:30:40.726
Aug 27 05:30:40.734: INFO: Located ControllerRevision: "e2e-spp84-daemon-set-5fc589c9b6"
STEP: Patching ControllerRevision "e2e-spp84-daemon-set-5fc589c9b6" 08/27/22 05:30:40.738
Aug 27 05:30:40.748: INFO: e2e-spp84-daemon-set-5fc589c9b6 has been patched
STEP: Create a new ControllerRevision 08/27/22 05:30:40.748
Aug 27 05:30:40.757: INFO: Created ControllerRevision: e2e-spp84-daemon-set-54857d4c96
STEP: Confirm that there are two ControllerRevisions 08/27/22 05:30:40.757
Aug 27 05:30:40.757: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 27 05:30:40.768: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-spp84-daemon-set-5fc589c9b6" 08/27/22 05:30:40.768
STEP: Confirm that there is only one ControllerRevision 08/27/22 05:30:40.776
Aug 27 05:30:40.776: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 27 05:30:40.780: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-spp84-daemon-set-54857d4c96" 08/27/22 05:30:40.789
Aug 27 05:30:40.805: INFO: e2e-spp84-daemon-set-54857d4c96 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 08/27/22 05:30:40.805
W0827 05:30:40.813540      19 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 08/27/22 05:30:40.813
Aug 27 05:30:40.813: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 27 05:30:41.826: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 27 05:30:41.829: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-spp84-daemon-set-54857d4c96=updated" 08/27/22 05:30:41.829
STEP: Confirm that there is only one ControllerRevision 08/27/22 05:30:41.834
Aug 27 05:30:41.834: INFO: Requesting list of ControllerRevisions to confirm quantity
Aug 27 05:30:41.837: INFO: Found 1 ControllerRevisions
Aug 27 05:30:41.839: INFO: ControllerRevision "e2e-spp84-daemon-set-758457dbc7" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-spp84-daemon-set" 08/27/22 05:30:41.842
STEP: deleting DaemonSet.extensions e2e-spp84-daemon-set in namespace controllerrevisions-1471, will wait for the garbage collector to delete the pods 08/27/22 05:30:41.842
Aug 27 05:30:41.899: INFO: Deleting DaemonSet.extensions e2e-spp84-daemon-set took: 4.560879ms
Aug 27 05:30:42.000: INFO: Terminating DaemonSet.extensions e2e-spp84-daemon-set pods took: 100.605936ms
Aug 27 05:30:43.303: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 0
Aug 27 05:30:43.303: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-spp84-daemon-set
Aug 27 05:30:43.305: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1397"},"items":null}

Aug 27 05:30:43.308: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1397"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:30:43.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-1471" for this suite. 08/27/22 05:30:43.318
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":7,"skipped":130,"failed":0}
------------------------------
â€¢ [4.684 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:30:38.639
    Aug 27 05:30:38.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename controllerrevisions 08/27/22 05:30:38.639
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:38.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:38.663
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-spp84-daemon-set" 08/27/22 05:30:38.686
    STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:30:38.69
    Aug 27 05:30:38.695: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:38.699: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 0
    Aug 27 05:30:38.699: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:39.704: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:39.707: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 0
    Aug 27 05:30:39.707: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:40.705: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:40.709: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 2
    Aug 27 05:30:40.709: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-spp84-daemon-set
    STEP: Confirm DaemonSet "e2e-spp84-daemon-set" successfully created with "daemonset-name=e2e-spp84-daemon-set" label 08/27/22 05:30:40.717
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-spp84-daemon-set" 08/27/22 05:30:40.726
    Aug 27 05:30:40.734: INFO: Located ControllerRevision: "e2e-spp84-daemon-set-5fc589c9b6"
    STEP: Patching ControllerRevision "e2e-spp84-daemon-set-5fc589c9b6" 08/27/22 05:30:40.738
    Aug 27 05:30:40.748: INFO: e2e-spp84-daemon-set-5fc589c9b6 has been patched
    STEP: Create a new ControllerRevision 08/27/22 05:30:40.748
    Aug 27 05:30:40.757: INFO: Created ControllerRevision: e2e-spp84-daemon-set-54857d4c96
    STEP: Confirm that there are two ControllerRevisions 08/27/22 05:30:40.757
    Aug 27 05:30:40.757: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 27 05:30:40.768: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-spp84-daemon-set-5fc589c9b6" 08/27/22 05:30:40.768
    STEP: Confirm that there is only one ControllerRevision 08/27/22 05:30:40.776
    Aug 27 05:30:40.776: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 27 05:30:40.780: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-spp84-daemon-set-54857d4c96" 08/27/22 05:30:40.789
    Aug 27 05:30:40.805: INFO: e2e-spp84-daemon-set-54857d4c96 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 08/27/22 05:30:40.805
    W0827 05:30:40.813540      19 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 08/27/22 05:30:40.813
    Aug 27 05:30:40.813: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 27 05:30:41.826: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 27 05:30:41.829: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-spp84-daemon-set-54857d4c96=updated" 08/27/22 05:30:41.829
    STEP: Confirm that there is only one ControllerRevision 08/27/22 05:30:41.834
    Aug 27 05:30:41.834: INFO: Requesting list of ControllerRevisions to confirm quantity
    Aug 27 05:30:41.837: INFO: Found 1 ControllerRevisions
    Aug 27 05:30:41.839: INFO: ControllerRevision "e2e-spp84-daemon-set-758457dbc7" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-spp84-daemon-set" 08/27/22 05:30:41.842
    STEP: deleting DaemonSet.extensions e2e-spp84-daemon-set in namespace controllerrevisions-1471, will wait for the garbage collector to delete the pods 08/27/22 05:30:41.842
    Aug 27 05:30:41.899: INFO: Deleting DaemonSet.extensions e2e-spp84-daemon-set took: 4.560879ms
    Aug 27 05:30:42.000: INFO: Terminating DaemonSet.extensions e2e-spp84-daemon-set pods took: 100.605936ms
    Aug 27 05:30:43.303: INFO: Number of nodes with available pods controlled by daemonset e2e-spp84-daemon-set: 0
    Aug 27 05:30:43.303: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-spp84-daemon-set
    Aug 27 05:30:43.305: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1397"},"items":null}

    Aug 27 05:30:43.308: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1397"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:30:43.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-1471" for this suite. 08/27/22 05:30:43.318
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:30:43.326
Aug 27 05:30:43.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 05:30:43.327
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:43.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:43.349
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 08/27/22 05:30:43.37
STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:30:43.38
Aug 27 05:30:43.383: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:43.386: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:30:43.386: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:44.390: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:44.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:44.393: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:30:45.390: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:45.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 05:30:45.393: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 08/27/22 05:30:45.396
Aug 27 05:30:45.410: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:45.413: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:45.414: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:46.418: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:46.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:46.421: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:47.418: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:47.423: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:30:47.423: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:30:48.419: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:30:48.423: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 05:30:48.423: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/27/22 05:30:48.428
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8751, will wait for the garbage collector to delete the pods 08/27/22 05:30:48.428
Aug 27 05:30:48.491: INFO: Deleting DaemonSet.extensions daemon-set took: 10.046824ms
Aug 27 05:30:48.592: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.288155ms
Aug 27 05:30:51.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:30:51.295: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 27 05:30:51.301: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1519"},"items":null}

Aug 27 05:30:51.304: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1519"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:30:51.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8751" for this suite. 08/27/22 05:30:51.332
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":8,"skipped":153,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.010 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:30:43.326
    Aug 27 05:30:43.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 05:30:43.327
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:43.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:43.349
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 08/27/22 05:30:43.37
    STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:30:43.38
    Aug 27 05:30:43.383: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:43.386: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:30:43.386: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:44.390: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:44.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:44.393: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:30:45.390: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:45.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 05:30:45.393: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 08/27/22 05:30:45.396
    Aug 27 05:30:45.410: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:45.413: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:45.414: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:46.418: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:46.421: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:46.421: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:47.418: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:47.423: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:30:47.423: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:30:48.419: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:30:48.423: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 05:30:48.423: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/27/22 05:30:48.428
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8751, will wait for the garbage collector to delete the pods 08/27/22 05:30:48.428
    Aug 27 05:30:48.491: INFO: Deleting DaemonSet.extensions daemon-set took: 10.046824ms
    Aug 27 05:30:48.592: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.288155ms
    Aug 27 05:30:51.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:30:51.295: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 27 05:30:51.301: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"1519"},"items":null}

    Aug 27 05:30:51.304: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"1519"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:30:51.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8751" for this suite. 08/27/22 05:30:51.332
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:30:51.337
Aug 27 05:30:51.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 05:30:51.339
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:51.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:51.357
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-be055bcf-b273-452f-b2a1-7b395b21aeec 08/27/22 05:30:51.36
STEP: Creating a pod to test consume configMaps 08/27/22 05:30:51.365
Aug 27 05:30:51.372: INFO: Waiting up to 5m0s for pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977" in namespace "configmap-6816" to be "Succeeded or Failed"
Aug 27 05:30:51.375: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977": Phase="Pending", Reason="", readiness=false. Elapsed: 3.702529ms
Aug 27 05:30:53.379: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007134474s
Aug 27 05:30:55.382: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010453375s
STEP: Saw pod success 08/27/22 05:30:55.382
Aug 27 05:30:55.382: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977" satisfied condition "Succeeded or Failed"
Aug 27 05:30:55.385: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977 container configmap-volume-test: <nil>
STEP: delete the pod 08/27/22 05:30:55.391
Aug 27 05:30:55.403: INFO: Waiting for pod pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977 to disappear
Aug 27 05:30:55.407: INFO: Pod pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 05:30:55.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6816" for this suite. 08/27/22 05:30:55.411
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":9,"skipped":171,"failed":0}
------------------------------
â€¢ [4.081 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:30:51.337
    Aug 27 05:30:51.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 05:30:51.339
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:51.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:51.357
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-be055bcf-b273-452f-b2a1-7b395b21aeec 08/27/22 05:30:51.36
    STEP: Creating a pod to test consume configMaps 08/27/22 05:30:51.365
    Aug 27 05:30:51.372: INFO: Waiting up to 5m0s for pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977" in namespace "configmap-6816" to be "Succeeded or Failed"
    Aug 27 05:30:51.375: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977": Phase="Pending", Reason="", readiness=false. Elapsed: 3.702529ms
    Aug 27 05:30:53.379: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007134474s
    Aug 27 05:30:55.382: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010453375s
    STEP: Saw pod success 08/27/22 05:30:55.382
    Aug 27 05:30:55.382: INFO: Pod "pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977" satisfied condition "Succeeded or Failed"
    Aug 27 05:30:55.385: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977 container configmap-volume-test: <nil>
    STEP: delete the pod 08/27/22 05:30:55.391
    Aug 27 05:30:55.403: INFO: Waiting for pod pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977 to disappear
    Aug 27 05:30:55.407: INFO: Pod pod-configmaps-8eecf5d7-d526-4bde-a421-df8c5d2e0977 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 05:30:55.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6816" for this suite. 08/27/22 05:30:55.411
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:30:55.421
Aug 27 05:30:55.421: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pod-network-test 08/27/22 05:30:55.422
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:55.446
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:55.451
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-1448 08/27/22 05:30:55.455
STEP: creating a selector 08/27/22 05:30:55.455
STEP: Creating the service pods in kubernetes 08/27/22 05:30:55.455
Aug 27 05:30:55.455: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 05:30:55.473: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1448" to be "running and ready"
Aug 27 05:30:55.521: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 47.842491ms
Aug 27 05:30:55.521: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:30:57.525: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052267929s
Aug 27 05:30:57.526: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:30:59.525: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052136239s
Aug 27 05:30:59.525: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:31:01.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.054187452s
Aug 27 05:31:01.528: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:03.524: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.051347284s
Aug 27 05:31:03.525: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:05.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.0534164s
Aug 27 05:31:05.527: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:07.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.054216924s
Aug 27 05:31:07.527: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:09.525: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.052229057s
Aug 27 05:31:09.525: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:11.526: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.052375189s
Aug 27 05:31:11.526: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:13.526: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.052970406s
Aug 27 05:31:13.526: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:15.531: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.058117428s
Aug 27 05:31:15.531: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:31:17.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.053595601s
Aug 27 05:31:17.527: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 27 05:31:17.527: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 27 05:31:17.530: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1448" to be "running and ready"
Aug 27 05:31:17.532: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.631019ms
Aug 27 05:31:17.532: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 27 05:31:17.532: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 08/27/22 05:31:17.536
Aug 27 05:31:17.546: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1448" to be "running"
Aug 27 05:31:17.551: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.754617ms
Aug 27 05:31:19.556: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010729715s
Aug 27 05:31:19.556: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 27 05:31:19.559: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1448" to be "running"
Aug 27 05:31:19.562: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.238571ms
Aug 27 05:31:19.562: INFO: Pod "host-test-container-pod" satisfied condition "running"
Aug 27 05:31:19.564: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug 27 05:31:19.564: INFO: Going to poll 10.2.137.8 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Aug 27 05:31:19.570: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.137.8:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1448 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:31:19.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:31:19.570: INFO: ExecWithOptions: Clientset creation
Aug 27 05:31:19.570: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-1448/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.2.137.8%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 27 05:31:19.693: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 27 05:31:19.693: INFO: Going to poll 10.2.35.9 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Aug 27 05:31:19.697: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.35.9:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1448 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:31:19.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:31:19.698: INFO: ExecWithOptions: Clientset creation
Aug 27 05:31:19.698: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-1448/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.2.35.9%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 27 05:31:19.768: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 27 05:31:19.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1448" for this suite. 08/27/22 05:31:19.771
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":10,"skipped":216,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.355 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:30:55.421
    Aug 27 05:30:55.421: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pod-network-test 08/27/22 05:30:55.422
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:30:55.446
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:30:55.451
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-1448 08/27/22 05:30:55.455
    STEP: creating a selector 08/27/22 05:30:55.455
    STEP: Creating the service pods in kubernetes 08/27/22 05:30:55.455
    Aug 27 05:30:55.455: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 27 05:30:55.473: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1448" to be "running and ready"
    Aug 27 05:30:55.521: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 47.842491ms
    Aug 27 05:30:55.521: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:30:57.525: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052267929s
    Aug 27 05:30:57.526: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:30:59.525: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052136239s
    Aug 27 05:30:59.525: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:31:01.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.054187452s
    Aug 27 05:31:01.528: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:03.524: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.051347284s
    Aug 27 05:31:03.525: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:05.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.0534164s
    Aug 27 05:31:05.527: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:07.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.054216924s
    Aug 27 05:31:07.527: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:09.525: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.052229057s
    Aug 27 05:31:09.525: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:11.526: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.052375189s
    Aug 27 05:31:11.526: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:13.526: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.052970406s
    Aug 27 05:31:13.526: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:15.531: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.058117428s
    Aug 27 05:31:15.531: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:31:17.527: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.053595601s
    Aug 27 05:31:17.527: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 27 05:31:17.527: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 27 05:31:17.530: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1448" to be "running and ready"
    Aug 27 05:31:17.532: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.631019ms
    Aug 27 05:31:17.532: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 27 05:31:17.532: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 08/27/22 05:31:17.536
    Aug 27 05:31:17.546: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1448" to be "running"
    Aug 27 05:31:17.551: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.754617ms
    Aug 27 05:31:19.556: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010729715s
    Aug 27 05:31:19.556: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 27 05:31:19.559: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1448" to be "running"
    Aug 27 05:31:19.562: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.238571ms
    Aug 27 05:31:19.562: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Aug 27 05:31:19.564: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Aug 27 05:31:19.564: INFO: Going to poll 10.2.137.8 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Aug 27 05:31:19.570: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.137.8:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1448 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:31:19.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:31:19.570: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:31:19.570: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-1448/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.2.137.8%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 27 05:31:19.693: INFO: Found all 1 expected endpoints: [netserver-0]
    Aug 27 05:31:19.693: INFO: Going to poll 10.2.35.9 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Aug 27 05:31:19.697: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.35.9:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1448 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:31:19.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:31:19.698: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:31:19.698: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-1448/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.2.35.9%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 27 05:31:19.768: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 27 05:31:19.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1448" for this suite. 08/27/22 05:31:19.771
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:19.781
Aug 27 05:31:19.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 05:31:19.783
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:19.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:19.803
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-3233 08/27/22 05:31:19.807
STEP: creating service affinity-clusterip-transition in namespace services-3233 08/27/22 05:31:19.808
STEP: creating replication controller affinity-clusterip-transition in namespace services-3233 08/27/22 05:31:19.816
I0827 05:31:19.833605      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3233, replica count: 3
I0827 05:31:22.884691      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 05:31:22.892: INFO: Creating new exec pod
Aug 27 05:31:22.900: INFO: Waiting up to 5m0s for pod "execpod-affinityz48qk" in namespace "services-3233" to be "running"
Aug 27 05:31:22.904: INFO: Pod "execpod-affinityz48qk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371652ms
Aug 27 05:31:24.914: INFO: Pod "execpod-affinityz48qk": Phase="Running", Reason="", readiness=true. Elapsed: 2.013042209s
Aug 27 05:31:24.914: INFO: Pod "execpod-affinityz48qk" satisfied condition "running"
Aug 27 05:31:25.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Aug 27 05:31:26.120: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Aug 27 05:31:26.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 05:31:26.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.36.28 80'
Aug 27 05:31:26.242: INFO: stderr: "+ nc -v -t -w 2 10.3.36.28 80\n+ echo hostName\nConnection to 10.3.36.28 80 port [tcp/http] succeeded!\n"
Aug 27 05:31:26.242: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 05:31:26.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.36.28:80/ ; done'
Aug 27 05:31:26.497: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n"
Aug 27 05:31:26.497: INFO: stdout: "\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp"
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
Aug 27 05:31:26.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.36.28:80/ ; done'
Aug 27 05:31:26.746: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n"
Aug 27 05:31:26.747: INFO: stdout: "\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh"
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
Aug 27 05:31:26.747: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3233, will wait for the garbage collector to delete the pods 08/27/22 05:31:26.759
Aug 27 05:31:26.818: INFO: Deleting ReplicationController affinity-clusterip-transition took: 5.002472ms
Aug 27 05:31:26.920: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.853986ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 05:31:29.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3233" for this suite. 08/27/22 05:31:29.245
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":11,"skipped":221,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.473 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:19.781
    Aug 27 05:31:19.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 05:31:19.783
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:19.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:19.803
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-3233 08/27/22 05:31:19.807
    STEP: creating service affinity-clusterip-transition in namespace services-3233 08/27/22 05:31:19.808
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3233 08/27/22 05:31:19.816
    I0827 05:31:19.833605      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3233, replica count: 3
    I0827 05:31:22.884691      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 05:31:22.892: INFO: Creating new exec pod
    Aug 27 05:31:22.900: INFO: Waiting up to 5m0s for pod "execpod-affinityz48qk" in namespace "services-3233" to be "running"
    Aug 27 05:31:22.904: INFO: Pod "execpod-affinityz48qk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371652ms
    Aug 27 05:31:24.914: INFO: Pod "execpod-affinityz48qk": Phase="Running", Reason="", readiness=true. Elapsed: 2.013042209s
    Aug 27 05:31:24.914: INFO: Pod "execpod-affinityz48qk" satisfied condition "running"
    Aug 27 05:31:25.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Aug 27 05:31:26.120: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Aug 27 05:31:26.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 05:31:26.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.36.28 80'
    Aug 27 05:31:26.242: INFO: stderr: "+ nc -v -t -w 2 10.3.36.28 80\n+ echo hostName\nConnection to 10.3.36.28 80 port [tcp/http] succeeded!\n"
    Aug 27 05:31:26.242: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 05:31:26.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.36.28:80/ ; done'
    Aug 27 05:31:26.497: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n"
    Aug 27 05:31:26.497: INFO: stdout: "\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp\naffinity-clusterip-transition-dnxww\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-tdgqp"
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-dnxww
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.497: INFO: Received response from host: affinity-clusterip-transition-tdgqp
    Aug 27 05:31:26.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3233 exec execpod-affinityz48qk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.36.28:80/ ; done'
    Aug 27 05:31:26.746: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.36.28:80/\n"
    Aug 27 05:31:26.747: INFO: stdout: "\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh\naffinity-clusterip-transition-pdbmh"
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Received response from host: affinity-clusterip-transition-pdbmh
    Aug 27 05:31:26.747: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3233, will wait for the garbage collector to delete the pods 08/27/22 05:31:26.759
    Aug 27 05:31:26.818: INFO: Deleting ReplicationController affinity-clusterip-transition took: 5.002472ms
    Aug 27 05:31:26.920: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.853986ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 05:31:29.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3233" for this suite. 08/27/22 05:31:29.245
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:29.261
Aug 27 05:31:29.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-runtime 08/27/22 05:31:29.262
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:29.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:29.293
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 08/27/22 05:31:29.299
STEP: wait for the container to reach Failed 08/27/22 05:31:29.306
STEP: get the container status 08/27/22 05:31:33.324
STEP: the container should be terminated 08/27/22 05:31:33.327
STEP: the termination message should be set 08/27/22 05:31:33.327
Aug 27 05:31:33.328: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 08/27/22 05:31:33.328
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 27 05:31:33.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2493" for this suite. 08/27/22 05:31:33.345
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":12,"skipped":243,"failed":0}
------------------------------
â€¢ [4.091 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:29.261
    Aug 27 05:31:29.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-runtime 08/27/22 05:31:29.262
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:29.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:29.293
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 08/27/22 05:31:29.299
    STEP: wait for the container to reach Failed 08/27/22 05:31:29.306
    STEP: get the container status 08/27/22 05:31:33.324
    STEP: the container should be terminated 08/27/22 05:31:33.327
    STEP: the termination message should be set 08/27/22 05:31:33.327
    Aug 27 05:31:33.328: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 08/27/22 05:31:33.328
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 27 05:31:33.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-2493" for this suite. 08/27/22 05:31:33.345
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:33.352
Aug 27 05:31:33.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 05:31:33.353
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:33.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:33.38
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 08/27/22 05:31:33.384
STEP: Getting a ResourceQuota 08/27/22 05:31:33.388
STEP: Updating a ResourceQuota 08/27/22 05:31:33.393
STEP: Verifying a ResourceQuota was modified 08/27/22 05:31:33.401
STEP: Deleting a ResourceQuota 08/27/22 05:31:33.406
STEP: Verifying the deleted ResourceQuota 08/27/22 05:31:33.418
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 05:31:33.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5480" for this suite. 08/27/22 05:31:33.428
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":13,"skipped":247,"failed":0}
------------------------------
â€¢ [0.115 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:33.352
    Aug 27 05:31:33.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 05:31:33.353
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:33.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:33.38
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 08/27/22 05:31:33.384
    STEP: Getting a ResourceQuota 08/27/22 05:31:33.388
    STEP: Updating a ResourceQuota 08/27/22 05:31:33.393
    STEP: Verifying a ResourceQuota was modified 08/27/22 05:31:33.401
    STEP: Deleting a ResourceQuota 08/27/22 05:31:33.406
    STEP: Verifying the deleted ResourceQuota 08/27/22 05:31:33.418
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 05:31:33.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5480" for this suite. 08/27/22 05:31:33.428
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:33.476
Aug 27 05:31:33.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 05:31:33.477
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:33.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:33.509
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 08/27/22 05:31:33.538
STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:31:33.543
Aug 27 05:31:33.548: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:33.564: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:31:33.564: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:31:34.572: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:34.575: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:31:34.575: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:31:35.577: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:35.583: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:31:35.583: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 05:31:36.568: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:36.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 05:31:36.571: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 08/27/22 05:31:36.574
Aug 27 05:31:36.590: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:36.596: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:31:36.596: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:31:37.609: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:37.626: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 05:31:37.626: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 05:31:38.608: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 05:31:38.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 05:31:38.614: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 08/27/22 05:31:38.614
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/27/22 05:31:38.622
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6227, will wait for the garbage collector to delete the pods 08/27/22 05:31:38.623
Aug 27 05:31:38.688: INFO: Deleting DaemonSet.extensions daemon-set took: 8.460124ms
Aug 27 05:31:38.789: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.916097ms
Aug 27 05:31:41.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 05:31:41.193: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 27 05:31:41.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2011"},"items":null}

Aug 27 05:31:41.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2011"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:31:41.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6227" for this suite. 08/27/22 05:31:41.218
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":14,"skipped":250,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.754 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:33.476
    Aug 27 05:31:33.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 05:31:33.477
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:33.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:33.509
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 08/27/22 05:31:33.538
    STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 05:31:33.543
    Aug 27 05:31:33.548: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:33.564: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:31:33.564: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:31:34.572: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:34.575: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:31:34.575: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:31:35.577: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:35.583: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:31:35.583: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 05:31:36.568: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:36.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 05:31:36.571: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 08/27/22 05:31:36.574
    Aug 27 05:31:36.590: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:36.596: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:31:36.596: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:31:37.609: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:37.626: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 05:31:37.626: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 05:31:38.608: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 05:31:38.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 05:31:38.614: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 08/27/22 05:31:38.614
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/27/22 05:31:38.622
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6227, will wait for the garbage collector to delete the pods 08/27/22 05:31:38.623
    Aug 27 05:31:38.688: INFO: Deleting DaemonSet.extensions daemon-set took: 8.460124ms
    Aug 27 05:31:38.789: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.916097ms
    Aug 27 05:31:41.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 05:31:41.193: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 27 05:31:41.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2011"},"items":null}

    Aug 27 05:31:41.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2011"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:31:41.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6227" for this suite. 08/27/22 05:31:41.218
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:41.228
Aug 27 05:31:41.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 05:31:41.229
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:41.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:41.262
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 08/27/22 05:31:41.266
Aug 27 05:31:41.274: INFO: Waiting up to 5m0s for pod "annotationupdate159f3245-7891-4375-affe-908882270e18" in namespace "downward-api-1520" to be "running and ready"
Aug 27 05:31:41.283: INFO: Pod "annotationupdate159f3245-7891-4375-affe-908882270e18": Phase="Pending", Reason="", readiness=false. Elapsed: 8.50777ms
Aug 27 05:31:41.283: INFO: The phase of Pod annotationupdate159f3245-7891-4375-affe-908882270e18 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:31:43.288: INFO: Pod "annotationupdate159f3245-7891-4375-affe-908882270e18": Phase="Running", Reason="", readiness=true. Elapsed: 2.013339457s
Aug 27 05:31:43.288: INFO: The phase of Pod annotationupdate159f3245-7891-4375-affe-908882270e18 is Running (Ready = true)
Aug 27 05:31:43.288: INFO: Pod "annotationupdate159f3245-7891-4375-affe-908882270e18" satisfied condition "running and ready"
Aug 27 05:31:43.806: INFO: Successfully updated pod "annotationupdate159f3245-7891-4375-affe-908882270e18"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 05:31:47.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1520" for this suite. 08/27/22 05:31:47.835
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":15,"skipped":274,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.614 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:41.228
    Aug 27 05:31:41.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 05:31:41.229
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:41.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:41.262
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 08/27/22 05:31:41.266
    Aug 27 05:31:41.274: INFO: Waiting up to 5m0s for pod "annotationupdate159f3245-7891-4375-affe-908882270e18" in namespace "downward-api-1520" to be "running and ready"
    Aug 27 05:31:41.283: INFO: Pod "annotationupdate159f3245-7891-4375-affe-908882270e18": Phase="Pending", Reason="", readiness=false. Elapsed: 8.50777ms
    Aug 27 05:31:41.283: INFO: The phase of Pod annotationupdate159f3245-7891-4375-affe-908882270e18 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:31:43.288: INFO: Pod "annotationupdate159f3245-7891-4375-affe-908882270e18": Phase="Running", Reason="", readiness=true. Elapsed: 2.013339457s
    Aug 27 05:31:43.288: INFO: The phase of Pod annotationupdate159f3245-7891-4375-affe-908882270e18 is Running (Ready = true)
    Aug 27 05:31:43.288: INFO: Pod "annotationupdate159f3245-7891-4375-affe-908882270e18" satisfied condition "running and ready"
    Aug 27 05:31:43.806: INFO: Successfully updated pod "annotationupdate159f3245-7891-4375-affe-908882270e18"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 05:31:47.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1520" for this suite. 08/27/22 05:31:47.835
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:47.842
Aug 27 05:31:47.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 05:31:47.844
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:47.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:47.877
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 08/27/22 05:31:47.889
Aug 27 05:31:47.895: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b" in namespace "downward-api-2914" to be "Succeeded or Failed"
Aug 27 05:31:47.899: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.922902ms
Aug 27 05:31:49.904: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008605056s
Aug 27 05:31:51.903: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008224543s
STEP: Saw pod success 08/27/22 05:31:51.903
Aug 27 05:31:51.904: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b" satisfied condition "Succeeded or Failed"
Aug 27 05:31:51.907: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b container client-container: <nil>
STEP: delete the pod 08/27/22 05:31:51.925
Aug 27 05:31:51.941: INFO: Waiting for pod downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b to disappear
Aug 27 05:31:51.945: INFO: Pod downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 05:31:51.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2914" for this suite. 08/27/22 05:31:51.951
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":16,"skipped":277,"failed":0}
------------------------------
â€¢ [4.117 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:47.842
    Aug 27 05:31:47.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 05:31:47.844
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:47.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:47.877
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 08/27/22 05:31:47.889
    Aug 27 05:31:47.895: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b" in namespace "downward-api-2914" to be "Succeeded or Failed"
    Aug 27 05:31:47.899: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.922902ms
    Aug 27 05:31:49.904: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008605056s
    Aug 27 05:31:51.903: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008224543s
    STEP: Saw pod success 08/27/22 05:31:51.903
    Aug 27 05:31:51.904: INFO: Pod "downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b" satisfied condition "Succeeded or Failed"
    Aug 27 05:31:51.907: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b container client-container: <nil>
    STEP: delete the pod 08/27/22 05:31:51.925
    Aug 27 05:31:51.941: INFO: Waiting for pod downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b to disappear
    Aug 27 05:31:51.945: INFO: Pod downwardapi-volume-32d09b70-06f4-41e2-94f2-af76f4a76f7b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 05:31:51.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2914" for this suite. 08/27/22 05:31:51.951
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:51.96
Aug 27 05:31:51.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename security-context-test 08/27/22 05:31:51.961
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:51.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:52.003
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Aug 27 05:31:52.038: INFO: Waiting up to 5m0s for pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24" in namespace "security-context-test-2747" to be "Succeeded or Failed"
Aug 27 05:31:52.046: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24": Phase="Pending", Reason="", readiness=false. Elapsed: 7.928634ms
Aug 27 05:31:54.049: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011633387s
Aug 27 05:31:56.049: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011528828s
Aug 27 05:31:56.049: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 27 05:31:56.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2747" for this suite. 08/27/22 05:31:56.054
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":17,"skipped":297,"failed":0}
------------------------------
â€¢ [4.106 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:51.96
    Aug 27 05:31:51.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename security-context-test 08/27/22 05:31:51.961
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:51.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:52.003
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Aug 27 05:31:52.038: INFO: Waiting up to 5m0s for pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24" in namespace "security-context-test-2747" to be "Succeeded or Failed"
    Aug 27 05:31:52.046: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24": Phase="Pending", Reason="", readiness=false. Elapsed: 7.928634ms
    Aug 27 05:31:54.049: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011633387s
    Aug 27 05:31:56.049: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011528828s
    Aug 27 05:31:56.049: INFO: Pod "busybox-user-65534-c99d428a-2503-4d61-af03-c4c8d757de24" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 27 05:31:56.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2747" for this suite. 08/27/22 05:31:56.054
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:31:56.07
Aug 27 05:31:56.070: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 05:31:56.07
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:56.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:56.095
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 08/27/22 05:31:56.101
STEP: Ensuring ResourceQuota status is calculated 08/27/22 05:31:56.105
STEP: Creating a ResourceQuota with not terminating scope 08/27/22 05:31:58.109
STEP: Ensuring ResourceQuota status is calculated 08/27/22 05:31:58.113
STEP: Creating a long running pod 08/27/22 05:32:00.118
STEP: Ensuring resource quota with not terminating scope captures the pod usage 08/27/22 05:32:00.129
STEP: Ensuring resource quota with terminating scope ignored the pod usage 08/27/22 05:32:02.134
STEP: Deleting the pod 08/27/22 05:32:04.139
STEP: Ensuring resource quota status released the pod usage 08/27/22 05:32:04.153
STEP: Creating a terminating pod 08/27/22 05:32:06.158
STEP: Ensuring resource quota with terminating scope captures the pod usage 08/27/22 05:32:06.169
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 08/27/22 05:32:08.173
STEP: Deleting the pod 08/27/22 05:32:10.178
STEP: Ensuring resource quota status released the pod usage 08/27/22 05:32:10.227
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 05:32:12.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5338" for this suite. 08/27/22 05:32:12.235
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":18,"skipped":342,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.174 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:31:56.07
    Aug 27 05:31:56.070: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 05:31:56.07
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:31:56.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:31:56.095
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 08/27/22 05:31:56.101
    STEP: Ensuring ResourceQuota status is calculated 08/27/22 05:31:56.105
    STEP: Creating a ResourceQuota with not terminating scope 08/27/22 05:31:58.109
    STEP: Ensuring ResourceQuota status is calculated 08/27/22 05:31:58.113
    STEP: Creating a long running pod 08/27/22 05:32:00.118
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 08/27/22 05:32:00.129
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 08/27/22 05:32:02.134
    STEP: Deleting the pod 08/27/22 05:32:04.139
    STEP: Ensuring resource quota status released the pod usage 08/27/22 05:32:04.153
    STEP: Creating a terminating pod 08/27/22 05:32:06.158
    STEP: Ensuring resource quota with terminating scope captures the pod usage 08/27/22 05:32:06.169
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 08/27/22 05:32:08.173
    STEP: Deleting the pod 08/27/22 05:32:10.178
    STEP: Ensuring resource quota status released the pod usage 08/27/22 05:32:10.227
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 05:32:12.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5338" for this suite. 08/27/22 05:32:12.235
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:12.244
Aug 27 05:32:12.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 05:32:12.245
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:12.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:12.269
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 08/27/22 05:32:12.276
STEP: fetching the ConfigMap 08/27/22 05:32:12.28
STEP: patching the ConfigMap 08/27/22 05:32:12.282
STEP: listing all ConfigMaps in all namespaces with a label selector 08/27/22 05:32:12.287
STEP: deleting the ConfigMap by collection with a label selector 08/27/22 05:32:12.294
STEP: listing all ConfigMaps in test namespace 08/27/22 05:32:12.299
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 05:32:12.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1924" for this suite. 08/27/22 05:32:12.304
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":19,"skipped":358,"failed":0}
------------------------------
â€¢ [0.064 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:12.244
    Aug 27 05:32:12.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 05:32:12.245
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:12.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:12.269
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 08/27/22 05:32:12.276
    STEP: fetching the ConfigMap 08/27/22 05:32:12.28
    STEP: patching the ConfigMap 08/27/22 05:32:12.282
    STEP: listing all ConfigMaps in all namespaces with a label selector 08/27/22 05:32:12.287
    STEP: deleting the ConfigMap by collection with a label selector 08/27/22 05:32:12.294
    STEP: listing all ConfigMaps in test namespace 08/27/22 05:32:12.299
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 05:32:12.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1924" for this suite. 08/27/22 05:32:12.304
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:12.311
Aug 27 05:32:12.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:32:12.312
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:12.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:12.331
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-4a79caab-0bc2-4fc6-a7e0-c80f375e52a6 08/27/22 05:32:12.336
STEP: Creating a pod to test consume configMaps 08/27/22 05:32:12.339
Aug 27 05:32:12.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35" in namespace "projected-6174" to be "Succeeded or Failed"
Aug 27 05:32:12.348: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.580147ms
Aug 27 05:32:14.353: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35": Phase="Running", Reason="", readiness=false. Elapsed: 2.007279128s
Aug 27 05:32:16.351: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005995853s
STEP: Saw pod success 08/27/22 05:32:16.351
Aug 27 05:32:16.352: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35" satisfied condition "Succeeded or Failed"
Aug 27 05:32:16.355: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35 container projected-configmap-volume-test: <nil>
STEP: delete the pod 08/27/22 05:32:16.363
Aug 27 05:32:16.375: INFO: Waiting for pod pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35 to disappear
Aug 27 05:32:16.378: INFO: Pod pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 05:32:16.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6174" for this suite. 08/27/22 05:32:16.382
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":20,"skipped":366,"failed":0}
------------------------------
â€¢ [4.076 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:12.311
    Aug 27 05:32:12.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:32:12.312
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:12.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:12.331
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-4a79caab-0bc2-4fc6-a7e0-c80f375e52a6 08/27/22 05:32:12.336
    STEP: Creating a pod to test consume configMaps 08/27/22 05:32:12.339
    Aug 27 05:32:12.345: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35" in namespace "projected-6174" to be "Succeeded or Failed"
    Aug 27 05:32:12.348: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.580147ms
    Aug 27 05:32:14.353: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35": Phase="Running", Reason="", readiness=false. Elapsed: 2.007279128s
    Aug 27 05:32:16.351: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005995853s
    STEP: Saw pod success 08/27/22 05:32:16.351
    Aug 27 05:32:16.352: INFO: Pod "pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35" satisfied condition "Succeeded or Failed"
    Aug 27 05:32:16.355: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 08/27/22 05:32:16.363
    Aug 27 05:32:16.375: INFO: Waiting for pod pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35 to disappear
    Aug 27 05:32:16.378: INFO: Pod pod-projected-configmaps-1004e601-b639-4718-84ec-3e8ff5392c35 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 05:32:16.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6174" for this suite. 08/27/22 05:32:16.382
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:16.389
Aug 27 05:32:16.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:32:16.39
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:16.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:16.417
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:32:16.441
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:32:16.83
STEP: Deploying the webhook pod 08/27/22 05:32:16.847
STEP: Wait for the deployment to be ready 08/27/22 05:32:16.856
Aug 27 05:32:16.862: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Aug 27 05:32:18.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/27/22 05:32:20.882
STEP: Verifying the service has paired with the endpoint 08/27/22 05:32:20.906
Aug 27 05:32:21.907: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Aug 27 05:32:21.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8774-crds.webhook.example.com via the AdmissionRegistration API 08/27/22 05:32:22.428
Aug 27 05:32:22.720: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version 08/27/22 05:32:22.927
STEP: Patching Custom Resource Definition to set v2 as storage 08/27/22 05:32:23.042
STEP: Patching the custom resource while v2 is storage version 08/27/22 05:32:23.064
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:32:23.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6645" for this suite. 08/27/22 05:32:23.651
STEP: Destroying namespace "webhook-6645-markers" for this suite. 08/27/22 05:32:23.655
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":21,"skipped":370,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.369 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:16.389
    Aug 27 05:32:16.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:32:16.39
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:16.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:16.417
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:32:16.441
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:32:16.83
    STEP: Deploying the webhook pod 08/27/22 05:32:16.847
    STEP: Wait for the deployment to be ready 08/27/22 05:32:16.856
    Aug 27 05:32:16.862: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Aug 27 05:32:18.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 5, 32, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/27/22 05:32:20.882
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:32:20.906
    Aug 27 05:32:21.907: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Aug 27 05:32:21.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8774-crds.webhook.example.com via the AdmissionRegistration API 08/27/22 05:32:22.428
    Aug 27 05:32:22.720: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource while v1 is storage version 08/27/22 05:32:22.927
    STEP: Patching Custom Resource Definition to set v2 as storage 08/27/22 05:32:23.042
    STEP: Patching the custom resource while v2 is storage version 08/27/22 05:32:23.064
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:32:23.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6645" for this suite. 08/27/22 05:32:23.651
    STEP: Destroying namespace "webhook-6645-markers" for this suite. 08/27/22 05:32:23.655
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:23.763
Aug 27 05:32:23.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pod-network-test 08/27/22 05:32:23.765
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:23.798
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:23.809
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-6098 08/27/22 05:32:23.817
STEP: creating a selector 08/27/22 05:32:23.817
STEP: Creating the service pods in kubernetes 08/27/22 05:32:23.817
Aug 27 05:32:23.817: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 05:32:23.840: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6098" to be "running and ready"
Aug 27 05:32:23.847: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.991926ms
Aug 27 05:32:23.847: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:32:25.852: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.011846526s
Aug 27 05:32:25.852: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:32:27.852: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.012128543s
Aug 27 05:32:27.853: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:32:29.852: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.012094042s
Aug 27 05:32:29.852: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:32:31.851: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.010831273s
Aug 27 05:32:31.851: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:32:33.853: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.012470443s
Aug 27 05:32:33.853: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:32:35.854: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.013741501s
Aug 27 05:32:35.854: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 27 05:32:35.854: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 27 05:32:35.858: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6098" to be "running and ready"
Aug 27 05:32:35.862: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.524747ms
Aug 27 05:32:35.862: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 27 05:32:35.862: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 08/27/22 05:32:35.865
Aug 27 05:32:35.870: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6098" to be "running"
Aug 27 05:32:35.874: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.700327ms
Aug 27 05:32:37.879: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009243514s
Aug 27 05:32:37.879: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 27 05:32:37.882: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug 27 05:32:37.882: INFO: Breadth first check of 10.2.137.12 on host 10.0.31.158...
Aug 27 05:32:37.886: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.22:9080/dial?request=hostname&protocol=udp&host=10.2.137.12&port=8081&tries=1'] Namespace:pod-network-test-6098 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:32:37.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:32:37.886: INFO: ExecWithOptions: Clientset creation
Aug 27 05:32:37.886: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-6098/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.2.137.12%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 27 05:32:37.962: INFO: Waiting for responses: map[]
Aug 27 05:32:37.962: INFO: reached 10.2.137.12 after 0/1 tries
Aug 27 05:32:37.962: INFO: Breadth first check of 10.2.35.21 on host 10.0.47.192...
Aug 27 05:32:37.968: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.22:9080/dial?request=hostname&protocol=udp&host=10.2.35.21&port=8081&tries=1'] Namespace:pod-network-test-6098 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:32:37.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:32:37.969: INFO: ExecWithOptions: Clientset creation
Aug 27 05:32:37.969: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-6098/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.2.35.21%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 27 05:32:38.027: INFO: Waiting for responses: map[]
Aug 27 05:32:38.027: INFO: reached 10.2.35.21 after 0/1 tries
Aug 27 05:32:38.027: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 27 05:32:38.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6098" for this suite. 08/27/22 05:32:38.031
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":22,"skipped":372,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.272 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:23.763
    Aug 27 05:32:23.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pod-network-test 08/27/22 05:32:23.765
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:23.798
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:23.809
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-6098 08/27/22 05:32:23.817
    STEP: creating a selector 08/27/22 05:32:23.817
    STEP: Creating the service pods in kubernetes 08/27/22 05:32:23.817
    Aug 27 05:32:23.817: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 27 05:32:23.840: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6098" to be "running and ready"
    Aug 27 05:32:23.847: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.991926ms
    Aug 27 05:32:23.847: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:32:25.852: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.011846526s
    Aug 27 05:32:25.852: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:32:27.852: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.012128543s
    Aug 27 05:32:27.853: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:32:29.852: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.012094042s
    Aug 27 05:32:29.852: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:32:31.851: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.010831273s
    Aug 27 05:32:31.851: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:32:33.853: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.012470443s
    Aug 27 05:32:33.853: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:32:35.854: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.013741501s
    Aug 27 05:32:35.854: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 27 05:32:35.854: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 27 05:32:35.858: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6098" to be "running and ready"
    Aug 27 05:32:35.862: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.524747ms
    Aug 27 05:32:35.862: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 27 05:32:35.862: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 08/27/22 05:32:35.865
    Aug 27 05:32:35.870: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6098" to be "running"
    Aug 27 05:32:35.874: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.700327ms
    Aug 27 05:32:37.879: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009243514s
    Aug 27 05:32:37.879: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 27 05:32:37.882: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Aug 27 05:32:37.882: INFO: Breadth first check of 10.2.137.12 on host 10.0.31.158...
    Aug 27 05:32:37.886: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.22:9080/dial?request=hostname&protocol=udp&host=10.2.137.12&port=8081&tries=1'] Namespace:pod-network-test-6098 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:32:37.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:32:37.886: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:32:37.886: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-6098/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.2.137.12%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 27 05:32:37.962: INFO: Waiting for responses: map[]
    Aug 27 05:32:37.962: INFO: reached 10.2.137.12 after 0/1 tries
    Aug 27 05:32:37.962: INFO: Breadth first check of 10.2.35.21 on host 10.0.47.192...
    Aug 27 05:32:37.968: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.22:9080/dial?request=hostname&protocol=udp&host=10.2.35.21&port=8081&tries=1'] Namespace:pod-network-test-6098 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:32:37.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:32:37.969: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:32:37.969: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-6098/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.22%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.2.35.21%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 27 05:32:38.027: INFO: Waiting for responses: map[]
    Aug 27 05:32:38.027: INFO: reached 10.2.35.21 after 0/1 tries
    Aug 27 05:32:38.027: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 27 05:32:38.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6098" for this suite. 08/27/22 05:32:38.031
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:38.037
Aug 27 05:32:38.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 05:32:38.04
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:38.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:38.067
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 08/27/22 05:32:38.073
Aug 27 05:32:38.079: INFO: Waiting up to 5m0s for pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494" in namespace "downward-api-3195" to be "Succeeded or Failed"
Aug 27 05:32:38.083: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494": Phase="Pending", Reason="", readiness=false. Elapsed: 4.317237ms
Aug 27 05:32:40.087: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008035995s
Aug 27 05:32:42.094: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015318133s
STEP: Saw pod success 08/27/22 05:32:42.094
Aug 27 05:32:42.095: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494" satisfied condition "Succeeded or Failed"
Aug 27 05:32:42.098: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494 container dapi-container: <nil>
STEP: delete the pod 08/27/22 05:32:42.108
Aug 27 05:32:42.120: INFO: Waiting for pod downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494 to disappear
Aug 27 05:32:42.124: INFO: Pod downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 27 05:32:42.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3195" for this suite. 08/27/22 05:32:42.129
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":23,"skipped":374,"failed":0}
------------------------------
â€¢ [4.099 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:38.037
    Aug 27 05:32:38.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 05:32:38.04
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:38.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:38.067
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 08/27/22 05:32:38.073
    Aug 27 05:32:38.079: INFO: Waiting up to 5m0s for pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494" in namespace "downward-api-3195" to be "Succeeded or Failed"
    Aug 27 05:32:38.083: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494": Phase="Pending", Reason="", readiness=false. Elapsed: 4.317237ms
    Aug 27 05:32:40.087: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008035995s
    Aug 27 05:32:42.094: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015318133s
    STEP: Saw pod success 08/27/22 05:32:42.094
    Aug 27 05:32:42.095: INFO: Pod "downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494" satisfied condition "Succeeded or Failed"
    Aug 27 05:32:42.098: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 05:32:42.108
    Aug 27 05:32:42.120: INFO: Waiting for pod downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494 to disappear
    Aug 27 05:32:42.124: INFO: Pod downward-api-2034c158-8c01-4f9a-8d70-0eed8d878494 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 27 05:32:42.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3195" for this suite. 08/27/22 05:32:42.129
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:42.138
Aug 27 05:32:42.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replication-controller 08/27/22 05:32:42.139
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:42.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:42.16
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 08/27/22 05:32:42.171
STEP: waiting for RC to be added 08/27/22 05:32:42.177
STEP: waiting for available Replicas 08/27/22 05:32:42.177
STEP: patching ReplicationController 08/27/22 05:32:45.565
STEP: waiting for RC to be modified 08/27/22 05:32:45.577
STEP: patching ReplicationController status 08/27/22 05:32:45.577
STEP: waiting for RC to be modified 08/27/22 05:32:45.582
STEP: waiting for available Replicas 08/27/22 05:32:45.583
STEP: fetching ReplicationController status 08/27/22 05:32:45.589
STEP: patching ReplicationController scale 08/27/22 05:32:45.593
STEP: waiting for RC to be modified 08/27/22 05:32:45.6
STEP: waiting for ReplicationController's scale to be the max amount 08/27/22 05:32:45.6
STEP: fetching ReplicationController; ensuring that it's patched 08/27/22 05:32:49.274
STEP: updating ReplicationController status 08/27/22 05:32:49.277
STEP: waiting for RC to be modified 08/27/22 05:32:49.281
STEP: listing all ReplicationControllers 08/27/22 05:32:49.281
STEP: checking that ReplicationController has expected values 08/27/22 05:32:49.284
STEP: deleting ReplicationControllers by collection 08/27/22 05:32:49.284
STEP: waiting for ReplicationController to have a DELETED watchEvent 08/27/22 05:32:49.293
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 27 05:32:49.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3201" for this suite. 08/27/22 05:32:49.36
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":24,"skipped":409,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.226 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:42.138
    Aug 27 05:32:42.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replication-controller 08/27/22 05:32:42.139
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:42.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:42.16
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 08/27/22 05:32:42.171
    STEP: waiting for RC to be added 08/27/22 05:32:42.177
    STEP: waiting for available Replicas 08/27/22 05:32:42.177
    STEP: patching ReplicationController 08/27/22 05:32:45.565
    STEP: waiting for RC to be modified 08/27/22 05:32:45.577
    STEP: patching ReplicationController status 08/27/22 05:32:45.577
    STEP: waiting for RC to be modified 08/27/22 05:32:45.582
    STEP: waiting for available Replicas 08/27/22 05:32:45.583
    STEP: fetching ReplicationController status 08/27/22 05:32:45.589
    STEP: patching ReplicationController scale 08/27/22 05:32:45.593
    STEP: waiting for RC to be modified 08/27/22 05:32:45.6
    STEP: waiting for ReplicationController's scale to be the max amount 08/27/22 05:32:45.6
    STEP: fetching ReplicationController; ensuring that it's patched 08/27/22 05:32:49.274
    STEP: updating ReplicationController status 08/27/22 05:32:49.277
    STEP: waiting for RC to be modified 08/27/22 05:32:49.281
    STEP: listing all ReplicationControllers 08/27/22 05:32:49.281
    STEP: checking that ReplicationController has expected values 08/27/22 05:32:49.284
    STEP: deleting ReplicationControllers by collection 08/27/22 05:32:49.284
    STEP: waiting for ReplicationController to have a DELETED watchEvent 08/27/22 05:32:49.293
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 27 05:32:49.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3201" for this suite. 08/27/22 05:32:49.36
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:32:49.365
Aug 27 05:32:49.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 05:32:49.366
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:49.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:49.386
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1446 08/27/22 05:32:49.39
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-1446 08/27/22 05:32:49.398
Aug 27 05:32:49.410: INFO: Found 0 stateful pods, waiting for 1
Aug 27 05:32:59.422: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 08/27/22 05:32:59.435
STEP: Getting /status 08/27/22 05:32:59.462
Aug 27 05:32:59.473: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 08/27/22 05:32:59.473
Aug 27 05:32:59.495: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 08/27/22 05:32:59.495
Aug 27 05:32:59.506: INFO: Observed &StatefulSet event: ADDED
Aug 27 05:32:59.506: INFO: Found Statefulset ss in namespace statefulset-1446 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 27 05:32:59.506: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 08/27/22 05:32:59.506
Aug 27 05:32:59.506: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 27 05:32:59.523: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 08/27/22 05:32:59.523
Aug 27 05:32:59.533: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 05:32:59.533: INFO: Deleting all statefulset in ns statefulset-1446
Aug 27 05:32:59.539: INFO: Scaling statefulset ss to 0
Aug 27 05:33:09.573: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 05:33:09.576: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 05:33:09.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1446" for this suite. 08/27/22 05:33:09.589
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":25,"skipped":412,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.228 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:32:49.365
    Aug 27 05:32:49.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 05:32:49.366
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:32:49.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:32:49.386
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1446 08/27/22 05:32:49.39
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-1446 08/27/22 05:32:49.398
    Aug 27 05:32:49.410: INFO: Found 0 stateful pods, waiting for 1
    Aug 27 05:32:59.422: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 08/27/22 05:32:59.435
    STEP: Getting /status 08/27/22 05:32:59.462
    Aug 27 05:32:59.473: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 08/27/22 05:32:59.473
    Aug 27 05:32:59.495: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 08/27/22 05:32:59.495
    Aug 27 05:32:59.506: INFO: Observed &StatefulSet event: ADDED
    Aug 27 05:32:59.506: INFO: Found Statefulset ss in namespace statefulset-1446 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 27 05:32:59.506: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 08/27/22 05:32:59.506
    Aug 27 05:32:59.506: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 27 05:32:59.523: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 08/27/22 05:32:59.523
    Aug 27 05:32:59.533: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 05:32:59.533: INFO: Deleting all statefulset in ns statefulset-1446
    Aug 27 05:32:59.539: INFO: Scaling statefulset ss to 0
    Aug 27 05:33:09.573: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 05:33:09.576: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 05:33:09.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1446" for this suite. 08/27/22 05:33:09.589
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:09.614
Aug 27 05:33:09.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:33:09.615
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:09.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:09.664
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-bf9caac7-bf08-46a5-98b7-6953cc92ea07 08/27/22 05:33:09.677
STEP: Creating a pod to test consume secrets 08/27/22 05:33:09.681
Aug 27 05:33:09.690: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7" in namespace "projected-8300" to be "Succeeded or Failed"
Aug 27 05:33:09.694: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.357842ms
Aug 27 05:33:11.699: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009314669s
Aug 27 05:33:13.700: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009896373s
STEP: Saw pod success 08/27/22 05:33:13.7
Aug 27 05:33:13.700: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7" satisfied condition "Succeeded or Failed"
Aug 27 05:33:13.703: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/27/22 05:33:13.709
Aug 27 05:33:13.718: INFO: Waiting for pod pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7 to disappear
Aug 27 05:33:13.721: INFO: Pod pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 05:33:13.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8300" for this suite. 08/27/22 05:33:13.724
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":26,"skipped":431,"failed":0}
------------------------------
â€¢ [4.117 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:09.614
    Aug 27 05:33:09.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:33:09.615
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:09.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:09.664
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-bf9caac7-bf08-46a5-98b7-6953cc92ea07 08/27/22 05:33:09.677
    STEP: Creating a pod to test consume secrets 08/27/22 05:33:09.681
    Aug 27 05:33:09.690: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7" in namespace "projected-8300" to be "Succeeded or Failed"
    Aug 27 05:33:09.694: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.357842ms
    Aug 27 05:33:11.699: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009314669s
    Aug 27 05:33:13.700: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009896373s
    STEP: Saw pod success 08/27/22 05:33:13.7
    Aug 27 05:33:13.700: INFO: Pod "pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7" satisfied condition "Succeeded or Failed"
    Aug 27 05:33:13.703: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 05:33:13.709
    Aug 27 05:33:13.718: INFO: Waiting for pod pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7 to disappear
    Aug 27 05:33:13.721: INFO: Pod pod-projected-secrets-993923c3-bf8f-458e-a92c-ef54de41aab7 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 05:33:13.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8300" for this suite. 08/27/22 05:33:13.724
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:13.734
Aug 27 05:33:13.734: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 05:33:13.736
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:13.749
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:13.753
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 05:33:13.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2719" for this suite. 08/27/22 05:33:13.786
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":27,"skipped":442,"failed":0}
------------------------------
â€¢ [0.057 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:13.734
    Aug 27 05:33:13.734: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 05:33:13.736
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:13.749
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:13.753
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 05:33:13.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2719" for this suite. 08/27/22 05:33:13.786
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:13.791
Aug 27 05:33:13.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 05:33:13.792
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:13.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:13.813
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 08/27/22 05:33:13.816
Aug 27 05:33:13.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug 27 05:33:13.904: INFO: stderr: ""
Aug 27 05:33:13.904: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 08/27/22 05:33:13.904
Aug 27 05:33:13.904: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug 27 05:33:13.904: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8787" to be "running and ready, or succeeded"
Aug 27 05:33:13.908: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.852251ms
Aug 27 05:33:13.908: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-10-0-47-192' to be 'Running' but was 'Pending'
Aug 27 05:33:15.912: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008129231s
Aug 27 05:33:15.912: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug 27 05:33:15.912: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 08/27/22 05:33:15.912
Aug 27 05:33:15.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator'
Aug 27 05:33:16.021: INFO: stderr: ""
Aug 27 05:33:16.021: INFO: stdout: "I0827 05:33:14.658097       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/7c8w 298\nI0827 05:33:14.858116       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/9lk 520\nI0827 05:33:15.058663       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/8sdn 260\nI0827 05:33:15.259023       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/b8z 520\nI0827 05:33:15.458380       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/hhv7 208\nI0827 05:33:15.658701       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/2cm 594\nI0827 05:33:15.859009       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/tqph 319\n"
STEP: limiting log lines 08/27/22 05:33:16.021
Aug 27 05:33:16.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --tail=1'
Aug 27 05:33:16.125: INFO: stderr: ""
Aug 27 05:33:16.125: INFO: stdout: "I0827 05:33:16.058174       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/lvk 467\n"
Aug 27 05:33:16.125: INFO: got output "I0827 05:33:16.058174       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/lvk 467\n"
STEP: limiting log bytes 08/27/22 05:33:16.125
Aug 27 05:33:16.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --limit-bytes=1'
Aug 27 05:33:16.205: INFO: stderr: ""
Aug 27 05:33:16.205: INFO: stdout: "I"
Aug 27 05:33:16.205: INFO: got output "I"
STEP: exposing timestamps 08/27/22 05:33:16.205
Aug 27 05:33:16.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --tail=1 --timestamps'
Aug 27 05:33:16.280: INFO: stderr: ""
Aug 27 05:33:16.280: INFO: stdout: "2022-08-27T05:33:16.258785989Z I0827 05:33:16.258672       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/cv8 369\n"
Aug 27 05:33:16.280: INFO: got output "2022-08-27T05:33:16.258785989Z I0827 05:33:16.258672       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/cv8 369\n"
STEP: restricting to a time range 08/27/22 05:33:16.28
Aug 27 05:33:18.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --since=1s'
Aug 27 05:33:18.863: INFO: stderr: ""
Aug 27 05:33:18.863: INFO: stdout: "I0827 05:33:18.058127       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/b2l 262\nI0827 05:33:18.258489       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/26qg 440\nI0827 05:33:18.458843       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/tl59 469\nI0827 05:33:18.658125       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/jn4b 358\nI0827 05:33:18.858490       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/rs8w 492\n"
Aug 27 05:33:18.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --since=24h'
Aug 27 05:33:18.948: INFO: stderr: ""
Aug 27 05:33:18.948: INFO: stdout: "I0827 05:33:14.658097       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/7c8w 298\nI0827 05:33:14.858116       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/9lk 520\nI0827 05:33:15.058663       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/8sdn 260\nI0827 05:33:15.259023       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/b8z 520\nI0827 05:33:15.458380       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/hhv7 208\nI0827 05:33:15.658701       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/2cm 594\nI0827 05:33:15.859009       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/tqph 319\nI0827 05:33:16.058174       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/lvk 467\nI0827 05:33:16.258672       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/cv8 369\nI0827 05:33:16.458261       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/svpx 571\nI0827 05:33:16.658608       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/rb2v 330\nI0827 05:33:16.859076       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/ssg9 264\nI0827 05:33:17.058497       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/fv9 311\nI0827 05:33:17.258860       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/rpdm 315\nI0827 05:33:17.458150       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/fnd 242\nI0827 05:33:17.658384       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/77rq 421\nI0827 05:33:17.858851       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/k6d 457\nI0827 05:33:18.058127       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/b2l 262\nI0827 05:33:18.258489       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/26qg 440\nI0827 05:33:18.458843       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/tl59 469\nI0827 05:33:18.658125       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/jn4b 358\nI0827 05:33:18.858490       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/rs8w 492\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Aug 27 05:33:18.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 delete pod logs-generator'
Aug 27 05:33:20.365: INFO: stderr: ""
Aug 27 05:33:20.365: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 05:33:20.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8787" for this suite. 08/27/22 05:33:20.368
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":28,"skipped":447,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.583 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:13.791
    Aug 27 05:33:13.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 05:33:13.792
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:13.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:13.813
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 08/27/22 05:33:13.816
    Aug 27 05:33:13.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Aug 27 05:33:13.904: INFO: stderr: ""
    Aug 27 05:33:13.904: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 08/27/22 05:33:13.904
    Aug 27 05:33:13.904: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Aug 27 05:33:13.904: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8787" to be "running and ready, or succeeded"
    Aug 27 05:33:13.908: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.852251ms
    Aug 27 05:33:13.908: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-10-0-47-192' to be 'Running' but was 'Pending'
    Aug 27 05:33:15.912: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008129231s
    Aug 27 05:33:15.912: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Aug 27 05:33:15.912: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 08/27/22 05:33:15.912
    Aug 27 05:33:15.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator'
    Aug 27 05:33:16.021: INFO: stderr: ""
    Aug 27 05:33:16.021: INFO: stdout: "I0827 05:33:14.658097       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/7c8w 298\nI0827 05:33:14.858116       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/9lk 520\nI0827 05:33:15.058663       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/8sdn 260\nI0827 05:33:15.259023       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/b8z 520\nI0827 05:33:15.458380       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/hhv7 208\nI0827 05:33:15.658701       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/2cm 594\nI0827 05:33:15.859009       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/tqph 319\n"
    STEP: limiting log lines 08/27/22 05:33:16.021
    Aug 27 05:33:16.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --tail=1'
    Aug 27 05:33:16.125: INFO: stderr: ""
    Aug 27 05:33:16.125: INFO: stdout: "I0827 05:33:16.058174       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/lvk 467\n"
    Aug 27 05:33:16.125: INFO: got output "I0827 05:33:16.058174       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/lvk 467\n"
    STEP: limiting log bytes 08/27/22 05:33:16.125
    Aug 27 05:33:16.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --limit-bytes=1'
    Aug 27 05:33:16.205: INFO: stderr: ""
    Aug 27 05:33:16.205: INFO: stdout: "I"
    Aug 27 05:33:16.205: INFO: got output "I"
    STEP: exposing timestamps 08/27/22 05:33:16.205
    Aug 27 05:33:16.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --tail=1 --timestamps'
    Aug 27 05:33:16.280: INFO: stderr: ""
    Aug 27 05:33:16.280: INFO: stdout: "2022-08-27T05:33:16.258785989Z I0827 05:33:16.258672       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/cv8 369\n"
    Aug 27 05:33:16.280: INFO: got output "2022-08-27T05:33:16.258785989Z I0827 05:33:16.258672       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/cv8 369\n"
    STEP: restricting to a time range 08/27/22 05:33:16.28
    Aug 27 05:33:18.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --since=1s'
    Aug 27 05:33:18.863: INFO: stderr: ""
    Aug 27 05:33:18.863: INFO: stdout: "I0827 05:33:18.058127       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/b2l 262\nI0827 05:33:18.258489       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/26qg 440\nI0827 05:33:18.458843       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/tl59 469\nI0827 05:33:18.658125       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/jn4b 358\nI0827 05:33:18.858490       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/rs8w 492\n"
    Aug 27 05:33:18.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 logs logs-generator logs-generator --since=24h'
    Aug 27 05:33:18.948: INFO: stderr: ""
    Aug 27 05:33:18.948: INFO: stdout: "I0827 05:33:14.658097       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/7c8w 298\nI0827 05:33:14.858116       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/9lk 520\nI0827 05:33:15.058663       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/8sdn 260\nI0827 05:33:15.259023       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/b8z 520\nI0827 05:33:15.458380       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/hhv7 208\nI0827 05:33:15.658701       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/2cm 594\nI0827 05:33:15.859009       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/tqph 319\nI0827 05:33:16.058174       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/lvk 467\nI0827 05:33:16.258672       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/cv8 369\nI0827 05:33:16.458261       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/svpx 571\nI0827 05:33:16.658608       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/rb2v 330\nI0827 05:33:16.859076       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/ssg9 264\nI0827 05:33:17.058497       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/fv9 311\nI0827 05:33:17.258860       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/rpdm 315\nI0827 05:33:17.458150       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/fnd 242\nI0827 05:33:17.658384       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/77rq 421\nI0827 05:33:17.858851       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/k6d 457\nI0827 05:33:18.058127       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/b2l 262\nI0827 05:33:18.258489       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/26qg 440\nI0827 05:33:18.458843       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/tl59 469\nI0827 05:33:18.658125       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/jn4b 358\nI0827 05:33:18.858490       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/rs8w 492\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Aug 27 05:33:18.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8787 delete pod logs-generator'
    Aug 27 05:33:20.365: INFO: stderr: ""
    Aug 27 05:33:20.365: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 05:33:20.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8787" for this suite. 08/27/22 05:33:20.368
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:20.376
Aug 27 05:33:20.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 05:33:20.378
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:20.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:20.398
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-aba3889b-4b1b-493d-86d0-71d4e490849a 08/27/22 05:33:20.402
STEP: Creating a pod to test consume configMaps 08/27/22 05:33:20.408
Aug 27 05:33:20.415: INFO: Waiting up to 5m0s for pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc" in namespace "configmap-498" to be "Succeeded or Failed"
Aug 27 05:33:20.418: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.059666ms
Aug 27 05:33:22.422: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc": Phase="Running", Reason="", readiness=false. Elapsed: 2.006850256s
Aug 27 05:33:24.423: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007948394s
STEP: Saw pod success 08/27/22 05:33:24.423
Aug 27 05:33:24.423: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc" satisfied condition "Succeeded or Failed"
Aug 27 05:33:24.426: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc container agnhost-container: <nil>
STEP: delete the pod 08/27/22 05:33:24.432
Aug 27 05:33:24.441: INFO: Waiting for pod pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc to disappear
Aug 27 05:33:24.444: INFO: Pod pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 05:33:24.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-498" for this suite. 08/27/22 05:33:24.448
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":29,"skipped":503,"failed":0}
------------------------------
â€¢ [4.075 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:20.376
    Aug 27 05:33:20.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 05:33:20.378
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:20.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:20.398
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-aba3889b-4b1b-493d-86d0-71d4e490849a 08/27/22 05:33:20.402
    STEP: Creating a pod to test consume configMaps 08/27/22 05:33:20.408
    Aug 27 05:33:20.415: INFO: Waiting up to 5m0s for pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc" in namespace "configmap-498" to be "Succeeded or Failed"
    Aug 27 05:33:20.418: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.059666ms
    Aug 27 05:33:22.422: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc": Phase="Running", Reason="", readiness=false. Elapsed: 2.006850256s
    Aug 27 05:33:24.423: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007948394s
    STEP: Saw pod success 08/27/22 05:33:24.423
    Aug 27 05:33:24.423: INFO: Pod "pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc" satisfied condition "Succeeded or Failed"
    Aug 27 05:33:24.426: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 05:33:24.432
    Aug 27 05:33:24.441: INFO: Waiting for pod pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc to disappear
    Aug 27 05:33:24.444: INFO: Pod pod-configmaps-5cb8bfec-380d-485a-b61a-9d25019a3edc no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 05:33:24.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-498" for this suite. 08/27/22 05:33:24.448
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:24.454
Aug 27 05:33:24.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename runtimeclass 08/27/22 05:33:24.455
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:24.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:24.477
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Aug 27 05:33:24.490: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5347 to be scheduled
Aug 27 05:33:24.494: INFO: 1 pods are not scheduled: [runtimeclass-5347/test-runtimeclass-runtimeclass-5347-preconfigured-handler-bksfw(029c4539-3981-4b61-af43-fe5b7e70ac44)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 27 05:33:26.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5347" for this suite. 08/27/22 05:33:26.508
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":30,"skipped":526,"failed":0}
------------------------------
â€¢ [2.058 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:24.454
    Aug 27 05:33:24.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename runtimeclass 08/27/22 05:33:24.455
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:24.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:24.477
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Aug 27 05:33:24.490: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5347 to be scheduled
    Aug 27 05:33:24.494: INFO: 1 pods are not scheduled: [runtimeclass-5347/test-runtimeclass-runtimeclass-5347-preconfigured-handler-bksfw(029c4539-3981-4b61-af43-fe5b7e70ac44)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 27 05:33:26.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5347" for this suite. 08/27/22 05:33:26.508
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:26.515
Aug 27 05:33:26.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:33:26.516
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:26.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:26.537
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:33:26.551
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:33:27.07
STEP: Deploying the webhook pod 08/27/22 05:33:27.077
STEP: Wait for the deployment to be ready 08/27/22 05:33:27.093
Aug 27 05:33:27.110: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 05:33:29.134
STEP: Verifying the service has paired with the endpoint 08/27/22 05:33:29.142
Aug 27 05:33:30.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 08/27/22 05:33:30.146
STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:30.146
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 08/27/22 05:33:30.162
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 08/27/22 05:33:31.178
STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:31.178
STEP: Having no error when timeout is longer than webhook latency 08/27/22 05:33:32.247
STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:32.247
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 08/27/22 05:33:37.317
STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:37.317
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:33:42.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9824" for this suite. 08/27/22 05:33:42.357
STEP: Destroying namespace "webhook-9824-markers" for this suite. 08/27/22 05:33:42.363
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":31,"skipped":552,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.941 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:26.515
    Aug 27 05:33:26.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:33:26.516
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:26.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:26.537
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:33:26.551
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:33:27.07
    STEP: Deploying the webhook pod 08/27/22 05:33:27.077
    STEP: Wait for the deployment to be ready 08/27/22 05:33:27.093
    Aug 27 05:33:27.110: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 05:33:29.134
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:33:29.142
    Aug 27 05:33:30.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 08/27/22 05:33:30.146
    STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:30.146
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 08/27/22 05:33:30.162
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 08/27/22 05:33:31.178
    STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:31.178
    STEP: Having no error when timeout is longer than webhook latency 08/27/22 05:33:32.247
    STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:32.247
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 08/27/22 05:33:37.317
    STEP: Registering slow webhook via the AdmissionRegistration API 08/27/22 05:33:37.317
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:33:42.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9824" for this suite. 08/27/22 05:33:42.357
    STEP: Destroying namespace "webhook-9824-markers" for this suite. 08/27/22 05:33:42.363
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:33:42.475
Aug 27 05:33:42.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-pred 08/27/22 05:33:42.477
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:42.52
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:42.524
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 27 05:33:42.532: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 05:33:42.541: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 05:33:42.545: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
Aug 27 05:33:42.550: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 05:33:42.550: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 05:33:42.550: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 05:33:42.550: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 05:33:42.550: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 05:33:42.550: INFO: 	Container e2e ready: true, restart count 0
Aug 27 05:33:42.550: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 05:33:42.550: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 05:33:42.550: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 05:33:42.550: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 05:33:42.550: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
Aug 27 05:33:42.557: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 05:33:42.557: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 05:33:42.557: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 05:33:42.557: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 05:33:42.557: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
Aug 27 05:33:42.557: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 05:33:42.557: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 05:33:42.557: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 05:33:42.557: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/27/22 05:33:42.557
Aug 27 05:33:42.570: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3581" to be "running"
Aug 27 05:33:42.594: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.514133ms
Aug 27 05:33:44.598: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.027096793s
Aug 27 05:33:44.598: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/27/22 05:33:44.601
STEP: Trying to apply a random label on the found node. 08/27/22 05:33:44.625
STEP: verifying the node has the label kubernetes.io/e2e-676ff8ca-8365-4b54-80a8-bcbd1fee3ce3 95 08/27/22 05:33:44.637
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 08/27/22 05:33:44.64
Aug 27 05:33:44.644: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3581" to be "not pending"
Aug 27 05:33:44.647: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.857872ms
Aug 27 05:33:46.657: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012011813s
Aug 27 05:33:46.657: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.0.47.192 on the node which pod4 resides and expect not scheduled 08/27/22 05:33:46.657
Aug 27 05:33:46.678: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3581" to be "not pending"
Aug 27 05:33:46.702: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 23.909298ms
Aug 27 05:33:48.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02787351s
Aug 27 05:33:50.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029094086s
Aug 27 05:33:52.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031538616s
Aug 27 05:33:54.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028631182s
Aug 27 05:33:56.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02749327s
Aug 27 05:33:58.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.028803019s
Aug 27 05:34:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.028940622s
Aug 27 05:34:02.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.027496387s
Aug 27 05:34:04.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.029131404s
Aug 27 05:34:06.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.027069391s
Aug 27 05:34:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.028534784s
Aug 27 05:34:10.722: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.043765263s
Aug 27 05:34:12.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.027680821s
Aug 27 05:34:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.028396832s
Aug 27 05:34:16.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.027543241s
Aug 27 05:34:18.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.029868082s
Aug 27 05:34:20.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.030011561s
Aug 27 05:34:22.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.02738346s
Aug 27 05:34:24.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.027407354s
Aug 27 05:34:26.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.029207382s
Aug 27 05:34:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.028977232s
Aug 27 05:34:30.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.033180919s
Aug 27 05:34:32.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.02834396s
Aug 27 05:34:34.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.028654491s
Aug 27 05:34:36.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.027740372s
Aug 27 05:34:38.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.028746153s
Aug 27 05:34:40.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.027653379s
Aug 27 05:34:42.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.029555243s
Aug 27 05:34:44.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.031158287s
Aug 27 05:34:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.028845483s
Aug 27 05:34:48.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.029300648s
Aug 27 05:34:50.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.028410484s
Aug 27 05:34:52.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.027656276s
Aug 27 05:34:54.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.036054321s
Aug 27 05:34:56.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.027445409s
Aug 27 05:34:58.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.029657398s
Aug 27 05:35:00.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.030470055s
Aug 27 05:35:02.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.027205502s
Aug 27 05:35:04.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.02871525s
Aug 27 05:35:06.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.027584748s
Aug 27 05:35:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.028851591s
Aug 27 05:35:10.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.030262695s
Aug 27 05:35:12.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.028979927s
Aug 27 05:35:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.028418284s
Aug 27 05:35:16.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.028168585s
Aug 27 05:35:18.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.028812616s
Aug 27 05:35:20.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.029246514s
Aug 27 05:35:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.028441608s
Aug 27 05:35:24.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.028559925s
Aug 27 05:35:26.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.027798105s
Aug 27 05:35:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.028839657s
Aug 27 05:35:30.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.028856758s
Aug 27 05:35:32.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.027872732s
Aug 27 05:35:34.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.029113146s
Aug 27 05:35:36.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.029093398s
Aug 27 05:35:38.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.028230061s
Aug 27 05:35:40.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.028597582s
Aug 27 05:35:42.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.027509375s
Aug 27 05:35:44.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.027742287s
Aug 27 05:35:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.028408964s
Aug 27 05:35:48.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.032880116s
Aug 27 05:35:50.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.028636331s
Aug 27 05:35:52.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.028794415s
Aug 27 05:35:54.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.027628243s
Aug 27 05:35:56.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.027652121s
Aug 27 05:35:58.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.029018877s
Aug 27 05:36:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.028556262s
Aug 27 05:36:02.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.028718024s
Aug 27 05:36:04.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.029557024s
Aug 27 05:36:06.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.027843818s
Aug 27 05:36:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.028243442s
Aug 27 05:36:10.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.028516387s
Aug 27 05:36:12.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.02867361s
Aug 27 05:36:14.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.031590532s
Aug 27 05:36:16.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.028550338s
Aug 27 05:36:18.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.030921939s
Aug 27 05:36:20.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.029416922s
Aug 27 05:36:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.028582844s
Aug 27 05:36:24.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.028432734s
Aug 27 05:36:26.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.035996752s
Aug 27 05:36:28.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.032657026s
Aug 27 05:36:30.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.027382592s
Aug 27 05:36:32.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.027936026s
Aug 27 05:36:34.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.029133496s
Aug 27 05:36:36.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.027583547s
Aug 27 05:36:38.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.029271256s
Aug 27 05:36:40.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.029502186s
Aug 27 05:36:42.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.028477653s
Aug 27 05:36:44.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.029044348s
Aug 27 05:36:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.028474059s
Aug 27 05:36:48.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.028039748s
Aug 27 05:36:50.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.032696033s
Aug 27 05:36:52.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.027936725s
Aug 27 05:36:54.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.028890863s
Aug 27 05:36:56.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.028151398s
Aug 27 05:36:58.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.030115626s
Aug 27 05:37:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.028840046s
Aug 27 05:37:02.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.028455727s
Aug 27 05:37:04.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.029997513s
Aug 27 05:37:06.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.02888982s
Aug 27 05:37:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.028403205s
Aug 27 05:37:10.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.02723818s
Aug 27 05:37:12.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.029129196s
Aug 27 05:37:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.028263797s
Aug 27 05:37:16.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.027828289s
Aug 27 05:37:18.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.029250944s
Aug 27 05:37:20.726: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.04764312s
Aug 27 05:37:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.028216154s
Aug 27 05:37:24.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.027734586s
Aug 27 05:37:26.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.027689898s
Aug 27 05:37:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.028662985s
Aug 27 05:37:30.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.029303935s
Aug 27 05:37:32.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.027069504s
Aug 27 05:37:34.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.029249268s
Aug 27 05:37:36.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.027374463s
Aug 27 05:37:38.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.028172975s
Aug 27 05:37:40.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.027897698s
Aug 27 05:37:42.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.029374098s
Aug 27 05:37:44.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.029039022s
Aug 27 05:37:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.028405325s
Aug 27 05:37:48.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.028783437s
Aug 27 05:37:50.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.02929831s
Aug 27 05:37:52.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.027510544s
Aug 27 05:37:54.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.028894731s
Aug 27 05:37:56.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.031132158s
Aug 27 05:37:58.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.029134848s
Aug 27 05:38:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.029037256s
Aug 27 05:38:02.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.027833903s
Aug 27 05:38:04.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.030981242s
Aug 27 05:38:06.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.028979706s
Aug 27 05:38:08.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.030763974s
Aug 27 05:38:10.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.027268606s
Aug 27 05:38:12.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.028459631s
Aug 27 05:38:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.028302005s
Aug 27 05:38:16.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.02743376s
Aug 27 05:38:18.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.030239467s
Aug 27 05:38:20.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.027840181s
Aug 27 05:38:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.02846553s
Aug 27 05:38:24.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.028447764s
Aug 27 05:38:26.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.028094854s
Aug 27 05:38:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.028932512s
Aug 27 05:38:30.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.028952089s
Aug 27 05:38:32.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.031326019s
Aug 27 05:38:34.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.028018684s
Aug 27 05:38:36.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.028145526s
Aug 27 05:38:38.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.031034169s
Aug 27 05:38:40.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.029383616s
Aug 27 05:38:42.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.028021763s
Aug 27 05:38:44.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.029499446s
Aug 27 05:38:46.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.029651689s
Aug 27 05:38:46.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.037016888s
STEP: removing the label kubernetes.io/e2e-676ff8ca-8365-4b54-80a8-bcbd1fee3ce3 off the node ip-10-0-47-192 08/27/22 05:38:46.715
STEP: verifying the node doesn't have the label kubernetes.io/e2e-676ff8ca-8365-4b54-80a8-bcbd1fee3ce3 08/27/22 05:38:46.728
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:38:46.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3581" for this suite. 08/27/22 05:38:46.738
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":32,"skipped":652,"failed":0}
------------------------------
â€¢ [SLOW TEST] [304.275 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:33:42.475
    Aug 27 05:33:42.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-pred 08/27/22 05:33:42.477
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:33:42.52
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:33:42.524
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 27 05:33:42.532: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 27 05:33:42.541: INFO: Waiting for terminating namespaces to be deleted...
    Aug 27 05:33:42.545: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
    Aug 27 05:33:42.550: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 05:33:42.550: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 05:33:42.550: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 05:33:42.550: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 05:33:42.550: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 05:33:42.550: INFO: 	Container e2e ready: true, restart count 0
    Aug 27 05:33:42.550: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 05:33:42.550: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 05:33:42.550: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 05:33:42.550: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 27 05:33:42.550: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
    Aug 27 05:33:42.557: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 05:33:42.557: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 05:33:42.557: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 05:33:42.557: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 05:33:42.557: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
    Aug 27 05:33:42.557: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 27 05:33:42.557: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 05:33:42.557: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 05:33:42.557: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/27/22 05:33:42.557
    Aug 27 05:33:42.570: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3581" to be "running"
    Aug 27 05:33:42.594: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.514133ms
    Aug 27 05:33:44.598: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.027096793s
    Aug 27 05:33:44.598: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/27/22 05:33:44.601
    STEP: Trying to apply a random label on the found node. 08/27/22 05:33:44.625
    STEP: verifying the node has the label kubernetes.io/e2e-676ff8ca-8365-4b54-80a8-bcbd1fee3ce3 95 08/27/22 05:33:44.637
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 08/27/22 05:33:44.64
    Aug 27 05:33:44.644: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3581" to be "not pending"
    Aug 27 05:33:44.647: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.857872ms
    Aug 27 05:33:46.657: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012011813s
    Aug 27 05:33:46.657: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.0.47.192 on the node which pod4 resides and expect not scheduled 08/27/22 05:33:46.657
    Aug 27 05:33:46.678: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3581" to be "not pending"
    Aug 27 05:33:46.702: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 23.909298ms
    Aug 27 05:33:48.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02787351s
    Aug 27 05:33:50.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029094086s
    Aug 27 05:33:52.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031538616s
    Aug 27 05:33:54.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028631182s
    Aug 27 05:33:56.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02749327s
    Aug 27 05:33:58.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.028803019s
    Aug 27 05:34:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.028940622s
    Aug 27 05:34:02.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.027496387s
    Aug 27 05:34:04.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.029131404s
    Aug 27 05:34:06.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.027069391s
    Aug 27 05:34:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.028534784s
    Aug 27 05:34:10.722: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.043765263s
    Aug 27 05:34:12.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.027680821s
    Aug 27 05:34:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.028396832s
    Aug 27 05:34:16.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.027543241s
    Aug 27 05:34:18.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.029868082s
    Aug 27 05:34:20.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.030011561s
    Aug 27 05:34:22.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.02738346s
    Aug 27 05:34:24.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.027407354s
    Aug 27 05:34:26.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.029207382s
    Aug 27 05:34:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.028977232s
    Aug 27 05:34:30.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.033180919s
    Aug 27 05:34:32.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.02834396s
    Aug 27 05:34:34.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.028654491s
    Aug 27 05:34:36.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.027740372s
    Aug 27 05:34:38.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.028746153s
    Aug 27 05:34:40.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.027653379s
    Aug 27 05:34:42.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.029555243s
    Aug 27 05:34:44.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.031158287s
    Aug 27 05:34:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.028845483s
    Aug 27 05:34:48.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.029300648s
    Aug 27 05:34:50.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.028410484s
    Aug 27 05:34:52.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.027656276s
    Aug 27 05:34:54.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.036054321s
    Aug 27 05:34:56.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.027445409s
    Aug 27 05:34:58.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.029657398s
    Aug 27 05:35:00.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.030470055s
    Aug 27 05:35:02.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.027205502s
    Aug 27 05:35:04.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.02871525s
    Aug 27 05:35:06.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.027584748s
    Aug 27 05:35:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.028851591s
    Aug 27 05:35:10.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.030262695s
    Aug 27 05:35:12.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.028979927s
    Aug 27 05:35:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.028418284s
    Aug 27 05:35:16.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.028168585s
    Aug 27 05:35:18.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.028812616s
    Aug 27 05:35:20.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.029246514s
    Aug 27 05:35:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.028441608s
    Aug 27 05:35:24.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.028559925s
    Aug 27 05:35:26.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.027798105s
    Aug 27 05:35:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.028839657s
    Aug 27 05:35:30.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.028856758s
    Aug 27 05:35:32.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.027872732s
    Aug 27 05:35:34.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.029113146s
    Aug 27 05:35:36.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.029093398s
    Aug 27 05:35:38.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.028230061s
    Aug 27 05:35:40.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.028597582s
    Aug 27 05:35:42.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.027509375s
    Aug 27 05:35:44.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.027742287s
    Aug 27 05:35:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.028408964s
    Aug 27 05:35:48.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.032880116s
    Aug 27 05:35:50.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.028636331s
    Aug 27 05:35:52.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.028794415s
    Aug 27 05:35:54.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.027628243s
    Aug 27 05:35:56.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.027652121s
    Aug 27 05:35:58.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.029018877s
    Aug 27 05:36:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.028556262s
    Aug 27 05:36:02.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.028718024s
    Aug 27 05:36:04.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.029557024s
    Aug 27 05:36:06.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.027843818s
    Aug 27 05:36:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.028243442s
    Aug 27 05:36:10.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.028516387s
    Aug 27 05:36:12.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.02867361s
    Aug 27 05:36:14.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.031590532s
    Aug 27 05:36:16.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.028550338s
    Aug 27 05:36:18.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.030921939s
    Aug 27 05:36:20.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.029416922s
    Aug 27 05:36:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.028582844s
    Aug 27 05:36:24.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.028432734s
    Aug 27 05:36:26.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.035996752s
    Aug 27 05:36:28.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.032657026s
    Aug 27 05:36:30.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.027382592s
    Aug 27 05:36:32.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.027936026s
    Aug 27 05:36:34.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.029133496s
    Aug 27 05:36:36.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.027583547s
    Aug 27 05:36:38.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.029271256s
    Aug 27 05:36:40.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.029502186s
    Aug 27 05:36:42.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.028477653s
    Aug 27 05:36:44.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.029044348s
    Aug 27 05:36:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.028474059s
    Aug 27 05:36:48.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.028039748s
    Aug 27 05:36:50.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.032696033s
    Aug 27 05:36:52.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.027936725s
    Aug 27 05:36:54.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.028890863s
    Aug 27 05:36:56.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.028151398s
    Aug 27 05:36:58.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.030115626s
    Aug 27 05:37:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.028840046s
    Aug 27 05:37:02.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.028455727s
    Aug 27 05:37:04.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.029997513s
    Aug 27 05:37:06.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.02888982s
    Aug 27 05:37:08.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.028403205s
    Aug 27 05:37:10.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.02723818s
    Aug 27 05:37:12.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.029129196s
    Aug 27 05:37:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.028263797s
    Aug 27 05:37:16.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.027828289s
    Aug 27 05:37:18.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.029250944s
    Aug 27 05:37:20.726: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.04764312s
    Aug 27 05:37:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.028216154s
    Aug 27 05:37:24.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.027734586s
    Aug 27 05:37:26.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.027689898s
    Aug 27 05:37:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.028662985s
    Aug 27 05:37:30.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.029303935s
    Aug 27 05:37:32.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.027069504s
    Aug 27 05:37:34.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.029249268s
    Aug 27 05:37:36.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.027374463s
    Aug 27 05:37:38.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.028172975s
    Aug 27 05:37:40.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.027897698s
    Aug 27 05:37:42.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.029374098s
    Aug 27 05:37:44.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.029039022s
    Aug 27 05:37:46.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.028405325s
    Aug 27 05:37:48.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.028783437s
    Aug 27 05:37:50.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.02929831s
    Aug 27 05:37:52.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.027510544s
    Aug 27 05:37:54.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.028894731s
    Aug 27 05:37:56.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.031132158s
    Aug 27 05:37:58.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.029134848s
    Aug 27 05:38:00.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.029037256s
    Aug 27 05:38:02.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.027833903s
    Aug 27 05:38:04.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.030981242s
    Aug 27 05:38:06.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.028979706s
    Aug 27 05:38:08.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.030763974s
    Aug 27 05:38:10.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.027268606s
    Aug 27 05:38:12.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.028459631s
    Aug 27 05:38:14.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.028302005s
    Aug 27 05:38:16.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.02743376s
    Aug 27 05:38:18.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.030239467s
    Aug 27 05:38:20.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.027840181s
    Aug 27 05:38:22.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.02846553s
    Aug 27 05:38:24.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.028447764s
    Aug 27 05:38:26.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.028094854s
    Aug 27 05:38:28.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.028932512s
    Aug 27 05:38:30.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.028952089s
    Aug 27 05:38:32.710: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.031326019s
    Aug 27 05:38:34.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.028018684s
    Aug 27 05:38:36.707: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.028145526s
    Aug 27 05:38:38.709: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.031034169s
    Aug 27 05:38:40.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.029383616s
    Aug 27 05:38:42.706: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.028021763s
    Aug 27 05:38:44.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.029499446s
    Aug 27 05:38:46.708: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.029651689s
    Aug 27 05:38:46.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.037016888s
    STEP: removing the label kubernetes.io/e2e-676ff8ca-8365-4b54-80a8-bcbd1fee3ce3 off the node ip-10-0-47-192 08/27/22 05:38:46.715
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-676ff8ca-8365-4b54-80a8-bcbd1fee3ce3 08/27/22 05:38:46.728
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:38:46.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3581" for this suite. 08/27/22 05:38:46.738
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:38:46.75
Aug 27 05:38:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 05:38:46.753
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:46.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:46.785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 05:38:46.789
Aug 27 05:38:46.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-1022 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Aug 27 05:38:46.912: INFO: stderr: ""
Aug 27 05:38:46.912: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 08/27/22 05:38:46.912
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Aug 27 05:38:46.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-1022 delete pods e2e-test-httpd-pod'
Aug 27 05:38:49.037: INFO: stderr: ""
Aug 27 05:38:49.037: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 05:38:49.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1022" for this suite. 08/27/22 05:38:49.042
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":33,"skipped":654,"failed":0}
------------------------------
â€¢ [2.297 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:38:46.75
    Aug 27 05:38:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 05:38:46.753
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:46.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:46.785
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 05:38:46.789
    Aug 27 05:38:46.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-1022 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Aug 27 05:38:46.912: INFO: stderr: ""
    Aug 27 05:38:46.912: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 08/27/22 05:38:46.912
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Aug 27 05:38:46.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-1022 delete pods e2e-test-httpd-pod'
    Aug 27 05:38:49.037: INFO: stderr: ""
    Aug 27 05:38:49.037: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 05:38:49.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1022" for this suite. 08/27/22 05:38:49.042
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:38:49.048
Aug 27 05:38:49.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:38:49.05
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:49.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:49.077
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:38:49.094
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:38:49.644
STEP: Deploying the webhook pod 08/27/22 05:38:49.651
STEP: Wait for the deployment to be ready 08/27/22 05:38:49.661
Aug 27 05:38:49.671: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 05:38:51.681
STEP: Verifying the service has paired with the endpoint 08/27/22 05:38:51.708
Aug 27 05:38:52.708: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 08/27/22 05:38:52.711
STEP: create a pod that should be updated by the webhook 08/27/22 05:38:52.724
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:38:52.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7427" for this suite. 08/27/22 05:38:52.792
STEP: Destroying namespace "webhook-7427-markers" for this suite. 08/27/22 05:38:52.799
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":34,"skipped":662,"failed":0}
------------------------------
â€¢ [3.883 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:38:49.048
    Aug 27 05:38:49.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:38:49.05
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:49.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:49.077
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:38:49.094
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:38:49.644
    STEP: Deploying the webhook pod 08/27/22 05:38:49.651
    STEP: Wait for the deployment to be ready 08/27/22 05:38:49.661
    Aug 27 05:38:49.671: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 05:38:51.681
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:38:51.708
    Aug 27 05:38:52.708: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 08/27/22 05:38:52.711
    STEP: create a pod that should be updated by the webhook 08/27/22 05:38:52.724
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:38:52.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7427" for this suite. 08/27/22 05:38:52.792
    STEP: Destroying namespace "webhook-7427-markers" for this suite. 08/27/22 05:38:52.799
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:38:52.942
Aug 27 05:38:52.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:38:52.943
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:52.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:52.987
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 08/27/22 05:38:52.995
Aug 27 05:38:53.008: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd" in namespace "projected-2486" to be "Succeeded or Failed"
Aug 27 05:38:53.017: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.714478ms
Aug 27 05:38:55.021: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012336182s
Aug 27 05:38:57.022: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013431207s
STEP: Saw pod success 08/27/22 05:38:57.022
Aug 27 05:38:57.022: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd" satisfied condition "Succeeded or Failed"
Aug 27 05:38:57.029: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd container client-container: <nil>
STEP: delete the pod 08/27/22 05:38:57.05
Aug 27 05:38:57.059: INFO: Waiting for pod downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd to disappear
Aug 27 05:38:57.064: INFO: Pod downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 05:38:57.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2486" for this suite. 08/27/22 05:38:57.067
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":35,"skipped":709,"failed":0}
------------------------------
â€¢ [4.129 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:38:52.942
    Aug 27 05:38:52.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:38:52.943
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:52.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:52.987
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 08/27/22 05:38:52.995
    Aug 27 05:38:53.008: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd" in namespace "projected-2486" to be "Succeeded or Failed"
    Aug 27 05:38:53.017: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.714478ms
    Aug 27 05:38:55.021: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012336182s
    Aug 27 05:38:57.022: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013431207s
    STEP: Saw pod success 08/27/22 05:38:57.022
    Aug 27 05:38:57.022: INFO: Pod "downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd" satisfied condition "Succeeded or Failed"
    Aug 27 05:38:57.029: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd container client-container: <nil>
    STEP: delete the pod 08/27/22 05:38:57.05
    Aug 27 05:38:57.059: INFO: Waiting for pod downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd to disappear
    Aug 27 05:38:57.064: INFO: Pod downwardapi-volume-6416fd6c-0860-4f09-8bd3-d371ec1d00dd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 05:38:57.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2486" for this suite. 08/27/22 05:38:57.067
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:38:57.077
Aug 27 05:38:57.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename cronjob 08/27/22 05:38:57.078
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:57.101
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:57.107
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 08/27/22 05:38:57.111
STEP: Ensuring a job is scheduled 08/27/22 05:38:57.121
STEP: Ensuring exactly one is scheduled 08/27/22 05:39:01.133
STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/27/22 05:39:01.141
STEP: Ensuring no more jobs are scheduled 08/27/22 05:39:01.146
STEP: Removing cronjob 08/27/22 05:44:01.156
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 27 05:44:01.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7619" for this suite. 08/27/22 05:44:01.178
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":36,"skipped":742,"failed":0}
------------------------------
â€¢ [SLOW TEST] [304.113 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:38:57.077
    Aug 27 05:38:57.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename cronjob 08/27/22 05:38:57.078
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:38:57.101
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:38:57.107
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 08/27/22 05:38:57.111
    STEP: Ensuring a job is scheduled 08/27/22 05:38:57.121
    STEP: Ensuring exactly one is scheduled 08/27/22 05:39:01.133
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/27/22 05:39:01.141
    STEP: Ensuring no more jobs are scheduled 08/27/22 05:39:01.146
    STEP: Removing cronjob 08/27/22 05:44:01.156
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 27 05:44:01.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7619" for this suite. 08/27/22 05:44:01.178
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:01.191
Aug 27 05:44:01.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 05:44:01.193
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:01.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:01.384
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 08/27/22 05:44:01.409
Aug 27 05:44:01.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce" in namespace "downward-api-6169" to be "Succeeded or Failed"
Aug 27 05:44:01.473: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce": Phase="Pending", Reason="", readiness=false. Elapsed: 18.564211ms
Aug 27 05:44:03.491: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036555077s
Aug 27 05:44:05.477: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022868421s
STEP: Saw pod success 08/27/22 05:44:05.478
Aug 27 05:44:05.478: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce" satisfied condition "Succeeded or Failed"
Aug 27 05:44:05.481: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce container client-container: <nil>
STEP: delete the pod 08/27/22 05:44:05.513
Aug 27 05:44:05.527: INFO: Waiting for pod downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce to disappear
Aug 27 05:44:05.531: INFO: Pod downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 05:44:05.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6169" for this suite. 08/27/22 05:44:05.535
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":37,"skipped":753,"failed":0}
------------------------------
â€¢ [4.349 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:01.191
    Aug 27 05:44:01.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 05:44:01.193
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:01.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:01.384
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 08/27/22 05:44:01.409
    Aug 27 05:44:01.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce" in namespace "downward-api-6169" to be "Succeeded or Failed"
    Aug 27 05:44:01.473: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce": Phase="Pending", Reason="", readiness=false. Elapsed: 18.564211ms
    Aug 27 05:44:03.491: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036555077s
    Aug 27 05:44:05.477: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022868421s
    STEP: Saw pod success 08/27/22 05:44:05.478
    Aug 27 05:44:05.478: INFO: Pod "downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce" satisfied condition "Succeeded or Failed"
    Aug 27 05:44:05.481: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce container client-container: <nil>
    STEP: delete the pod 08/27/22 05:44:05.513
    Aug 27 05:44:05.527: INFO: Waiting for pod downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce to disappear
    Aug 27 05:44:05.531: INFO: Pod downwardapi-volume-b4491ccf-b4b2-49ae-a170-103b33afc5ce no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 05:44:05.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6169" for this suite. 08/27/22 05:44:05.535
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:05.546
Aug 27 05:44:05.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-pred 08/27/22 05:44:05.547
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:05.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:05.6
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 27 05:44:05.606: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 05:44:05.617: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 05:44:05.621: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
Aug 27 05:44:05.627: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 05:44:05.627: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 05:44:05.627: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 05:44:05.627: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 05:44:05.627: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 05:44:05.627: INFO: 	Container e2e ready: true, restart count 0
Aug 27 05:44:05.627: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 05:44:05.627: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 05:44:05.627: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 05:44:05.627: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 05:44:05.627: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
Aug 27 05:44:05.632: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 05:44:05.632: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 05:44:05.632: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 05:44:05.633: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 05:44:05.633: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
Aug 27 05:44:05.633: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 05:44:05.633: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 05:44:05.633: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 05:44:05.633: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node ip-10-0-31-158 08/27/22 05:44:05.656
STEP: verifying the node has the label node ip-10-0-47-192 08/27/22 05:44:05.673
Aug 27 05:44:05.685: INFO: Pod calico-node-gc879 requesting resource cpu=100m on Node ip-10-0-31-158
Aug 27 05:44:05.685: INFO: Pod calico-node-tj9v9 requesting resource cpu=100m on Node ip-10-0-47-192
Aug 27 05:44:05.685: INFO: Pod kube-proxy-jnlr9 requesting resource cpu=0m on Node ip-10-0-47-192
Aug 27 05:44:05.685: INFO: Pod kube-proxy-wmg2x requesting resource cpu=0m on Node ip-10-0-31-158
Aug 27 05:44:05.685: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-47-192
Aug 27 05:44:05.685: INFO: Pod sonobuoy-e2e-job-a7872b18ebcd44d0 requesting resource cpu=0m on Node ip-10-0-31-158
Aug 27 05:44:05.685: INFO: Pod sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj requesting resource cpu=0m on Node ip-10-0-31-158
Aug 27 05:44:05.685: INFO: Pod sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 requesting resource cpu=0m on Node ip-10-0-47-192
STEP: Starting Pods to consume most of the cluster CPU. 08/27/22 05:44:05.685
Aug 27 05:44:05.686: INFO: Creating a pod which consumes cpu=1330m on Node ip-10-0-31-158
Aug 27 05:44:05.696: INFO: Creating a pod which consumes cpu=1330m on Node ip-10-0-47-192
Aug 27 05:44:05.705: INFO: Waiting up to 5m0s for pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5" in namespace "sched-pred-8961" to be "running"
Aug 27 05:44:05.731: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.525305ms
Aug 27 05:44:07.736: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029140184s
Aug 27 05:44:09.736: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5": Phase="Running", Reason="", readiness=true. Elapsed: 4.02971625s
Aug 27 05:44:09.736: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5" satisfied condition "running"
Aug 27 05:44:09.736: INFO: Waiting up to 5m0s for pod "filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5" in namespace "sched-pred-8961" to be "running"
Aug 27 05:44:09.740: INFO: Pod "filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5": Phase="Running", Reason="", readiness=true. Elapsed: 3.308718ms
Aug 27 05:44:09.740: INFO: Pod "filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 08/27/22 05:44:09.74
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d56b1965535], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8961/filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5 to ip-10-0-31-158] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d56e8b1b552], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.8"] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d573d7482a8], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.8" in 1.422039323s] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d573fdca585], Reason = [Created], Message = [Created container filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d574be547ec], Reason = [Started], Message = [Started container filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56b2fcac7b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8961/filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5 to ip-10-0-47-192] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56dec5fc51], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/27/22 05:44:09.743
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56dfbc581d], Reason = [Created], Message = [Created container filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5] 08/27/22 05:44:09.744
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56e4d80eb6], Reason = [Started], Message = [Started container filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5] 08/27/22 05:44:09.744
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.170f1d57a2bf92c1], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/controller: }, 3 Insufficient cpu. preemption: 0/3 nodes are available: 1 Preemption is not helpful for scheduling, 2 No preemption victims found for incoming pod.] 08/27/22 05:44:09.763
STEP: removing the label node off the node ip-10-0-31-158 08/27/22 05:44:10.762
STEP: verifying the node doesn't have the label node 08/27/22 05:44:10.781
STEP: removing the label node off the node ip-10-0-47-192 08/27/22 05:44:10.802
STEP: verifying the node doesn't have the label node 08/27/22 05:44:10.824
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:44:10.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8961" for this suite. 08/27/22 05:44:10.844
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":38,"skipped":792,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.310 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:05.546
    Aug 27 05:44:05.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-pred 08/27/22 05:44:05.547
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:05.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:05.6
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 27 05:44:05.606: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 27 05:44:05.617: INFO: Waiting for terminating namespaces to be deleted...
    Aug 27 05:44:05.621: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
    Aug 27 05:44:05.627: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 05:44:05.627: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 05:44:05.627: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 05:44:05.627: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 05:44:05.627: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 05:44:05.627: INFO: 	Container e2e ready: true, restart count 0
    Aug 27 05:44:05.627: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 05:44:05.627: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 05:44:05.627: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 05:44:05.627: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 27 05:44:05.627: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
    Aug 27 05:44:05.632: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 05:44:05.632: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 05:44:05.632: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 05:44:05.633: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 05:44:05.633: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
    Aug 27 05:44:05.633: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 27 05:44:05.633: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 05:44:05.633: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 05:44:05.633: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node ip-10-0-31-158 08/27/22 05:44:05.656
    STEP: verifying the node has the label node ip-10-0-47-192 08/27/22 05:44:05.673
    Aug 27 05:44:05.685: INFO: Pod calico-node-gc879 requesting resource cpu=100m on Node ip-10-0-31-158
    Aug 27 05:44:05.685: INFO: Pod calico-node-tj9v9 requesting resource cpu=100m on Node ip-10-0-47-192
    Aug 27 05:44:05.685: INFO: Pod kube-proxy-jnlr9 requesting resource cpu=0m on Node ip-10-0-47-192
    Aug 27 05:44:05.685: INFO: Pod kube-proxy-wmg2x requesting resource cpu=0m on Node ip-10-0-31-158
    Aug 27 05:44:05.685: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-47-192
    Aug 27 05:44:05.685: INFO: Pod sonobuoy-e2e-job-a7872b18ebcd44d0 requesting resource cpu=0m on Node ip-10-0-31-158
    Aug 27 05:44:05.685: INFO: Pod sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj requesting resource cpu=0m on Node ip-10-0-31-158
    Aug 27 05:44:05.685: INFO: Pod sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 requesting resource cpu=0m on Node ip-10-0-47-192
    STEP: Starting Pods to consume most of the cluster CPU. 08/27/22 05:44:05.685
    Aug 27 05:44:05.686: INFO: Creating a pod which consumes cpu=1330m on Node ip-10-0-31-158
    Aug 27 05:44:05.696: INFO: Creating a pod which consumes cpu=1330m on Node ip-10-0-47-192
    Aug 27 05:44:05.705: INFO: Waiting up to 5m0s for pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5" in namespace "sched-pred-8961" to be "running"
    Aug 27 05:44:05.731: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.525305ms
    Aug 27 05:44:07.736: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029140184s
    Aug 27 05:44:09.736: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5": Phase="Running", Reason="", readiness=true. Elapsed: 4.02971625s
    Aug 27 05:44:09.736: INFO: Pod "filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5" satisfied condition "running"
    Aug 27 05:44:09.736: INFO: Waiting up to 5m0s for pod "filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5" in namespace "sched-pred-8961" to be "running"
    Aug 27 05:44:09.740: INFO: Pod "filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5": Phase="Running", Reason="", readiness=true. Elapsed: 3.308718ms
    Aug 27 05:44:09.740: INFO: Pod "filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 08/27/22 05:44:09.74
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d56b1965535], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8961/filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5 to ip-10-0-31-158] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d56e8b1b552], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.8"] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d573d7482a8], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.8" in 1.422039323s] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d573fdca585], Reason = [Created], Message = [Created container filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5.170f1d574be547ec], Reason = [Started], Message = [Started container filler-pod-213dbee7-b87e-41ca-ac31-e1027a5b5de5] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56b2fcac7b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8961/filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5 to ip-10-0-47-192] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56dec5fc51], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 08/27/22 05:44:09.743
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56dfbc581d], Reason = [Created], Message = [Created container filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5] 08/27/22 05:44:09.744
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5.170f1d56e4d80eb6], Reason = [Started], Message = [Started container filler-pod-3e4e1424-5b72-496e-81ab-2f923769bcb5] 08/27/22 05:44:09.744
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.170f1d57a2bf92c1], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/controller: }, 3 Insufficient cpu. preemption: 0/3 nodes are available: 1 Preemption is not helpful for scheduling, 2 No preemption victims found for incoming pod.] 08/27/22 05:44:09.763
    STEP: removing the label node off the node ip-10-0-31-158 08/27/22 05:44:10.762
    STEP: verifying the node doesn't have the label node 08/27/22 05:44:10.781
    STEP: removing the label node off the node ip-10-0-47-192 08/27/22 05:44:10.802
    STEP: verifying the node doesn't have the label node 08/27/22 05:44:10.824
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:44:10.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8961" for this suite. 08/27/22 05:44:10.844
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:10.86
Aug 27 05:44:10.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replicaset 08/27/22 05:44:10.861
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:10.901
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:10.914
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Aug 27 05:44:10.924: INFO: Creating ReplicaSet my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646
Aug 27 05:44:10.944: INFO: Pod name my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646: Found 0 pods out of 1
Aug 27 05:44:15.951: INFO: Pod name my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646: Found 1 pods out of 1
Aug 27 05:44:15.951: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646" is running
Aug 27 05:44:15.951: INFO: Waiting up to 5m0s for pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4" in namespace "replicaset-8165" to be "running"
Aug 27 05:44:15.955: INFO: Pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4": Phase="Running", Reason="", readiness=true. Elapsed: 3.952523ms
Aug 27 05:44:15.955: INFO: Pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4" satisfied condition "running"
Aug 27 05:44:15.955: INFO: Pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:10 +0000 UTC Reason: Message:}])
Aug 27 05:44:15.956: INFO: Trying to dial the pod
Aug 27 05:44:20.968: INFO: Controller my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646: Got expected result from replica 1 [my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4]: "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 27 05:44:20.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8165" for this suite. 08/27/22 05:44:20.971
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":39,"skipped":799,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.116 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:10.86
    Aug 27 05:44:10.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replicaset 08/27/22 05:44:10.861
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:10.901
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:10.914
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Aug 27 05:44:10.924: INFO: Creating ReplicaSet my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646
    Aug 27 05:44:10.944: INFO: Pod name my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646: Found 0 pods out of 1
    Aug 27 05:44:15.951: INFO: Pod name my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646: Found 1 pods out of 1
    Aug 27 05:44:15.951: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646" is running
    Aug 27 05:44:15.951: INFO: Waiting up to 5m0s for pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4" in namespace "replicaset-8165" to be "running"
    Aug 27 05:44:15.955: INFO: Pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4": Phase="Running", Reason="", readiness=true. Elapsed: 3.952523ms
    Aug 27 05:44:15.955: INFO: Pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4" satisfied condition "running"
    Aug 27 05:44:15.955: INFO: Pod "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 05:44:10 +0000 UTC Reason: Message:}])
    Aug 27 05:44:15.956: INFO: Trying to dial the pod
    Aug 27 05:44:20.968: INFO: Controller my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646: Got expected result from replica 1 [my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4]: "my-hostname-basic-f8dac6b6-72d9-481e-9ae7-a71304d71646-6pcz4", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 27 05:44:20.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8165" for this suite. 08/27/22 05:44:20.971
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:20.98
Aug 27 05:44:20.980: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 05:44:20.981
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:20.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:21.005
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 08/27/22 05:44:21.009
Aug 27 05:44:21.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5892 create -f -'
Aug 27 05:44:22.431: INFO: stderr: ""
Aug 27 05:44:22.431: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 08/27/22 05:44:22.431
Aug 27 05:44:22.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5892 diff -f -'
Aug 27 05:44:22.809: INFO: rc: 1
Aug 27 05:44:22.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5892 delete -f -'
Aug 27 05:44:22.879: INFO: stderr: ""
Aug 27 05:44:22.879: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 05:44:22.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5892" for this suite. 08/27/22 05:44:22.883
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":40,"skipped":813,"failed":0}
------------------------------
â€¢ [1.909 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:20.98
    Aug 27 05:44:20.980: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 05:44:20.981
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:20.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:21.005
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 08/27/22 05:44:21.009
    Aug 27 05:44:21.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5892 create -f -'
    Aug 27 05:44:22.431: INFO: stderr: ""
    Aug 27 05:44:22.431: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 08/27/22 05:44:22.431
    Aug 27 05:44:22.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5892 diff -f -'
    Aug 27 05:44:22.809: INFO: rc: 1
    Aug 27 05:44:22.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5892 delete -f -'
    Aug 27 05:44:22.879: INFO: stderr: ""
    Aug 27 05:44:22.879: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 05:44:22.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5892" for this suite. 08/27/22 05:44:22.883
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:22.889
Aug 27 05:44:22.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 05:44:22.891
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:22.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:22.966
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Aug 27 05:44:22.972: INFO: Creating deployment "webserver-deployment"
Aug 27 05:44:22.987: INFO: Waiting for observed generation 1
Aug 27 05:44:25.000: INFO: Waiting for all required pods to come up
Aug 27 05:44:25.004: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 08/27/22 05:44:25.004
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-glwrc" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-w7kgx" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2fr9k" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7xqf9" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gb74s" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-jsfs9" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hmzg5" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-k5vxl" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-mq9xx" in namespace "deployment-5022" to be "running"
Aug 27 05:44:25.008: INFO: Pod "webserver-deployment-845c8977d9-w7kgx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.857733ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-gb74s": Phase="Pending", Reason="", readiness=false. Elapsed: 7.980961ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-mq9xx": Phase="Pending", Reason="", readiness=false. Elapsed: 7.844145ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-glwrc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.546159ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-7xqf9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.370793ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-2fr9k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.516441ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-k5vxl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.13336ms
Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-hmzg5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.265262ms
Aug 27 05:44:25.014: INFO: Pod "webserver-deployment-845c8977d9-jsfs9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.441354ms
Aug 27 05:44:27.025: INFO: Pod "webserver-deployment-845c8977d9-w7kgx": Phase="Running", Reason="", readiness=true. Elapsed: 2.020067868s
Aug 27 05:44:27.025: INFO: Pod "webserver-deployment-845c8977d9-w7kgx" satisfied condition "running"
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-gb74s": Phase="Running", Reason="", readiness=true. Elapsed: 2.042298203s
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-gb74s" satisfied condition "running"
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-jsfs9": Phase="Running", Reason="", readiness=true. Elapsed: 2.042311426s
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-jsfs9" satisfied condition "running"
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-k5vxl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04218004s
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-hmzg5": Phase="Running", Reason="", readiness=true. Elapsed: 2.042198477s
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-hmzg5" satisfied condition "running"
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-2fr9k": Phase="Running", Reason="", readiness=true. Elapsed: 2.042632192s
Aug 27 05:44:27.048: INFO: Pod "webserver-deployment-845c8977d9-2fr9k" satisfied condition "running"
Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-glwrc": Phase="Running", Reason="", readiness=true. Elapsed: 2.042636751s
Aug 27 05:44:27.048: INFO: Pod "webserver-deployment-845c8977d9-glwrc" satisfied condition "running"
Aug 27 05:44:27.048: INFO: Pod "webserver-deployment-845c8977d9-7xqf9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042623846s
Aug 27 05:44:27.049: INFO: Pod "webserver-deployment-845c8977d9-mq9xx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043553415s
Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-7xqf9": Phase="Running", Reason="", readiness=true. Elapsed: 4.01336326s
Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-7xqf9" satisfied condition "running"
Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-mq9xx": Phase="Running", Reason="", readiness=true. Elapsed: 4.012961885s
Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-mq9xx" satisfied condition "running"
Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-k5vxl": Phase="Running", Reason="", readiness=true. Elapsed: 4.013061917s
Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-k5vxl" satisfied condition "running"
Aug 27 05:44:29.018: INFO: Waiting for deployment "webserver-deployment" to complete
Aug 27 05:44:29.025: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug 27 05:44:29.034: INFO: Updating deployment webserver-deployment
Aug 27 05:44:29.034: INFO: Waiting for observed generation 2
Aug 27 05:44:31.042: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 27 05:44:31.056: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 27 05:44:31.069: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 27 05:44:31.088: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 27 05:44:31.088: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 27 05:44:31.093: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 27 05:44:31.100: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug 27 05:44:31.100: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug 27 05:44:31.120: INFO: Updating deployment webserver-deployment
Aug 27 05:44:31.121: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug 27 05:44:31.129: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 27 05:44:31.139: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 05:44:31.183: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5022  1d7ef620-0a96-4931-8bc7-780836846a1b 4532 3 2022-08-27 05:44:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003698428 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-08-27 05:44:29 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-27 05:44:31 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Aug 27 05:44:31.239: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-5022  b78097ec-032f-4527-a16f-5d1ffff821f9 4529 3 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1d7ef620-0a96-4931-8bc7-780836846a1b 0xc003698857 0xc003698858}] [] [{kube-controller-manager Update apps/v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1d7ef620-0a96-4931-8bc7-780836846a1b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036988f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 05:44:31.239: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug 27 05:44:31.239: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-5022  b7148a63-880c-4432-b955-ce4da80ff6e5 4528 3 2022-08-27 05:44:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1d7ef620-0a96-4931-8bc7-780836846a1b 0xc003698957 0xc003698958}] [] [{kube-controller-manager Update apps/v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1d7ef620-0a96-4931-8bc7-780836846a1b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036989e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Aug 27 05:44:31.309: INFO: Pod "webserver-deployment-69b7448995-2jqm5" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2jqm5 webserver-deployment-69b7448995- deployment-5022  c843950d-29f1-4180-9826-ec1c4a366011 4554 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003698f00 0xc003698f01}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mg5vl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mg5vl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.311: INFO: Pod "webserver-deployment-69b7448995-4hftw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-4hftw webserver-deployment-69b7448995- deployment-5022  7bb1f1fd-6227-4786-a10e-9754025f8d25 4522 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:e2d9fbdebbf8ecbf6a514e75c732092b2c3716ed26ff59831d317318ee63d705 cni.projectcalico.org/podIP:10.2.137.24/32 cni.projectcalico.org/podIPs:10.2.137.24/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699090 0xc003699091}] [] [{Go-http-client Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d7hf6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d7hf6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.24,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.312: INFO: Pod "webserver-deployment-69b7448995-7r55c" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7r55c webserver-deployment-69b7448995- deployment-5022  509c2616-e09b-4f66-bf49-60470d96ed0e 4559 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc0036992c0 0xc0036992c1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dk2j4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dk2j4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.315: INFO: Pod "webserver-deployment-69b7448995-d27z6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-d27z6 webserver-deployment-69b7448995- deployment-5022  cef07484-f42e-4535-9158-a01eb78b887b 4503 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0194bfff7e8870bf8f1ea1e62a97e7dfb1f4217b3a8003c1d2d008af1e816d9a cni.projectcalico.org/podIP:10.2.35.43/32 cni.projectcalico.org/podIPs:10.2.35.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699437 0xc003699438}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-08-27 05:44:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-krg8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-krg8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.315: INFO: Pod "webserver-deployment-69b7448995-gzws4" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-gzws4 webserver-deployment-69b7448995- deployment-5022  dcb1da27-aa10-4f4e-abcb-136391537f90 4552 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699640 0xc003699641}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fxr9c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fxr9c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.317: INFO: Pod "webserver-deployment-69b7448995-nrqff" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-nrqff webserver-deployment-69b7448995- deployment-5022  e1c639b3-5576-4013-bcfe-a0e82a845b65 4560 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699787 0xc003699788}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s4vqw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s4vqw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.321: INFO: Pod "webserver-deployment-69b7448995-qxkrk" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qxkrk webserver-deployment-69b7448995- deployment-5022  bab0f3f5-7cf6-4b37-ae6b-0a66baa3a15b 4510 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5e0071723e50c35796e03d35fca7e6ff3366a0a8cf7f7d9fdbeedc53d55ec8e7 cni.projectcalico.org/podIP:10.2.35.44/32 cni.projectcalico.org/podIPs:10.2.35.44/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc0036998f7 0xc0036998f8}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svvm9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svvm9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.322: INFO: Pod "webserver-deployment-69b7448995-v5xm9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-v5xm9 webserver-deployment-69b7448995- deployment-5022  451c83a9-775c-4cc4-8ecf-60ec8bdf53c7 4541 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699b00 0xc003699b01}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6jlr8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6jlr8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.323: INFO: Pod "webserver-deployment-69b7448995-wfds7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wfds7 webserver-deployment-69b7448995- deployment-5022  e7b49e0e-b0bc-4b52-9030-e64f8315bf64 4556 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699c70 0xc003699c71}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mgm6r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mgm6r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.326: INFO: Pod "webserver-deployment-69b7448995-wsw8w" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wsw8w webserver-deployment-69b7448995- deployment-5022  801fc0cf-6773-4796-9ceb-6bfc9ac3ec00 4491 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9293d7370c757bfdf449bd474272b4e2a5df2e35dd072f508dccb8cd777d6fa3 cni.projectcalico.org/podIP:10.2.35.42/32 cni.projectcalico.org/podIPs:10.2.35.42/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699e00 0xc003699e01}] [] [{Go-http-client Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dc95f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dc95f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.326: INFO: Pod "webserver-deployment-69b7448995-x9fdf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-x9fdf webserver-deployment-69b7448995- deployment-5022  1b54deaa-6cc5-42c9-89df-7fe00e4bacfe 4561 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc002f76000 0xc002f76001}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wrnz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wrnz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.328: INFO: Pod "webserver-deployment-69b7448995-xtjrn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xtjrn webserver-deployment-69b7448995- deployment-5022  04845069-cb6a-4e36-a396-63ffa4ff06e3 4525 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:23a7ddf315acf98091a7730c7c1ef636ec2ecb78847271d29230ac901696a6e1 cni.projectcalico.org/podIP:10.2.137.23/32 cni.projectcalico.org/podIPs:10.2.137.23/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc002f76167 0xc002f76168}] [] [{Go-http-client Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9b9sj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9b9sj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.23,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.328: INFO: Pod "webserver-deployment-845c8977d9-2fr9k" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2fr9k webserver-deployment-845c8977d9- deployment-5022  43284c77-1b84-40e7-8149-85b3eb859a63 4369 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:161d3a3265876c7d946fbe5a80b65329c94ebc714d3cfb0bfa67d7ea97328600 cni.projectcalico.org/podIP:10.2.137.22/32 cni.projectcalico.org/podIPs:10.2.137.22/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f763c0 0xc002f763c1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.22\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l6f2c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l6f2c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.22,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://52f10c0aecd56b588bd48c45e2da43379902b74344378e5b2f710b5660bf66de,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.329: INFO: Pod "webserver-deployment-845c8977d9-74rmr" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-74rmr webserver-deployment-845c8977d9- deployment-5022  ea37160a-037a-42d6-8573-f86bba4400e0 4557 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f765d0 0xc002f765d1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4gzqc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4gzqc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.329: INFO: Pod "webserver-deployment-845c8977d9-8mj4k" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8mj4k webserver-deployment-845c8977d9- deployment-5022  69b6cda0-6d28-44f2-9386-cd82006faaa5 4328 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5bbff7709cdca711051349a0e04b972ddbc1d8ded4eb9502918ec79043a272b5 cni.projectcalico.org/podIP:10.2.137.18/32 cni.projectcalico.org/podIPs:10.2.137.18/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76750 0xc002f76751}] [] [{Go-http-client Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p69n2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p69n2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.18,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://75bd307050351e01081ed8de91269084bbdd029a66f345205ac67f2724e6e25b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.329: INFO: Pod "webserver-deployment-845c8977d9-bcnhc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bcnhc webserver-deployment-845c8977d9- deployment-5022  b600d0e2-e03c-43ad-9401-d94738142615 4562 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76950 0xc002f76951}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bt92n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bt92n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.330: INFO: Pod "webserver-deployment-845c8977d9-g2jdp" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-g2jdp webserver-deployment-845c8977d9- deployment-5022  9592938b-de81-405a-ad41-60c5569bb5e3 4564 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76a87 0xc002f76a88}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l7nmw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l7nmw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.331: INFO: Pod "webserver-deployment-845c8977d9-g52js" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-g52js webserver-deployment-845c8977d9- deployment-5022  b98dec3b-fd3b-42ec-96ad-07a409046364 4551 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76bc7 0xc002f76bc8}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-92dtk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-92dtk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.332: INFO: Pod "webserver-deployment-845c8977d9-gb74s" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gb74s webserver-deployment-845c8977d9- deployment-5022  22ad6b80-24fb-40ca-8b49-3a2fd6870639 4336 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a4c145bc6c8a1ee5d9042136086798f53b9ce7b5d251648995c014a70c1fcd3a cni.projectcalico.org/podIP:10.2.137.19/32 cni.projectcalico.org/podIPs:10.2.137.19/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76d50 0xc002f76d51}] [] [{Go-http-client Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.19\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dmx99,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dmx99,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.19,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2d77af5a75ea8d9f366aea29969dd98808de1889fb48f32b7074ee6f0c264f36,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.19,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.333: INFO: Pod "webserver-deployment-845c8977d9-glwrc" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-glwrc webserver-deployment-845c8977d9- deployment-5022  5c44858d-815e-4e84-b686-cd4d94f17bb4 4399 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f2082714765e91d0192021fbed3bac3cbc449d9d4acc72d16156320f7fe065f6 cni.projectcalico.org/podIP:10.2.35.41/32 cni.projectcalico.org/podIPs:10.2.35.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76f70 0xc002f76f71}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ncps8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ncps8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.41,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://91dfa4b9b75efa01d0ea75fbb00803f769bfd1bc7f6957bef94d3b8bb7f34cdb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.339: INFO: Pod "webserver-deployment-845c8977d9-gr88w" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gr88w webserver-deployment-845c8977d9- deployment-5022  e3cfbe49-0073-467b-bf16-d26b1157f7ae 4563 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77180 0xc002f77181}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kdfj4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kdfj4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.352: INFO: Pod "webserver-deployment-845c8977d9-jsfs9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-jsfs9 webserver-deployment-845c8977d9- deployment-5022  4d87cd64-eabb-49e2-bac8-c69168efee28 4389 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e2e944e634cd133a327c245303aa5d5d0f794f45878a604ada2c72a3540d9265 cni.projectcalico.org/podIP:10.2.137.21/32 cni.projectcalico.org/podIPs:10.2.137.21/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f772d7 0xc002f772d8}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bslsv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bslsv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.21,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5d0c665aaccaa502dd3df0bbdf941677029a913d55dac4d3bde59be550a09b33,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.357: INFO: Pod "webserver-deployment-845c8977d9-k5vxl" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-k5vxl webserver-deployment-845c8977d9- deployment-5022  50d644c7-4333-487e-b438-3d54619e0848 4409 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:0713012108bf1cd006db16a6ee9989a377e89831f57ed47490efc06eef1addf9 cni.projectcalico.org/podIP:10.2.35.37/32 cni.projectcalico.org/podIPs:10.2.35.37/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77500 0xc002f77501}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sp8f2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sp8f2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.37,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1a6da6ee3c0384a5c943f4ae5d708ff94fbf43fab2deb279a4746de8654f1005,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.357: INFO: Pod "webserver-deployment-845c8977d9-kttvd" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kttvd webserver-deployment-845c8977d9- deployment-5022  10e599a3-f586-4a20-8bbb-c04d862e02f6 4565 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77710 0xc002f77711}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lrfjj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lrfjj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.359: INFO: Pod "webserver-deployment-845c8977d9-mq9xx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mq9xx webserver-deployment-845c8977d9- deployment-5022  f7dbca5c-1f2b-4c1e-9335-d10a6ccd26f3 4402 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fca1959416751284a93375bb94d924deee2c0e00d36b7d33b1e95050ed8229b4 cni.projectcalico.org/podIP:10.2.35.39/32 cni.projectcalico.org/podIPs:10.2.35.39/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77867 0xc002f77868}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5d2sf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5d2sf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.39,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7e482c9cb475c5ecad08015b01ebc1d5f25f052fab484a04e011a0b6884baa04,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.360: INFO: Pod "webserver-deployment-845c8977d9-n7mp7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-n7mp7 webserver-deployment-845c8977d9- deployment-5022  aa834eec-471f-47f4-999b-a9043746b1bf 4549 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77a70 0xc002f77a71}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mlkxb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mlkxb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.361: INFO: Pod "webserver-deployment-845c8977d9-sbrxb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-sbrxb webserver-deployment-845c8977d9- deployment-5022  c844c355-c040-409e-b286-f5778561d9a8 4539 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77bd0 0xc002f77bd1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cvjsd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cvjsd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.364: INFO: Pod "webserver-deployment-845c8977d9-spwzg" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-spwzg webserver-deployment-845c8977d9- deployment-5022  871a9ed3-80de-4a06-9034-ec22a5414ff9 4555 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77d30 0xc002f77d31}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vp27h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vp27h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.364: INFO: Pod "webserver-deployment-845c8977d9-tnz5p" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tnz5p webserver-deployment-845c8977d9- deployment-5022  9f55b778-5e6e-4e91-99fa-5a0b9c4c782d 4548 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77e90 0xc002f77e91}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sr7ck,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sr7ck,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.366: INFO: Pod "webserver-deployment-845c8977d9-tw7v8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tw7v8 webserver-deployment-845c8977d9- deployment-5022  de19b518-42ff-4553-bfb2-9cefefb74e8d 4553 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77ff0 0xc002f77ff1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjp74,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjp74,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.366: INFO: Pod "webserver-deployment-845c8977d9-w7kgx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-w7kgx webserver-deployment-845c8977d9- deployment-5022  2c014a5d-bf43-4669-b123-2a6e53e41035 4352 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f21441e55a27305bc349c74c63935875cba710f86d85f4dff057d429f97de165 cni.projectcalico.org/podIP:10.2.137.20/32 cni.projectcalico.org/podIPs:10.2.137.20/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f9a170 0xc002f9a171}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s6gbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s6gbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.20,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a1348b73f363ace791265c84447724b92c5eaef75b8d53b8053620441fd2cdfa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 05:44:31.367: INFO: Pod "webserver-deployment-845c8977d9-z2wd7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-z2wd7 webserver-deployment-845c8977d9- deployment-5022  a0725602-3d34-4d4a-991f-5c56f6b9569d 4558 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f9a380 0xc002f9a381}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l8nw2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l8nw2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 05:44:31.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5022" for this suite. 08/27/22 05:44:31.382
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":41,"skipped":824,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.512 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:22.889
    Aug 27 05:44:22.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 05:44:22.891
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:22.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:22.966
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Aug 27 05:44:22.972: INFO: Creating deployment "webserver-deployment"
    Aug 27 05:44:22.987: INFO: Waiting for observed generation 1
    Aug 27 05:44:25.000: INFO: Waiting for all required pods to come up
    Aug 27 05:44:25.004: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 08/27/22 05:44:25.004
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-glwrc" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-w7kgx" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2fr9k" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7xqf9" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gb74s" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-jsfs9" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hmzg5" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-k5vxl" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.005: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-mq9xx" in namespace "deployment-5022" to be "running"
    Aug 27 05:44:25.008: INFO: Pod "webserver-deployment-845c8977d9-w7kgx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.857733ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-gb74s": Phase="Pending", Reason="", readiness=false. Elapsed: 7.980961ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-mq9xx": Phase="Pending", Reason="", readiness=false. Elapsed: 7.844145ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-glwrc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.546159ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-7xqf9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.370793ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-2fr9k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.516441ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-k5vxl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.13336ms
    Aug 27 05:44:25.013: INFO: Pod "webserver-deployment-845c8977d9-hmzg5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.265262ms
    Aug 27 05:44:25.014: INFO: Pod "webserver-deployment-845c8977d9-jsfs9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.441354ms
    Aug 27 05:44:27.025: INFO: Pod "webserver-deployment-845c8977d9-w7kgx": Phase="Running", Reason="", readiness=true. Elapsed: 2.020067868s
    Aug 27 05:44:27.025: INFO: Pod "webserver-deployment-845c8977d9-w7kgx" satisfied condition "running"
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-gb74s": Phase="Running", Reason="", readiness=true. Elapsed: 2.042298203s
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-gb74s" satisfied condition "running"
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-jsfs9": Phase="Running", Reason="", readiness=true. Elapsed: 2.042311426s
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-jsfs9" satisfied condition "running"
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-k5vxl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04218004s
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-hmzg5": Phase="Running", Reason="", readiness=true. Elapsed: 2.042198477s
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-hmzg5" satisfied condition "running"
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-2fr9k": Phase="Running", Reason="", readiness=true. Elapsed: 2.042632192s
    Aug 27 05:44:27.048: INFO: Pod "webserver-deployment-845c8977d9-2fr9k" satisfied condition "running"
    Aug 27 05:44:27.047: INFO: Pod "webserver-deployment-845c8977d9-glwrc": Phase="Running", Reason="", readiness=true. Elapsed: 2.042636751s
    Aug 27 05:44:27.048: INFO: Pod "webserver-deployment-845c8977d9-glwrc" satisfied condition "running"
    Aug 27 05:44:27.048: INFO: Pod "webserver-deployment-845c8977d9-7xqf9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042623846s
    Aug 27 05:44:27.049: INFO: Pod "webserver-deployment-845c8977d9-mq9xx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043553415s
    Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-7xqf9": Phase="Running", Reason="", readiness=true. Elapsed: 4.01336326s
    Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-7xqf9" satisfied condition "running"
    Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-mq9xx": Phase="Running", Reason="", readiness=true. Elapsed: 4.012961885s
    Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-mq9xx" satisfied condition "running"
    Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-k5vxl": Phase="Running", Reason="", readiness=true. Elapsed: 4.013061917s
    Aug 27 05:44:29.018: INFO: Pod "webserver-deployment-845c8977d9-k5vxl" satisfied condition "running"
    Aug 27 05:44:29.018: INFO: Waiting for deployment "webserver-deployment" to complete
    Aug 27 05:44:29.025: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Aug 27 05:44:29.034: INFO: Updating deployment webserver-deployment
    Aug 27 05:44:29.034: INFO: Waiting for observed generation 2
    Aug 27 05:44:31.042: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Aug 27 05:44:31.056: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Aug 27 05:44:31.069: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Aug 27 05:44:31.088: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Aug 27 05:44:31.088: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Aug 27 05:44:31.093: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Aug 27 05:44:31.100: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Aug 27 05:44:31.100: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Aug 27 05:44:31.120: INFO: Updating deployment webserver-deployment
    Aug 27 05:44:31.121: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Aug 27 05:44:31.129: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Aug 27 05:44:31.139: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 05:44:31.183: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-5022  1d7ef620-0a96-4931-8bc7-780836846a1b 4532 3 2022-08-27 05:44:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003698428 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-08-27 05:44:29 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-27 05:44:31 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Aug 27 05:44:31.239: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-5022  b78097ec-032f-4527-a16f-5d1ffff821f9 4529 3 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1d7ef620-0a96-4931-8bc7-780836846a1b 0xc003698857 0xc003698858}] [] [{kube-controller-manager Update apps/v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1d7ef620-0a96-4931-8bc7-780836846a1b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036988f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 05:44:31.239: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Aug 27 05:44:31.239: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-5022  b7148a63-880c-4432-b955-ce4da80ff6e5 4528 3 2022-08-27 05:44:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1d7ef620-0a96-4931-8bc7-780836846a1b 0xc003698957 0xc003698958}] [] [{kube-controller-manager Update apps/v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1d7ef620-0a96-4931-8bc7-780836846a1b\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036989e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 05:44:31.309: INFO: Pod "webserver-deployment-69b7448995-2jqm5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2jqm5 webserver-deployment-69b7448995- deployment-5022  c843950d-29f1-4180-9826-ec1c4a366011 4554 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003698f00 0xc003698f01}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mg5vl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mg5vl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.311: INFO: Pod "webserver-deployment-69b7448995-4hftw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-4hftw webserver-deployment-69b7448995- deployment-5022  7bb1f1fd-6227-4786-a10e-9754025f8d25 4522 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:e2d9fbdebbf8ecbf6a514e75c732092b2c3716ed26ff59831d317318ee63d705 cni.projectcalico.org/podIP:10.2.137.24/32 cni.projectcalico.org/podIPs:10.2.137.24/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699090 0xc003699091}] [] [{Go-http-client Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d7hf6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d7hf6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.24,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.312: INFO: Pod "webserver-deployment-69b7448995-7r55c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7r55c webserver-deployment-69b7448995- deployment-5022  509c2616-e09b-4f66-bf49-60470d96ed0e 4559 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc0036992c0 0xc0036992c1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dk2j4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dk2j4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.315: INFO: Pod "webserver-deployment-69b7448995-d27z6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-d27z6 webserver-deployment-69b7448995- deployment-5022  cef07484-f42e-4535-9158-a01eb78b887b 4503 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0194bfff7e8870bf8f1ea1e62a97e7dfb1f4217b3a8003c1d2d008af1e816d9a cni.projectcalico.org/podIP:10.2.35.43/32 cni.projectcalico.org/podIPs:10.2.35.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699437 0xc003699438}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-08-27 05:44:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-krg8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-krg8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.315: INFO: Pod "webserver-deployment-69b7448995-gzws4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-gzws4 webserver-deployment-69b7448995- deployment-5022  dcb1da27-aa10-4f4e-abcb-136391537f90 4552 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699640 0xc003699641}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fxr9c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fxr9c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.317: INFO: Pod "webserver-deployment-69b7448995-nrqff" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-nrqff webserver-deployment-69b7448995- deployment-5022  e1c639b3-5576-4013-bcfe-a0e82a845b65 4560 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699787 0xc003699788}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s4vqw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s4vqw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.321: INFO: Pod "webserver-deployment-69b7448995-qxkrk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qxkrk webserver-deployment-69b7448995- deployment-5022  bab0f3f5-7cf6-4b37-ae6b-0a66baa3a15b 4510 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5e0071723e50c35796e03d35fca7e6ff3366a0a8cf7f7d9fdbeedc53d55ec8e7 cni.projectcalico.org/podIP:10.2.35.44/32 cni.projectcalico.org/podIPs:10.2.35.44/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc0036998f7 0xc0036998f8}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svvm9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svvm9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.322: INFO: Pod "webserver-deployment-69b7448995-v5xm9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-v5xm9 webserver-deployment-69b7448995- deployment-5022  451c83a9-775c-4cc4-8ecf-60ec8bdf53c7 4541 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699b00 0xc003699b01}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6jlr8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6jlr8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.323: INFO: Pod "webserver-deployment-69b7448995-wfds7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wfds7 webserver-deployment-69b7448995- deployment-5022  e7b49e0e-b0bc-4b52-9030-e64f8315bf64 4556 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699c70 0xc003699c71}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mgm6r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mgm6r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.326: INFO: Pod "webserver-deployment-69b7448995-wsw8w" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wsw8w webserver-deployment-69b7448995- deployment-5022  801fc0cf-6773-4796-9ceb-6bfc9ac3ec00 4491 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9293d7370c757bfdf449bd474272b4e2a5df2e35dd072f508dccb8cd777d6fa3 cni.projectcalico.org/podIP:10.2.35.42/32 cni.projectcalico.org/podIPs:10.2.35.42/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc003699e00 0xc003699e01}] [] [{Go-http-client Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dc95f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dc95f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.326: INFO: Pod "webserver-deployment-69b7448995-x9fdf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-x9fdf webserver-deployment-69b7448995- deployment-5022  1b54deaa-6cc5-42c9-89df-7fe00e4bacfe 4561 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc002f76000 0xc002f76001}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9wrnz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9wrnz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.328: INFO: Pod "webserver-deployment-69b7448995-xtjrn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xtjrn webserver-deployment-69b7448995- deployment-5022  04845069-cb6a-4e36-a396-63ffa4ff06e3 4525 0 2022-08-27 05:44:29 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:23a7ddf315acf98091a7730c7c1ef636ec2ecb78847271d29230ac901696a6e1 cni.projectcalico.org/podIP:10.2.137.23/32 cni.projectcalico.org/podIPs:10.2.137.23/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 b78097ec-032f-4527-a16f-5d1ffff821f9 0xc002f76167 0xc002f76168}] [] [{Go-http-client Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b78097ec-032f-4527-a16f-5d1ffff821f9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9b9sj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9b9sj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.23,StartTime:2022-08-27 05:44:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.328: INFO: Pod "webserver-deployment-845c8977d9-2fr9k" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2fr9k webserver-deployment-845c8977d9- deployment-5022  43284c77-1b84-40e7-8149-85b3eb859a63 4369 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:161d3a3265876c7d946fbe5a80b65329c94ebc714d3cfb0bfa67d7ea97328600 cni.projectcalico.org/podIP:10.2.137.22/32 cni.projectcalico.org/podIPs:10.2.137.22/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f763c0 0xc002f763c1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.22\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l6f2c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l6f2c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.22,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://52f10c0aecd56b588bd48c45e2da43379902b74344378e5b2f710b5660bf66de,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.329: INFO: Pod "webserver-deployment-845c8977d9-74rmr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-74rmr webserver-deployment-845c8977d9- deployment-5022  ea37160a-037a-42d6-8573-f86bba4400e0 4557 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f765d0 0xc002f765d1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4gzqc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4gzqc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.329: INFO: Pod "webserver-deployment-845c8977d9-8mj4k" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8mj4k webserver-deployment-845c8977d9- deployment-5022  69b6cda0-6d28-44f2-9386-cd82006faaa5 4328 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5bbff7709cdca711051349a0e04b972ddbc1d8ded4eb9502918ec79043a272b5 cni.projectcalico.org/podIP:10.2.137.18/32 cni.projectcalico.org/podIPs:10.2.137.18/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76750 0xc002f76751}] [] [{Go-http-client Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p69n2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p69n2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.18,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://75bd307050351e01081ed8de91269084bbdd029a66f345205ac67f2724e6e25b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.329: INFO: Pod "webserver-deployment-845c8977d9-bcnhc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bcnhc webserver-deployment-845c8977d9- deployment-5022  b600d0e2-e03c-43ad-9401-d94738142615 4562 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76950 0xc002f76951}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bt92n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bt92n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.330: INFO: Pod "webserver-deployment-845c8977d9-g2jdp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-g2jdp webserver-deployment-845c8977d9- deployment-5022  9592938b-de81-405a-ad41-60c5569bb5e3 4564 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76a87 0xc002f76a88}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l7nmw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l7nmw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.331: INFO: Pod "webserver-deployment-845c8977d9-g52js" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-g52js webserver-deployment-845c8977d9- deployment-5022  b98dec3b-fd3b-42ec-96ad-07a409046364 4551 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76bc7 0xc002f76bc8}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-92dtk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-92dtk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.332: INFO: Pod "webserver-deployment-845c8977d9-gb74s" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gb74s webserver-deployment-845c8977d9- deployment-5022  22ad6b80-24fb-40ca-8b49-3a2fd6870639 4336 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a4c145bc6c8a1ee5d9042136086798f53b9ce7b5d251648995c014a70c1fcd3a cni.projectcalico.org/podIP:10.2.137.19/32 cni.projectcalico.org/podIPs:10.2.137.19/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76d50 0xc002f76d51}] [] [{Go-http-client Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.19\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dmx99,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dmx99,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.19,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2d77af5a75ea8d9f366aea29969dd98808de1889fb48f32b7074ee6f0c264f36,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.19,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.333: INFO: Pod "webserver-deployment-845c8977d9-glwrc" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-glwrc webserver-deployment-845c8977d9- deployment-5022  5c44858d-815e-4e84-b686-cd4d94f17bb4 4399 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f2082714765e91d0192021fbed3bac3cbc449d9d4acc72d16156320f7fe065f6 cni.projectcalico.org/podIP:10.2.35.41/32 cni.projectcalico.org/podIPs:10.2.35.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f76f70 0xc002f76f71}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ncps8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ncps8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.41,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://91dfa4b9b75efa01d0ea75fbb00803f769bfd1bc7f6957bef94d3b8bb7f34cdb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.339: INFO: Pod "webserver-deployment-845c8977d9-gr88w" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gr88w webserver-deployment-845c8977d9- deployment-5022  e3cfbe49-0073-467b-bf16-d26b1157f7ae 4563 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77180 0xc002f77181}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kdfj4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kdfj4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.352: INFO: Pod "webserver-deployment-845c8977d9-jsfs9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-jsfs9 webserver-deployment-845c8977d9- deployment-5022  4d87cd64-eabb-49e2-bac8-c69168efee28 4389 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e2e944e634cd133a327c245303aa5d5d0f794f45878a604ada2c72a3540d9265 cni.projectcalico.org/podIP:10.2.137.21/32 cni.projectcalico.org/podIPs:10.2.137.21/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f772d7 0xc002f772d8}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bslsv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bslsv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.21,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5d0c665aaccaa502dd3df0bbdf941677029a913d55dac4d3bde59be550a09b33,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.357: INFO: Pod "webserver-deployment-845c8977d9-k5vxl" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-k5vxl webserver-deployment-845c8977d9- deployment-5022  50d644c7-4333-487e-b438-3d54619e0848 4409 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:0713012108bf1cd006db16a6ee9989a377e89831f57ed47490efc06eef1addf9 cni.projectcalico.org/podIP:10.2.35.37/32 cni.projectcalico.org/podIPs:10.2.35.37/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77500 0xc002f77501}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sp8f2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sp8f2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.37,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1a6da6ee3c0384a5c943f4ae5d708ff94fbf43fab2deb279a4746de8654f1005,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.357: INFO: Pod "webserver-deployment-845c8977d9-kttvd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kttvd webserver-deployment-845c8977d9- deployment-5022  10e599a3-f586-4a20-8bbb-c04d862e02f6 4565 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77710 0xc002f77711}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lrfjj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lrfjj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.359: INFO: Pod "webserver-deployment-845c8977d9-mq9xx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mq9xx webserver-deployment-845c8977d9- deployment-5022  f7dbca5c-1f2b-4c1e-9335-d10a6ccd26f3 4402 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fca1959416751284a93375bb94d924deee2c0e00d36b7d33b1e95050ed8229b4 cni.projectcalico.org/podIP:10.2.35.39/32 cni.projectcalico.org/podIPs:10.2.35.39/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77867 0xc002f77868}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5d2sf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5d2sf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.39,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7e482c9cb475c5ecad08015b01ebc1d5f25f052fab484a04e011a0b6884baa04,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.360: INFO: Pod "webserver-deployment-845c8977d9-n7mp7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-n7mp7 webserver-deployment-845c8977d9- deployment-5022  aa834eec-471f-47f4-999b-a9043746b1bf 4549 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77a70 0xc002f77a71}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mlkxb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mlkxb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.361: INFO: Pod "webserver-deployment-845c8977d9-sbrxb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-sbrxb webserver-deployment-845c8977d9- deployment-5022  c844c355-c040-409e-b286-f5778561d9a8 4539 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77bd0 0xc002f77bd1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cvjsd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cvjsd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.364: INFO: Pod "webserver-deployment-845c8977d9-spwzg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-spwzg webserver-deployment-845c8977d9- deployment-5022  871a9ed3-80de-4a06-9034-ec22a5414ff9 4555 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77d30 0xc002f77d31}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vp27h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vp27h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.364: INFO: Pod "webserver-deployment-845c8977d9-tnz5p" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tnz5p webserver-deployment-845c8977d9- deployment-5022  9f55b778-5e6e-4e91-99fa-5a0b9c4c782d 4548 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77e90 0xc002f77e91}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sr7ck,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sr7ck,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.366: INFO: Pod "webserver-deployment-845c8977d9-tw7v8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tw7v8 webserver-deployment-845c8977d9- deployment-5022  de19b518-42ff-4553-bfb2-9cefefb74e8d 4553 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f77ff0 0xc002f77ff1}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjp74,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjp74,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.366: INFO: Pod "webserver-deployment-845c8977d9-w7kgx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-w7kgx webserver-deployment-845c8977d9- deployment-5022  2c014a5d-bf43-4669-b123-2a6e53e41035 4352 0 2022-08-27 05:44:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f21441e55a27305bc349c74c63935875cba710f86d85f4dff057d429f97de165 cni.projectcalico.org/podIP:10.2.137.20/32 cni.projectcalico.org/podIPs:10.2.137.20/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f9a170 0xc002f9a171}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 05:44:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 05:44:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s6gbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s6gbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 05:44:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.20,StartTime:2022-08-27 05:44:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 05:44:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a1348b73f363ace791265c84447724b92c5eaef75b8d53b8053620441fd2cdfa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 05:44:31.367: INFO: Pod "webserver-deployment-845c8977d9-z2wd7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-z2wd7 webserver-deployment-845c8977d9- deployment-5022  a0725602-3d34-4d4a-991f-5c56f6b9569d 4558 0 2022-08-27 05:44:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 b7148a63-880c-4432-b955-ce4da80ff6e5 0xc002f9a380 0xc002f9a381}] [] [{kube-controller-manager Update v1 2022-08-27 05:44:31 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7148a63-880c-4432-b955-ce4da80ff6e5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l8nw2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l8nw2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 05:44:31.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5022" for this suite. 08/27/22 05:44:31.382
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:31.405
Aug 27 05:44:31.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename disruption 08/27/22 05:44:31.41
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:31.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:31.462
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 08/27/22 05:44:31.466
STEP: Waiting for the pdb to be processed 08/27/22 05:44:31.474
STEP: updating the pdb 08/27/22 05:44:33.482
STEP: Waiting for the pdb to be processed 08/27/22 05:44:33.488
STEP: patching the pdb 08/27/22 05:44:35.504
STEP: Waiting for the pdb to be processed 08/27/22 05:44:35.519
STEP: Waiting for the pdb to be deleted 08/27/22 05:44:37.543
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 27 05:44:37.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8328" for this suite. 08/27/22 05:44:37.572
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":42,"skipped":824,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.187 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:31.405
    Aug 27 05:44:31.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename disruption 08/27/22 05:44:31.41
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:31.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:31.462
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 08/27/22 05:44:31.466
    STEP: Waiting for the pdb to be processed 08/27/22 05:44:31.474
    STEP: updating the pdb 08/27/22 05:44:33.482
    STEP: Waiting for the pdb to be processed 08/27/22 05:44:33.488
    STEP: patching the pdb 08/27/22 05:44:35.504
    STEP: Waiting for the pdb to be processed 08/27/22 05:44:35.519
    STEP: Waiting for the pdb to be deleted 08/27/22 05:44:37.543
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 27 05:44:37.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8328" for this suite. 08/27/22 05:44:37.572
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:37.593
Aug 27 05:44:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename namespaces 08/27/22 05:44:37.597
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:37.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:37.675
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 08/27/22 05:44:37.696
STEP: patching the Namespace 08/27/22 05:44:37.726
STEP: get the Namespace and ensuring it has the label 08/27/22 05:44:37.734
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:44:37.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2130" for this suite. 08/27/22 05:44:37.746
STEP: Destroying namespace "nspatchtest-79de1b22-abd0-4702-8ac4-e631956266da-929" for this suite. 08/27/22 05:44:37.751
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":43,"skipped":827,"failed":0}
------------------------------
â€¢ [0.180 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:37.593
    Aug 27 05:44:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename namespaces 08/27/22 05:44:37.597
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:37.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:37.675
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 08/27/22 05:44:37.696
    STEP: patching the Namespace 08/27/22 05:44:37.726
    STEP: get the Namespace and ensuring it has the label 08/27/22 05:44:37.734
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:44:37.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2130" for this suite. 08/27/22 05:44:37.746
    STEP: Destroying namespace "nspatchtest-79de1b22-abd0-4702-8ac4-e631956266da-929" for this suite. 08/27/22 05:44:37.751
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:37.881
Aug 27 05:44:37.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 05:44:37.884
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:37.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:37.949
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 08/27/22 05:44:37.954
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 08/27/22 05:44:37.965
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 08/27/22 05:44:37.965
STEP: fetching the /apis/apiextensions.k8s.io discovery document 08/27/22 05:44:37.965
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 08/27/22 05:44:37.967
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 08/27/22 05:44:37.967
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 08/27/22 05:44:37.97
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:44:37.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2133" for this suite. 08/27/22 05:44:37.974
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":44,"skipped":870,"failed":0}
------------------------------
â€¢ [0.099 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:37.881
    Aug 27 05:44:37.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 05:44:37.884
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:37.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:37.949
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 08/27/22 05:44:37.954
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 08/27/22 05:44:37.965
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 08/27/22 05:44:37.965
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 08/27/22 05:44:37.965
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 08/27/22 05:44:37.967
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 08/27/22 05:44:37.967
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 08/27/22 05:44:37.97
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:44:37.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2133" for this suite. 08/27/22 05:44:37.974
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:44:37.981
Aug 27 05:44:37.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pod-network-test 08/27/22 05:44:37.982
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:38.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:38.051
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-4357 08/27/22 05:44:38.058
STEP: creating a selector 08/27/22 05:44:38.058
STEP: Creating the service pods in kubernetes 08/27/22 05:44:38.058
Aug 27 05:44:38.058: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 05:44:38.103: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4357" to be "running and ready"
Aug 27 05:44:38.120: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.838628ms
Aug 27 05:44:38.120: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:44:40.124: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02147683s
Aug 27 05:44:40.124: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:44:42.124: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.021295114s
Aug 27 05:44:42.124: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:44:44.124: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.020873762s
Aug 27 05:44:44.124: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:44:46.125: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.022027151s
Aug 27 05:44:46.125: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:44:48.125: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021909672s
Aug 27 05:44:48.125: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 05:44:50.124: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.020958603s
Aug 27 05:44:50.124: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 27 05:44:50.124: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 27 05:44:50.130: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4357" to be "running and ready"
Aug 27 05:44:50.133: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 3.51372ms
Aug 27 05:44:50.133: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 27 05:44:52.138: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.007988231s
Aug 27 05:44:52.138: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 27 05:44:54.137: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.007340673s
Aug 27 05:44:54.137: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 27 05:44:56.138: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.008081862s
Aug 27 05:44:56.138: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 27 05:44:58.138: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.00792433s
Aug 27 05:44:58.138: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Aug 27 05:45:00.137: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.007671982s
Aug 27 05:45:00.137: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 27 05:45:00.137: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 08/27/22 05:45:00.142
Aug 27 05:45:00.173: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4357" to be "running"
Aug 27 05:45:00.190: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.724546ms
Aug 27 05:45:02.195: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022369763s
Aug 27 05:45:02.195: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 27 05:45:02.203: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug 27 05:45:02.203: INFO: Breadth first check of 10.2.137.25 on host 10.0.31.158...
Aug 27 05:45:02.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.46:9080/dial?request=hostname&protocol=http&host=10.2.137.25&port=8083&tries=1'] Namespace:pod-network-test-4357 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:45:02.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:45:02.214: INFO: ExecWithOptions: Clientset creation
Aug 27 05:45:02.215: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4357/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.46%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.2.137.25%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 27 05:45:02.329: INFO: Waiting for responses: map[]
Aug 27 05:45:02.329: INFO: reached 10.2.137.25 after 0/1 tries
Aug 27 05:45:02.329: INFO: Breadth first check of 10.2.35.45 on host 10.0.47.192...
Aug 27 05:45:02.333: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.46:9080/dial?request=hostname&protocol=http&host=10.2.35.45&port=8083&tries=1'] Namespace:pod-network-test-4357 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:45:02.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:45:02.334: INFO: ExecWithOptions: Clientset creation
Aug 27 05:45:02.334: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4357/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.46%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.2.35.45%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Aug 27 05:45:02.443: INFO: Waiting for responses: map[]
Aug 27 05:45:02.443: INFO: reached 10.2.35.45 after 0/1 tries
Aug 27 05:45:02.443: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 27 05:45:02.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4357" for this suite. 08/27/22 05:45:02.448
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":45,"skipped":877,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.474 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:44:37.981
    Aug 27 05:44:37.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pod-network-test 08/27/22 05:44:37.982
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:44:38.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:44:38.051
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-4357 08/27/22 05:44:38.058
    STEP: creating a selector 08/27/22 05:44:38.058
    STEP: Creating the service pods in kubernetes 08/27/22 05:44:38.058
    Aug 27 05:44:38.058: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 27 05:44:38.103: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4357" to be "running and ready"
    Aug 27 05:44:38.120: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.838628ms
    Aug 27 05:44:38.120: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:44:40.124: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02147683s
    Aug 27 05:44:40.124: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:44:42.124: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.021295114s
    Aug 27 05:44:42.124: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:44:44.124: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.020873762s
    Aug 27 05:44:44.124: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:44:46.125: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.022027151s
    Aug 27 05:44:46.125: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:44:48.125: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021909672s
    Aug 27 05:44:48.125: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 05:44:50.124: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.020958603s
    Aug 27 05:44:50.124: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 27 05:44:50.124: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 27 05:44:50.130: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4357" to be "running and ready"
    Aug 27 05:44:50.133: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 3.51372ms
    Aug 27 05:44:50.133: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 27 05:44:52.138: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.007988231s
    Aug 27 05:44:52.138: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 27 05:44:54.137: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.007340673s
    Aug 27 05:44:54.137: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 27 05:44:56.138: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.008081862s
    Aug 27 05:44:56.138: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 27 05:44:58.138: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.00792433s
    Aug 27 05:44:58.138: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Aug 27 05:45:00.137: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.007671982s
    Aug 27 05:45:00.137: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 27 05:45:00.137: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 08/27/22 05:45:00.142
    Aug 27 05:45:00.173: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4357" to be "running"
    Aug 27 05:45:00.190: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.724546ms
    Aug 27 05:45:02.195: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022369763s
    Aug 27 05:45:02.195: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 27 05:45:02.203: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Aug 27 05:45:02.203: INFO: Breadth first check of 10.2.137.25 on host 10.0.31.158...
    Aug 27 05:45:02.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.46:9080/dial?request=hostname&protocol=http&host=10.2.137.25&port=8083&tries=1'] Namespace:pod-network-test-4357 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:45:02.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:45:02.214: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:45:02.215: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4357/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.46%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.2.137.25%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 27 05:45:02.329: INFO: Waiting for responses: map[]
    Aug 27 05:45:02.329: INFO: reached 10.2.137.25 after 0/1 tries
    Aug 27 05:45:02.329: INFO: Breadth first check of 10.2.35.45 on host 10.0.47.192...
    Aug 27 05:45:02.333: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.35.46:9080/dial?request=hostname&protocol=http&host=10.2.35.45&port=8083&tries=1'] Namespace:pod-network-test-4357 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:45:02.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:45:02.334: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:45:02.334: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4357/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.2.35.46%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.2.35.45%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Aug 27 05:45:02.443: INFO: Waiting for responses: map[]
    Aug 27 05:45:02.443: INFO: reached 10.2.35.45 after 0/1 tries
    Aug 27 05:45:02.443: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 27 05:45:02.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4357" for this suite. 08/27/22 05:45:02.448
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:45:02.457
Aug 27 05:45:02.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 05:45:02.458
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:45:02.491
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:45:02.496
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 08/27/22 05:45:02.503
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_udp@PTR;check="$$(dig +tcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_tcp@PTR;sleep 1; done
 08/27/22 05:45:02.57
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_udp@PTR;check="$$(dig +tcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_tcp@PTR;sleep 1; done
 08/27/22 05:45:02.57
STEP: creating a pod to probe DNS 08/27/22 05:45:02.57
STEP: submitting the pod to kubernetes 08/27/22 05:45:02.57
Aug 27 05:45:02.597: INFO: Waiting up to 15m0s for pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4" in namespace "dns-2566" to be "running"
Aug 27 05:45:02.603: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.081471ms
Aug 27 05:45:04.608: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010628057s
Aug 27 05:45:06.608: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010418962s
Aug 27 05:45:08.611: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013261227s
Aug 27 05:45:10.621: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023306973s
Aug 27 05:45:12.607: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Running", Reason="", readiness=true. Elapsed: 10.009888438s
Aug 27 05:45:12.608: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4" satisfied condition "running"
STEP: retrieving the pod 08/27/22 05:45:12.608
STEP: looking for the results for each expected name from probers 08/27/22 05:45:12.612
Aug 27 05:45:12.620: INFO: Unable to read wheezy_udp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.624: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.629: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.634: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.659: INFO: Unable to read jessie_udp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.663: INFO: Unable to read jessie_tcp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.670: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.675: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
Aug 27 05:45:12.691: INFO: Lookups using dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4 failed for: [wheezy_udp@dns-test-service.dns-2566.svc.cluster.local wheezy_tcp@dns-test-service.dns-2566.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local jessie_udp@dns-test-service.dns-2566.svc.cluster.local jessie_tcp@dns-test-service.dns-2566.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local]

Aug 27 05:45:17.757: INFO: DNS probes using dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4 succeeded

STEP: deleting the pod 08/27/22 05:45:17.757
STEP: deleting the test service 08/27/22 05:45:17.772
STEP: deleting the test headless service 08/27/22 05:45:17.834
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 05:45:17.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2566" for this suite. 08/27/22 05:45:17.867
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":46,"skipped":878,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.419 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:45:02.457
    Aug 27 05:45:02.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 05:45:02.458
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:45:02.491
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:45:02.496
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 08/27/22 05:45:02.503
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_udp@PTR;check="$$(dig +tcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_tcp@PTR;sleep 1; done
     08/27/22 05:45:02.57
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2566.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2566.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2566.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_udp@PTR;check="$$(dig +tcp +noall +answer +search 216.30.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.30.216_tcp@PTR;sleep 1; done
     08/27/22 05:45:02.57
    STEP: creating a pod to probe DNS 08/27/22 05:45:02.57
    STEP: submitting the pod to kubernetes 08/27/22 05:45:02.57
    Aug 27 05:45:02.597: INFO: Waiting up to 15m0s for pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4" in namespace "dns-2566" to be "running"
    Aug 27 05:45:02.603: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.081471ms
    Aug 27 05:45:04.608: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010628057s
    Aug 27 05:45:06.608: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010418962s
    Aug 27 05:45:08.611: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013261227s
    Aug 27 05:45:10.621: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023306973s
    Aug 27 05:45:12.607: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4": Phase="Running", Reason="", readiness=true. Elapsed: 10.009888438s
    Aug 27 05:45:12.608: INFO: Pod "dns-test-c3c553f3-b311-4975-874e-66c48700bed4" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 05:45:12.608
    STEP: looking for the results for each expected name from probers 08/27/22 05:45:12.612
    Aug 27 05:45:12.620: INFO: Unable to read wheezy_udp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.624: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.629: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.634: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.659: INFO: Unable to read jessie_udp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.663: INFO: Unable to read jessie_tcp@dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.670: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.675: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local from pod dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4: the server could not find the requested resource (get pods dns-test-c3c553f3-b311-4975-874e-66c48700bed4)
    Aug 27 05:45:12.691: INFO: Lookups using dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4 failed for: [wheezy_udp@dns-test-service.dns-2566.svc.cluster.local wheezy_tcp@dns-test-service.dns-2566.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local jessie_udp@dns-test-service.dns-2566.svc.cluster.local jessie_tcp@dns-test-service.dns-2566.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2566.svc.cluster.local]

    Aug 27 05:45:17.757: INFO: DNS probes using dns-2566/dns-test-c3c553f3-b311-4975-874e-66c48700bed4 succeeded

    STEP: deleting the pod 08/27/22 05:45:17.757
    STEP: deleting the test service 08/27/22 05:45:17.772
    STEP: deleting the test headless service 08/27/22 05:45:17.834
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 05:45:17.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2566" for this suite. 08/27/22 05:45:17.867
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:45:17.878
Aug 27 05:45:17.878: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 05:45:17.879
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:45:17.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:45:17.901
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 08/27/22 05:45:17.906
Aug 27 05:45:17.913: INFO: Waiting up to 5m0s for pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6" in namespace "emptydir-3868" to be "Succeeded or Failed"
Aug 27 05:45:17.917: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.07234ms
Aug 27 05:45:19.920: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006385946s
Aug 27 05:45:21.921: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007518605s
STEP: Saw pod success 08/27/22 05:45:21.921
Aug 27 05:45:21.922: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6" satisfied condition "Succeeded or Failed"
Aug 27 05:45:21.924: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-948f2d4f-3737-47de-9241-4ce98c60a2c6 container test-container: <nil>
STEP: delete the pod 08/27/22 05:45:21.94
Aug 27 05:45:21.947: INFO: Waiting for pod pod-948f2d4f-3737-47de-9241-4ce98c60a2c6 to disappear
Aug 27 05:45:21.949: INFO: Pod pod-948f2d4f-3737-47de-9241-4ce98c60a2c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 05:45:21.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3868" for this suite. 08/27/22 05:45:21.952
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":47,"skipped":888,"failed":0}
------------------------------
â€¢ [4.079 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:45:17.878
    Aug 27 05:45:17.878: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 05:45:17.879
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:45:17.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:45:17.901
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 08/27/22 05:45:17.906
    Aug 27 05:45:17.913: INFO: Waiting up to 5m0s for pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6" in namespace "emptydir-3868" to be "Succeeded or Failed"
    Aug 27 05:45:17.917: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.07234ms
    Aug 27 05:45:19.920: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006385946s
    Aug 27 05:45:21.921: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007518605s
    STEP: Saw pod success 08/27/22 05:45:21.921
    Aug 27 05:45:21.922: INFO: Pod "pod-948f2d4f-3737-47de-9241-4ce98c60a2c6" satisfied condition "Succeeded or Failed"
    Aug 27 05:45:21.924: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-948f2d4f-3737-47de-9241-4ce98c60a2c6 container test-container: <nil>
    STEP: delete the pod 08/27/22 05:45:21.94
    Aug 27 05:45:21.947: INFO: Waiting for pod pod-948f2d4f-3737-47de-9241-4ce98c60a2c6 to disappear
    Aug 27 05:45:21.949: INFO: Pod pod-948f2d4f-3737-47de-9241-4ce98c60a2c6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 05:45:21.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3868" for this suite. 08/27/22 05:45:21.952
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:45:21.961
Aug 27 05:45:21.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-preemption 08/27/22 05:45:21.962
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:45:21.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:45:21.981
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 27 05:45:21.994: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 05:46:22.017: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 08/27/22 05:46:22.02
Aug 27 05:46:22.043: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 27 05:46:22.052: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 27 05:46:22.093: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 27 05:46:22.099: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 08/27/22 05:46:22.099
Aug 27 05:46:22.099: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4935" to be "running"
Aug 27 05:46:22.108: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.934688ms
Aug 27 05:46:24.112: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013080957s
Aug 27 05:46:26.117: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.018132098s
Aug 27 05:46:26.118: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Aug 27 05:46:26.118: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4935" to be "running"
Aug 27 05:46:26.122: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.162043ms
Aug 27 05:46:26.122: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 27 05:46:26.122: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4935" to be "running"
Aug 27 05:46:26.126: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.725187ms
Aug 27 05:46:26.126: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 27 05:46:26.126: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4935" to be "running"
Aug 27 05:46:26.129: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.285928ms
Aug 27 05:46:26.129: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 08/27/22 05:46:26.129
Aug 27 05:46:26.135: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4935" to be "running"
Aug 27 05:46:26.140: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.465411ms
Aug 27 05:46:28.144: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009345106s
Aug 27 05:46:30.144: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008490456s
Aug 27 05:46:32.150: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.014863298s
Aug 27 05:46:32.150: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:46:32.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4935" for this suite. 08/27/22 05:46:32.176
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":48,"skipped":945,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.269 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:45:21.961
    Aug 27 05:45:21.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-preemption 08/27/22 05:45:21.962
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:45:21.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:45:21.981
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 27 05:45:21.994: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 27 05:46:22.017: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 08/27/22 05:46:22.02
    Aug 27 05:46:22.043: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Aug 27 05:46:22.052: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Aug 27 05:46:22.093: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Aug 27 05:46:22.099: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 08/27/22 05:46:22.099
    Aug 27 05:46:22.099: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4935" to be "running"
    Aug 27 05:46:22.108: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.934688ms
    Aug 27 05:46:24.112: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013080957s
    Aug 27 05:46:26.117: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.018132098s
    Aug 27 05:46:26.118: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Aug 27 05:46:26.118: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4935" to be "running"
    Aug 27 05:46:26.122: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.162043ms
    Aug 27 05:46:26.122: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 27 05:46:26.122: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4935" to be "running"
    Aug 27 05:46:26.126: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.725187ms
    Aug 27 05:46:26.126: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 27 05:46:26.126: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4935" to be "running"
    Aug 27 05:46:26.129: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.285928ms
    Aug 27 05:46:26.129: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 08/27/22 05:46:26.129
    Aug 27 05:46:26.135: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4935" to be "running"
    Aug 27 05:46:26.140: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.465411ms
    Aug 27 05:46:28.144: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009345106s
    Aug 27 05:46:30.144: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008490456s
    Aug 27 05:46:32.150: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.014863298s
    Aug 27 05:46:32.150: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:46:32.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4935" for this suite. 08/27/22 05:46:32.176
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:46:32.231
Aug 27 05:46:32.231: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 05:46:32.233
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:46:32.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:46:32.27
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Aug 27 05:46:32.336: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b835f7c7-9e9c-4b16-a13a-480aad71c607", Controller:(*bool)(0xc0037bf0a6), BlockOwnerDeletion:(*bool)(0xc0037bf0a7)}}
Aug 27 05:46:32.357: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0ccb0d96-71f4-4b6e-b0e7-3d6c48e9aca5", Controller:(*bool)(0xc003be7076), BlockOwnerDeletion:(*bool)(0xc003be7077)}}
Aug 27 05:46:32.410: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"eb201c65-9e8a-485f-86fd-df2ebde0d20b", Controller:(*bool)(0xc0037bf30e), BlockOwnerDeletion:(*bool)(0xc0037bf30f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 05:46:37.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-540" for this suite. 08/27/22 05:46:37.499
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":49,"skipped":983,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.293 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:46:32.231
    Aug 27 05:46:32.231: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 05:46:32.233
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:46:32.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:46:32.27
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Aug 27 05:46:32.336: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b835f7c7-9e9c-4b16-a13a-480aad71c607", Controller:(*bool)(0xc0037bf0a6), BlockOwnerDeletion:(*bool)(0xc0037bf0a7)}}
    Aug 27 05:46:32.357: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0ccb0d96-71f4-4b6e-b0e7-3d6c48e9aca5", Controller:(*bool)(0xc003be7076), BlockOwnerDeletion:(*bool)(0xc003be7077)}}
    Aug 27 05:46:32.410: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"eb201c65-9e8a-485f-86fd-df2ebde0d20b", Controller:(*bool)(0xc0037bf30e), BlockOwnerDeletion:(*bool)(0xc0037bf30f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 05:46:37.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-540" for this suite. 08/27/22 05:46:37.499
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:46:37.555
Aug 27 05:46:37.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:46:37.557
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:46:37.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:46:37.633
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-24ebd472-9875-4dcd-8d88-a4940126f1b9 08/27/22 05:46:37.677
STEP: Creating configMap with name cm-test-opt-upd-e9cf9c0e-af75-4de7-9cc8-c30e4b2361b6 08/27/22 05:46:37.688
STEP: Creating the pod 08/27/22 05:46:37.708
Aug 27 05:46:37.723: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a" in namespace "projected-8454" to be "running and ready"
Aug 27 05:46:37.741: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.771692ms
Aug 27 05:46:37.741: INFO: The phase of Pod pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:46:39.745: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022262538s
Aug 27 05:46:39.746: INFO: The phase of Pod pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:46:41.745: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a": Phase="Running", Reason="", readiness=true. Elapsed: 4.021710826s
Aug 27 05:46:41.745: INFO: The phase of Pod pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a is Running (Ready = true)
Aug 27 05:46:41.745: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-24ebd472-9875-4dcd-8d88-a4940126f1b9 08/27/22 05:46:41.765
STEP: Updating configmap cm-test-opt-upd-e9cf9c0e-af75-4de7-9cc8-c30e4b2361b6 08/27/22 05:46:41.771
STEP: Creating configMap with name cm-test-opt-create-6d563791-05ad-415d-8a81-4102d19d0481 08/27/22 05:46:41.775
STEP: waiting to observe update in volume 08/27/22 05:46:41.78
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 05:48:08.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8454" for this suite. 08/27/22 05:48:08.2
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":50,"skipped":1015,"failed":0}
------------------------------
â€¢ [SLOW TEST] [90.654 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:46:37.555
    Aug 27 05:46:37.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:46:37.557
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:46:37.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:46:37.633
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-24ebd472-9875-4dcd-8d88-a4940126f1b9 08/27/22 05:46:37.677
    STEP: Creating configMap with name cm-test-opt-upd-e9cf9c0e-af75-4de7-9cc8-c30e4b2361b6 08/27/22 05:46:37.688
    STEP: Creating the pod 08/27/22 05:46:37.708
    Aug 27 05:46:37.723: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a" in namespace "projected-8454" to be "running and ready"
    Aug 27 05:46:37.741: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.771692ms
    Aug 27 05:46:37.741: INFO: The phase of Pod pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:46:39.745: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022262538s
    Aug 27 05:46:39.746: INFO: The phase of Pod pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:46:41.745: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a": Phase="Running", Reason="", readiness=true. Elapsed: 4.021710826s
    Aug 27 05:46:41.745: INFO: The phase of Pod pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a is Running (Ready = true)
    Aug 27 05:46:41.745: INFO: Pod "pod-projected-configmaps-912b7ee0-3d71-4f7b-bb4a-09e557928c9a" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-24ebd472-9875-4dcd-8d88-a4940126f1b9 08/27/22 05:46:41.765
    STEP: Updating configmap cm-test-opt-upd-e9cf9c0e-af75-4de7-9cc8-c30e4b2361b6 08/27/22 05:46:41.771
    STEP: Creating configMap with name cm-test-opt-create-6d563791-05ad-415d-8a81-4102d19d0481 08/27/22 05:46:41.775
    STEP: waiting to observe update in volume 08/27/22 05:46:41.78
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 05:48:08.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8454" for this suite. 08/27/22 05:48:08.2
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:48:08.21
Aug 27 05:48:08.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename init-container 08/27/22 05:48:08.211
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:08.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:08.248
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 08/27/22 05:48:08.251
Aug 27 05:48:08.251: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 05:48:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3183" for this suite. 08/27/22 05:48:13.702
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":51,"skipped":1016,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.503 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:48:08.21
    Aug 27 05:48:08.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename init-container 08/27/22 05:48:08.211
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:08.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:08.248
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 08/27/22 05:48:08.251
    Aug 27 05:48:08.251: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 05:48:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-3183" for this suite. 08/27/22 05:48:13.702
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:48:13.73
Aug 27 05:48:13.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename subpath 08/27/22 05:48:13.732
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:13.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:13.802
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/27/22 05:48:13.807
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-76cs 08/27/22 05:48:13.827
STEP: Creating a pod to test atomic-volume-subpath 08/27/22 05:48:13.828
Aug 27 05:48:13.854: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-76cs" in namespace "subpath-6592" to be "Succeeded or Failed"
Aug 27 05:48:13.860: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.586632ms
Aug 27 05:48:15.865: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 2.011263669s
Aug 27 05:48:17.866: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 4.011810675s
Aug 27 05:48:19.863: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 6.009662484s
Aug 27 05:48:21.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 8.010113304s
Aug 27 05:48:23.863: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 10.009516151s
Aug 27 05:48:25.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 12.01028623s
Aug 27 05:48:27.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 14.010312614s
Aug 27 05:48:29.865: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 16.011676602s
Aug 27 05:48:31.865: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 18.011607482s
Aug 27 05:48:33.866: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 20.011723004s
Aug 27 05:48:35.866: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=false. Elapsed: 22.012321724s
Aug 27 05:48:37.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.010378932s
STEP: Saw pod success 08/27/22 05:48:37.864
Aug 27 05:48:37.865: INFO: Pod "pod-subpath-test-projected-76cs" satisfied condition "Succeeded or Failed"
Aug 27 05:48:37.867: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-subpath-test-projected-76cs container test-container-subpath-projected-76cs: <nil>
STEP: delete the pod 08/27/22 05:48:37.888
Aug 27 05:48:37.898: INFO: Waiting for pod pod-subpath-test-projected-76cs to disappear
Aug 27 05:48:37.901: INFO: Pod pod-subpath-test-projected-76cs no longer exists
STEP: Deleting pod pod-subpath-test-projected-76cs 08/27/22 05:48:37.901
Aug 27 05:48:37.902: INFO: Deleting pod "pod-subpath-test-projected-76cs" in namespace "subpath-6592"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 27 05:48:37.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6592" for this suite. 08/27/22 05:48:37.907
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":52,"skipped":1038,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.182 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:48:13.73
    Aug 27 05:48:13.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename subpath 08/27/22 05:48:13.732
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:13.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:13.802
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/27/22 05:48:13.807
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-76cs 08/27/22 05:48:13.827
    STEP: Creating a pod to test atomic-volume-subpath 08/27/22 05:48:13.828
    Aug 27 05:48:13.854: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-76cs" in namespace "subpath-6592" to be "Succeeded or Failed"
    Aug 27 05:48:13.860: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.586632ms
    Aug 27 05:48:15.865: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 2.011263669s
    Aug 27 05:48:17.866: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 4.011810675s
    Aug 27 05:48:19.863: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 6.009662484s
    Aug 27 05:48:21.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 8.010113304s
    Aug 27 05:48:23.863: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 10.009516151s
    Aug 27 05:48:25.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 12.01028623s
    Aug 27 05:48:27.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 14.010312614s
    Aug 27 05:48:29.865: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 16.011676602s
    Aug 27 05:48:31.865: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 18.011607482s
    Aug 27 05:48:33.866: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=true. Elapsed: 20.011723004s
    Aug 27 05:48:35.866: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Running", Reason="", readiness=false. Elapsed: 22.012321724s
    Aug 27 05:48:37.864: INFO: Pod "pod-subpath-test-projected-76cs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.010378932s
    STEP: Saw pod success 08/27/22 05:48:37.864
    Aug 27 05:48:37.865: INFO: Pod "pod-subpath-test-projected-76cs" satisfied condition "Succeeded or Failed"
    Aug 27 05:48:37.867: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-subpath-test-projected-76cs container test-container-subpath-projected-76cs: <nil>
    STEP: delete the pod 08/27/22 05:48:37.888
    Aug 27 05:48:37.898: INFO: Waiting for pod pod-subpath-test-projected-76cs to disappear
    Aug 27 05:48:37.901: INFO: Pod pod-subpath-test-projected-76cs no longer exists
    STEP: Deleting pod pod-subpath-test-projected-76cs 08/27/22 05:48:37.901
    Aug 27 05:48:37.902: INFO: Deleting pod "pod-subpath-test-projected-76cs" in namespace "subpath-6592"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 27 05:48:37.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6592" for this suite. 08/27/22 05:48:37.907
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:48:37.914
Aug 27 05:48:37.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 05:48:37.915
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:37.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:38.006
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-a77f23f3-465e-4e50-9d55-4f78517ecc2f 08/27/22 05:48:38.01
STEP: Creating a pod to test consume secrets 08/27/22 05:48:38.02
Aug 27 05:48:38.029: INFO: Waiting up to 5m0s for pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7" in namespace "secrets-4283" to be "Succeeded or Failed"
Aug 27 05:48:38.032: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.976489ms
Aug 27 05:48:40.040: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010511473s
Aug 27 05:48:42.036: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007100775s
STEP: Saw pod success 08/27/22 05:48:42.036
Aug 27 05:48:42.037: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7" satisfied condition "Succeeded or Failed"
Aug 27 05:48:42.040: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 05:48:42.052
Aug 27 05:48:42.078: INFO: Waiting for pod pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7 to disappear
Aug 27 05:48:42.083: INFO: Pod pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 05:48:42.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4283" for this suite. 08/27/22 05:48:42.087
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":53,"skipped":1044,"failed":0}
------------------------------
â€¢ [4.178 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:48:37.914
    Aug 27 05:48:37.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 05:48:37.915
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:37.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:38.006
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-a77f23f3-465e-4e50-9d55-4f78517ecc2f 08/27/22 05:48:38.01
    STEP: Creating a pod to test consume secrets 08/27/22 05:48:38.02
    Aug 27 05:48:38.029: INFO: Waiting up to 5m0s for pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7" in namespace "secrets-4283" to be "Succeeded or Failed"
    Aug 27 05:48:38.032: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.976489ms
    Aug 27 05:48:40.040: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010511473s
    Aug 27 05:48:42.036: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007100775s
    STEP: Saw pod success 08/27/22 05:48:42.036
    Aug 27 05:48:42.037: INFO: Pod "pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7" satisfied condition "Succeeded or Failed"
    Aug 27 05:48:42.040: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 05:48:42.052
    Aug 27 05:48:42.078: INFO: Waiting for pod pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7 to disappear
    Aug 27 05:48:42.083: INFO: Pod pod-secrets-578bd7fa-2fe2-4ca5-8e0d-d31ce5d529c7 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 05:48:42.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4283" for this suite. 08/27/22 05:48:42.087
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:48:42.094
Aug 27 05:48:42.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename subpath 08/27/22 05:48:42.096
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:42.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:42.143
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/27/22 05:48:42.147
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-xgfj 08/27/22 05:48:42.153
STEP: Creating a pod to test atomic-volume-subpath 08/27/22 05:48:42.153
Aug 27 05:48:42.159: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xgfj" in namespace "subpath-5376" to be "Succeeded or Failed"
Aug 27 05:48:42.161: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.234982ms
Aug 27 05:48:44.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 2.006480832s
Aug 27 05:48:46.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 4.007011185s
Aug 27 05:48:48.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 6.00708154s
Aug 27 05:48:50.167: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 8.007988437s
Aug 27 05:48:52.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 10.005676868s
Aug 27 05:48:54.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 12.005930588s
Aug 27 05:48:56.167: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 14.007694797s
Aug 27 05:48:58.207: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 16.047626702s
Aug 27 05:49:00.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 18.007319668s
Aug 27 05:49:02.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 20.006048484s
Aug 27 05:49:04.188: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=false. Elapsed: 22.029489298s
Aug 27 05:49:06.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.00724248s
STEP: Saw pod success 08/27/22 05:49:06.166
Aug 27 05:49:06.167: INFO: Pod "pod-subpath-test-configmap-xgfj" satisfied condition "Succeeded or Failed"
Aug 27 05:49:06.170: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-subpath-test-configmap-xgfj container test-container-subpath-configmap-xgfj: <nil>
STEP: delete the pod 08/27/22 05:49:06.179
Aug 27 05:49:06.196: INFO: Waiting for pod pod-subpath-test-configmap-xgfj to disappear
Aug 27 05:49:06.199: INFO: Pod pod-subpath-test-configmap-xgfj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xgfj 08/27/22 05:49:06.199
Aug 27 05:49:06.200: INFO: Deleting pod "pod-subpath-test-configmap-xgfj" in namespace "subpath-5376"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 27 05:49:06.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5376" for this suite. 08/27/22 05:49:06.214
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":54,"skipped":1053,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.126 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:48:42.094
    Aug 27 05:48:42.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename subpath 08/27/22 05:48:42.096
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:48:42.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:48:42.143
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/27/22 05:48:42.147
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-xgfj 08/27/22 05:48:42.153
    STEP: Creating a pod to test atomic-volume-subpath 08/27/22 05:48:42.153
    Aug 27 05:48:42.159: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xgfj" in namespace "subpath-5376" to be "Succeeded or Failed"
    Aug 27 05:48:42.161: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.234982ms
    Aug 27 05:48:44.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 2.006480832s
    Aug 27 05:48:46.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 4.007011185s
    Aug 27 05:48:48.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 6.00708154s
    Aug 27 05:48:50.167: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 8.007988437s
    Aug 27 05:48:52.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 10.005676868s
    Aug 27 05:48:54.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 12.005930588s
    Aug 27 05:48:56.167: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 14.007694797s
    Aug 27 05:48:58.207: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 16.047626702s
    Aug 27 05:49:00.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 18.007319668s
    Aug 27 05:49:02.165: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=true. Elapsed: 20.006048484s
    Aug 27 05:49:04.188: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Running", Reason="", readiness=false. Elapsed: 22.029489298s
    Aug 27 05:49:06.166: INFO: Pod "pod-subpath-test-configmap-xgfj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.00724248s
    STEP: Saw pod success 08/27/22 05:49:06.166
    Aug 27 05:49:06.167: INFO: Pod "pod-subpath-test-configmap-xgfj" satisfied condition "Succeeded or Failed"
    Aug 27 05:49:06.170: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-subpath-test-configmap-xgfj container test-container-subpath-configmap-xgfj: <nil>
    STEP: delete the pod 08/27/22 05:49:06.179
    Aug 27 05:49:06.196: INFO: Waiting for pod pod-subpath-test-configmap-xgfj to disappear
    Aug 27 05:49:06.199: INFO: Pod pod-subpath-test-configmap-xgfj no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-xgfj 08/27/22 05:49:06.199
    Aug 27 05:49:06.200: INFO: Deleting pod "pod-subpath-test-configmap-xgfj" in namespace "subpath-5376"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 27 05:49:06.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5376" for this suite. 08/27/22 05:49:06.214
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:49:06.221
Aug 27 05:49:06.221: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 05:49:06.222
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:49:06.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:49:06.247
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7606 08/27/22 05:49:06.25
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 08/27/22 05:49:06.255
STEP: Creating stateful set ss in namespace statefulset-7606 08/27/22 05:49:06.264
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7606 08/27/22 05:49:06.275
Aug 27 05:49:06.279: INFO: Found 0 stateful pods, waiting for 1
Aug 27 05:49:16.284: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 08/27/22 05:49:16.284
Aug 27 05:49:16.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 05:49:16.423: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 05:49:16.423: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 05:49:16.423: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 05:49:16.426: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 27 05:49:26.432: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 05:49:26.432: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 05:49:26.447: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999769s
Aug 27 05:49:27.451: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997112865s
Aug 27 05:49:28.457: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992903108s
Aug 27 05:49:29.461: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986169926s
Aug 27 05:49:30.464: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982966633s
Aug 27 05:49:31.468: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979089472s
Aug 27 05:49:32.472: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975905817s
Aug 27 05:49:33.476: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97241511s
Aug 27 05:49:34.479: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968304613s
Aug 27 05:49:35.483: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.446904ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7606 08/27/22 05:49:36.484
Aug 27 05:49:36.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 05:49:36.655: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 05:49:36.655: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 05:49:36.655: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 05:49:36.671: INFO: Found 1 stateful pods, waiting for 3
Aug 27 05:49:46.675: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 05:49:46.676: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 05:49:46.676: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 08/27/22 05:49:46.676
STEP: Scale down will halt with unhealthy stateful pod 08/27/22 05:49:46.676
Aug 27 05:49:46.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 05:49:46.843: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 05:49:46.843: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 05:49:46.843: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 05:49:46.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 05:49:47.075: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 05:49:47.075: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 05:49:47.075: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 05:49:47.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 05:49:47.330: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 05:49:47.330: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 05:49:47.330: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 05:49:47.330: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 05:49:47.333: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 27 05:49:57.340: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 05:49:57.340: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 05:49:57.340: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 05:49:57.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999663s
Aug 27 05:49:58.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992651072s
Aug 27 05:49:59.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98893449s
Aug 27 05:50:00.371: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984517931s
Aug 27 05:50:01.375: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978898823s
Aug 27 05:50:02.379: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974854275s
Aug 27 05:50:03.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971055107s
Aug 27 05:50:04.388: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966496796s
Aug 27 05:50:05.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962604612s
Aug 27 05:50:06.401: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.944196ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7606 08/27/22 05:50:07.402
Aug 27 05:50:07.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 05:50:07.609: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 05:50:07.609: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 05:50:07.609: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 05:50:07.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 05:50:07.865: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 05:50:07.865: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 05:50:07.865: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 05:50:07.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 05:50:08.072: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 05:50:08.072: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 05:50:08.072: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 05:50:08.072: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 08/27/22 05:50:18.159
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 05:50:18.159: INFO: Deleting all statefulset in ns statefulset-7606
Aug 27 05:50:18.162: INFO: Scaling statefulset ss to 0
Aug 27 05:50:18.170: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 05:50:18.173: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 05:50:18.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7606" for this suite. 08/27/22 05:50:18.187
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":55,"skipped":1053,"failed":0}
------------------------------
â€¢ [SLOW TEST] [71.982 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:49:06.221
    Aug 27 05:49:06.221: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 05:49:06.222
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:49:06.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:49:06.247
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7606 08/27/22 05:49:06.25
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 08/27/22 05:49:06.255
    STEP: Creating stateful set ss in namespace statefulset-7606 08/27/22 05:49:06.264
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7606 08/27/22 05:49:06.275
    Aug 27 05:49:06.279: INFO: Found 0 stateful pods, waiting for 1
    Aug 27 05:49:16.284: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 08/27/22 05:49:16.284
    Aug 27 05:49:16.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 05:49:16.423: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 05:49:16.423: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 05:49:16.423: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 05:49:16.426: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Aug 27 05:49:26.432: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 05:49:26.432: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 05:49:26.447: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999769s
    Aug 27 05:49:27.451: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997112865s
    Aug 27 05:49:28.457: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992903108s
    Aug 27 05:49:29.461: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986169926s
    Aug 27 05:49:30.464: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982966633s
    Aug 27 05:49:31.468: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979089472s
    Aug 27 05:49:32.472: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975905817s
    Aug 27 05:49:33.476: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.97241511s
    Aug 27 05:49:34.479: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968304613s
    Aug 27 05:49:35.483: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.446904ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7606 08/27/22 05:49:36.484
    Aug 27 05:49:36.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 05:49:36.655: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 05:49:36.655: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 05:49:36.655: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 05:49:36.671: INFO: Found 1 stateful pods, waiting for 3
    Aug 27 05:49:46.675: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 05:49:46.676: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 05:49:46.676: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 08/27/22 05:49:46.676
    STEP: Scale down will halt with unhealthy stateful pod 08/27/22 05:49:46.676
    Aug 27 05:49:46.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 05:49:46.843: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 05:49:46.843: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 05:49:46.843: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 05:49:46.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 05:49:47.075: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 05:49:47.075: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 05:49:47.075: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 05:49:47.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 05:49:47.330: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 05:49:47.330: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 05:49:47.330: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 05:49:47.330: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 05:49:47.333: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Aug 27 05:49:57.340: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 05:49:57.340: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 05:49:57.340: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 05:49:57.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999663s
    Aug 27 05:49:58.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992651072s
    Aug 27 05:49:59.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98893449s
    Aug 27 05:50:00.371: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984517931s
    Aug 27 05:50:01.375: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978898823s
    Aug 27 05:50:02.379: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974854275s
    Aug 27 05:50:03.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971055107s
    Aug 27 05:50:04.388: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966496796s
    Aug 27 05:50:05.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962604612s
    Aug 27 05:50:06.401: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.944196ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7606 08/27/22 05:50:07.402
    Aug 27 05:50:07.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 05:50:07.609: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 05:50:07.609: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 05:50:07.609: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 05:50:07.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 05:50:07.865: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 05:50:07.865: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 05:50:07.865: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 05:50:07.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-7606 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 05:50:08.072: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 05:50:08.072: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 05:50:08.072: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 05:50:08.072: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 08/27/22 05:50:18.159
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 05:50:18.159: INFO: Deleting all statefulset in ns statefulset-7606
    Aug 27 05:50:18.162: INFO: Scaling statefulset ss to 0
    Aug 27 05:50:18.170: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 05:50:18.173: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 05:50:18.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7606" for this suite. 08/27/22 05:50:18.187
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:50:18.203
Aug 27 05:50:18.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 05:50:18.205
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:50:18.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:50:18.283
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 08/27/22 05:50:18.291
STEP: delete the rc 08/27/22 05:50:23.299
STEP: wait for the rc to be deleted 08/27/22 05:50:23.313
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 08/27/22 05:50:28.354
STEP: Gathering metrics 08/27/22 05:50:58.371
Aug 27 05:50:58.395: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
Aug 27 05:50:58.398: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 3.314115ms
Aug 27 05:50:58.398: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
Aug 27 05:50:58.398: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
Aug 27 05:50:58.532: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 27 05:50:58.532: INFO: Deleting pod "simpletest.rc-2l4qj" in namespace "gc-4652"
Aug 27 05:50:58.545: INFO: Deleting pod "simpletest.rc-2rw52" in namespace "gc-4652"
Aug 27 05:50:58.567: INFO: Deleting pod "simpletest.rc-2sdbz" in namespace "gc-4652"
Aug 27 05:50:58.589: INFO: Deleting pod "simpletest.rc-2z66h" in namespace "gc-4652"
Aug 27 05:50:58.619: INFO: Deleting pod "simpletest.rc-47jqn" in namespace "gc-4652"
Aug 27 05:50:58.637: INFO: Deleting pod "simpletest.rc-4m8nh" in namespace "gc-4652"
Aug 27 05:50:58.680: INFO: Deleting pod "simpletest.rc-4qc95" in namespace "gc-4652"
Aug 27 05:50:58.703: INFO: Deleting pod "simpletest.rc-55nhd" in namespace "gc-4652"
Aug 27 05:50:58.723: INFO: Deleting pod "simpletest.rc-564vd" in namespace "gc-4652"
Aug 27 05:50:58.747: INFO: Deleting pod "simpletest.rc-579kw" in namespace "gc-4652"
Aug 27 05:50:58.763: INFO: Deleting pod "simpletest.rc-5hl9h" in namespace "gc-4652"
Aug 27 05:50:58.778: INFO: Deleting pod "simpletest.rc-5q8cc" in namespace "gc-4652"
Aug 27 05:50:58.813: INFO: Deleting pod "simpletest.rc-64ngk" in namespace "gc-4652"
Aug 27 05:50:58.830: INFO: Deleting pod "simpletest.rc-68x8f" in namespace "gc-4652"
Aug 27 05:50:58.843: INFO: Deleting pod "simpletest.rc-6gt9c" in namespace "gc-4652"
Aug 27 05:50:58.857: INFO: Deleting pod "simpletest.rc-6rb7k" in namespace "gc-4652"
Aug 27 05:50:58.870: INFO: Deleting pod "simpletest.rc-6t66j" in namespace "gc-4652"
Aug 27 05:50:58.915: INFO: Deleting pod "simpletest.rc-6xq2c" in namespace "gc-4652"
Aug 27 05:50:58.939: INFO: Deleting pod "simpletest.rc-77n4d" in namespace "gc-4652"
Aug 27 05:50:58.967: INFO: Deleting pod "simpletest.rc-7bh79" in namespace "gc-4652"
Aug 27 05:50:58.977: INFO: Deleting pod "simpletest.rc-9bltd" in namespace "gc-4652"
Aug 27 05:50:59.025: INFO: Deleting pod "simpletest.rc-9r5ld" in namespace "gc-4652"
Aug 27 05:50:59.043: INFO: Deleting pod "simpletest.rc-9tv5j" in namespace "gc-4652"
Aug 27 05:50:59.059: INFO: Deleting pod "simpletest.rc-b78f4" in namespace "gc-4652"
Aug 27 05:50:59.075: INFO: Deleting pod "simpletest.rc-bgg44" in namespace "gc-4652"
Aug 27 05:50:59.095: INFO: Deleting pod "simpletest.rc-bqdgk" in namespace "gc-4652"
Aug 27 05:50:59.121: INFO: Deleting pod "simpletest.rc-brcb9" in namespace "gc-4652"
Aug 27 05:50:59.143: INFO: Deleting pod "simpletest.rc-c2nnp" in namespace "gc-4652"
Aug 27 05:50:59.176: INFO: Deleting pod "simpletest.rc-crgjq" in namespace "gc-4652"
Aug 27 05:50:59.212: INFO: Deleting pod "simpletest.rc-crjks" in namespace "gc-4652"
Aug 27 05:50:59.232: INFO: Deleting pod "simpletest.rc-ctl97" in namespace "gc-4652"
Aug 27 05:50:59.246: INFO: Deleting pod "simpletest.rc-cwclj" in namespace "gc-4652"
Aug 27 05:50:59.272: INFO: Deleting pod "simpletest.rc-czbms" in namespace "gc-4652"
Aug 27 05:50:59.288: INFO: Deleting pod "simpletest.rc-d588v" in namespace "gc-4652"
Aug 27 05:50:59.297: INFO: Deleting pod "simpletest.rc-dgkrr" in namespace "gc-4652"
Aug 27 05:50:59.308: INFO: Deleting pod "simpletest.rc-f258m" in namespace "gc-4652"
Aug 27 05:50:59.320: INFO: Deleting pod "simpletest.rc-fsshq" in namespace "gc-4652"
Aug 27 05:50:59.353: INFO: Deleting pod "simpletest.rc-ftlfw" in namespace "gc-4652"
Aug 27 05:50:59.375: INFO: Deleting pod "simpletest.rc-g5q7b" in namespace "gc-4652"
Aug 27 05:50:59.394: INFO: Deleting pod "simpletest.rc-g6wbd" in namespace "gc-4652"
Aug 27 05:50:59.408: INFO: Deleting pod "simpletest.rc-gf69c" in namespace "gc-4652"
Aug 27 05:50:59.422: INFO: Deleting pod "simpletest.rc-hfnzx" in namespace "gc-4652"
Aug 27 05:50:59.434: INFO: Deleting pod "simpletest.rc-hhb4d" in namespace "gc-4652"
Aug 27 05:50:59.447: INFO: Deleting pod "simpletest.rc-htb7v" in namespace "gc-4652"
Aug 27 05:50:59.457: INFO: Deleting pod "simpletest.rc-j5s2n" in namespace "gc-4652"
Aug 27 05:50:59.469: INFO: Deleting pod "simpletest.rc-jdmlq" in namespace "gc-4652"
Aug 27 05:50:59.480: INFO: Deleting pod "simpletest.rc-jtz7g" in namespace "gc-4652"
Aug 27 05:50:59.497: INFO: Deleting pod "simpletest.rc-jz7gb" in namespace "gc-4652"
Aug 27 05:50:59.510: INFO: Deleting pod "simpletest.rc-jzj5t" in namespace "gc-4652"
Aug 27 05:50:59.532: INFO: Deleting pod "simpletest.rc-k5929" in namespace "gc-4652"
Aug 27 05:50:59.547: INFO: Deleting pod "simpletest.rc-kct9l" in namespace "gc-4652"
Aug 27 05:50:59.574: INFO: Deleting pod "simpletest.rc-kp4dv" in namespace "gc-4652"
Aug 27 05:50:59.582: INFO: Deleting pod "simpletest.rc-kss49" in namespace "gc-4652"
Aug 27 05:50:59.591: INFO: Deleting pod "simpletest.rc-kt2bf" in namespace "gc-4652"
Aug 27 05:50:59.603: INFO: Deleting pod "simpletest.rc-ktq47" in namespace "gc-4652"
Aug 27 05:50:59.612: INFO: Deleting pod "simpletest.rc-l9zq6" in namespace "gc-4652"
Aug 27 05:50:59.621: INFO: Deleting pod "simpletest.rc-lwxmw" in namespace "gc-4652"
Aug 27 05:50:59.631: INFO: Deleting pod "simpletest.rc-mr8lk" in namespace "gc-4652"
Aug 27 05:50:59.642: INFO: Deleting pod "simpletest.rc-mrmgg" in namespace "gc-4652"
Aug 27 05:50:59.650: INFO: Deleting pod "simpletest.rc-mrwtw" in namespace "gc-4652"
Aug 27 05:50:59.663: INFO: Deleting pod "simpletest.rc-mxdf6" in namespace "gc-4652"
Aug 27 05:50:59.675: INFO: Deleting pod "simpletest.rc-mxhgv" in namespace "gc-4652"
Aug 27 05:50:59.686: INFO: Deleting pod "simpletest.rc-mxjnq" in namespace "gc-4652"
Aug 27 05:50:59.695: INFO: Deleting pod "simpletest.rc-n4vdk" in namespace "gc-4652"
Aug 27 05:50:59.706: INFO: Deleting pod "simpletest.rc-n6hps" in namespace "gc-4652"
Aug 27 05:50:59.714: INFO: Deleting pod "simpletest.rc-ncw6q" in namespace "gc-4652"
Aug 27 05:50:59.724: INFO: Deleting pod "simpletest.rc-nnvwd" in namespace "gc-4652"
Aug 27 05:50:59.739: INFO: Deleting pod "simpletest.rc-ns6ld" in namespace "gc-4652"
Aug 27 05:50:59.749: INFO: Deleting pod "simpletest.rc-prfgs" in namespace "gc-4652"
Aug 27 05:50:59.764: INFO: Deleting pod "simpletest.rc-q6856" in namespace "gc-4652"
Aug 27 05:50:59.784: INFO: Deleting pod "simpletest.rc-qcdtr" in namespace "gc-4652"
Aug 27 05:50:59.792: INFO: Deleting pod "simpletest.rc-qh9qk" in namespace "gc-4652"
Aug 27 05:50:59.805: INFO: Deleting pod "simpletest.rc-rchcv" in namespace "gc-4652"
Aug 27 05:50:59.819: INFO: Deleting pod "simpletest.rc-rdnqv" in namespace "gc-4652"
Aug 27 05:50:59.833: INFO: Deleting pod "simpletest.rc-rk85n" in namespace "gc-4652"
Aug 27 05:50:59.846: INFO: Deleting pod "simpletest.rc-rs2b6" in namespace "gc-4652"
Aug 27 05:50:59.875: INFO: Deleting pod "simpletest.rc-rw78l" in namespace "gc-4652"
Aug 27 05:50:59.936: INFO: Deleting pod "simpletest.rc-rxcgn" in namespace "gc-4652"
Aug 27 05:50:59.975: INFO: Deleting pod "simpletest.rc-rxjtx" in namespace "gc-4652"
Aug 27 05:51:00.030: INFO: Deleting pod "simpletest.rc-s9xms" in namespace "gc-4652"
Aug 27 05:51:00.072: INFO: Deleting pod "simpletest.rc-sdrqn" in namespace "gc-4652"
Aug 27 05:51:00.154: INFO: Deleting pod "simpletest.rc-sgmfj" in namespace "gc-4652"
Aug 27 05:51:00.199: INFO: Deleting pod "simpletest.rc-tb2kv" in namespace "gc-4652"
Aug 27 05:51:00.215: INFO: Deleting pod "simpletest.rc-tbzln" in namespace "gc-4652"
Aug 27 05:51:00.270: INFO: Deleting pod "simpletest.rc-tn57d" in namespace "gc-4652"
Aug 27 05:51:00.316: INFO: Deleting pod "simpletest.rc-tq8jw" in namespace "gc-4652"
Aug 27 05:51:00.371: INFO: Deleting pod "simpletest.rc-v5hfg" in namespace "gc-4652"
Aug 27 05:51:00.433: INFO: Deleting pod "simpletest.rc-v7999" in namespace "gc-4652"
Aug 27 05:51:00.482: INFO: Deleting pod "simpletest.rc-w2vzq" in namespace "gc-4652"
Aug 27 05:51:00.537: INFO: Deleting pod "simpletest.rc-w6jzh" in namespace "gc-4652"
Aug 27 05:51:00.576: INFO: Deleting pod "simpletest.rc-wmlrg" in namespace "gc-4652"
Aug 27 05:51:00.627: INFO: Deleting pod "simpletest.rc-wqq2r" in namespace "gc-4652"
Aug 27 05:51:00.674: INFO: Deleting pod "simpletest.rc-x2jct" in namespace "gc-4652"
Aug 27 05:51:00.721: INFO: Deleting pod "simpletest.rc-x5pmd" in namespace "gc-4652"
Aug 27 05:51:00.792: INFO: Deleting pod "simpletest.rc-xmn2g" in namespace "gc-4652"
Aug 27 05:51:00.819: INFO: Deleting pod "simpletest.rc-z92rj" in namespace "gc-4652"
Aug 27 05:51:00.872: INFO: Deleting pod "simpletest.rc-zdt5q" in namespace "gc-4652"
Aug 27 05:51:00.916: INFO: Deleting pod "simpletest.rc-zkwnr" in namespace "gc-4652"
Aug 27 05:51:00.970: INFO: Deleting pod "simpletest.rc-zlpsl" in namespace "gc-4652"
Aug 27 05:51:01.031: INFO: Deleting pod "simpletest.rc-zs96w" in namespace "gc-4652"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 05:51:01.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4652" for this suite. 08/27/22 05:51:01.115
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":56,"skipped":1054,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.973 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:50:18.203
    Aug 27 05:50:18.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 05:50:18.205
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:50:18.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:50:18.283
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 08/27/22 05:50:18.291
    STEP: delete the rc 08/27/22 05:50:23.299
    STEP: wait for the rc to be deleted 08/27/22 05:50:23.313
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 08/27/22 05:50:28.354
    STEP: Gathering metrics 08/27/22 05:50:58.371
    Aug 27 05:50:58.395: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
    Aug 27 05:50:58.398: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 3.314115ms
    Aug 27 05:50:58.398: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
    Aug 27 05:50:58.398: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
    Aug 27 05:50:58.532: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Aug 27 05:50:58.532: INFO: Deleting pod "simpletest.rc-2l4qj" in namespace "gc-4652"
    Aug 27 05:50:58.545: INFO: Deleting pod "simpletest.rc-2rw52" in namespace "gc-4652"
    Aug 27 05:50:58.567: INFO: Deleting pod "simpletest.rc-2sdbz" in namespace "gc-4652"
    Aug 27 05:50:58.589: INFO: Deleting pod "simpletest.rc-2z66h" in namespace "gc-4652"
    Aug 27 05:50:58.619: INFO: Deleting pod "simpletest.rc-47jqn" in namespace "gc-4652"
    Aug 27 05:50:58.637: INFO: Deleting pod "simpletest.rc-4m8nh" in namespace "gc-4652"
    Aug 27 05:50:58.680: INFO: Deleting pod "simpletest.rc-4qc95" in namespace "gc-4652"
    Aug 27 05:50:58.703: INFO: Deleting pod "simpletest.rc-55nhd" in namespace "gc-4652"
    Aug 27 05:50:58.723: INFO: Deleting pod "simpletest.rc-564vd" in namespace "gc-4652"
    Aug 27 05:50:58.747: INFO: Deleting pod "simpletest.rc-579kw" in namespace "gc-4652"
    Aug 27 05:50:58.763: INFO: Deleting pod "simpletest.rc-5hl9h" in namespace "gc-4652"
    Aug 27 05:50:58.778: INFO: Deleting pod "simpletest.rc-5q8cc" in namespace "gc-4652"
    Aug 27 05:50:58.813: INFO: Deleting pod "simpletest.rc-64ngk" in namespace "gc-4652"
    Aug 27 05:50:58.830: INFO: Deleting pod "simpletest.rc-68x8f" in namespace "gc-4652"
    Aug 27 05:50:58.843: INFO: Deleting pod "simpletest.rc-6gt9c" in namespace "gc-4652"
    Aug 27 05:50:58.857: INFO: Deleting pod "simpletest.rc-6rb7k" in namespace "gc-4652"
    Aug 27 05:50:58.870: INFO: Deleting pod "simpletest.rc-6t66j" in namespace "gc-4652"
    Aug 27 05:50:58.915: INFO: Deleting pod "simpletest.rc-6xq2c" in namespace "gc-4652"
    Aug 27 05:50:58.939: INFO: Deleting pod "simpletest.rc-77n4d" in namespace "gc-4652"
    Aug 27 05:50:58.967: INFO: Deleting pod "simpletest.rc-7bh79" in namespace "gc-4652"
    Aug 27 05:50:58.977: INFO: Deleting pod "simpletest.rc-9bltd" in namespace "gc-4652"
    Aug 27 05:50:59.025: INFO: Deleting pod "simpletest.rc-9r5ld" in namespace "gc-4652"
    Aug 27 05:50:59.043: INFO: Deleting pod "simpletest.rc-9tv5j" in namespace "gc-4652"
    Aug 27 05:50:59.059: INFO: Deleting pod "simpletest.rc-b78f4" in namespace "gc-4652"
    Aug 27 05:50:59.075: INFO: Deleting pod "simpletest.rc-bgg44" in namespace "gc-4652"
    Aug 27 05:50:59.095: INFO: Deleting pod "simpletest.rc-bqdgk" in namespace "gc-4652"
    Aug 27 05:50:59.121: INFO: Deleting pod "simpletest.rc-brcb9" in namespace "gc-4652"
    Aug 27 05:50:59.143: INFO: Deleting pod "simpletest.rc-c2nnp" in namespace "gc-4652"
    Aug 27 05:50:59.176: INFO: Deleting pod "simpletest.rc-crgjq" in namespace "gc-4652"
    Aug 27 05:50:59.212: INFO: Deleting pod "simpletest.rc-crjks" in namespace "gc-4652"
    Aug 27 05:50:59.232: INFO: Deleting pod "simpletest.rc-ctl97" in namespace "gc-4652"
    Aug 27 05:50:59.246: INFO: Deleting pod "simpletest.rc-cwclj" in namespace "gc-4652"
    Aug 27 05:50:59.272: INFO: Deleting pod "simpletest.rc-czbms" in namespace "gc-4652"
    Aug 27 05:50:59.288: INFO: Deleting pod "simpletest.rc-d588v" in namespace "gc-4652"
    Aug 27 05:50:59.297: INFO: Deleting pod "simpletest.rc-dgkrr" in namespace "gc-4652"
    Aug 27 05:50:59.308: INFO: Deleting pod "simpletest.rc-f258m" in namespace "gc-4652"
    Aug 27 05:50:59.320: INFO: Deleting pod "simpletest.rc-fsshq" in namespace "gc-4652"
    Aug 27 05:50:59.353: INFO: Deleting pod "simpletest.rc-ftlfw" in namespace "gc-4652"
    Aug 27 05:50:59.375: INFO: Deleting pod "simpletest.rc-g5q7b" in namespace "gc-4652"
    Aug 27 05:50:59.394: INFO: Deleting pod "simpletest.rc-g6wbd" in namespace "gc-4652"
    Aug 27 05:50:59.408: INFO: Deleting pod "simpletest.rc-gf69c" in namespace "gc-4652"
    Aug 27 05:50:59.422: INFO: Deleting pod "simpletest.rc-hfnzx" in namespace "gc-4652"
    Aug 27 05:50:59.434: INFO: Deleting pod "simpletest.rc-hhb4d" in namespace "gc-4652"
    Aug 27 05:50:59.447: INFO: Deleting pod "simpletest.rc-htb7v" in namespace "gc-4652"
    Aug 27 05:50:59.457: INFO: Deleting pod "simpletest.rc-j5s2n" in namespace "gc-4652"
    Aug 27 05:50:59.469: INFO: Deleting pod "simpletest.rc-jdmlq" in namespace "gc-4652"
    Aug 27 05:50:59.480: INFO: Deleting pod "simpletest.rc-jtz7g" in namespace "gc-4652"
    Aug 27 05:50:59.497: INFO: Deleting pod "simpletest.rc-jz7gb" in namespace "gc-4652"
    Aug 27 05:50:59.510: INFO: Deleting pod "simpletest.rc-jzj5t" in namespace "gc-4652"
    Aug 27 05:50:59.532: INFO: Deleting pod "simpletest.rc-k5929" in namespace "gc-4652"
    Aug 27 05:50:59.547: INFO: Deleting pod "simpletest.rc-kct9l" in namespace "gc-4652"
    Aug 27 05:50:59.574: INFO: Deleting pod "simpletest.rc-kp4dv" in namespace "gc-4652"
    Aug 27 05:50:59.582: INFO: Deleting pod "simpletest.rc-kss49" in namespace "gc-4652"
    Aug 27 05:50:59.591: INFO: Deleting pod "simpletest.rc-kt2bf" in namespace "gc-4652"
    Aug 27 05:50:59.603: INFO: Deleting pod "simpletest.rc-ktq47" in namespace "gc-4652"
    Aug 27 05:50:59.612: INFO: Deleting pod "simpletest.rc-l9zq6" in namespace "gc-4652"
    Aug 27 05:50:59.621: INFO: Deleting pod "simpletest.rc-lwxmw" in namespace "gc-4652"
    Aug 27 05:50:59.631: INFO: Deleting pod "simpletest.rc-mr8lk" in namespace "gc-4652"
    Aug 27 05:50:59.642: INFO: Deleting pod "simpletest.rc-mrmgg" in namespace "gc-4652"
    Aug 27 05:50:59.650: INFO: Deleting pod "simpletest.rc-mrwtw" in namespace "gc-4652"
    Aug 27 05:50:59.663: INFO: Deleting pod "simpletest.rc-mxdf6" in namespace "gc-4652"
    Aug 27 05:50:59.675: INFO: Deleting pod "simpletest.rc-mxhgv" in namespace "gc-4652"
    Aug 27 05:50:59.686: INFO: Deleting pod "simpletest.rc-mxjnq" in namespace "gc-4652"
    Aug 27 05:50:59.695: INFO: Deleting pod "simpletest.rc-n4vdk" in namespace "gc-4652"
    Aug 27 05:50:59.706: INFO: Deleting pod "simpletest.rc-n6hps" in namespace "gc-4652"
    Aug 27 05:50:59.714: INFO: Deleting pod "simpletest.rc-ncw6q" in namespace "gc-4652"
    Aug 27 05:50:59.724: INFO: Deleting pod "simpletest.rc-nnvwd" in namespace "gc-4652"
    Aug 27 05:50:59.739: INFO: Deleting pod "simpletest.rc-ns6ld" in namespace "gc-4652"
    Aug 27 05:50:59.749: INFO: Deleting pod "simpletest.rc-prfgs" in namespace "gc-4652"
    Aug 27 05:50:59.764: INFO: Deleting pod "simpletest.rc-q6856" in namespace "gc-4652"
    Aug 27 05:50:59.784: INFO: Deleting pod "simpletest.rc-qcdtr" in namespace "gc-4652"
    Aug 27 05:50:59.792: INFO: Deleting pod "simpletest.rc-qh9qk" in namespace "gc-4652"
    Aug 27 05:50:59.805: INFO: Deleting pod "simpletest.rc-rchcv" in namespace "gc-4652"
    Aug 27 05:50:59.819: INFO: Deleting pod "simpletest.rc-rdnqv" in namespace "gc-4652"
    Aug 27 05:50:59.833: INFO: Deleting pod "simpletest.rc-rk85n" in namespace "gc-4652"
    Aug 27 05:50:59.846: INFO: Deleting pod "simpletest.rc-rs2b6" in namespace "gc-4652"
    Aug 27 05:50:59.875: INFO: Deleting pod "simpletest.rc-rw78l" in namespace "gc-4652"
    Aug 27 05:50:59.936: INFO: Deleting pod "simpletest.rc-rxcgn" in namespace "gc-4652"
    Aug 27 05:50:59.975: INFO: Deleting pod "simpletest.rc-rxjtx" in namespace "gc-4652"
    Aug 27 05:51:00.030: INFO: Deleting pod "simpletest.rc-s9xms" in namespace "gc-4652"
    Aug 27 05:51:00.072: INFO: Deleting pod "simpletest.rc-sdrqn" in namespace "gc-4652"
    Aug 27 05:51:00.154: INFO: Deleting pod "simpletest.rc-sgmfj" in namespace "gc-4652"
    Aug 27 05:51:00.199: INFO: Deleting pod "simpletest.rc-tb2kv" in namespace "gc-4652"
    Aug 27 05:51:00.215: INFO: Deleting pod "simpletest.rc-tbzln" in namespace "gc-4652"
    Aug 27 05:51:00.270: INFO: Deleting pod "simpletest.rc-tn57d" in namespace "gc-4652"
    Aug 27 05:51:00.316: INFO: Deleting pod "simpletest.rc-tq8jw" in namespace "gc-4652"
    Aug 27 05:51:00.371: INFO: Deleting pod "simpletest.rc-v5hfg" in namespace "gc-4652"
    Aug 27 05:51:00.433: INFO: Deleting pod "simpletest.rc-v7999" in namespace "gc-4652"
    Aug 27 05:51:00.482: INFO: Deleting pod "simpletest.rc-w2vzq" in namespace "gc-4652"
    Aug 27 05:51:00.537: INFO: Deleting pod "simpletest.rc-w6jzh" in namespace "gc-4652"
    Aug 27 05:51:00.576: INFO: Deleting pod "simpletest.rc-wmlrg" in namespace "gc-4652"
    Aug 27 05:51:00.627: INFO: Deleting pod "simpletest.rc-wqq2r" in namespace "gc-4652"
    Aug 27 05:51:00.674: INFO: Deleting pod "simpletest.rc-x2jct" in namespace "gc-4652"
    Aug 27 05:51:00.721: INFO: Deleting pod "simpletest.rc-x5pmd" in namespace "gc-4652"
    Aug 27 05:51:00.792: INFO: Deleting pod "simpletest.rc-xmn2g" in namespace "gc-4652"
    Aug 27 05:51:00.819: INFO: Deleting pod "simpletest.rc-z92rj" in namespace "gc-4652"
    Aug 27 05:51:00.872: INFO: Deleting pod "simpletest.rc-zdt5q" in namespace "gc-4652"
    Aug 27 05:51:00.916: INFO: Deleting pod "simpletest.rc-zkwnr" in namespace "gc-4652"
    Aug 27 05:51:00.970: INFO: Deleting pod "simpletest.rc-zlpsl" in namespace "gc-4652"
    Aug 27 05:51:01.031: INFO: Deleting pod "simpletest.rc-zs96w" in namespace "gc-4652"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 05:51:01.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4652" for this suite. 08/27/22 05:51:01.115
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:01.188
Aug 27 05:51:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 05:51:01.189
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:01.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:01.213
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 08/27/22 05:51:01.218
Aug 27 05:51:01.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-9861 create -f -'
Aug 27 05:51:01.965: INFO: stderr: ""
Aug 27 05:51:01.965: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/27/22 05:51:01.965
Aug 27 05:51:02.980: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:02.980: INFO: Found 0 / 1
Aug 27 05:51:03.970: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:03.970: INFO: Found 0 / 1
Aug 27 05:51:04.989: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:04.989: INFO: Found 0 / 1
Aug 27 05:51:06.001: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:06.001: INFO: Found 0 / 1
Aug 27 05:51:06.981: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:06.981: INFO: Found 0 / 1
Aug 27 05:51:07.981: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:07.981: INFO: Found 0 / 1
Aug 27 05:51:08.978: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:08.978: INFO: Found 0 / 1
Aug 27 05:51:09.986: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:09.986: INFO: Found 1 / 1
Aug 27 05:51:09.986: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 08/27/22 05:51:09.986
Aug 27 05:51:09.999: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:09.999: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 05:51:09.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-9861 patch pod agnhost-primary-6b2s4 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 27 05:51:10.171: INFO: stderr: ""
Aug 27 05:51:10.171: INFO: stdout: "pod/agnhost-primary-6b2s4 patched\n"
STEP: checking annotations 08/27/22 05:51:10.172
Aug 27 05:51:10.177: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 05:51:10.177: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 05:51:10.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9861" for this suite. 08/27/22 05:51:10.207
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":57,"skipped":1092,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.040 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:01.188
    Aug 27 05:51:01.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 05:51:01.189
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:01.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:01.213
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 08/27/22 05:51:01.218
    Aug 27 05:51:01.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-9861 create -f -'
    Aug 27 05:51:01.965: INFO: stderr: ""
    Aug 27 05:51:01.965: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/27/22 05:51:01.965
    Aug 27 05:51:02.980: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:02.980: INFO: Found 0 / 1
    Aug 27 05:51:03.970: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:03.970: INFO: Found 0 / 1
    Aug 27 05:51:04.989: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:04.989: INFO: Found 0 / 1
    Aug 27 05:51:06.001: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:06.001: INFO: Found 0 / 1
    Aug 27 05:51:06.981: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:06.981: INFO: Found 0 / 1
    Aug 27 05:51:07.981: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:07.981: INFO: Found 0 / 1
    Aug 27 05:51:08.978: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:08.978: INFO: Found 0 / 1
    Aug 27 05:51:09.986: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:09.986: INFO: Found 1 / 1
    Aug 27 05:51:09.986: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 08/27/22 05:51:09.986
    Aug 27 05:51:09.999: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:09.999: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 27 05:51:09.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-9861 patch pod agnhost-primary-6b2s4 -p {"metadata":{"annotations":{"x":"y"}}}'
    Aug 27 05:51:10.171: INFO: stderr: ""
    Aug 27 05:51:10.171: INFO: stdout: "pod/agnhost-primary-6b2s4 patched\n"
    STEP: checking annotations 08/27/22 05:51:10.172
    Aug 27 05:51:10.177: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 05:51:10.177: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 05:51:10.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9861" for this suite. 08/27/22 05:51:10.207
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:10.229
Aug 27 05:51:10.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 05:51:10.23
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:10.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:10.286
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5705 08/27/22 05:51:10.325
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/27/22 05:51:10.379
STEP: creating service externalsvc in namespace services-5705 08/27/22 05:51:10.379
STEP: creating replication controller externalsvc in namespace services-5705 08/27/22 05:51:10.43
I0827 05:51:10.450384      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5705, replica count: 2
I0827 05:51:13.502501      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 05:51:16.502753      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 05:51:19.503985      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 08/27/22 05:51:19.507
Aug 27 05:51:19.521: INFO: Creating new exec pod
Aug 27 05:51:19.530: INFO: Waiting up to 5m0s for pod "execpods8wk2" in namespace "services-5705" to be "running"
Aug 27 05:51:19.539: INFO: Pod "execpods8wk2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.133618ms
Aug 27 05:51:21.542: INFO: Pod "execpods8wk2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011650393s
Aug 27 05:51:21.542: INFO: Pod "execpods8wk2" satisfied condition "running"
Aug 27 05:51:21.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5705 exec execpods8wk2 -- /bin/sh -x -c nslookup clusterip-service.services-5705.svc.cluster.local'
Aug 27 05:51:21.748: INFO: stderr: "+ nslookup clusterip-service.services-5705.svc.cluster.local\n"
Aug 27 05:51:21.748: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-5705.svc.cluster.local\tcanonical name = externalsvc.services-5705.svc.cluster.local.\nName:\texternalsvc.services-5705.svc.cluster.local\nAddress: 10.3.227.52\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5705, will wait for the garbage collector to delete the pods 08/27/22 05:51:21.748
Aug 27 05:51:21.807: INFO: Deleting ReplicationController externalsvc took: 4.618163ms
Aug 27 05:51:21.908: INFO: Terminating ReplicationController externalsvc pods took: 101.316305ms
Aug 27 05:51:23.825: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 05:51:23.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5705" for this suite. 08/27/22 05:51:23.861
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":58,"skipped":1099,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.645 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:10.229
    Aug 27 05:51:10.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 05:51:10.23
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:10.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:10.286
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5705 08/27/22 05:51:10.325
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/27/22 05:51:10.379
    STEP: creating service externalsvc in namespace services-5705 08/27/22 05:51:10.379
    STEP: creating replication controller externalsvc in namespace services-5705 08/27/22 05:51:10.43
    I0827 05:51:10.450384      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5705, replica count: 2
    I0827 05:51:13.502501      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0827 05:51:16.502753      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0827 05:51:19.503985      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 08/27/22 05:51:19.507
    Aug 27 05:51:19.521: INFO: Creating new exec pod
    Aug 27 05:51:19.530: INFO: Waiting up to 5m0s for pod "execpods8wk2" in namespace "services-5705" to be "running"
    Aug 27 05:51:19.539: INFO: Pod "execpods8wk2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.133618ms
    Aug 27 05:51:21.542: INFO: Pod "execpods8wk2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011650393s
    Aug 27 05:51:21.542: INFO: Pod "execpods8wk2" satisfied condition "running"
    Aug 27 05:51:21.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5705 exec execpods8wk2 -- /bin/sh -x -c nslookup clusterip-service.services-5705.svc.cluster.local'
    Aug 27 05:51:21.748: INFO: stderr: "+ nslookup clusterip-service.services-5705.svc.cluster.local\n"
    Aug 27 05:51:21.748: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-5705.svc.cluster.local\tcanonical name = externalsvc.services-5705.svc.cluster.local.\nName:\texternalsvc.services-5705.svc.cluster.local\nAddress: 10.3.227.52\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-5705, will wait for the garbage collector to delete the pods 08/27/22 05:51:21.748
    Aug 27 05:51:21.807: INFO: Deleting ReplicationController externalsvc took: 4.618163ms
    Aug 27 05:51:21.908: INFO: Terminating ReplicationController externalsvc pods took: 101.316305ms
    Aug 27 05:51:23.825: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 05:51:23.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5705" for this suite. 08/27/22 05:51:23.861
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:23.879
Aug 27 05:51:23.879: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 05:51:23.88
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:23.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:23.908
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 08/27/22 05:51:23.912
Aug 27 05:51:23.918: INFO: Waiting up to 5m0s for pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232" in namespace "emptydir-1550" to be "Succeeded or Failed"
Aug 27 05:51:23.922: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232": Phase="Pending", Reason="", readiness=false. Elapsed: 4.328301ms
Aug 27 05:51:25.926: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008160815s
Aug 27 05:51:27.925: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007629836s
STEP: Saw pod success 08/27/22 05:51:27.926
Aug 27 05:51:27.926: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232" satisfied condition "Succeeded or Failed"
Aug 27 05:51:27.928: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232 container test-container: <nil>
STEP: delete the pod 08/27/22 05:51:27.946
Aug 27 05:51:27.956: INFO: Waiting for pod pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232 to disappear
Aug 27 05:51:27.958: INFO: Pod pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 05:51:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1550" for this suite. 08/27/22 05:51:27.961
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":59,"skipped":1128,"failed":0}
------------------------------
â€¢ [4.086 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:23.879
    Aug 27 05:51:23.879: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 05:51:23.88
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:23.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:23.908
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 08/27/22 05:51:23.912
    Aug 27 05:51:23.918: INFO: Waiting up to 5m0s for pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232" in namespace "emptydir-1550" to be "Succeeded or Failed"
    Aug 27 05:51:23.922: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232": Phase="Pending", Reason="", readiness=false. Elapsed: 4.328301ms
    Aug 27 05:51:25.926: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008160815s
    Aug 27 05:51:27.925: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007629836s
    STEP: Saw pod success 08/27/22 05:51:27.926
    Aug 27 05:51:27.926: INFO: Pod "pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232" satisfied condition "Succeeded or Failed"
    Aug 27 05:51:27.928: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232 container test-container: <nil>
    STEP: delete the pod 08/27/22 05:51:27.946
    Aug 27 05:51:27.956: INFO: Waiting for pod pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232 to disappear
    Aug 27 05:51:27.958: INFO: Pod pod-0dcdb81d-64a4-44be-9b74-7a58d6bc3232 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 05:51:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1550" for this suite. 08/27/22 05:51:27.961
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:27.967
Aug 27 05:51:27.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename limitrange 08/27/22 05:51:27.968
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:27.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:27.988
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 08/27/22 05:51:27.994
STEP: Setting up watch 08/27/22 05:51:27.995
STEP: Submitting a LimitRange 08/27/22 05:51:28.099
STEP: Verifying LimitRange creation was observed 08/27/22 05:51:28.106
STEP: Fetching the LimitRange to ensure it has proper values 08/27/22 05:51:28.106
Aug 27 05:51:28.109: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 27 05:51:28.109: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 08/27/22 05:51:28.109
STEP: Ensuring Pod has resource requirements applied from LimitRange 08/27/22 05:51:28.115
Aug 27 05:51:28.121: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 27 05:51:28.122: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 08/27/22 05:51:28.122
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 08/27/22 05:51:28.131
Aug 27 05:51:28.137: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Aug 27 05:51:28.137: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 08/27/22 05:51:28.137
STEP: Failing to create a Pod with more than max resources 08/27/22 05:51:28.148
STEP: Updating a LimitRange 08/27/22 05:51:28.15
STEP: Verifying LimitRange updating is effective 08/27/22 05:51:28.155
STEP: Creating a Pod with less than former min resources 08/27/22 05:51:30.159
STEP: Failing to create a Pod with more than max resources 08/27/22 05:51:30.168
STEP: Deleting a LimitRange 08/27/22 05:51:30.175
STEP: Verifying the LimitRange was deleted 08/27/22 05:51:30.188
Aug 27 05:51:35.196: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 08/27/22 05:51:35.196
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Aug 27 05:51:35.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-168" for this suite. 08/27/22 05:51:35.214
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":60,"skipped":1136,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.261 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:27.967
    Aug 27 05:51:27.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename limitrange 08/27/22 05:51:27.968
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:27.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:27.988
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 08/27/22 05:51:27.994
    STEP: Setting up watch 08/27/22 05:51:27.995
    STEP: Submitting a LimitRange 08/27/22 05:51:28.099
    STEP: Verifying LimitRange creation was observed 08/27/22 05:51:28.106
    STEP: Fetching the LimitRange to ensure it has proper values 08/27/22 05:51:28.106
    Aug 27 05:51:28.109: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Aug 27 05:51:28.109: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 08/27/22 05:51:28.109
    STEP: Ensuring Pod has resource requirements applied from LimitRange 08/27/22 05:51:28.115
    Aug 27 05:51:28.121: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Aug 27 05:51:28.122: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 08/27/22 05:51:28.122
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 08/27/22 05:51:28.131
    Aug 27 05:51:28.137: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Aug 27 05:51:28.137: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 08/27/22 05:51:28.137
    STEP: Failing to create a Pod with more than max resources 08/27/22 05:51:28.148
    STEP: Updating a LimitRange 08/27/22 05:51:28.15
    STEP: Verifying LimitRange updating is effective 08/27/22 05:51:28.155
    STEP: Creating a Pod with less than former min resources 08/27/22 05:51:30.159
    STEP: Failing to create a Pod with more than max resources 08/27/22 05:51:30.168
    STEP: Deleting a LimitRange 08/27/22 05:51:30.175
    STEP: Verifying the LimitRange was deleted 08/27/22 05:51:30.188
    Aug 27 05:51:35.196: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 08/27/22 05:51:35.196
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Aug 27 05:51:35.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-168" for this suite. 08/27/22 05:51:35.214
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:35.233
Aug 27 05:51:35.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 05:51:35.234
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:35.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:35.259
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 08/27/22 05:51:35.262
Aug 27 05:51:35.269: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d" in namespace "emptydir-3909" to be "running"
Aug 27 05:51:35.274: INFO: Pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.096811ms
Aug 27 05:51:37.279: INFO: Pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d": Phase="Running", Reason="", readiness=false. Elapsed: 2.009878729s
Aug 27 05:51:37.279: INFO: Pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d" satisfied condition "running"
STEP: Reading file content from the nginx-container 08/27/22 05:51:37.279
Aug 27 05:51:37.279: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3909 PodName:pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:51:37.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:51:37.280: INFO: ExecWithOptions: Clientset creation
Aug 27 05:51:37.280: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/emptydir-3909/pods/pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Aug 27 05:51:37.346: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 05:51:37.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3909" for this suite. 08/27/22 05:51:37.356
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":61,"skipped":1156,"failed":0}
------------------------------
â€¢ [2.129 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:35.233
    Aug 27 05:51:35.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 05:51:35.234
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:35.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:35.259
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 08/27/22 05:51:35.262
    Aug 27 05:51:35.269: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d" in namespace "emptydir-3909" to be "running"
    Aug 27 05:51:35.274: INFO: Pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.096811ms
    Aug 27 05:51:37.279: INFO: Pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d": Phase="Running", Reason="", readiness=false. Elapsed: 2.009878729s
    Aug 27 05:51:37.279: INFO: Pod "pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d" satisfied condition "running"
    STEP: Reading file content from the nginx-container 08/27/22 05:51:37.279
    Aug 27 05:51:37.279: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3909 PodName:pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:51:37.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:51:37.280: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:51:37.280: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/emptydir-3909/pods/pod-sharedvolume-5d26770e-bdfb-434e-bcaf-f3376bdb3a8d/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Aug 27 05:51:37.346: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 05:51:37.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3909" for this suite. 08/27/22 05:51:37.356
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:37.363
Aug 27 05:51:37.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename endpointslice 08/27/22 05:51:37.364
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:37.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:37.407
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 27 05:51:37.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7534" for this suite. 08/27/22 05:51:37.532
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":62,"skipped":1159,"failed":0}
------------------------------
â€¢ [0.182 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:37.363
    Aug 27 05:51:37.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename endpointslice 08/27/22 05:51:37.364
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:37.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:37.407
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 27 05:51:37.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7534" for this suite. 08/27/22 05:51:37.532
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:37.546
Aug 27 05:51:37.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename conformance-tests 08/27/22 05:51:37.547
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:37.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:37.617
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 08/27/22 05:51:37.635
Aug 27 05:51:37.636: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Aug 27 05:51:37.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-3200" for this suite. 08/27/22 05:51:37.689
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":63,"skipped":1162,"failed":0}
------------------------------
â€¢ [0.162 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:37.546
    Aug 27 05:51:37.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename conformance-tests 08/27/22 05:51:37.547
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:37.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:37.617
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 08/27/22 05:51:37.635
    Aug 27 05:51:37.636: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Aug 27 05:51:37.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-3200" for this suite. 08/27/22 05:51:37.689
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:51:37.762
Aug 27 05:51:37.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename subpath 08/27/22 05:51:37.764
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:37.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:37.812
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/27/22 05:51:37.82
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-2n4p 08/27/22 05:51:37.835
STEP: Creating a pod to test atomic-volume-subpath 08/27/22 05:51:37.835
Aug 27 05:51:37.842: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2n4p" in namespace "subpath-3943" to be "Succeeded or Failed"
Aug 27 05:51:37.848: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034046ms
Aug 27 05:51:39.851: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 2.009375362s
Aug 27 05:51:41.851: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 4.009225211s
Aug 27 05:51:43.852: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 6.009830764s
Aug 27 05:51:45.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 8.010857993s
Aug 27 05:51:47.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 10.011092601s
Aug 27 05:51:49.851: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 12.009492753s
Aug 27 05:51:51.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 14.010890799s
Aug 27 05:51:53.852: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 16.009899191s
Aug 27 05:51:55.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 18.01140314s
Aug 27 05:51:57.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 20.010930174s
Aug 27 05:51:59.852: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=false. Elapsed: 22.010180593s
Aug 27 05:52:01.871: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029422296s
STEP: Saw pod success 08/27/22 05:52:01.872
Aug 27 05:52:01.872: INFO: Pod "pod-subpath-test-secret-2n4p" satisfied condition "Succeeded or Failed"
Aug 27 05:52:01.895: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-subpath-test-secret-2n4p container test-container-subpath-secret-2n4p: <nil>
STEP: delete the pod 08/27/22 05:52:01.957
Aug 27 05:52:02.049: INFO: Waiting for pod pod-subpath-test-secret-2n4p to disappear
Aug 27 05:52:02.060: INFO: Pod pod-subpath-test-secret-2n4p no longer exists
STEP: Deleting pod pod-subpath-test-secret-2n4p 08/27/22 05:52:02.06
Aug 27 05:52:02.060: INFO: Deleting pod "pod-subpath-test-secret-2n4p" in namespace "subpath-3943"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 27 05:52:02.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3943" for this suite. 08/27/22 05:52:02.079
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":64,"skipped":1198,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.329 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:51:37.762
    Aug 27 05:51:37.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename subpath 08/27/22 05:51:37.764
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:51:37.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:51:37.812
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/27/22 05:51:37.82
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-2n4p 08/27/22 05:51:37.835
    STEP: Creating a pod to test atomic-volume-subpath 08/27/22 05:51:37.835
    Aug 27 05:51:37.842: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2n4p" in namespace "subpath-3943" to be "Succeeded or Failed"
    Aug 27 05:51:37.848: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034046ms
    Aug 27 05:51:39.851: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 2.009375362s
    Aug 27 05:51:41.851: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 4.009225211s
    Aug 27 05:51:43.852: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 6.009830764s
    Aug 27 05:51:45.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 8.010857993s
    Aug 27 05:51:47.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 10.011092601s
    Aug 27 05:51:49.851: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 12.009492753s
    Aug 27 05:51:51.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 14.010890799s
    Aug 27 05:51:53.852: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 16.009899191s
    Aug 27 05:51:55.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 18.01140314s
    Aug 27 05:51:57.853: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=true. Elapsed: 20.010930174s
    Aug 27 05:51:59.852: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Running", Reason="", readiness=false. Elapsed: 22.010180593s
    Aug 27 05:52:01.871: INFO: Pod "pod-subpath-test-secret-2n4p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029422296s
    STEP: Saw pod success 08/27/22 05:52:01.872
    Aug 27 05:52:01.872: INFO: Pod "pod-subpath-test-secret-2n4p" satisfied condition "Succeeded or Failed"
    Aug 27 05:52:01.895: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-subpath-test-secret-2n4p container test-container-subpath-secret-2n4p: <nil>
    STEP: delete the pod 08/27/22 05:52:01.957
    Aug 27 05:52:02.049: INFO: Waiting for pod pod-subpath-test-secret-2n4p to disappear
    Aug 27 05:52:02.060: INFO: Pod pod-subpath-test-secret-2n4p no longer exists
    STEP: Deleting pod pod-subpath-test-secret-2n4p 08/27/22 05:52:02.06
    Aug 27 05:52:02.060: INFO: Deleting pod "pod-subpath-test-secret-2n4p" in namespace "subpath-3943"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 27 05:52:02.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3943" for this suite. 08/27/22 05:52:02.079
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:52:02.093
Aug 27 05:52:02.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 05:52:02.099
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:52:02.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:52:02.159
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2679 08/27/22 05:52:02.164
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 08/27/22 05:52:02.173
Aug 27 05:52:02.261: INFO: Found 0 stateful pods, waiting for 3
Aug 27 05:52:12.269: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 05:52:12.270: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 05:52:12.270: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/27/22 05:52:12.293
Aug 27 05:52:12.323: INFO: Updating stateful set ss2
STEP: Creating a new revision 08/27/22 05:52:12.323
STEP: Not applying an update when the partition is greater than the number of replicas 08/27/22 05:52:22.344
STEP: Performing a canary update 08/27/22 05:52:22.344
Aug 27 05:52:22.364: INFO: Updating stateful set ss2
Aug 27 05:52:22.372: INFO: Waiting for Pod statefulset-2679/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 08/27/22 05:52:32.379
Aug 27 05:52:32.440: INFO: Found 1 stateful pods, waiting for 3
Aug 27 05:52:42.445: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 05:52:42.446: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 05:52:42.446: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 08/27/22 05:52:42.451
Aug 27 05:52:42.476: INFO: Updating stateful set ss2
Aug 27 05:52:42.495: INFO: Waiting for Pod statefulset-2679/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Aug 27 05:52:52.523: INFO: Updating stateful set ss2
Aug 27 05:52:52.533: INFO: Waiting for StatefulSet statefulset-2679/ss2 to complete update
Aug 27 05:52:52.533: INFO: Waiting for Pod statefulset-2679/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 05:53:02.541: INFO: Deleting all statefulset in ns statefulset-2679
Aug 27 05:53:02.547: INFO: Scaling statefulset ss2 to 0
Aug 27 05:53:12.582: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 05:53:12.588: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 05:53:12.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2679" for this suite. 08/27/22 05:53:12.617
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":65,"skipped":1209,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.547 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:52:02.093
    Aug 27 05:52:02.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 05:52:02.099
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:52:02.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:52:02.159
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2679 08/27/22 05:52:02.164
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 08/27/22 05:52:02.173
    Aug 27 05:52:02.261: INFO: Found 0 stateful pods, waiting for 3
    Aug 27 05:52:12.269: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 05:52:12.270: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 05:52:12.270: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/27/22 05:52:12.293
    Aug 27 05:52:12.323: INFO: Updating stateful set ss2
    STEP: Creating a new revision 08/27/22 05:52:12.323
    STEP: Not applying an update when the partition is greater than the number of replicas 08/27/22 05:52:22.344
    STEP: Performing a canary update 08/27/22 05:52:22.344
    Aug 27 05:52:22.364: INFO: Updating stateful set ss2
    Aug 27 05:52:22.372: INFO: Waiting for Pod statefulset-2679/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 08/27/22 05:52:32.379
    Aug 27 05:52:32.440: INFO: Found 1 stateful pods, waiting for 3
    Aug 27 05:52:42.445: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 05:52:42.446: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 05:52:42.446: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 08/27/22 05:52:42.451
    Aug 27 05:52:42.476: INFO: Updating stateful set ss2
    Aug 27 05:52:42.495: INFO: Waiting for Pod statefulset-2679/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Aug 27 05:52:52.523: INFO: Updating stateful set ss2
    Aug 27 05:52:52.533: INFO: Waiting for StatefulSet statefulset-2679/ss2 to complete update
    Aug 27 05:52:52.533: INFO: Waiting for Pod statefulset-2679/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 05:53:02.541: INFO: Deleting all statefulset in ns statefulset-2679
    Aug 27 05:53:02.547: INFO: Scaling statefulset ss2 to 0
    Aug 27 05:53:12.582: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 05:53:12.588: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 05:53:12.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2679" for this suite. 08/27/22 05:53:12.617
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:53:12.642
Aug 27 05:53:12.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 05:53:12.644
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:12.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:12.683
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 08/27/22 05:53:12.692
Aug 27 05:53:12.702: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc" in namespace "downward-api-5924" to be "Succeeded or Failed"
Aug 27 05:53:12.717: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.371202ms
Aug 27 05:53:14.721: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018933301s
Aug 27 05:53:16.723: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021060139s
STEP: Saw pod success 08/27/22 05:53:16.724
Aug 27 05:53:16.724: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc" satisfied condition "Succeeded or Failed"
Aug 27 05:53:16.729: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc container client-container: <nil>
STEP: delete the pod 08/27/22 05:53:16.757
Aug 27 05:53:16.777: INFO: Waiting for pod downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc to disappear
Aug 27 05:53:16.797: INFO: Pod downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 05:53:16.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5924" for this suite. 08/27/22 05:53:16.806
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":66,"skipped":1213,"failed":0}
------------------------------
â€¢ [4.179 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:53:12.642
    Aug 27 05:53:12.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 05:53:12.644
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:12.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:12.683
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 08/27/22 05:53:12.692
    Aug 27 05:53:12.702: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc" in namespace "downward-api-5924" to be "Succeeded or Failed"
    Aug 27 05:53:12.717: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.371202ms
    Aug 27 05:53:14.721: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018933301s
    Aug 27 05:53:16.723: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021060139s
    STEP: Saw pod success 08/27/22 05:53:16.724
    Aug 27 05:53:16.724: INFO: Pod "downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc" satisfied condition "Succeeded or Failed"
    Aug 27 05:53:16.729: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc container client-container: <nil>
    STEP: delete the pod 08/27/22 05:53:16.757
    Aug 27 05:53:16.777: INFO: Waiting for pod downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc to disappear
    Aug 27 05:53:16.797: INFO: Pod downwardapi-volume-45cb7c0e-03de-4b5c-a969-6f822faf1fcc no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 05:53:16.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5924" for this suite. 08/27/22 05:53:16.806
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:53:16.828
Aug 27 05:53:16.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:53:16.83
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:16.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:16.854
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:53:16.895
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:53:17.717
STEP: Deploying the webhook pod 08/27/22 05:53:17.724
STEP: Wait for the deployment to be ready 08/27/22 05:53:17.735
Aug 27 05:53:17.741: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/27/22 05:53:19.752
STEP: Verifying the service has paired with the endpoint 08/27/22 05:53:19.759
Aug 27 05:53:20.760: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 08/27/22 05:53:20.762
STEP: create a pod that should be denied by the webhook 08/27/22 05:53:20.779
STEP: create a pod that causes the webhook to hang 08/27/22 05:53:20.791
STEP: create a configmap that should be denied by the webhook 08/27/22 05:53:30.798
STEP: create a configmap that should be admitted by the webhook 08/27/22 05:53:30.814
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 08/27/22 05:53:30.828
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 08/27/22 05:53:30.843
STEP: create a namespace that bypass the webhook 08/27/22 05:53:30.85
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 08/27/22 05:53:30.857
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:53:30.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3153" for this suite. 08/27/22 05:53:30.914
STEP: Destroying namespace "webhook-3153-markers" for this suite. 08/27/22 05:53:30.919
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":67,"skipped":1245,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.179 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:53:16.828
    Aug 27 05:53:16.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:53:16.83
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:16.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:16.854
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:53:16.895
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:53:17.717
    STEP: Deploying the webhook pod 08/27/22 05:53:17.724
    STEP: Wait for the deployment to be ready 08/27/22 05:53:17.735
    Aug 27 05:53:17.741: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/27/22 05:53:19.752
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:53:19.759
    Aug 27 05:53:20.760: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 08/27/22 05:53:20.762
    STEP: create a pod that should be denied by the webhook 08/27/22 05:53:20.779
    STEP: create a pod that causes the webhook to hang 08/27/22 05:53:20.791
    STEP: create a configmap that should be denied by the webhook 08/27/22 05:53:30.798
    STEP: create a configmap that should be admitted by the webhook 08/27/22 05:53:30.814
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 08/27/22 05:53:30.828
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 08/27/22 05:53:30.843
    STEP: create a namespace that bypass the webhook 08/27/22 05:53:30.85
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 08/27/22 05:53:30.857
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:53:30.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3153" for this suite. 08/27/22 05:53:30.914
    STEP: Destroying namespace "webhook-3153-markers" for this suite. 08/27/22 05:53:30.919
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:53:31.008
Aug 27 05:53:31.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename security-context-test 08/27/22 05:53:31.009
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:31.059
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:31.071
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Aug 27 05:53:31.088: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f" in namespace "security-context-test-4774" to be "Succeeded or Failed"
Aug 27 05:53:31.093: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.290993ms
Aug 27 05:53:33.098: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009472078s
Aug 27 05:53:35.100: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011985817s
Aug 27 05:53:35.101: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f" satisfied condition "Succeeded or Failed"
Aug 27 05:53:35.110: INFO: Got logs for pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 27 05:53:35.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4774" for this suite. 08/27/22 05:53:35.114
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":68,"skipped":1249,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:53:31.008
    Aug 27 05:53:31.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename security-context-test 08/27/22 05:53:31.009
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:31.059
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:31.071
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Aug 27 05:53:31.088: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f" in namespace "security-context-test-4774" to be "Succeeded or Failed"
    Aug 27 05:53:31.093: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.290993ms
    Aug 27 05:53:33.098: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009472078s
    Aug 27 05:53:35.100: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011985817s
    Aug 27 05:53:35.101: INFO: Pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f" satisfied condition "Succeeded or Failed"
    Aug 27 05:53:35.110: INFO: Got logs for pod "busybox-privileged-false-fbf388b0-ea67-46e2-8cab-db3439defc3f": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 27 05:53:35.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4774" for this suite. 08/27/22 05:53:35.114
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:53:35.124
Aug 27 05:53:35.124: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:53:35.125
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:35.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:35.234
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-9d1cd581-aac3-4f68-8123-53906065c149 08/27/22 05:53:35.238
STEP: Creating a pod to test consume configMaps 08/27/22 05:53:35.244
Aug 27 05:53:35.256: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1" in namespace "projected-6265" to be "Succeeded or Failed"
Aug 27 05:53:35.370: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1": Phase="Pending", Reason="", readiness=false. Elapsed: 113.395171ms
Aug 27 05:53:37.373: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1": Phase="Running", Reason="", readiness=false. Elapsed: 2.117247159s
Aug 27 05:53:39.374: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118368614s
STEP: Saw pod success 08/27/22 05:53:39.375
Aug 27 05:53:39.375: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1" satisfied condition "Succeeded or Failed"
Aug 27 05:53:39.379: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 05:53:39.384
Aug 27 05:53:39.393: INFO: Waiting for pod pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1 to disappear
Aug 27 05:53:39.395: INFO: Pod pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 05:53:39.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6265" for this suite. 08/27/22 05:53:39.398
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":69,"skipped":1256,"failed":0}
------------------------------
â€¢ [4.279 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:53:35.124
    Aug 27 05:53:35.124: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:53:35.125
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:35.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:35.234
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-9d1cd581-aac3-4f68-8123-53906065c149 08/27/22 05:53:35.238
    STEP: Creating a pod to test consume configMaps 08/27/22 05:53:35.244
    Aug 27 05:53:35.256: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1" in namespace "projected-6265" to be "Succeeded or Failed"
    Aug 27 05:53:35.370: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1": Phase="Pending", Reason="", readiness=false. Elapsed: 113.395171ms
    Aug 27 05:53:37.373: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1": Phase="Running", Reason="", readiness=false. Elapsed: 2.117247159s
    Aug 27 05:53:39.374: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118368614s
    STEP: Saw pod success 08/27/22 05:53:39.375
    Aug 27 05:53:39.375: INFO: Pod "pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1" satisfied condition "Succeeded or Failed"
    Aug 27 05:53:39.379: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 05:53:39.384
    Aug 27 05:53:39.393: INFO: Waiting for pod pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1 to disappear
    Aug 27 05:53:39.395: INFO: Pod pod-projected-configmaps-c6212095-61c9-46a9-a251-39a22e8e14f1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 05:53:39.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6265" for this suite. 08/27/22 05:53:39.398
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:53:39.405
Aug 27 05:53:39.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 05:53:39.406
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:39.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:39.426
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 08/27/22 05:53:39.429
Aug 27 05:53:39.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:53:41.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:53:54.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5125" for this suite. 08/27/22 05:53:54.121
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":70,"skipped":1279,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.721 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:53:39.405
    Aug 27 05:53:39.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 05:53:39.406
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:39.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:39.426
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 08/27/22 05:53:39.429
    Aug 27 05:53:39.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:53:41.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:53:54.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5125" for this suite. 08/27/22 05:53:54.121
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:53:54.128
Aug 27 05:53:54.128: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:53:54.129
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:54.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:54.149
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:53:54.164
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:53:54.711
STEP: Deploying the webhook pod 08/27/22 05:53:54.725
STEP: Wait for the deployment to be ready 08/27/22 05:53:54.739
Aug 27 05:53:54.752: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/27/22 05:53:56.761
STEP: Verifying the service has paired with the endpoint 08/27/22 05:53:56.769
Aug 27 05:53:57.769: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Aug 27 05:53:57.773: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9841-crds.webhook.example.com via the AdmissionRegistration API 08/27/22 05:53:58.287
STEP: Creating a custom resource that should be mutated by the webhook 08/27/22 05:53:58.302
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:54:00.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3681" for this suite. 08/27/22 05:54:00.908
STEP: Destroying namespace "webhook-3681-markers" for this suite. 08/27/22 05:54:00.914
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":71,"skipped":1296,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.867 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:53:54.128
    Aug 27 05:53:54.128: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:53:54.129
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:53:54.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:53:54.149
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:53:54.164
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:53:54.711
    STEP: Deploying the webhook pod 08/27/22 05:53:54.725
    STEP: Wait for the deployment to be ready 08/27/22 05:53:54.739
    Aug 27 05:53:54.752: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/27/22 05:53:56.761
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:53:56.769
    Aug 27 05:53:57.769: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Aug 27 05:53:57.773: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9841-crds.webhook.example.com via the AdmissionRegistration API 08/27/22 05:53:58.287
    STEP: Creating a custom resource that should be mutated by the webhook 08/27/22 05:53:58.302
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:54:00.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3681" for this suite. 08/27/22 05:54:00.908
    STEP: Destroying namespace "webhook-3681-markers" for this suite. 08/27/22 05:54:00.914
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:54:00.996
Aug 27 05:54:00.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 05:54:00.997
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:01.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:01.046
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 08/27/22 05:54:01.055
STEP: Getting a ResourceQuota 08/27/22 05:54:01.06
STEP: Listing all ResourceQuotas with LabelSelector 08/27/22 05:54:01.067
STEP: Patching the ResourceQuota 08/27/22 05:54:01.071
STEP: Deleting a Collection of ResourceQuotas 08/27/22 05:54:01.079
STEP: Verifying the deleted ResourceQuota 08/27/22 05:54:01.092
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 05:54:01.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4396" for this suite. 08/27/22 05:54:01.104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":72,"skipped":1309,"failed":0}
------------------------------
â€¢ [0.265 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:54:00.996
    Aug 27 05:54:00.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 05:54:00.997
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:01.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:01.046
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 08/27/22 05:54:01.055
    STEP: Getting a ResourceQuota 08/27/22 05:54:01.06
    STEP: Listing all ResourceQuotas with LabelSelector 08/27/22 05:54:01.067
    STEP: Patching the ResourceQuota 08/27/22 05:54:01.071
    STEP: Deleting a Collection of ResourceQuotas 08/27/22 05:54:01.079
    STEP: Verifying the deleted ResourceQuota 08/27/22 05:54:01.092
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 05:54:01.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4396" for this suite. 08/27/22 05:54:01.104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:54:01.263
Aug 27 05:54:01.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 05:54:01.267
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:01.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:01.426
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-28a7856f-c51a-4877-938a-694adbb6b70d 08/27/22 05:54:01.434
STEP: Creating a pod to test consume configMaps 08/27/22 05:54:01.441
Aug 27 05:54:01.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe" in namespace "configmap-4845" to be "Succeeded or Failed"
Aug 27 05:54:01.453: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1673ms
Aug 27 05:54:03.457: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008979226s
Aug 27 05:54:05.494: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045099981s
STEP: Saw pod success 08/27/22 05:54:05.494
Aug 27 05:54:05.494: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe" satisfied condition "Succeeded or Failed"
Aug 27 05:54:05.515: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe container agnhost-container: <nil>
STEP: delete the pod 08/27/22 05:54:05.527
Aug 27 05:54:05.540: INFO: Waiting for pod pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe to disappear
Aug 27 05:54:05.543: INFO: Pod pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 05:54:05.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4845" for this suite. 08/27/22 05:54:05.548
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":73,"skipped":1382,"failed":0}
------------------------------
â€¢ [4.289 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:54:01.263
    Aug 27 05:54:01.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 05:54:01.267
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:01.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:01.426
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-28a7856f-c51a-4877-938a-694adbb6b70d 08/27/22 05:54:01.434
    STEP: Creating a pod to test consume configMaps 08/27/22 05:54:01.441
    Aug 27 05:54:01.448: INFO: Waiting up to 5m0s for pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe" in namespace "configmap-4845" to be "Succeeded or Failed"
    Aug 27 05:54:01.453: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1673ms
    Aug 27 05:54:03.457: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008979226s
    Aug 27 05:54:05.494: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045099981s
    STEP: Saw pod success 08/27/22 05:54:05.494
    Aug 27 05:54:05.494: INFO: Pod "pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe" satisfied condition "Succeeded or Failed"
    Aug 27 05:54:05.515: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 05:54:05.527
    Aug 27 05:54:05.540: INFO: Waiting for pod pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe to disappear
    Aug 27 05:54:05.543: INFO: Pod pod-configmaps-c27709c6-492a-408d-a795-364e43f036fe no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 05:54:05.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4845" for this suite. 08/27/22 05:54:05.548
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:54:05.561
Aug 27 05:54:05.561: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:54:05.562
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:05.59
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:05.595
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-2eac615a-d316-402f-b13d-76ad2921d8f6 08/27/22 05:54:05.6
STEP: Creating a pod to test consume configMaps 08/27/22 05:54:05.605
Aug 27 05:54:05.618: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5" in namespace "projected-7510" to be "Succeeded or Failed"
Aug 27 05:54:05.627: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.124029ms
Aug 27 05:54:07.653: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035625005s
Aug 27 05:54:09.633: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015664037s
STEP: Saw pod success 08/27/22 05:54:09.633
Aug 27 05:54:09.634: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5" satisfied condition "Succeeded or Failed"
Aug 27 05:54:09.637: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 05:54:09.643
Aug 27 05:54:09.654: INFO: Waiting for pod pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5 to disappear
Aug 27 05:54:09.659: INFO: Pod pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 05:54:09.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7510" for this suite. 08/27/22 05:54:09.662
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":74,"skipped":1430,"failed":0}
------------------------------
â€¢ [4.106 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:54:05.561
    Aug 27 05:54:05.561: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:54:05.562
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:05.59
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:05.595
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-2eac615a-d316-402f-b13d-76ad2921d8f6 08/27/22 05:54:05.6
    STEP: Creating a pod to test consume configMaps 08/27/22 05:54:05.605
    Aug 27 05:54:05.618: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5" in namespace "projected-7510" to be "Succeeded or Failed"
    Aug 27 05:54:05.627: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.124029ms
    Aug 27 05:54:07.653: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035625005s
    Aug 27 05:54:09.633: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015664037s
    STEP: Saw pod success 08/27/22 05:54:09.633
    Aug 27 05:54:09.634: INFO: Pod "pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5" satisfied condition "Succeeded or Failed"
    Aug 27 05:54:09.637: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 05:54:09.643
    Aug 27 05:54:09.654: INFO: Waiting for pod pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5 to disappear
    Aug 27 05:54:09.659: INFO: Pod pod-projected-configmaps-02507389-50f7-4767-949a-b8b6c2e5c6e5 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 05:54:09.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7510" for this suite. 08/27/22 05:54:09.662
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:54:09.669
Aug 27 05:54:09.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-preemption 08/27/22 05:54:09.67
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:09.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:09.694
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 27 05:54:09.711: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 05:55:09.740: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 08/27/22 05:55:09.744
Aug 27 05:55:09.766: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 27 05:55:09.784: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 27 05:55:09.844: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 27 05:55:09.879: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 08/27/22 05:55:09.879
Aug 27 05:55:09.879: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8082" to be "running"
Aug 27 05:55:09.913: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 34.067247ms
Aug 27 05:55:11.930: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.0504015s
Aug 27 05:55:11.930: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Aug 27 05:55:11.930: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8082" to be "running"
Aug 27 05:55:11.934: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.763993ms
Aug 27 05:55:11.934: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Aug 27 05:55:11.934: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8082" to be "running"
Aug 27 05:55:11.937: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.093377ms
Aug 27 05:55:13.941: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.00706555s
Aug 27 05:55:13.941: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Aug 27 05:55:13.941: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8082" to be "running"
Aug 27 05:55:13.948: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.022922ms
Aug 27 05:55:13.948: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 08/27/22 05:55:13.948
Aug 27 05:55:13.956: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Aug 27 05:55:13.961: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.681239ms
Aug 27 05:55:15.966: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010075146s
Aug 27 05:55:17.966: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009732578s
Aug 27 05:55:17.966: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 27 05:55:18.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8082" for this suite. 08/27/22 05:55:18.019
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":75,"skipped":1437,"failed":0}
------------------------------
â€¢ [SLOW TEST] [68.391 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:54:09.669
    Aug 27 05:54:09.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-preemption 08/27/22 05:54:09.67
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:54:09.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:54:09.694
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 27 05:54:09.711: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 27 05:55:09.740: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 08/27/22 05:55:09.744
    Aug 27 05:55:09.766: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Aug 27 05:55:09.784: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Aug 27 05:55:09.844: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Aug 27 05:55:09.879: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 08/27/22 05:55:09.879
    Aug 27 05:55:09.879: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8082" to be "running"
    Aug 27 05:55:09.913: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 34.067247ms
    Aug 27 05:55:11.930: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.0504015s
    Aug 27 05:55:11.930: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Aug 27 05:55:11.930: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8082" to be "running"
    Aug 27 05:55:11.934: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.763993ms
    Aug 27 05:55:11.934: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Aug 27 05:55:11.934: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8082" to be "running"
    Aug 27 05:55:11.937: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.093377ms
    Aug 27 05:55:13.941: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.00706555s
    Aug 27 05:55:13.941: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Aug 27 05:55:13.941: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8082" to be "running"
    Aug 27 05:55:13.948: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.022922ms
    Aug 27 05:55:13.948: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 08/27/22 05:55:13.948
    Aug 27 05:55:13.956: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Aug 27 05:55:13.961: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.681239ms
    Aug 27 05:55:15.966: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010075146s
    Aug 27 05:55:17.966: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009732578s
    Aug 27 05:55:17.966: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 05:55:18.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8082" for this suite. 08/27/22 05:55:18.019
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:55:18.064
Aug 27 05:55:18.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 05:55:18.065
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:18.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:18.101
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-ba65e205-464b-4dfc-8514-92d2abf7d4ea 08/27/22 05:55:18.105
STEP: Creating a pod to test consume configMaps 08/27/22 05:55:18.109
Aug 27 05:55:18.117: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f" in namespace "projected-9991" to be "Succeeded or Failed"
Aug 27 05:55:18.120: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.470265ms
Aug 27 05:55:20.125: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008429881s
Aug 27 05:55:22.125: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007801132s
STEP: Saw pod success 08/27/22 05:55:22.125
Aug 27 05:55:22.125: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f" satisfied condition "Succeeded or Failed"
Aug 27 05:55:22.128: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f container agnhost-container: <nil>
STEP: delete the pod 08/27/22 05:55:22.141
Aug 27 05:55:22.151: INFO: Waiting for pod pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f to disappear
Aug 27 05:55:22.154: INFO: Pod pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 05:55:22.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9991" for this suite. 08/27/22 05:55:22.157
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":76,"skipped":1448,"failed":0}
------------------------------
â€¢ [4.098 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:55:18.064
    Aug 27 05:55:18.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 05:55:18.065
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:18.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:18.101
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-ba65e205-464b-4dfc-8514-92d2abf7d4ea 08/27/22 05:55:18.105
    STEP: Creating a pod to test consume configMaps 08/27/22 05:55:18.109
    Aug 27 05:55:18.117: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f" in namespace "projected-9991" to be "Succeeded or Failed"
    Aug 27 05:55:18.120: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.470265ms
    Aug 27 05:55:20.125: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008429881s
    Aug 27 05:55:22.125: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007801132s
    STEP: Saw pod success 08/27/22 05:55:22.125
    Aug 27 05:55:22.125: INFO: Pod "pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f" satisfied condition "Succeeded or Failed"
    Aug 27 05:55:22.128: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 05:55:22.141
    Aug 27 05:55:22.151: INFO: Waiting for pod pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f to disappear
    Aug 27 05:55:22.154: INFO: Pod pod-projected-configmaps-043de68e-08a5-4d3b-ab51-11945cb3c90f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 05:55:22.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9991" for this suite. 08/27/22 05:55:22.157
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:55:22.168
Aug 27 05:55:22.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replicaset 08/27/22 05:55:22.169
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:22.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:22.189
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 08/27/22 05:55:22.192
Aug 27 05:55:22.199: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 27 05:55:27.205: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/27/22 05:55:27.205
STEP: getting scale subresource 08/27/22 05:55:27.205
STEP: updating a scale subresource 08/27/22 05:55:27.211
STEP: verifying the replicaset Spec.Replicas was modified 08/27/22 05:55:27.221
STEP: Patch a scale subresource 08/27/22 05:55:27.226
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 27 05:55:27.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9254" for this suite. 08/27/22 05:55:27.265
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":77,"skipped":1502,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.120 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:55:22.168
    Aug 27 05:55:22.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replicaset 08/27/22 05:55:22.169
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:22.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:22.189
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 08/27/22 05:55:22.192
    Aug 27 05:55:22.199: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 27 05:55:27.205: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/27/22 05:55:27.205
    STEP: getting scale subresource 08/27/22 05:55:27.205
    STEP: updating a scale subresource 08/27/22 05:55:27.211
    STEP: verifying the replicaset Spec.Replicas was modified 08/27/22 05:55:27.221
    STEP: Patch a scale subresource 08/27/22 05:55:27.226
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 27 05:55:27.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9254" for this suite. 08/27/22 05:55:27.265
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:55:27.291
Aug 27 05:55:27.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:55:27.292
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:27.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:27.333
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:55:27.374
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:55:28.154
STEP: Deploying the webhook pod 08/27/22 05:55:28.158
STEP: Wait for the deployment to be ready 08/27/22 05:55:28.167
Aug 27 05:55:28.172: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/27/22 05:55:30.18
STEP: Verifying the service has paired with the endpoint 08/27/22 05:55:30.193
Aug 27 05:55:31.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 08/27/22 05:55:31.197
STEP: create a pod 08/27/22 05:55:31.214
Aug 27 05:55:31.220: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-6900" to be "running"
Aug 27 05:55:31.224: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.531935ms
Aug 27 05:55:33.227: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007111758s
Aug 27 05:55:33.227: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 08/27/22 05:55:33.227
Aug 27 05:55:33.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=webhook-6900 attach --namespace=webhook-6900 to-be-attached-pod -i -c=container1'
Aug 27 05:55:33.328: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:55:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6900" for this suite. 08/27/22 05:55:33.337
STEP: Destroying namespace "webhook-6900-markers" for this suite. 08/27/22 05:55:33.341
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":78,"skipped":1523,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.106 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:55:27.291
    Aug 27 05:55:27.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:55:27.292
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:27.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:27.333
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:55:27.374
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:55:28.154
    STEP: Deploying the webhook pod 08/27/22 05:55:28.158
    STEP: Wait for the deployment to be ready 08/27/22 05:55:28.167
    Aug 27 05:55:28.172: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/27/22 05:55:30.18
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:55:30.193
    Aug 27 05:55:31.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 08/27/22 05:55:31.197
    STEP: create a pod 08/27/22 05:55:31.214
    Aug 27 05:55:31.220: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-6900" to be "running"
    Aug 27 05:55:31.224: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.531935ms
    Aug 27 05:55:33.227: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007111758s
    Aug 27 05:55:33.227: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 08/27/22 05:55:33.227
    Aug 27 05:55:33.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=webhook-6900 attach --namespace=webhook-6900 to-be-attached-pod -i -c=container1'
    Aug 27 05:55:33.328: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:55:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6900" for this suite. 08/27/22 05:55:33.337
    STEP: Destroying namespace "webhook-6900-markers" for this suite. 08/27/22 05:55:33.341
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:55:33.4
Aug 27 05:55:33.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 05:55:33.402
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:33.431
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:33.44
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 05:55:33.462
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:55:34.006
STEP: Deploying the webhook pod 08/27/22 05:55:34.012
STEP: Wait for the deployment to be ready 08/27/22 05:55:34.024
Aug 27 05:55:34.034: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 05:55:36.058
STEP: Verifying the service has paired with the endpoint 08/27/22 05:55:36.074
Aug 27 05:55:37.074: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 08/27/22 05:55:37.13
STEP: Creating a configMap that should be mutated 08/27/22 05:55:37.147
STEP: Deleting the collection of validation webhooks 08/27/22 05:55:37.192
STEP: Creating a configMap that should not be mutated 08/27/22 05:55:37.232
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:55:37.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7009" for this suite. 08/27/22 05:55:37.244
STEP: Destroying namespace "webhook-7009-markers" for this suite. 08/27/22 05:55:37.248
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":79,"skipped":1526,"failed":0}
------------------------------
â€¢ [3.896 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:55:33.4
    Aug 27 05:55:33.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 05:55:33.402
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:33.431
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:33.44
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 05:55:33.462
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 05:55:34.006
    STEP: Deploying the webhook pod 08/27/22 05:55:34.012
    STEP: Wait for the deployment to be ready 08/27/22 05:55:34.024
    Aug 27 05:55:34.034: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 05:55:36.058
    STEP: Verifying the service has paired with the endpoint 08/27/22 05:55:36.074
    Aug 27 05:55:37.074: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 08/27/22 05:55:37.13
    STEP: Creating a configMap that should be mutated 08/27/22 05:55:37.147
    STEP: Deleting the collection of validation webhooks 08/27/22 05:55:37.192
    STEP: Creating a configMap that should not be mutated 08/27/22 05:55:37.232
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:55:37.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7009" for this suite. 08/27/22 05:55:37.244
    STEP: Destroying namespace "webhook-7009-markers" for this suite. 08/27/22 05:55:37.248
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:55:37.304
Aug 27 05:55:37.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 05:55:37.305
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:37.338
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:37.347
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 08/27/22 05:55:37.356
STEP: waiting for pod running 08/27/22 05:55:37.368
Aug 27 05:55:37.368: INFO: Waiting up to 2m0s for pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" in namespace "var-expansion-7052" to be "running"
Aug 27 05:55:37.375: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636": Phase="Pending", Reason="", readiness=false. Elapsed: 4.592697ms
Aug 27 05:55:39.379: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636": Phase="Running", Reason="", readiness=true. Elapsed: 2.009344085s
Aug 27 05:55:39.379: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" satisfied condition "running"
STEP: creating a file in subpath 08/27/22 05:55:39.379
Aug 27 05:55:39.382: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7052 PodName:var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:55:39.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:55:39.383: INFO: ExecWithOptions: Clientset creation
Aug 27 05:55:39.383: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/var-expansion-7052/pods/var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 08/27/22 05:55:39.458
Aug 27 05:55:39.461: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7052 PodName:var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 05:55:39.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 05:55:39.462: INFO: ExecWithOptions: Clientset creation
Aug 27 05:55:39.462: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/var-expansion-7052/pods/var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 08/27/22 05:55:39.518
Aug 27 05:55:40.027: INFO: Successfully updated pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636"
STEP: waiting for annotated pod running 08/27/22 05:55:40.027
Aug 27 05:55:40.027: INFO: Waiting up to 2m0s for pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" in namespace "var-expansion-7052" to be "running"
Aug 27 05:55:40.031: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636": Phase="Running", Reason="", readiness=true. Elapsed: 3.644317ms
Aug 27 05:55:40.031: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" satisfied condition "running"
STEP: deleting the pod gracefully 08/27/22 05:55:40.031
Aug 27 05:55:40.031: INFO: Deleting pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" in namespace "var-expansion-7052"
Aug 27 05:55:40.035: INFO: Wait up to 5m0s for pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 05:56:14.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7052" for this suite. 08/27/22 05:56:14.051
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":80,"skipped":1546,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.752 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:55:37.304
    Aug 27 05:55:37.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 05:55:37.305
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:55:37.338
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:55:37.347
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 08/27/22 05:55:37.356
    STEP: waiting for pod running 08/27/22 05:55:37.368
    Aug 27 05:55:37.368: INFO: Waiting up to 2m0s for pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" in namespace "var-expansion-7052" to be "running"
    Aug 27 05:55:37.375: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636": Phase="Pending", Reason="", readiness=false. Elapsed: 4.592697ms
    Aug 27 05:55:39.379: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636": Phase="Running", Reason="", readiness=true. Elapsed: 2.009344085s
    Aug 27 05:55:39.379: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" satisfied condition "running"
    STEP: creating a file in subpath 08/27/22 05:55:39.379
    Aug 27 05:55:39.382: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-7052 PodName:var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:55:39.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:55:39.383: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:55:39.383: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/var-expansion-7052/pods/var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 08/27/22 05:55:39.458
    Aug 27 05:55:39.461: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-7052 PodName:var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 05:55:39.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 05:55:39.462: INFO: ExecWithOptions: Clientset creation
    Aug 27 05:55:39.462: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/var-expansion-7052/pods/var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 08/27/22 05:55:39.518
    Aug 27 05:55:40.027: INFO: Successfully updated pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636"
    STEP: waiting for annotated pod running 08/27/22 05:55:40.027
    Aug 27 05:55:40.027: INFO: Waiting up to 2m0s for pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" in namespace "var-expansion-7052" to be "running"
    Aug 27 05:55:40.031: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636": Phase="Running", Reason="", readiness=true. Elapsed: 3.644317ms
    Aug 27 05:55:40.031: INFO: Pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" satisfied condition "running"
    STEP: deleting the pod gracefully 08/27/22 05:55:40.031
    Aug 27 05:55:40.031: INFO: Deleting pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" in namespace "var-expansion-7052"
    Aug 27 05:55:40.035: INFO: Wait up to 5m0s for pod "var-expansion-9640f356-d0ed-4ff1-8b56-4c553a0ef636" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 05:56:14.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7052" for this suite. 08/27/22 05:56:14.051
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:56:14.055
Aug 27 05:56:14.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 05:56:14.057
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:56:14.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:56:14.091
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-4439 08/27/22 05:56:14.1
STEP: creating replication controller nodeport-test in namespace services-4439 08/27/22 05:56:14.115
I0827 05:56:14.130883      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4439, replica count: 2
I0827 05:56:17.182381      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 05:56:17.182: INFO: Creating new exec pod
Aug 27 05:56:17.188: INFO: Waiting up to 5m0s for pod "execpodghtjk" in namespace "services-4439" to be "running"
Aug 27 05:56:17.194: INFO: Pod "execpodghtjk": Phase="Pending", Reason="", readiness=false. Elapsed: 6.63101ms
Aug 27 05:56:19.198: INFO: Pod "execpodghtjk": Phase="Running", Reason="", readiness=true. Elapsed: 2.010104588s
Aug 27 05:56:19.198: INFO: Pod "execpodghtjk" satisfied condition "running"
Aug 27 05:56:20.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 27 05:56:20.346: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:20.346: INFO: stdout: ""
Aug 27 05:56:21.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 27 05:56:21.562: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:21.562: INFO: stdout: ""
Aug 27 05:56:22.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 27 05:56:22.521: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:22.521: INFO: stdout: "nodeport-test-xvs2f"
Aug 27 05:56:22.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
Aug 27 05:56:22.658: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.158.253 80\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:22.658: INFO: stdout: ""
Aug 27 05:56:23.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
Aug 27 05:56:23.802: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.158.253 80\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:23.802: INFO: stdout: ""
Aug 27 05:56:24.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
Aug 27 05:56:24.817: INFO: stderr: "+ nc -v -t -w 2 10.3.158.253 80\n+ echo hostName\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:24.817: INFO: stdout: ""
Aug 27 05:56:25.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
Aug 27 05:56:25.799: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.158.253 80\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:25.799: INFO: stdout: "nodeport-test-xvs2f"
Aug 27 05:56:25.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 32106'
Aug 27 05:56:25.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 32106\nConnection to 10.0.31.158 32106 port [tcp/*] succeeded!\n"
Aug 27 05:56:25.972: INFO: stdout: "nodeport-test-xvs2f"
Aug 27 05:56:25.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32106'
Aug 27 05:56:26.162: INFO: stderr: "+ echo hostName+ nc\n -v -t -w 2 10.0.47.192 32106\nConnection to 10.0.47.192 32106 port [tcp/*] succeeded!\n"
Aug 27 05:56:26.162: INFO: stdout: ""
Aug 27 05:56:27.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32106'
Aug 27 05:56:27.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32106\nConnection to 10.0.47.192 32106 port [tcp/*] succeeded!\n"
Aug 27 05:56:27.297: INFO: stdout: "nodeport-test-fkxrx"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 05:56:27.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4439" for this suite. 08/27/22 05:56:27.307
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":81,"skipped":1548,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.260 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:56:14.055
    Aug 27 05:56:14.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 05:56:14.057
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:56:14.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:56:14.091
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-4439 08/27/22 05:56:14.1
    STEP: creating replication controller nodeport-test in namespace services-4439 08/27/22 05:56:14.115
    I0827 05:56:14.130883      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4439, replica count: 2
    I0827 05:56:17.182381      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 05:56:17.182: INFO: Creating new exec pod
    Aug 27 05:56:17.188: INFO: Waiting up to 5m0s for pod "execpodghtjk" in namespace "services-4439" to be "running"
    Aug 27 05:56:17.194: INFO: Pod "execpodghtjk": Phase="Pending", Reason="", readiness=false. Elapsed: 6.63101ms
    Aug 27 05:56:19.198: INFO: Pod "execpodghtjk": Phase="Running", Reason="", readiness=true. Elapsed: 2.010104588s
    Aug 27 05:56:19.198: INFO: Pod "execpodghtjk" satisfied condition "running"
    Aug 27 05:56:20.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Aug 27 05:56:20.346: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:20.346: INFO: stdout: ""
    Aug 27 05:56:21.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Aug 27 05:56:21.562: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:21.562: INFO: stdout: ""
    Aug 27 05:56:22.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Aug 27 05:56:22.521: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:22.521: INFO: stdout: "nodeport-test-xvs2f"
    Aug 27 05:56:22.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
    Aug 27 05:56:22.658: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.158.253 80\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:22.658: INFO: stdout: ""
    Aug 27 05:56:23.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
    Aug 27 05:56:23.802: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.158.253 80\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:23.802: INFO: stdout: ""
    Aug 27 05:56:24.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
    Aug 27 05:56:24.817: INFO: stderr: "+ nc -v -t -w 2 10.3.158.253 80\n+ echo hostName\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:24.817: INFO: stdout: ""
    Aug 27 05:56:25.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.158.253 80'
    Aug 27 05:56:25.799: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.158.253 80\nConnection to 10.3.158.253 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:25.799: INFO: stdout: "nodeport-test-xvs2f"
    Aug 27 05:56:25.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 32106'
    Aug 27 05:56:25.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 32106\nConnection to 10.0.31.158 32106 port [tcp/*] succeeded!\n"
    Aug 27 05:56:25.972: INFO: stdout: "nodeport-test-xvs2f"
    Aug 27 05:56:25.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32106'
    Aug 27 05:56:26.162: INFO: stderr: "+ echo hostName+ nc\n -v -t -w 2 10.0.47.192 32106\nConnection to 10.0.47.192 32106 port [tcp/*] succeeded!\n"
    Aug 27 05:56:26.162: INFO: stdout: ""
    Aug 27 05:56:27.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4439 exec execpodghtjk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32106'
    Aug 27 05:56:27.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32106\nConnection to 10.0.47.192 32106 port [tcp/*] succeeded!\n"
    Aug 27 05:56:27.297: INFO: stdout: "nodeport-test-fkxrx"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 05:56:27.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4439" for this suite. 08/27/22 05:56:27.307
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:56:27.316
Aug 27 05:56:27.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 05:56:27.318
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:56:27.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:56:27.397
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-1338 08/27/22 05:56:27.408
Aug 27 05:56:27.419: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1338" to be "running and ready"
Aug 27 05:56:27.431: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 11.012959ms
Aug 27 05:56:27.431: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug 27 05:56:29.434: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.014727666s
Aug 27 05:56:29.434: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug 27 05:56:29.434: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Aug 27 05:56:29.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 27 05:56:29.657: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 27 05:56:29.657: INFO: stdout: "ipvs"
Aug 27 05:56:29.657: INFO: proxyMode: ipvs
Aug 27 05:56:29.669: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 05:56:29.673: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-1338 08/27/22 05:56:29.673
STEP: creating replication controller affinity-clusterip-timeout in namespace services-1338 08/27/22 05:56:29.703
I0827 05:56:29.716133      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-1338, replica count: 3
I0827 05:56:32.770394      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 05:56:32.787: INFO: Creating new exec pod
Aug 27 05:56:32.827: INFO: Waiting up to 5m0s for pod "execpod-affinity4q2x5" in namespace "services-1338" to be "running"
Aug 27 05:56:32.845: INFO: Pod "execpod-affinity4q2x5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.356286ms
Aug 27 05:56:34.850: INFO: Pod "execpod-affinity4q2x5": Phase="Running", Reason="", readiness=true. Elapsed: 2.023015345s
Aug 27 05:56:34.850: INFO: Pod "execpod-affinity4q2x5" satisfied condition "running"
Aug 27 05:56:35.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Aug 27 05:56:35.993: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:35.993: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 05:56:35.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.2.213 80'
Aug 27 05:56:36.241: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.2.213 80\nConnection to 10.3.2.213 80 port [tcp/http] succeeded!\n"
Aug 27 05:56:36.241: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 05:56:36.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.2.213:80/ ; done'
Aug 27 05:56:36.451: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n"
Aug 27 05:56:36.451: INFO: stdout: "\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6"
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
Aug 27 05:56:36.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.2.213:80/'
Aug 27 05:56:36.613: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n"
Aug 27 05:56:36.613: INFO: stdout: "affinity-clusterip-timeout-zfts6"
Aug 27 05:58:46.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.2.213:80/'
Aug 27 05:58:46.759: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n"
Aug 27 05:58:46.759: INFO: stdout: "affinity-clusterip-timeout-5hmph"
Aug 27 05:58:46.759: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-1338, will wait for the garbage collector to delete the pods 08/27/22 05:58:46.782
Aug 27 05:58:46.843: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 5.550181ms
Aug 27 05:58:47.044: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 201.137549ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 05:58:49.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1338" for this suite. 08/27/22 05:58:49.516
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":82,"skipped":1572,"failed":0}
------------------------------
â€¢ [SLOW TEST] [142.213 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:56:27.316
    Aug 27 05:56:27.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 05:56:27.318
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:56:27.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:56:27.397
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-1338 08/27/22 05:56:27.408
    Aug 27 05:56:27.419: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1338" to be "running and ready"
    Aug 27 05:56:27.431: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 11.012959ms
    Aug 27 05:56:27.431: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 05:56:29.434: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.014727666s
    Aug 27 05:56:29.434: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Aug 27 05:56:29.434: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Aug 27 05:56:29.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Aug 27 05:56:29.657: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Aug 27 05:56:29.657: INFO: stdout: "ipvs"
    Aug 27 05:56:29.657: INFO: proxyMode: ipvs
    Aug 27 05:56:29.669: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Aug 27 05:56:29.673: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-1338 08/27/22 05:56:29.673
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-1338 08/27/22 05:56:29.703
    I0827 05:56:29.716133      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-1338, replica count: 3
    I0827 05:56:32.770394      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 05:56:32.787: INFO: Creating new exec pod
    Aug 27 05:56:32.827: INFO: Waiting up to 5m0s for pod "execpod-affinity4q2x5" in namespace "services-1338" to be "running"
    Aug 27 05:56:32.845: INFO: Pod "execpod-affinity4q2x5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.356286ms
    Aug 27 05:56:34.850: INFO: Pod "execpod-affinity4q2x5": Phase="Running", Reason="", readiness=true. Elapsed: 2.023015345s
    Aug 27 05:56:34.850: INFO: Pod "execpod-affinity4q2x5" satisfied condition "running"
    Aug 27 05:56:35.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Aug 27 05:56:35.993: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:35.993: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 05:56:35.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.2.213 80'
    Aug 27 05:56:36.241: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.2.213 80\nConnection to 10.3.2.213 80 port [tcp/http] succeeded!\n"
    Aug 27 05:56:36.241: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 05:56:36.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.2.213:80/ ; done'
    Aug 27 05:56:36.451: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n"
    Aug 27 05:56:36.451: INFO: stdout: "\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6\naffinity-clusterip-timeout-zfts6"
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Received response from host: affinity-clusterip-timeout-zfts6
    Aug 27 05:56:36.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.2.213:80/'
    Aug 27 05:56:36.613: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n"
    Aug 27 05:56:36.613: INFO: stdout: "affinity-clusterip-timeout-zfts6"
    Aug 27 05:58:46.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1338 exec execpod-affinity4q2x5 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.3.2.213:80/'
    Aug 27 05:58:46.759: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.3.2.213:80/\n"
    Aug 27 05:58:46.759: INFO: stdout: "affinity-clusterip-timeout-5hmph"
    Aug 27 05:58:46.759: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-1338, will wait for the garbage collector to delete the pods 08/27/22 05:58:46.782
    Aug 27 05:58:46.843: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 5.550181ms
    Aug 27 05:58:47.044: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 201.137549ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 05:58:49.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1338" for this suite. 08/27/22 05:58:49.516
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:58:49.535
Aug 27 05:58:49.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 05:58:49.536
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:58:49.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:58:49.582
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7835 08/27/22 05:58:49.587
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/27/22 05:58:49.6
STEP: creating service externalsvc in namespace services-7835 08/27/22 05:58:49.601
STEP: creating replication controller externalsvc in namespace services-7835 08/27/22 05:58:49.625
I0827 05:58:49.631805      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7835, replica count: 2
I0827 05:58:52.682480      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 05:58:55.682786      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 08/27/22 05:58:55.686
Aug 27 05:58:55.700: INFO: Creating new exec pod
Aug 27 05:58:55.714: INFO: Waiting up to 5m0s for pod "execpodrm9p9" in namespace "services-7835" to be "running"
Aug 27 05:58:55.720: INFO: Pod "execpodrm9p9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.918957ms
Aug 27 05:58:57.724: INFO: Pod "execpodrm9p9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010570684s
Aug 27 05:58:57.725: INFO: Pod "execpodrm9p9" satisfied condition "running"
Aug 27 05:58:57.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-7835 exec execpodrm9p9 -- /bin/sh -x -c nslookup nodeport-service.services-7835.svc.cluster.local'
Aug 27 05:58:57.934: INFO: stderr: "+ nslookup nodeport-service.services-7835.svc.cluster.local\n"
Aug 27 05:58:57.935: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-7835.svc.cluster.local\tcanonical name = externalsvc.services-7835.svc.cluster.local.\nName:\texternalsvc.services-7835.svc.cluster.local\nAddress: 10.3.84.10\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7835, will wait for the garbage collector to delete the pods 08/27/22 05:58:57.935
Aug 27 05:58:57.994: INFO: Deleting ReplicationController externalsvc took: 4.597917ms
Aug 27 05:58:58.094: INFO: Terminating ReplicationController externalsvc pods took: 100.115109ms
Aug 27 05:59:00.534: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 05:59:00.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7835" for this suite. 08/27/22 05:59:00.579
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":83,"skipped":1584,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.066 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:58:49.535
    Aug 27 05:58:49.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 05:58:49.536
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:58:49.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:58:49.582
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-7835 08/27/22 05:58:49.587
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 08/27/22 05:58:49.6
    STEP: creating service externalsvc in namespace services-7835 08/27/22 05:58:49.601
    STEP: creating replication controller externalsvc in namespace services-7835 08/27/22 05:58:49.625
    I0827 05:58:49.631805      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7835, replica count: 2
    I0827 05:58:52.682480      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0827 05:58:55.682786      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 08/27/22 05:58:55.686
    Aug 27 05:58:55.700: INFO: Creating new exec pod
    Aug 27 05:58:55.714: INFO: Waiting up to 5m0s for pod "execpodrm9p9" in namespace "services-7835" to be "running"
    Aug 27 05:58:55.720: INFO: Pod "execpodrm9p9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.918957ms
    Aug 27 05:58:57.724: INFO: Pod "execpodrm9p9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010570684s
    Aug 27 05:58:57.725: INFO: Pod "execpodrm9p9" satisfied condition "running"
    Aug 27 05:58:57.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-7835 exec execpodrm9p9 -- /bin/sh -x -c nslookup nodeport-service.services-7835.svc.cluster.local'
    Aug 27 05:58:57.934: INFO: stderr: "+ nslookup nodeport-service.services-7835.svc.cluster.local\n"
    Aug 27 05:58:57.935: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-7835.svc.cluster.local\tcanonical name = externalsvc.services-7835.svc.cluster.local.\nName:\texternalsvc.services-7835.svc.cluster.local\nAddress: 10.3.84.10\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7835, will wait for the garbage collector to delete the pods 08/27/22 05:58:57.935
    Aug 27 05:58:57.994: INFO: Deleting ReplicationController externalsvc took: 4.597917ms
    Aug 27 05:58:58.094: INFO: Terminating ReplicationController externalsvc pods took: 100.115109ms
    Aug 27 05:59:00.534: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 05:59:00.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7835" for this suite. 08/27/22 05:59:00.579
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:59:00.601
Aug 27 05:59:00.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 05:59:00.603
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:59:00.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:59:00.63
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 08/27/22 05:59:00.637
Aug 27 05:59:00.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: rename a version 08/27/22 05:59:11.462
STEP: check the new version name is served 08/27/22 05:59:11.474
STEP: check the old version name is removed 08/27/22 05:59:13.626
STEP: check the other version is not changed 08/27/22 05:59:15.254
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 05:59:21.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-102" for this suite. 08/27/22 05:59:21.413
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":84,"skipped":1587,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.817 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:59:00.601
    Aug 27 05:59:00.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 05:59:00.603
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:59:00.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:59:00.63
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 08/27/22 05:59:00.637
    Aug 27 05:59:00.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: rename a version 08/27/22 05:59:11.462
    STEP: check the new version name is served 08/27/22 05:59:11.474
    STEP: check the old version name is removed 08/27/22 05:59:13.626
    STEP: check the other version is not changed 08/27/22 05:59:15.254
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 05:59:21.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-102" for this suite. 08/27/22 05:59:21.413
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:59:21.42
Aug 27 05:59:21.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 05:59:21.421
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:59:21.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:59:21.444
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-583e5f26-2188-4bbd-ad6d-4e428a417de3 08/27/22 05:59:21.447
STEP: Creating a pod to test consume secrets 08/27/22 05:59:21.45
Aug 27 05:59:21.456: INFO: Waiting up to 5m0s for pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a" in namespace "secrets-3629" to be "Succeeded or Failed"
Aug 27 05:59:21.459: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.501844ms
Aug 27 05:59:23.463: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006811373s
Aug 27 05:59:25.463: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006559985s
STEP: Saw pod success 08/27/22 05:59:25.463
Aug 27 05:59:25.463: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a" satisfied condition "Succeeded or Failed"
Aug 27 05:59:25.465: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 05:59:25.482
Aug 27 05:59:25.492: INFO: Waiting for pod pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a to disappear
Aug 27 05:59:25.495: INFO: Pod pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 05:59:25.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3629" for this suite. 08/27/22 05:59:25.498
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":85,"skipped":1594,"failed":0}
------------------------------
â€¢ [4.083 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:59:21.42
    Aug 27 05:59:21.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 05:59:21.421
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:59:21.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:59:21.444
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-583e5f26-2188-4bbd-ad6d-4e428a417de3 08/27/22 05:59:21.447
    STEP: Creating a pod to test consume secrets 08/27/22 05:59:21.45
    Aug 27 05:59:21.456: INFO: Waiting up to 5m0s for pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a" in namespace "secrets-3629" to be "Succeeded or Failed"
    Aug 27 05:59:21.459: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.501844ms
    Aug 27 05:59:23.463: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006811373s
    Aug 27 05:59:25.463: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006559985s
    STEP: Saw pod success 08/27/22 05:59:25.463
    Aug 27 05:59:25.463: INFO: Pod "pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a" satisfied condition "Succeeded or Failed"
    Aug 27 05:59:25.465: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 05:59:25.482
    Aug 27 05:59:25.492: INFO: Waiting for pod pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a to disappear
    Aug 27 05:59:25.495: INFO: Pod pod-secrets-18f4d094-aeac-4972-a8c0-a2e88436c44a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 05:59:25.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3629" for this suite. 08/27/22 05:59:25.498
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 05:59:25.505
Aug 27 05:59:25.505: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename cronjob 08/27/22 05:59:25.506
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:59:25.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:59:25.527
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 08/27/22 05:59:25.53
STEP: Ensuring more than one job is running at a time 08/27/22 05:59:25.534
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 08/27/22 06:01:01.54
STEP: Removing cronjob 08/27/22 06:01:01.543
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 27 06:01:01.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8570" for this suite. 08/27/22 06:01:01.558
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":86,"skipped":1605,"failed":0}
------------------------------
â€¢ [SLOW TEST] [96.166 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 05:59:25.505
    Aug 27 05:59:25.505: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename cronjob 08/27/22 05:59:25.506
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 05:59:25.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 05:59:25.527
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 08/27/22 05:59:25.53
    STEP: Ensuring more than one job is running at a time 08/27/22 05:59:25.534
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 08/27/22 06:01:01.54
    STEP: Removing cronjob 08/27/22 06:01:01.543
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 27 06:01:01.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8570" for this suite. 08/27/22 06:01:01.558
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:01.672
Aug 27 06:01:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename endpointslicemirroring 08/27/22 06:01:01.673
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:01.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:01.972
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 08/27/22 06:01:02.25
Aug 27 06:01:02.300: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 08/27/22 06:01:04.304
Aug 27 06:01:04.316: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 08/27/22 06:01:06.32
Aug 27 06:01:06.327: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Aug 27 06:01:08.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-9804" for this suite. 08/27/22 06:01:08.336
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":87,"skipped":1607,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.679 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:01.672
    Aug 27 06:01:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename endpointslicemirroring 08/27/22 06:01:01.673
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:01.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:01.972
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 08/27/22 06:01:02.25
    Aug 27 06:01:02.300: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 08/27/22 06:01:04.304
    Aug 27 06:01:04.316: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 08/27/22 06:01:06.32
    Aug 27 06:01:06.327: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Aug 27 06:01:08.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-9804" for this suite. 08/27/22 06:01:08.336
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:08.353
Aug 27 06:01:08.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:01:08.354
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:08.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:08.414
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:01:08.421
Aug 27 06:01:08.436: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3767" to be "running and ready"
Aug 27 06:01:08.447: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.993319ms
Aug 27 06:01:08.447: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:10.451: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.01524879s
Aug 27 06:01:10.451: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 27 06:01:10.451: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 08/27/22 06:01:10.454
Aug 27 06:01:10.459: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3767" to be "running and ready"
Aug 27 06:01:10.462: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.486843ms
Aug 27 06:01:10.462: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:12.466: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.006871202s
Aug 27 06:01:12.467: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Aug 27 06:01:12.467: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 08/27/22 06:01:12.47
STEP: delete the pod with lifecycle hook 08/27/22 06:01:12.485
Aug 27 06:01:12.490: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 06:01:12.493: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 06:01:14.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 06:01:14.497: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 27 06:01:16.493: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 27 06:01:16.498: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 27 06:01:16.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3767" for this suite. 08/27/22 06:01:16.503
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":88,"skipped":1608,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.160 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:08.353
    Aug 27 06:01:08.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:01:08.354
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:08.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:08.414
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:01:08.421
    Aug 27 06:01:08.436: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3767" to be "running and ready"
    Aug 27 06:01:08.447: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.993319ms
    Aug 27 06:01:08.447: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:10.451: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.01524879s
    Aug 27 06:01:10.451: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 27 06:01:10.451: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 08/27/22 06:01:10.454
    Aug 27 06:01:10.459: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-3767" to be "running and ready"
    Aug 27 06:01:10.462: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.486843ms
    Aug 27 06:01:10.462: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:12.466: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.006871202s
    Aug 27 06:01:12.467: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Aug 27 06:01:12.467: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 08/27/22 06:01:12.47
    STEP: delete the pod with lifecycle hook 08/27/22 06:01:12.485
    Aug 27 06:01:12.490: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 27 06:01:12.493: INFO: Pod pod-with-poststart-exec-hook still exists
    Aug 27 06:01:14.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 27 06:01:14.497: INFO: Pod pod-with-poststart-exec-hook still exists
    Aug 27 06:01:16.493: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Aug 27 06:01:16.498: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 27 06:01:16.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3767" for this suite. 08/27/22 06:01:16.503
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:16.517
Aug 27 06:01:16.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:01:16.519
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:16.547
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:16.551
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 08/27/22 06:01:16.555
Aug 27 06:01:16.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 create -f -'
Aug 27 06:01:18.068: INFO: stderr: ""
Aug 27 06:01:18.068: INFO: stdout: "pod/pause created\n"
Aug 27 06:01:18.068: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 27 06:01:18.068: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6274" to be "running and ready"
Aug 27 06:01:18.078: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.906061ms
Aug 27 06:01:18.078: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-10-0-47-192' to be 'Running' but was 'Pending'
Aug 27 06:01:20.083: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014703874s
Aug 27 06:01:20.083: INFO: Pod "pause" satisfied condition "running and ready"
Aug 27 06:01:20.083: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 08/27/22 06:01:20.083
Aug 27 06:01:20.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 label pods pause testing-label=testing-label-value'
Aug 27 06:01:20.163: INFO: stderr: ""
Aug 27 06:01:20.163: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 08/27/22 06:01:20.163
Aug 27 06:01:20.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get pod pause -L testing-label'
Aug 27 06:01:20.238: INFO: stderr: ""
Aug 27 06:01:20.238: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 08/27/22 06:01:20.238
Aug 27 06:01:20.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 label pods pause testing-label-'
Aug 27 06:01:20.319: INFO: stderr: ""
Aug 27 06:01:20.319: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 08/27/22 06:01:20.319
Aug 27 06:01:20.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get pod pause -L testing-label'
Aug 27 06:01:20.398: INFO: stderr: ""
Aug 27 06:01:20.398: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 08/27/22 06:01:20.398
Aug 27 06:01:20.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 delete --grace-period=0 --force -f -'
Aug 27 06:01:20.498: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 06:01:20.498: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 27 06:01:20.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get rc,svc -l name=pause --no-headers'
Aug 27 06:01:20.593: INFO: stderr: "No resources found in kubectl-6274 namespace.\n"
Aug 27 06:01:20.593: INFO: stdout: ""
Aug 27 06:01:20.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 06:01:20.659: INFO: stderr: ""
Aug 27 06:01:20.659: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:01:20.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6274" for this suite. 08/27/22 06:01:20.663
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":89,"skipped":1636,"failed":0}
------------------------------
â€¢ [4.151 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:16.517
    Aug 27 06:01:16.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:01:16.519
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:16.547
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:16.551
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 08/27/22 06:01:16.555
    Aug 27 06:01:16.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 create -f -'
    Aug 27 06:01:18.068: INFO: stderr: ""
    Aug 27 06:01:18.068: INFO: stdout: "pod/pause created\n"
    Aug 27 06:01:18.068: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Aug 27 06:01:18.068: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6274" to be "running and ready"
    Aug 27 06:01:18.078: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.906061ms
    Aug 27 06:01:18.078: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-10-0-47-192' to be 'Running' but was 'Pending'
    Aug 27 06:01:20.083: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014703874s
    Aug 27 06:01:20.083: INFO: Pod "pause" satisfied condition "running and ready"
    Aug 27 06:01:20.083: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 08/27/22 06:01:20.083
    Aug 27 06:01:20.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 label pods pause testing-label=testing-label-value'
    Aug 27 06:01:20.163: INFO: stderr: ""
    Aug 27 06:01:20.163: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 08/27/22 06:01:20.163
    Aug 27 06:01:20.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get pod pause -L testing-label'
    Aug 27 06:01:20.238: INFO: stderr: ""
    Aug 27 06:01:20.238: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 08/27/22 06:01:20.238
    Aug 27 06:01:20.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 label pods pause testing-label-'
    Aug 27 06:01:20.319: INFO: stderr: ""
    Aug 27 06:01:20.319: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 08/27/22 06:01:20.319
    Aug 27 06:01:20.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get pod pause -L testing-label'
    Aug 27 06:01:20.398: INFO: stderr: ""
    Aug 27 06:01:20.398: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 08/27/22 06:01:20.398
    Aug 27 06:01:20.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 delete --grace-period=0 --force -f -'
    Aug 27 06:01:20.498: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 06:01:20.498: INFO: stdout: "pod \"pause\" force deleted\n"
    Aug 27 06:01:20.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get rc,svc -l name=pause --no-headers'
    Aug 27 06:01:20.593: INFO: stderr: "No resources found in kubectl-6274 namespace.\n"
    Aug 27 06:01:20.593: INFO: stdout: ""
    Aug 27 06:01:20.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6274 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 27 06:01:20.659: INFO: stderr: ""
    Aug 27 06:01:20.659: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:01:20.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6274" for this suite. 08/27/22 06:01:20.663
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:20.669
Aug 27 06:01:20.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:01:20.67
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:20.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:20.692
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:01:20.7
Aug 27 06:01:20.708: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4327" to be "running and ready"
Aug 27 06:01:20.713: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537705ms
Aug 27 06:01:20.714: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:22.725: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016780715s
Aug 27 06:01:22.725: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 27 06:01:22.725: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 08/27/22 06:01:22.739
Aug 27 06:01:22.762: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-4327" to be "running and ready"
Aug 27 06:01:22.780: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 17.968217ms
Aug 27 06:01:22.780: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:24.784: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.022499284s
Aug 27 06:01:24.784: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Aug 27 06:01:24.784: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 08/27/22 06:01:24.787
STEP: delete the pod with lifecycle hook 08/27/22 06:01:24.801
Aug 27 06:01:24.811: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 06:01:24.821: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 06:01:26.822: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 06:01:26.825: INFO: Pod pod-with-poststart-http-hook still exists
Aug 27 06:01:28.823: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 27 06:01:28.826: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 27 06:01:28.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4327" for this suite. 08/27/22 06:01:28.83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":90,"skipped":1675,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.165 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:20.669
    Aug 27 06:01:20.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:01:20.67
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:20.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:20.692
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:01:20.7
    Aug 27 06:01:20.708: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4327" to be "running and ready"
    Aug 27 06:01:20.713: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537705ms
    Aug 27 06:01:20.714: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:22.725: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016780715s
    Aug 27 06:01:22.725: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 27 06:01:22.725: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 08/27/22 06:01:22.739
    Aug 27 06:01:22.762: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-4327" to be "running and ready"
    Aug 27 06:01:22.780: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 17.968217ms
    Aug 27 06:01:22.780: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:24.784: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.022499284s
    Aug 27 06:01:24.784: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Aug 27 06:01:24.784: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 08/27/22 06:01:24.787
    STEP: delete the pod with lifecycle hook 08/27/22 06:01:24.801
    Aug 27 06:01:24.811: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 27 06:01:24.821: INFO: Pod pod-with-poststart-http-hook still exists
    Aug 27 06:01:26.822: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 27 06:01:26.825: INFO: Pod pod-with-poststart-http-hook still exists
    Aug 27 06:01:28.823: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Aug 27 06:01:28.826: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 27 06:01:28.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4327" for this suite. 08/27/22 06:01:28.83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:28.84
Aug 27 06:01:28.841: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename watch 08/27/22 06:01:28.841
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:28.857
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:28.862
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 08/27/22 06:01:28.867
STEP: creating a new configmap 08/27/22 06:01:28.868
STEP: modifying the configmap once 08/27/22 06:01:28.877
STEP: closing the watch once it receives two notifications 08/27/22 06:01:28.886
Aug 27 06:01:28.888: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11504 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:01:28.888: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11505 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 08/27/22 06:01:28.888
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 08/27/22 06:01:28.896
STEP: deleting the configmap 08/27/22 06:01:28.898
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 08/27/22 06:01:28.905
Aug 27 06:01:28.905: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11506 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:01:28.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11507 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 27 06:01:28.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1681" for this suite. 08/27/22 06:01:28.91
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":91,"skipped":1716,"failed":0}
------------------------------
â€¢ [0.075 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:28.84
    Aug 27 06:01:28.841: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename watch 08/27/22 06:01:28.841
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:28.857
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:28.862
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 08/27/22 06:01:28.867
    STEP: creating a new configmap 08/27/22 06:01:28.868
    STEP: modifying the configmap once 08/27/22 06:01:28.877
    STEP: closing the watch once it receives two notifications 08/27/22 06:01:28.886
    Aug 27 06:01:28.888: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11504 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:01:28.888: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11505 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 08/27/22 06:01:28.888
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 08/27/22 06:01:28.896
    STEP: deleting the configmap 08/27/22 06:01:28.898
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 08/27/22 06:01:28.905
    Aug 27 06:01:28.905: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11506 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:01:28.905: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1681  a34430ab-5d07-4432-b5bb-7b38f87e7d9c 11507 0 2022-08-27 06:01:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:28 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 27 06:01:28.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1681" for this suite. 08/27/22 06:01:28.91
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:28.918
Aug 27 06:01:28.918: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:01:28.918
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:28.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:28.944
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 08/27/22 06:01:28.947
STEP: submitting the pod to kubernetes 08/27/22 06:01:28.948
Aug 27 06:01:28.957: INFO: Waiting up to 5m0s for pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" in namespace "pods-1433" to be "running and ready"
Aug 27 06:01:28.963: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.48675ms
Aug 27 06:01:28.963: INFO: The phase of Pod pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:30.967: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd": Phase="Running", Reason="", readiness=true. Elapsed: 2.010182233s
Aug 27 06:01:30.967: INFO: The phase of Pod pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd is Running (Ready = true)
Aug 27 06:01:30.967: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 08/27/22 06:01:30.97
STEP: updating the pod 08/27/22 06:01:30.973
Aug 27 06:01:31.482: INFO: Successfully updated pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd"
Aug 27 06:01:31.482: INFO: Waiting up to 5m0s for pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" in namespace "pods-1433" to be "running"
Aug 27 06:01:31.486: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd": Phase="Running", Reason="", readiness=true. Elapsed: 3.826832ms
Aug 27 06:01:31.486: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 08/27/22 06:01:31.486
Aug 27 06:01:31.493: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:01:31.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1433" for this suite. 08/27/22 06:01:31.497
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":92,"skipped":1731,"failed":0}
------------------------------
â€¢ [2.587 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:28.918
    Aug 27 06:01:28.918: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:01:28.918
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:28.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:28.944
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 08/27/22 06:01:28.947
    STEP: submitting the pod to kubernetes 08/27/22 06:01:28.948
    Aug 27 06:01:28.957: INFO: Waiting up to 5m0s for pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" in namespace "pods-1433" to be "running and ready"
    Aug 27 06:01:28.963: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.48675ms
    Aug 27 06:01:28.963: INFO: The phase of Pod pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:30.967: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd": Phase="Running", Reason="", readiness=true. Elapsed: 2.010182233s
    Aug 27 06:01:30.967: INFO: The phase of Pod pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd is Running (Ready = true)
    Aug 27 06:01:30.967: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 08/27/22 06:01:30.97
    STEP: updating the pod 08/27/22 06:01:30.973
    Aug 27 06:01:31.482: INFO: Successfully updated pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd"
    Aug 27 06:01:31.482: INFO: Waiting up to 5m0s for pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" in namespace "pods-1433" to be "running"
    Aug 27 06:01:31.486: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd": Phase="Running", Reason="", readiness=true. Elapsed: 3.826832ms
    Aug 27 06:01:31.486: INFO: Pod "pod-update-47e7bc2a-adbd-4e72-b73e-332d7eabf3cd" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 08/27/22 06:01:31.486
    Aug 27 06:01:31.493: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:01:31.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1433" for this suite. 08/27/22 06:01:31.497
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:31.513
Aug 27 06:01:31.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:01:31.514
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:31.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:31.541
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Aug 27 06:01:31.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 create -f -'
Aug 27 06:01:31.863: INFO: stderr: ""
Aug 27 06:01:31.863: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Aug 27 06:01:31.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 create -f -'
Aug 27 06:01:32.154: INFO: stderr: ""
Aug 27 06:01:32.154: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/27/22 06:01:32.154
Aug 27 06:01:33.158: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 06:01:33.158: INFO: Found 1 / 1
Aug 27 06:01:33.158: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 06:01:33.160: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 06:01:33.160: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 06:01:33.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe pod agnhost-primary-fgs9k'
Aug 27 06:01:33.233: INFO: stderr: ""
Aug 27 06:01:33.233: INFO: stdout: "Name:             agnhost-primary-fgs9k\nNamespace:        kubectl-8652\nPriority:         0\nService Account:  default\nNode:             ip-10-0-31-158/10.0.31.158\nStart Time:       Sat, 27 Aug 2022 06:01:31 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 0676b6e1f520d9dd552d2cc1ab60af462b9a86404922d1fc27742801792a3cb3\n                  cni.projectcalico.org/podIP: 10.2.137.100/32\n                  cni.projectcalico.org/podIPs: 10.2.137.100/32\nStatus:           Running\nIP:               10.2.137.100\nIPs:\n  IP:           10.2.137.100\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://78380fdaa5d4ad3fffafdc603f28b6dc60d46b20698e4a8c4b8dbce8c4fb900a\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 27 Aug 2022 06:01:32 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-s4xlq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-s4xlq:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-8652/agnhost-primary-fgs9k to ip-10-0-31-158\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Aug 27 06:01:33.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe rc agnhost-primary'
Aug 27 06:01:33.312: INFO: stderr: ""
Aug 27 06:01:33.312: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8652\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-fgs9k\n"
Aug 27 06:01:33.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe service agnhost-primary'
Aug 27 06:01:33.385: INFO: stderr: ""
Aug 27 06:01:33.385: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8652\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.3.135.29\nIPs:               10.3.135.29\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.2.137.100:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 27 06:01:33.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe node ip-10-0-13-52'
Aug 27 06:01:33.496: INFO: stderr: ""
Aug 27 06:01:33.496: INFO: stdout: "Name:               ip-10-0-13-52\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-13-52\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/controller=true\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.13.52/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.222.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 27 Aug 2022 05:27:44 +0000\nTaints:             node-role.kubernetes.io/controller:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-10-0-13-52\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 27 Aug 2022 06:01:23 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 27 Aug 2022 05:28:07 +0000   Sat, 27 Aug 2022 05:28:07 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:27:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:27:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:27:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:28:04 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.13.52\n  Hostname:    ip-10-0-13-52\nCapacity:\n  cpu:                1\n  ephemeral-storage:  30921708Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1977396Ki\n  pods:               110\nAllocatable:\n  cpu:                1\n  ephemeral-storage:  28497446046\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1874996Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec24c19e4939af8699f29957ba6eed06\n  System UUID:                ec24c19e-4939-af86-99f2-9957ba6eed06\n  Boot ID:                    d9b8dd7c-21f3-4a2a-97cc-35aed5800eb8\n  Kernel Version:             5.18.16-200.fc36.x86_64\n  OS Image:                   Fedora CoreOS 36.20220806.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.6\n  Kubelet Version:            v1.25.0\n  Kube-Proxy Version:         v1.25.0\nPodCIDR:                      10.2.2.0/24\nPodCIDRs:                     10.2.2.0/24\nProviderID:                   aws:///us-east-2a/i-0b6ccec4a5d9a4630\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-zdq5j                                          100m (10%)    0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                 coredns-5f79d78b9d-7nxjl                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     34m\n  kube-system                 coredns-5f79d78b9d-q67dt                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     34m\n  kube-system                 kube-apiserver-ip-10-0-13-52                               150m (15%)    0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                 kube-controller-manager-ip-10-0-13-52                      150m (15%)    0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                 kube-proxy-6wq89                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                 kube-scheduler-ip-10-0-13-52                               100m (10%)    0 (0%)      0 (0%)           0 (0%)         33m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-xmks6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                700m (70%)  0 (0%)\n  memory             140Mi (7%)  340Mi (18%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason          Age   From             Message\n  ----    ------          ----  ----             -------\n  Normal  Starting        33m   kube-proxy       \n  Normal  RegisteredNode  33m   node-controller  Node ip-10-0-13-52 event: Registered Node ip-10-0-13-52 in Controller\n"
Aug 27 06:01:33.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe namespace kubectl-8652'
Aug 27 06:01:33.594: INFO: stderr: ""
Aug 27 06:01:33.594: INFO: stdout: "Name:         kubectl-8652\nLabels:       e2e-framework=kubectl\n              e2e-run=2182355c-f2a3-4ab8-bbc3-0d6edf17ebec\n              kubernetes.io/metadata.name=kubectl-8652\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:01:33.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8652" for this suite. 08/27/22 06:01:33.598
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":93,"skipped":1757,"failed":0}
------------------------------
â€¢ [2.088 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:31.513
    Aug 27 06:01:31.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:01:31.514
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:31.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:31.541
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Aug 27 06:01:31.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 create -f -'
    Aug 27 06:01:31.863: INFO: stderr: ""
    Aug 27 06:01:31.863: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Aug 27 06:01:31.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 create -f -'
    Aug 27 06:01:32.154: INFO: stderr: ""
    Aug 27 06:01:32.154: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/27/22 06:01:32.154
    Aug 27 06:01:33.158: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 06:01:33.158: INFO: Found 1 / 1
    Aug 27 06:01:33.158: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Aug 27 06:01:33.160: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 06:01:33.160: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 27 06:01:33.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe pod agnhost-primary-fgs9k'
    Aug 27 06:01:33.233: INFO: stderr: ""
    Aug 27 06:01:33.233: INFO: stdout: "Name:             agnhost-primary-fgs9k\nNamespace:        kubectl-8652\nPriority:         0\nService Account:  default\nNode:             ip-10-0-31-158/10.0.31.158\nStart Time:       Sat, 27 Aug 2022 06:01:31 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 0676b6e1f520d9dd552d2cc1ab60af462b9a86404922d1fc27742801792a3cb3\n                  cni.projectcalico.org/podIP: 10.2.137.100/32\n                  cni.projectcalico.org/podIPs: 10.2.137.100/32\nStatus:           Running\nIP:               10.2.137.100\nIPs:\n  IP:           10.2.137.100\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://78380fdaa5d4ad3fffafdc603f28b6dc60d46b20698e4a8c4b8dbce8c4fb900a\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 27 Aug 2022 06:01:32 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-s4xlq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-s4xlq:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-8652/agnhost-primary-fgs9k to ip-10-0-31-158\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Aug 27 06:01:33.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe rc agnhost-primary'
    Aug 27 06:01:33.312: INFO: stderr: ""
    Aug 27 06:01:33.312: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8652\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-fgs9k\n"
    Aug 27 06:01:33.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe service agnhost-primary'
    Aug 27 06:01:33.385: INFO: stderr: ""
    Aug 27 06:01:33.385: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8652\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.3.135.29\nIPs:               10.3.135.29\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.2.137.100:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Aug 27 06:01:33.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe node ip-10-0-13-52'
    Aug 27 06:01:33.496: INFO: stderr: ""
    Aug 27 06:01:33.496: INFO: stdout: "Name:               ip-10-0-13-52\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-13-52\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/controller=true\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.13.52/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.222.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 27 Aug 2022 05:27:44 +0000\nTaints:             node-role.kubernetes.io/controller:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-10-0-13-52\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 27 Aug 2022 06:01:23 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 27 Aug 2022 05:28:07 +0000   Sat, 27 Aug 2022 05:28:07 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:27:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:27:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:27:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 27 Aug 2022 06:00:31 +0000   Sat, 27 Aug 2022 05:28:04 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.13.52\n  Hostname:    ip-10-0-13-52\nCapacity:\n  cpu:                1\n  ephemeral-storage:  30921708Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1977396Ki\n  pods:               110\nAllocatable:\n  cpu:                1\n  ephemeral-storage:  28497446046\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1874996Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec24c19e4939af8699f29957ba6eed06\n  System UUID:                ec24c19e-4939-af86-99f2-9957ba6eed06\n  Boot ID:                    d9b8dd7c-21f3-4a2a-97cc-35aed5800eb8\n  Kernel Version:             5.18.16-200.fc36.x86_64\n  OS Image:                   Fedora CoreOS 36.20220806.3.0\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.6\n  Kubelet Version:            v1.25.0\n  Kube-Proxy Version:         v1.25.0\nPodCIDR:                      10.2.2.0/24\nPodCIDRs:                     10.2.2.0/24\nProviderID:                   aws:///us-east-2a/i-0b6ccec4a5d9a4630\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-zdq5j                                          100m (10%)    0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                 coredns-5f79d78b9d-7nxjl                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     34m\n  kube-system                 coredns-5f79d78b9d-q67dt                                   100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     34m\n  kube-system                 kube-apiserver-ip-10-0-13-52                               150m (15%)    0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                 kube-controller-manager-ip-10-0-13-52                      150m (15%)    0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                 kube-proxy-6wq89                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                 kube-scheduler-ip-10-0-13-52                               100m (10%)    0 (0%)      0 (0%)           0 (0%)         33m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-xmks6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                700m (70%)  0 (0%)\n  memory             140Mi (7%)  340Mi (18%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason          Age   From             Message\n  ----    ------          ----  ----             -------\n  Normal  Starting        33m   kube-proxy       \n  Normal  RegisteredNode  33m   node-controller  Node ip-10-0-13-52 event: Registered Node ip-10-0-13-52 in Controller\n"
    Aug 27 06:01:33.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8652 describe namespace kubectl-8652'
    Aug 27 06:01:33.594: INFO: stderr: ""
    Aug 27 06:01:33.594: INFO: stdout: "Name:         kubectl-8652\nLabels:       e2e-framework=kubectl\n              e2e-run=2182355c-f2a3-4ab8-bbc3-0d6edf17ebec\n              kubernetes.io/metadata.name=kubectl-8652\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:01:33.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8652" for this suite. 08/27/22 06:01:33.598
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:33.606
Aug 27 06:01:33.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:01:33.607
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:33.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:33.627
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 08/27/22 06:01:33.63
Aug 27 06:01:33.635: INFO: Waiting up to 5m0s for pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820" in namespace "emptydir-1633" to be "Succeeded or Failed"
Aug 27 06:01:33.638: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820": Phase="Pending", Reason="", readiness=false. Elapsed: 3.060995ms
Aug 27 06:01:35.643: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008164174s
Aug 27 06:01:37.647: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01157405s
STEP: Saw pod success 08/27/22 06:01:37.647
Aug 27 06:01:37.647: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820" satisfied condition "Succeeded or Failed"
Aug 27 06:01:37.651: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-66044f6d-dc9a-4c69-92fa-c5102013c820 container test-container: <nil>
STEP: delete the pod 08/27/22 06:01:37.661
Aug 27 06:01:37.680: INFO: Waiting for pod pod-66044f6d-dc9a-4c69-92fa-c5102013c820 to disappear
Aug 27 06:01:37.683: INFO: Pod pod-66044f6d-dc9a-4c69-92fa-c5102013c820 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:01:37.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1633" for this suite. 08/27/22 06:01:37.687
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":94,"skipped":1821,"failed":0}
------------------------------
â€¢ [4.085 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:33.606
    Aug 27 06:01:33.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:01:33.607
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:33.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:33.627
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 08/27/22 06:01:33.63
    Aug 27 06:01:33.635: INFO: Waiting up to 5m0s for pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820" in namespace "emptydir-1633" to be "Succeeded or Failed"
    Aug 27 06:01:33.638: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820": Phase="Pending", Reason="", readiness=false. Elapsed: 3.060995ms
    Aug 27 06:01:35.643: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008164174s
    Aug 27 06:01:37.647: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01157405s
    STEP: Saw pod success 08/27/22 06:01:37.647
    Aug 27 06:01:37.647: INFO: Pod "pod-66044f6d-dc9a-4c69-92fa-c5102013c820" satisfied condition "Succeeded or Failed"
    Aug 27 06:01:37.651: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-66044f6d-dc9a-4c69-92fa-c5102013c820 container test-container: <nil>
    STEP: delete the pod 08/27/22 06:01:37.661
    Aug 27 06:01:37.680: INFO: Waiting for pod pod-66044f6d-dc9a-4c69-92fa-c5102013c820 to disappear
    Aug 27 06:01:37.683: INFO: Pod pod-66044f6d-dc9a-4c69-92fa-c5102013c820 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:01:37.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1633" for this suite. 08/27/22 06:01:37.687
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:37.692
Aug 27 06:01:37.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:01:37.693
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:37.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:37.71
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 08/27/22 06:01:37.713
Aug 27 06:01:37.720: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-2630  2bd09050-6f40-42d9-a198-2118d4994bea 11636 0 2022-08-27 06:01:37 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:37 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wnc4x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wnc4x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 06:01:37.720: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-2630" to be "running and ready"
Aug 27 06:01:37.725: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.583352ms
Aug 27 06:01:37.725: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:39.728: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.008404869s
Aug 27 06:01:39.729: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Aug 27 06:01:39.729: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 08/27/22 06:01:39.729
Aug 27 06:01:39.729: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2630 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:01:39.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:01:39.729: INFO: ExecWithOptions: Clientset creation
Aug 27 06:01:39.729: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/dns-2630/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 08/27/22 06:01:39.853
Aug 27 06:01:39.854: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2630 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:01:39.854: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:01:39.854: INFO: ExecWithOptions: Clientset creation
Aug 27 06:01:39.855: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/dns-2630/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 27 06:01:39.947: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:01:39.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2630" for this suite. 08/27/22 06:01:39.963
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":95,"skipped":1828,"failed":0}
------------------------------
â€¢ [2.276 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:37.692
    Aug 27 06:01:37.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:01:37.693
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:37.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:37.71
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 08/27/22 06:01:37.713
    Aug 27 06:01:37.720: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-2630  2bd09050-6f40-42d9-a198-2118d4994bea 11636 0 2022-08-27 06:01:37 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-08-27 06:01:37 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wnc4x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wnc4x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 06:01:37.720: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-2630" to be "running and ready"
    Aug 27 06:01:37.725: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.583352ms
    Aug 27 06:01:37.725: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:39.728: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.008404869s
    Aug 27 06:01:39.729: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Aug 27 06:01:39.729: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 08/27/22 06:01:39.729
    Aug 27 06:01:39.729: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2630 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:01:39.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:01:39.729: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:01:39.729: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/dns-2630/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 08/27/22 06:01:39.853
    Aug 27 06:01:39.854: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2630 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:01:39.854: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:01:39.854: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:01:39.855: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/dns-2630/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 27 06:01:39.947: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:01:39.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2630" for this suite. 08/27/22 06:01:39.963
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:39.969
Aug 27 06:01:39.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pod-network-test 08/27/22 06:01:39.97
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:39.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:39.99
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-4912 08/27/22 06:01:39.995
STEP: creating a selector 08/27/22 06:01:39.995
STEP: Creating the service pods in kubernetes 08/27/22 06:01:39.995
Aug 27 06:01:39.995: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 27 06:01:40.022: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4912" to be "running and ready"
Aug 27 06:01:40.033: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.983304ms
Aug 27 06:01:40.033: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:01:42.037: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.015334552s
Aug 27 06:01:42.037: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 06:01:44.038: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.016292444s
Aug 27 06:01:44.038: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 06:01:46.038: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.015984065s
Aug 27 06:01:46.038: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 06:01:48.037: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.015391844s
Aug 27 06:01:48.037: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 06:01:50.039: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016885397s
Aug 27 06:01:50.039: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Aug 27 06:01:52.040: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.018379854s
Aug 27 06:01:52.040: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Aug 27 06:01:52.040: INFO: Pod "netserver-0" satisfied condition "running and ready"
Aug 27 06:01:52.043: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4912" to be "running and ready"
Aug 27 06:01:52.048: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.900412ms
Aug 27 06:01:52.048: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Aug 27 06:01:52.048: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 08/27/22 06:01:52.054
Aug 27 06:01:52.072: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4912" to be "running"
Aug 27 06:01:52.096: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 23.975899ms
Aug 27 06:01:54.100: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.027931474s
Aug 27 06:01:54.100: INFO: Pod "test-container-pod" satisfied condition "running"
Aug 27 06:01:54.103: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-4912" to be "running"
Aug 27 06:01:54.106: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.753332ms
Aug 27 06:01:54.106: INFO: Pod "host-test-container-pod" satisfied condition "running"
Aug 27 06:01:54.108: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Aug 27 06:01:54.108: INFO: Going to poll 10.2.137.101 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Aug 27 06:01:54.111: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.137.101 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4912 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:01:54.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:01:54.112: INFO: ExecWithOptions: Clientset creation
Aug 27 06:01:54.112: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4912/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.2.137.101+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 27 06:01:55.171: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 27 06:01:55.171: INFO: Going to poll 10.2.35.142 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Aug 27 06:01:55.175: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.35.142 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4912 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:01:55.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:01:55.175: INFO: ExecWithOptions: Clientset creation
Aug 27 06:01:55.175: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4912/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.2.35.142+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Aug 27 06:01:56.242: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Aug 27 06:01:56.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4912" for this suite. 08/27/22 06:01:56.245
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":96,"skipped":1838,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.285 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:39.969
    Aug 27 06:01:39.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pod-network-test 08/27/22 06:01:39.97
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:39.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:39.99
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-4912 08/27/22 06:01:39.995
    STEP: creating a selector 08/27/22 06:01:39.995
    STEP: Creating the service pods in kubernetes 08/27/22 06:01:39.995
    Aug 27 06:01:39.995: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Aug 27 06:01:40.022: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4912" to be "running and ready"
    Aug 27 06:01:40.033: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.983304ms
    Aug 27 06:01:40.033: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:01:42.037: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.015334552s
    Aug 27 06:01:42.037: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 06:01:44.038: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.016292444s
    Aug 27 06:01:44.038: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 06:01:46.038: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.015984065s
    Aug 27 06:01:46.038: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 06:01:48.037: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.015391844s
    Aug 27 06:01:48.037: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 06:01:50.039: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016885397s
    Aug 27 06:01:50.039: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Aug 27 06:01:52.040: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.018379854s
    Aug 27 06:01:52.040: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Aug 27 06:01:52.040: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Aug 27 06:01:52.043: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4912" to be "running and ready"
    Aug 27 06:01:52.048: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.900412ms
    Aug 27 06:01:52.048: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Aug 27 06:01:52.048: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 08/27/22 06:01:52.054
    Aug 27 06:01:52.072: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4912" to be "running"
    Aug 27 06:01:52.096: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 23.975899ms
    Aug 27 06:01:54.100: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.027931474s
    Aug 27 06:01:54.100: INFO: Pod "test-container-pod" satisfied condition "running"
    Aug 27 06:01:54.103: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-4912" to be "running"
    Aug 27 06:01:54.106: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.753332ms
    Aug 27 06:01:54.106: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Aug 27 06:01:54.108: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Aug 27 06:01:54.108: INFO: Going to poll 10.2.137.101 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Aug 27 06:01:54.111: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.137.101 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4912 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:01:54.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:01:54.112: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:01:54.112: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4912/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.2.137.101+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 27 06:01:55.171: INFO: Found all 1 expected endpoints: [netserver-0]
    Aug 27 06:01:55.171: INFO: Going to poll 10.2.35.142 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Aug 27 06:01:55.175: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.35.142 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4912 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:01:55.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:01:55.175: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:01:55.175: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/pod-network-test-4912/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.2.35.142+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Aug 27 06:01:56.242: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Aug 27 06:01:56.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4912" for this suite. 08/27/22 06:01:56.245
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:56.255
Aug 27 06:01:56.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename events 08/27/22 06:01:56.256
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:56.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:56.284
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 08/27/22 06:01:56.288
STEP: listing all events in all namespaces 08/27/22 06:01:56.292
STEP: patching the test event 08/27/22 06:01:56.304
STEP: fetching the test event 08/27/22 06:01:56.31
STEP: updating the test event 08/27/22 06:01:56.317
STEP: getting the test event 08/27/22 06:01:56.326
STEP: deleting the test event 08/27/22 06:01:56.329
STEP: listing all events in all namespaces 08/27/22 06:01:56.335
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Aug 27 06:01:56.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1781" for this suite. 08/27/22 06:01:56.345
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":97,"skipped":1840,"failed":0}
------------------------------
â€¢ [0.095 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:56.255
    Aug 27 06:01:56.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename events 08/27/22 06:01:56.256
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:56.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:56.284
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 08/27/22 06:01:56.288
    STEP: listing all events in all namespaces 08/27/22 06:01:56.292
    STEP: patching the test event 08/27/22 06:01:56.304
    STEP: fetching the test event 08/27/22 06:01:56.31
    STEP: updating the test event 08/27/22 06:01:56.317
    STEP: getting the test event 08/27/22 06:01:56.326
    STEP: deleting the test event 08/27/22 06:01:56.329
    STEP: listing all events in all namespaces 08/27/22 06:01:56.335
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Aug 27 06:01:56.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1781" for this suite. 08/27/22 06:01:56.345
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:56.351
Aug 27 06:01:56.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:01:56.352
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:56.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:56.383
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 08/27/22 06:01:56.387
STEP: getting /apis/node.k8s.io 08/27/22 06:01:56.393
STEP: getting /apis/node.k8s.io/v1 08/27/22 06:01:56.396
STEP: creating 08/27/22 06:01:56.397
STEP: watching 08/27/22 06:01:56.408
Aug 27 06:01:56.408: INFO: starting watch
STEP: getting 08/27/22 06:01:56.417
STEP: listing 08/27/22 06:01:56.42
STEP: patching 08/27/22 06:01:56.423
STEP: updating 08/27/22 06:01:56.428
Aug 27 06:01:56.433: INFO: waiting for watch events with expected annotations
STEP: deleting 08/27/22 06:01:56.433
STEP: deleting a collection 08/27/22 06:01:56.444
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 27 06:01:56.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-449" for this suite. 08/27/22 06:01:56.462
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":98,"skipped":1849,"failed":0}
------------------------------
â€¢ [0.115 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:56.351
    Aug 27 06:01:56.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:01:56.352
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:56.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:56.383
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 08/27/22 06:01:56.387
    STEP: getting /apis/node.k8s.io 08/27/22 06:01:56.393
    STEP: getting /apis/node.k8s.io/v1 08/27/22 06:01:56.396
    STEP: creating 08/27/22 06:01:56.397
    STEP: watching 08/27/22 06:01:56.408
    Aug 27 06:01:56.408: INFO: starting watch
    STEP: getting 08/27/22 06:01:56.417
    STEP: listing 08/27/22 06:01:56.42
    STEP: patching 08/27/22 06:01:56.423
    STEP: updating 08/27/22 06:01:56.428
    Aug 27 06:01:56.433: INFO: waiting for watch events with expected annotations
    STEP: deleting 08/27/22 06:01:56.433
    STEP: deleting a collection 08/27/22 06:01:56.444
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 27 06:01:56.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-449" for this suite. 08/27/22 06:01:56.462
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:01:56.476
Aug 27 06:01:56.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:01:56.477
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:56.496
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:56.499
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 08/27/22 06:01:56.503
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 08/27/22 06:01:56.503
STEP: creating a pod to probe DNS 08/27/22 06:01:56.503
STEP: submitting the pod to kubernetes 08/27/22 06:01:56.503
Aug 27 06:01:56.510: INFO: Waiting up to 15m0s for pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329" in namespace "dns-2300" to be "running"
Aug 27 06:01:56.520: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 9.186863ms
Aug 27 06:01:58.524: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013509114s
Aug 27 06:02:00.525: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014859363s
Aug 27 06:02:02.549: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038829625s
Aug 27 06:02:04.526: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015095225s
Aug 27 06:02:06.524: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Running", Reason="", readiness=true. Elapsed: 10.013785877s
Aug 27 06:02:06.525: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:02:06.525
STEP: looking for the results for each expected name from probers 08/27/22 06:02:06.537
Aug 27 06:02:06.581: INFO: DNS probes using dns-2300/dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329 succeeded

STEP: deleting the pod 08/27/22 06:02:06.581
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:02:06.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2300" for this suite. 08/27/22 06:02:06.65
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":99,"skipped":1891,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.182 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:01:56.476
    Aug 27 06:01:56.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:01:56.477
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:01:56.496
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:01:56.499
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     08/27/22 06:01:56.503
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     08/27/22 06:01:56.503
    STEP: creating a pod to probe DNS 08/27/22 06:01:56.503
    STEP: submitting the pod to kubernetes 08/27/22 06:01:56.503
    Aug 27 06:01:56.510: INFO: Waiting up to 15m0s for pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329" in namespace "dns-2300" to be "running"
    Aug 27 06:01:56.520: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 9.186863ms
    Aug 27 06:01:58.524: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013509114s
    Aug 27 06:02:00.525: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014859363s
    Aug 27 06:02:02.549: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038829625s
    Aug 27 06:02:04.526: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015095225s
    Aug 27 06:02:06.524: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329": Phase="Running", Reason="", readiness=true. Elapsed: 10.013785877s
    Aug 27 06:02:06.525: INFO: Pod "dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:02:06.525
    STEP: looking for the results for each expected name from probers 08/27/22 06:02:06.537
    Aug 27 06:02:06.581: INFO: DNS probes using dns-2300/dns-test-dc6fa35d-92ea-4957-97e4-1795a7e91329 succeeded

    STEP: deleting the pod 08/27/22 06:02:06.581
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:02:06.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2300" for this suite. 08/27/22 06:02:06.65
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:02:06.665
Aug 27 06:02:06.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:02:06.671
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:02:06.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:02:06.709
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 08/27/22 06:02:06.713
STEP: listing secrets in all namespaces to ensure that there are more than zero 08/27/22 06:02:06.719
STEP: patching the secret 08/27/22 06:02:06.723
STEP: deleting the secret using a LabelSelector 08/27/22 06:02:06.731
STEP: listing secrets in all namespaces, searching for label name and value in patch 08/27/22 06:02:06.742
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:02:06.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9281" for this suite. 08/27/22 06:02:06.749
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":100,"skipped":1908,"failed":0}
------------------------------
â€¢ [0.093 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:02:06.665
    Aug 27 06:02:06.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:02:06.671
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:02:06.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:02:06.709
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 08/27/22 06:02:06.713
    STEP: listing secrets in all namespaces to ensure that there are more than zero 08/27/22 06:02:06.719
    STEP: patching the secret 08/27/22 06:02:06.723
    STEP: deleting the secret using a LabelSelector 08/27/22 06:02:06.731
    STEP: listing secrets in all namespaces, searching for label name and value in patch 08/27/22 06:02:06.742
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:02:06.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9281" for this suite. 08/27/22 06:02:06.749
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:02:06.776
Aug 27 06:02:06.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-watch 08/27/22 06:02:06.777
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:02:06.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:02:06.826
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Aug 27 06:02:06.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Creating first CR  08/27/22 06:02:09.399
Aug 27 06:02:09.404: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:09Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:09Z]] name:name1 resourceVersion:11911 uid:15d094d5-27ed-4351-9094-6f8157fa4139] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 08/27/22 06:02:19.407
Aug 27 06:02:19.415: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:19Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:19Z]] name:name2 resourceVersion:11947 uid:2242f168-193a-4934-aa58-3995b79fcaa2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 08/27/22 06:02:29.417
Aug 27 06:02:29.422: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:09Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:29Z]] name:name1 resourceVersion:11962 uid:15d094d5-27ed-4351-9094-6f8157fa4139] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 08/27/22 06:02:39.426
Aug 27 06:02:39.432: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:39Z]] name:name2 resourceVersion:11977 uid:2242f168-193a-4934-aa58-3995b79fcaa2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 08/27/22 06:02:49.432
Aug 27 06:02:49.438: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:09Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:29Z]] name:name1 resourceVersion:11992 uid:15d094d5-27ed-4351-9094-6f8157fa4139] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 08/27/22 06:02:59.439
Aug 27 06:02:59.445: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:39Z]] name:name2 resourceVersion:12007 uid:2242f168-193a-4934-aa58-3995b79fcaa2] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:03:09.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-955" for this suite. 08/27/22 06:03:09.97
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":101,"skipped":2012,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.203 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:02:06.776
    Aug 27 06:02:06.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-watch 08/27/22 06:02:06.777
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:02:06.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:02:06.826
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Aug 27 06:02:06.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Creating first CR  08/27/22 06:02:09.399
    Aug 27 06:02:09.404: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:09Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:09Z]] name:name1 resourceVersion:11911 uid:15d094d5-27ed-4351-9094-6f8157fa4139] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 08/27/22 06:02:19.407
    Aug 27 06:02:19.415: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:19Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:19Z]] name:name2 resourceVersion:11947 uid:2242f168-193a-4934-aa58-3995b79fcaa2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 08/27/22 06:02:29.417
    Aug 27 06:02:29.422: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:09Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:29Z]] name:name1 resourceVersion:11962 uid:15d094d5-27ed-4351-9094-6f8157fa4139] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 08/27/22 06:02:39.426
    Aug 27 06:02:39.432: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:39Z]] name:name2 resourceVersion:11977 uid:2242f168-193a-4934-aa58-3995b79fcaa2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 08/27/22 06:02:49.432
    Aug 27 06:02:49.438: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:09Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:29Z]] name:name1 resourceVersion:11992 uid:15d094d5-27ed-4351-9094-6f8157fa4139] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 08/27/22 06:02:59.439
    Aug 27 06:02:59.445: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-27T06:02:19Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-27T06:02:39Z]] name:name2 resourceVersion:12007 uid:2242f168-193a-4934-aa58-3995b79fcaa2] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:03:09.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-955" for this suite. 08/27/22 06:03:09.97
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:09.979
Aug 27 06:03:09.980: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:03:09.981
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:10.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:10.016
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:03:10.022
Aug 27 06:03:10.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd" in namespace "downward-api-2098" to be "Succeeded or Failed"
Aug 27 06:03:10.033: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019791ms
Aug 27 06:03:12.037: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007745039s
Aug 27 06:03:14.037: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007808765s
STEP: Saw pod success 08/27/22 06:03:14.037
Aug 27 06:03:14.037: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd" satisfied condition "Succeeded or Failed"
Aug 27 06:03:14.040: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd container client-container: <nil>
STEP: delete the pod 08/27/22 06:03:14.054
Aug 27 06:03:14.065: INFO: Waiting for pod downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd to disappear
Aug 27 06:03:14.070: INFO: Pod downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:03:14.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2098" for this suite. 08/27/22 06:03:14.073
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":102,"skipped":2012,"failed":0}
------------------------------
â€¢ [4.104 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:09.979
    Aug 27 06:03:09.980: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:03:09.981
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:10.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:10.016
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:03:10.022
    Aug 27 06:03:10.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd" in namespace "downward-api-2098" to be "Succeeded or Failed"
    Aug 27 06:03:10.033: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019791ms
    Aug 27 06:03:12.037: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007745039s
    Aug 27 06:03:14.037: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007808765s
    STEP: Saw pod success 08/27/22 06:03:14.037
    Aug 27 06:03:14.037: INFO: Pod "downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd" satisfied condition "Succeeded or Failed"
    Aug 27 06:03:14.040: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd container client-container: <nil>
    STEP: delete the pod 08/27/22 06:03:14.054
    Aug 27 06:03:14.065: INFO: Waiting for pod downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd to disappear
    Aug 27 06:03:14.070: INFO: Pod downwardapi-volume-3d933bc7-2936-4abe-9812-187cb81e71cd no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:03:14.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2098" for this suite. 08/27/22 06:03:14.073
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:14.089
Aug 27 06:03:14.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:03:14.09
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:14.106
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:14.11
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-1f4bde25-ff93-453b-ad56-5a29cc75ec22 08/27/22 06:03:14.119
STEP: Creating a pod to test consume secrets 08/27/22 06:03:14.123
Aug 27 06:03:14.130: INFO: Waiting up to 5m0s for pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09" in namespace "secrets-6151" to be "Succeeded or Failed"
Aug 27 06:03:14.133: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.66651ms
Aug 27 06:03:16.138: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007544476s
Aug 27 06:03:18.138: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007395813s
STEP: Saw pod success 08/27/22 06:03:18.138
Aug 27 06:03:18.138: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09" satisfied condition "Succeeded or Failed"
Aug 27 06:03:18.141: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:03:18.147
Aug 27 06:03:18.156: INFO: Waiting for pod pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09 to disappear
Aug 27 06:03:18.159: INFO: Pod pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:03:18.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6151" for this suite. 08/27/22 06:03:18.164
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":103,"skipped":2054,"failed":0}
------------------------------
â€¢ [4.079 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:14.089
    Aug 27 06:03:14.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:03:14.09
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:14.106
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:14.11
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-1f4bde25-ff93-453b-ad56-5a29cc75ec22 08/27/22 06:03:14.119
    STEP: Creating a pod to test consume secrets 08/27/22 06:03:14.123
    Aug 27 06:03:14.130: INFO: Waiting up to 5m0s for pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09" in namespace "secrets-6151" to be "Succeeded or Failed"
    Aug 27 06:03:14.133: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.66651ms
    Aug 27 06:03:16.138: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007544476s
    Aug 27 06:03:18.138: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007395813s
    STEP: Saw pod success 08/27/22 06:03:18.138
    Aug 27 06:03:18.138: INFO: Pod "pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09" satisfied condition "Succeeded or Failed"
    Aug 27 06:03:18.141: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:03:18.147
    Aug 27 06:03:18.156: INFO: Waiting for pod pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09 to disappear
    Aug 27 06:03:18.159: INFO: Pod pod-secrets-b5b9f315-4100-44a1-86ef-39b7f8ed5c09 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:03:18.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6151" for this suite. 08/27/22 06:03:18.164
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:18.171
Aug 27 06:03:18.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename cronjob 08/27/22 06:03:18.172
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:18.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:18.191
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 08/27/22 06:03:18.194
STEP: creating 08/27/22 06:03:18.195
STEP: getting 08/27/22 06:03:18.199
STEP: listing 08/27/22 06:03:18.202
STEP: watching 08/27/22 06:03:18.205
Aug 27 06:03:18.205: INFO: starting watch
STEP: cluster-wide listing 08/27/22 06:03:18.207
STEP: cluster-wide watching 08/27/22 06:03:18.209
Aug 27 06:03:18.209: INFO: starting watch
STEP: patching 08/27/22 06:03:18.211
STEP: updating 08/27/22 06:03:18.217
Aug 27 06:03:18.224: INFO: waiting for watch events with expected annotations
Aug 27 06:03:18.225: INFO: saw patched and updated annotations
STEP: patching /status 08/27/22 06:03:18.225
STEP: updating /status 08/27/22 06:03:18.233
STEP: get /status 08/27/22 06:03:18.241
STEP: deleting 08/27/22 06:03:18.245
STEP: deleting a collection 08/27/22 06:03:18.257
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 27 06:03:18.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9900" for this suite. 08/27/22 06:03:18.268
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":104,"skipped":2061,"failed":0}
------------------------------
â€¢ [0.101 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:18.171
    Aug 27 06:03:18.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename cronjob 08/27/22 06:03:18.172
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:18.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:18.191
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 08/27/22 06:03:18.194
    STEP: creating 08/27/22 06:03:18.195
    STEP: getting 08/27/22 06:03:18.199
    STEP: listing 08/27/22 06:03:18.202
    STEP: watching 08/27/22 06:03:18.205
    Aug 27 06:03:18.205: INFO: starting watch
    STEP: cluster-wide listing 08/27/22 06:03:18.207
    STEP: cluster-wide watching 08/27/22 06:03:18.209
    Aug 27 06:03:18.209: INFO: starting watch
    STEP: patching 08/27/22 06:03:18.211
    STEP: updating 08/27/22 06:03:18.217
    Aug 27 06:03:18.224: INFO: waiting for watch events with expected annotations
    Aug 27 06:03:18.225: INFO: saw patched and updated annotations
    STEP: patching /status 08/27/22 06:03:18.225
    STEP: updating /status 08/27/22 06:03:18.233
    STEP: get /status 08/27/22 06:03:18.241
    STEP: deleting 08/27/22 06:03:18.245
    STEP: deleting a collection 08/27/22 06:03:18.257
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 27 06:03:18.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9900" for this suite. 08/27/22 06:03:18.268
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:18.274
Aug 27 06:03:18.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename job 08/27/22 06:03:18.275
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:18.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:18.301
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 08/27/22 06:03:18.309
STEP: Ensuring job reaches completions 08/27/22 06:03:18.313
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 27 06:03:28.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-291" for this suite. 08/27/22 06:03:28.321
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":105,"skipped":2065,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.058 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:18.274
    Aug 27 06:03:18.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename job 08/27/22 06:03:18.275
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:18.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:18.301
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 08/27/22 06:03:18.309
    STEP: Ensuring job reaches completions 08/27/22 06:03:18.313
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 27 06:03:28.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-291" for this suite. 08/27/22 06:03:28.321
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:28.332
Aug 27 06:03:28.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replication-controller 08/27/22 06:03:28.339
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:28.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:28.373
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Aug 27 06:03:28.376: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 08/27/22 06:03:29.385
STEP: Checking rc "condition-test" has the desired failure condition set 08/27/22 06:03:29.39
STEP: Scaling down rc "condition-test" to satisfy pod quota 08/27/22 06:03:30.397
Aug 27 06:03:30.409: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 08/27/22 06:03:30.409
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 27 06:03:31.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3663" for this suite. 08/27/22 06:03:31.422
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":106,"skipped":2069,"failed":0}
------------------------------
â€¢ [3.094 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:28.332
    Aug 27 06:03:28.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replication-controller 08/27/22 06:03:28.339
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:28.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:28.373
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Aug 27 06:03:28.376: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 08/27/22 06:03:29.385
    STEP: Checking rc "condition-test" has the desired failure condition set 08/27/22 06:03:29.39
    STEP: Scaling down rc "condition-test" to satisfy pod quota 08/27/22 06:03:30.397
    Aug 27 06:03:30.409: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 08/27/22 06:03:30.409
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 27 06:03:31.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3663" for this suite. 08/27/22 06:03:31.422
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:31.427
Aug 27 06:03:31.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:03:31.429
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:31.444
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:31.451
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9125 08/27/22 06:03:31.455
STEP: changing the ExternalName service to type=NodePort 08/27/22 06:03:31.461
STEP: creating replication controller externalname-service in namespace services-9125 08/27/22 06:03:31.485
I0827 06:03:31.494228      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9125, replica count: 2
I0827 06:03:34.549626      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 06:03:34.549: INFO: Creating new exec pod
Aug 27 06:03:34.555: INFO: Waiting up to 5m0s for pod "execpodtq9cq" in namespace "services-9125" to be "running"
Aug 27 06:03:34.559: INFO: Pod "execpodtq9cq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78373ms
Aug 27 06:03:36.574: INFO: Pod "execpodtq9cq": Phase="Running", Reason="", readiness=true. Elapsed: 2.018157649s
Aug 27 06:03:36.574: INFO: Pod "execpodtq9cq" satisfied condition "running"
Aug 27 06:03:37.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 27 06:03:37.801: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:37.801: INFO: stdout: "externalname-service-pcf6s"
Aug 27 06:03:37.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
Aug 27 06:03:37.960: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:37.960: INFO: stdout: ""
Aug 27 06:03:38.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
Aug 27 06:03:39.105: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:39.105: INFO: stdout: ""
Aug 27 06:03:39.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
Aug 27 06:03:40.173: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:40.173: INFO: stdout: ""
Aug 27 06:03:40.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
Aug 27 06:03:41.127: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:41.127: INFO: stdout: "externalname-service-pcf6s"
Aug 27 06:03:41.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 32095'
Aug 27 06:03:41.340: INFO: stderr: "+ + nc -v -t -w 2 10.0.31.158 32095\necho hostName\nConnection to 10.0.31.158 32095 port [tcp/*] succeeded!\n"
Aug 27 06:03:41.340: INFO: stdout: ""
Aug 27 06:03:42.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 32095'
Aug 27 06:03:42.513: INFO: stderr: "+ nc -v -t -w 2 10.0.31.158 32095\n+ echo hostName\nConnection to 10.0.31.158 32095 port [tcp/*] succeeded!\n"
Aug 27 06:03:42.513: INFO: stdout: "externalname-service-k7svb"
Aug 27 06:03:42.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32095'
Aug 27 06:03:42.698: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32095\nConnection to 10.0.47.192 32095 port [tcp/*] succeeded!\n"
Aug 27 06:03:42.698: INFO: stdout: ""
Aug 27 06:03:43.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32095'
Aug 27 06:03:43.902: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32095\nConnection to 10.0.47.192 32095 port [tcp/*] succeeded!\n"
Aug 27 06:03:43.902: INFO: stdout: ""
Aug 27 06:03:44.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32095'
Aug 27 06:03:45.019: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32095\nConnection to 10.0.47.192 32095 port [tcp/*] succeeded!\n"
Aug 27 06:03:45.019: INFO: stdout: "externalname-service-pcf6s"
Aug 27 06:03:45.019: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:03:45.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9125" for this suite. 08/27/22 06:03:45.13
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":107,"skipped":2076,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.714 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:31.427
    Aug 27 06:03:31.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:03:31.429
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:31.444
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:31.451
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-9125 08/27/22 06:03:31.455
    STEP: changing the ExternalName service to type=NodePort 08/27/22 06:03:31.461
    STEP: creating replication controller externalname-service in namespace services-9125 08/27/22 06:03:31.485
    I0827 06:03:31.494228      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9125, replica count: 2
    I0827 06:03:34.549626      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 06:03:34.549: INFO: Creating new exec pod
    Aug 27 06:03:34.555: INFO: Waiting up to 5m0s for pod "execpodtq9cq" in namespace "services-9125" to be "running"
    Aug 27 06:03:34.559: INFO: Pod "execpodtq9cq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78373ms
    Aug 27 06:03:36.574: INFO: Pod "execpodtq9cq": Phase="Running", Reason="", readiness=true. Elapsed: 2.018157649s
    Aug 27 06:03:36.574: INFO: Pod "execpodtq9cq" satisfied condition "running"
    Aug 27 06:03:37.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 27 06:03:37.801: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:37.801: INFO: stdout: "externalname-service-pcf6s"
    Aug 27 06:03:37.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
    Aug 27 06:03:37.960: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:37.960: INFO: stdout: ""
    Aug 27 06:03:38.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
    Aug 27 06:03:39.105: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:39.105: INFO: stdout: ""
    Aug 27 06:03:39.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
    Aug 27 06:03:40.173: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:40.173: INFO: stdout: ""
    Aug 27 06:03:40.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.208.167 80'
    Aug 27 06:03:41.127: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.208.167 80\nConnection to 10.3.208.167 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:41.127: INFO: stdout: "externalname-service-pcf6s"
    Aug 27 06:03:41.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 32095'
    Aug 27 06:03:41.340: INFO: stderr: "+ + nc -v -t -w 2 10.0.31.158 32095\necho hostName\nConnection to 10.0.31.158 32095 port [tcp/*] succeeded!\n"
    Aug 27 06:03:41.340: INFO: stdout: ""
    Aug 27 06:03:42.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 32095'
    Aug 27 06:03:42.513: INFO: stderr: "+ nc -v -t -w 2 10.0.31.158 32095\n+ echo hostName\nConnection to 10.0.31.158 32095 port [tcp/*] succeeded!\n"
    Aug 27 06:03:42.513: INFO: stdout: "externalname-service-k7svb"
    Aug 27 06:03:42.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32095'
    Aug 27 06:03:42.698: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32095\nConnection to 10.0.47.192 32095 port [tcp/*] succeeded!\n"
    Aug 27 06:03:42.698: INFO: stdout: ""
    Aug 27 06:03:43.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32095'
    Aug 27 06:03:43.902: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32095\nConnection to 10.0.47.192 32095 port [tcp/*] succeeded!\n"
    Aug 27 06:03:43.902: INFO: stdout: ""
    Aug 27 06:03:44.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-9125 exec execpodtq9cq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 32095'
    Aug 27 06:03:45.019: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 32095\nConnection to 10.0.47.192 32095 port [tcp/*] succeeded!\n"
    Aug 27 06:03:45.019: INFO: stdout: "externalname-service-pcf6s"
    Aug 27 06:03:45.019: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:03:45.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9125" for this suite. 08/27/22 06:03:45.13
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:03:45.141
Aug 27 06:03:45.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:03:45.143
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:45.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:45.208
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-5640 08/27/22 06:03:45.214
Aug 27 06:03:45.228: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5640" to be "running and ready"
Aug 27 06:03:45.236: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 8.065164ms
Aug 27 06:03:45.236: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:03:47.241: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.012968169s
Aug 27 06:03:47.241: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug 27 06:03:47.241: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Aug 27 06:03:47.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 27 06:03:47.437: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 27 06:03:47.437: INFO: stdout: "ipvs"
Aug 27 06:03:47.437: INFO: proxyMode: ipvs
Aug 27 06:03:47.453: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 27 06:03:47.456: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-5640 08/27/22 06:03:47.456
STEP: creating replication controller affinity-nodeport-timeout in namespace services-5640 08/27/22 06:03:47.466
I0827 06:03:47.481094      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-5640, replica count: 3
I0827 06:03:50.546556      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 06:03:53.549244      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 06:03:53.557: INFO: Creating new exec pod
Aug 27 06:03:53.561: INFO: Waiting up to 5m0s for pod "execpod-affinitysvpwl" in namespace "services-5640" to be "running"
Aug 27 06:03:53.563: INFO: Pod "execpod-affinitysvpwl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.334792ms
Aug 27 06:03:55.571: INFO: Pod "execpod-affinitysvpwl": Phase="Running", Reason="", readiness=true. Elapsed: 2.010053832s
Aug 27 06:03:55.571: INFO: Pod "execpod-affinitysvpwl" satisfied condition "running"
Aug 27 06:03:56.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Aug 27 06:03:56.747: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:56.748: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:03:56.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.170.86 80'
Aug 27 06:03:56.883: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.170.86 80\nConnection to 10.3.170.86 80 port [tcp/http] succeeded!\n"
Aug 27 06:03:56.883: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:03:56.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 30639'
Aug 27 06:03:57.027: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 30639\nConnection to 10.0.31.158 30639 port [tcp/*] succeeded!\n"
Aug 27 06:03:57.027: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:03:57.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 30639'
Aug 27 06:03:57.176: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.0.47.192 30639\nConnection to 10.0.47.192 30639 port [tcp/*] succeeded!\n"
Aug 27 06:03:57.176: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:03:57.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30639/ ; done'
Aug 27 06:03:57.448: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n"
Aug 27 06:03:57.448: INFO: stdout: "\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd"
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
Aug 27 06:03:57.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.31.158:30639/'
Aug 27 06:03:57.730: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n"
Aug 27 06:03:57.730: INFO: stdout: "affinity-nodeport-timeout-bxktd"
Aug 27 06:06:07.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.31.158:30639/'
Aug 27 06:06:07.874: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n"
Aug 27 06:06:07.874: INFO: stdout: "affinity-nodeport-timeout-ntp6w"
Aug 27 06:06:07.874: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-5640, will wait for the garbage collector to delete the pods 08/27/22 06:06:07.888
Aug 27 06:06:07.951: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.924688ms
Aug 27 06:06:08.052: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.795558ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:06:10.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5640" for this suite. 08/27/22 06:06:10.581
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":108,"skipped":2076,"failed":0}
------------------------------
â€¢ [SLOW TEST] [145.446 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:03:45.141
    Aug 27 06:03:45.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:03:45.143
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:03:45.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:03:45.208
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-5640 08/27/22 06:03:45.214
    Aug 27 06:03:45.228: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5640" to be "running and ready"
    Aug 27 06:03:45.236: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 8.065164ms
    Aug 27 06:03:45.236: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:03:47.241: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.012968169s
    Aug 27 06:03:47.241: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Aug 27 06:03:47.241: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Aug 27 06:03:47.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Aug 27 06:03:47.437: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Aug 27 06:03:47.437: INFO: stdout: "ipvs"
    Aug 27 06:03:47.437: INFO: proxyMode: ipvs
    Aug 27 06:03:47.453: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Aug 27 06:03:47.456: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-5640 08/27/22 06:03:47.456
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-5640 08/27/22 06:03:47.466
    I0827 06:03:47.481094      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-5640, replica count: 3
    I0827 06:03:50.546556      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0827 06:03:53.549244      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 06:03:53.557: INFO: Creating new exec pod
    Aug 27 06:03:53.561: INFO: Waiting up to 5m0s for pod "execpod-affinitysvpwl" in namespace "services-5640" to be "running"
    Aug 27 06:03:53.563: INFO: Pod "execpod-affinitysvpwl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.334792ms
    Aug 27 06:03:55.571: INFO: Pod "execpod-affinitysvpwl": Phase="Running", Reason="", readiness=true. Elapsed: 2.010053832s
    Aug 27 06:03:55.571: INFO: Pod "execpod-affinitysvpwl" satisfied condition "running"
    Aug 27 06:03:56.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Aug 27 06:03:56.747: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:56.748: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:03:56.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.170.86 80'
    Aug 27 06:03:56.883: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.170.86 80\nConnection to 10.3.170.86 80 port [tcp/http] succeeded!\n"
    Aug 27 06:03:56.883: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:03:56.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 30639'
    Aug 27 06:03:57.027: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 30639\nConnection to 10.0.31.158 30639 port [tcp/*] succeeded!\n"
    Aug 27 06:03:57.027: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:03:57.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 30639'
    Aug 27 06:03:57.176: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.0.47.192 30639\nConnection to 10.0.47.192 30639 port [tcp/*] succeeded!\n"
    Aug 27 06:03:57.176: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:03:57.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30639/ ; done'
    Aug 27 06:03:57.448: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n"
    Aug 27 06:03:57.448: INFO: stdout: "\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd\naffinity-nodeport-timeout-bxktd"
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Received response from host: affinity-nodeport-timeout-bxktd
    Aug 27 06:03:57.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.31.158:30639/'
    Aug 27 06:03:57.730: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n"
    Aug 27 06:03:57.730: INFO: stdout: "affinity-nodeport-timeout-bxktd"
    Aug 27 06:06:07.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-5640 exec execpod-affinitysvpwl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.0.31.158:30639/'
    Aug 27 06:06:07.874: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.0.31.158:30639/\n"
    Aug 27 06:06:07.874: INFO: stdout: "affinity-nodeport-timeout-ntp6w"
    Aug 27 06:06:07.874: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-5640, will wait for the garbage collector to delete the pods 08/27/22 06:06:07.888
    Aug 27 06:06:07.951: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.924688ms
    Aug 27 06:06:08.052: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.795558ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:06:10.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5640" for this suite. 08/27/22 06:06:10.581
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:10.588
Aug 27 06:06:10.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename proxy 08/27/22 06:06:10.59
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:10.609
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:10.613
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Aug 27 06:06:10.617: INFO: Creating pod...
Aug 27 06:06:10.626: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1191" to be "running"
Aug 27 06:06:10.631: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.267175ms
Aug 27 06:06:12.639: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.01308719s
Aug 27 06:06:12.639: INFO: Pod "agnhost" satisfied condition "running"
Aug 27 06:06:12.639: INFO: Creating service...
Aug 27 06:06:12.646: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/DELETE
Aug 27 06:06:12.664: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 27 06:06:12.665: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/GET
Aug 27 06:06:12.671: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 27 06:06:12.672: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/HEAD
Aug 27 06:06:12.677: INFO: http.Client request:HEAD | StatusCode:200
Aug 27 06:06:12.677: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/OPTIONS
Aug 27 06:06:12.682: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 27 06:06:12.682: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/PATCH
Aug 27 06:06:12.688: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 27 06:06:12.688: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/POST
Aug 27 06:06:12.694: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 27 06:06:12.694: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/PUT
Aug 27 06:06:12.700: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 27 06:06:12.700: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/DELETE
Aug 27 06:06:12.707: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 27 06:06:12.707: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/GET
Aug 27 06:06:12.714: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 27 06:06:12.714: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/HEAD
Aug 27 06:06:12.721: INFO: http.Client request:HEAD | StatusCode:200
Aug 27 06:06:12.721: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/OPTIONS
Aug 27 06:06:12.741: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 27 06:06:12.741: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/PATCH
Aug 27 06:06:12.751: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 27 06:06:12.751: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/POST
Aug 27 06:06:12.766: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 27 06:06:12.766: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/PUT
Aug 27 06:06:12.781: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 27 06:06:12.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1191" for this suite. 08/27/22 06:06:12.786
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":109,"skipped":2076,"failed":0}
------------------------------
â€¢ [2.203 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:10.588
    Aug 27 06:06:10.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename proxy 08/27/22 06:06:10.59
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:10.609
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:10.613
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Aug 27 06:06:10.617: INFO: Creating pod...
    Aug 27 06:06:10.626: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1191" to be "running"
    Aug 27 06:06:10.631: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.267175ms
    Aug 27 06:06:12.639: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.01308719s
    Aug 27 06:06:12.639: INFO: Pod "agnhost" satisfied condition "running"
    Aug 27 06:06:12.639: INFO: Creating service...
    Aug 27 06:06:12.646: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/DELETE
    Aug 27 06:06:12.664: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 27 06:06:12.665: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/GET
    Aug 27 06:06:12.671: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Aug 27 06:06:12.672: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/HEAD
    Aug 27 06:06:12.677: INFO: http.Client request:HEAD | StatusCode:200
    Aug 27 06:06:12.677: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/OPTIONS
    Aug 27 06:06:12.682: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 27 06:06:12.682: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/PATCH
    Aug 27 06:06:12.688: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 27 06:06:12.688: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/POST
    Aug 27 06:06:12.694: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 27 06:06:12.694: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/pods/agnhost/proxy/some/path/with/PUT
    Aug 27 06:06:12.700: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 27 06:06:12.700: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/DELETE
    Aug 27 06:06:12.707: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 27 06:06:12.707: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/GET
    Aug 27 06:06:12.714: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Aug 27 06:06:12.714: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/HEAD
    Aug 27 06:06:12.721: INFO: http.Client request:HEAD | StatusCode:200
    Aug 27 06:06:12.721: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/OPTIONS
    Aug 27 06:06:12.741: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 27 06:06:12.741: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/PATCH
    Aug 27 06:06:12.751: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 27 06:06:12.751: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/POST
    Aug 27 06:06:12.766: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 27 06:06:12.766: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1191/services/test-service/proxy/some/path/with/PUT
    Aug 27 06:06:12.781: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 27 06:06:12.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1191" for this suite. 08/27/22 06:06:12.786
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:12.8
Aug 27 06:06:12.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename watch 08/27/22 06:06:12.801
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:12.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:12.858
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 08/27/22 06:06:12.862
STEP: creating a watch on configmaps with label B 08/27/22 06:06:12.868
STEP: creating a watch on configmaps with label A or B 08/27/22 06:06:12.871
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 08/27/22 06:06:12.876
Aug 27 06:06:12.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12849 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:06:12.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12849 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 08/27/22 06:06:12.883
Aug 27 06:06:12.892: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12850 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:06:12.892: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12850 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 08/27/22 06:06:12.892
Aug 27 06:06:12.901: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12851 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:06:12.901: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12851 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 08/27/22 06:06:12.901
Aug 27 06:06:12.910: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12852 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:06:12.911: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12852 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 08/27/22 06:06:12.911
Aug 27 06:06:12.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12853 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:06:12.918: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12853 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 08/27/22 06:06:22.919
Aug 27 06:06:22.926: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12920 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:06:22.927: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12920 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 27 06:06:32.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1589" for this suite. 08/27/22 06:06:32.956
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":110,"skipped":2108,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.163 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:12.8
    Aug 27 06:06:12.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename watch 08/27/22 06:06:12.801
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:12.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:12.858
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 08/27/22 06:06:12.862
    STEP: creating a watch on configmaps with label B 08/27/22 06:06:12.868
    STEP: creating a watch on configmaps with label A or B 08/27/22 06:06:12.871
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 08/27/22 06:06:12.876
    Aug 27 06:06:12.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12849 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:06:12.883: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12849 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 08/27/22 06:06:12.883
    Aug 27 06:06:12.892: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12850 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:06:12.892: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12850 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 08/27/22 06:06:12.892
    Aug 27 06:06:12.901: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12851 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:06:12.901: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12851 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 08/27/22 06:06:12.901
    Aug 27 06:06:12.910: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12852 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:06:12.911: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1589  7736c8c2-0b49-4a7b-85f3-1022fab95571 12852 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 08/27/22 06:06:12.911
    Aug 27 06:06:12.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12853 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:06:12.918: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12853 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 08/27/22 06:06:22.919
    Aug 27 06:06:22.926: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12920 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:06:22.927: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1589  ea6add55-f497-4831-8278-50959018208a 12920 0 2022-08-27 06:06:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-08-27 06:06:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 27 06:06:32.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1589" for this suite. 08/27/22 06:06:32.956
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:32.969
Aug 27 06:06:32.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename security-context 08/27/22 06:06:32.973
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:33.009
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:33.026
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/27/22 06:06:33.03
Aug 27 06:06:33.037: INFO: Waiting up to 5m0s for pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6" in namespace "security-context-7207" to be "Succeeded or Failed"
Aug 27 06:06:33.044: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.839388ms
Aug 27 06:06:35.049: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011310901s
Aug 27 06:06:37.049: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011665931s
STEP: Saw pod success 08/27/22 06:06:37.049
Aug 27 06:06:37.049: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6" satisfied condition "Succeeded or Failed"
Aug 27 06:06:37.052: INFO: Trying to get logs from node ip-10-0-47-192 pod security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6 container test-container: <nil>
STEP: delete the pod 08/27/22 06:06:37.07
Aug 27 06:06:37.079: INFO: Waiting for pod security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6 to disappear
Aug 27 06:06:37.082: INFO: Pod security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 27 06:06:37.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7207" for this suite. 08/27/22 06:06:37.086
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":111,"skipped":2135,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:32.969
    Aug 27 06:06:32.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename security-context 08/27/22 06:06:32.973
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:33.009
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:33.026
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/27/22 06:06:33.03
    Aug 27 06:06:33.037: INFO: Waiting up to 5m0s for pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6" in namespace "security-context-7207" to be "Succeeded or Failed"
    Aug 27 06:06:33.044: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.839388ms
    Aug 27 06:06:35.049: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011310901s
    Aug 27 06:06:37.049: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011665931s
    STEP: Saw pod success 08/27/22 06:06:37.049
    Aug 27 06:06:37.049: INFO: Pod "security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6" satisfied condition "Succeeded or Failed"
    Aug 27 06:06:37.052: INFO: Trying to get logs from node ip-10-0-47-192 pod security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6 container test-container: <nil>
    STEP: delete the pod 08/27/22 06:06:37.07
    Aug 27 06:06:37.079: INFO: Waiting for pod security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6 to disappear
    Aug 27 06:06:37.082: INFO: Pod security-context-38a58ca5-6f70-4145-a1a4-848343b8a9b6 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 27 06:06:37.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7207" for this suite. 08/27/22 06:06:37.086
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:37.093
Aug 27 06:06:37.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:06:37.094
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:37.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:37.124
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Aug 27 06:06:37.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-3240 version'
Aug 27 06:06:37.209: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Aug 27 06:06:37.209: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:38:15Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:06:37.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3240" for this suite. 08/27/22 06:06:37.213
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":112,"skipped":2149,"failed":0}
------------------------------
â€¢ [0.127 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:37.093
    Aug 27 06:06:37.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:06:37.094
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:37.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:37.124
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Aug 27 06:06:37.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-3240 version'
    Aug 27 06:06:37.209: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Aug 27 06:06:37.209: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:44:59Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.0\", GitCommit:\"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2\", GitTreeState:\"clean\", BuildDate:\"2022-08-23T17:38:15Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:06:37.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3240" for this suite. 08/27/22 06:06:37.213
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:37.221
Aug 27 06:06:37.221: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename security-context-test 08/27/22 06:06:37.221
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:37.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:37.246
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Aug 27 06:06:37.275: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8" in namespace "security-context-test-170" to be "Succeeded or Failed"
Aug 27 06:06:37.290: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.773846ms
Aug 27 06:06:39.294: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018359035s
Aug 27 06:06:41.296: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020399353s
Aug 27 06:06:41.296: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 27 06:06:41.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-170" for this suite. 08/27/22 06:06:41.301
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":113,"skipped":2163,"failed":0}
------------------------------
â€¢ [4.085 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:37.221
    Aug 27 06:06:37.221: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename security-context-test 08/27/22 06:06:37.221
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:37.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:37.246
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Aug 27 06:06:37.275: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8" in namespace "security-context-test-170" to be "Succeeded or Failed"
    Aug 27 06:06:37.290: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.773846ms
    Aug 27 06:06:39.294: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018359035s
    Aug 27 06:06:41.296: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020399353s
    Aug 27 06:06:41.296: INFO: Pod "busybox-readonly-false-8bdbfe56-2cab-442c-bbd1-50d8123f77a8" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 27 06:06:41.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-170" for this suite. 08/27/22 06:06:41.301
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:41.307
Aug 27 06:06:41.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:06:41.308
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:41.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:41.34
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:06:41.343
Aug 27 06:06:41.348: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61" in namespace "downward-api-2615" to be "Succeeded or Failed"
Aug 27 06:06:41.352: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371333ms
Aug 27 06:06:43.355: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00673727s
Aug 27 06:06:45.358: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008937909s
STEP: Saw pod success 08/27/22 06:06:45.358
Aug 27 06:06:45.358: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61" satisfied condition "Succeeded or Failed"
Aug 27 06:06:45.361: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61 container client-container: <nil>
STEP: delete the pod 08/27/22 06:06:45.367
Aug 27 06:06:45.378: INFO: Waiting for pod downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61 to disappear
Aug 27 06:06:45.382: INFO: Pod downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:06:45.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2615" for this suite. 08/27/22 06:06:45.385
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":114,"skipped":2170,"failed":0}
------------------------------
â€¢ [4.084 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:41.307
    Aug 27 06:06:41.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:06:41.308
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:41.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:41.34
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:06:41.343
    Aug 27 06:06:41.348: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61" in namespace "downward-api-2615" to be "Succeeded or Failed"
    Aug 27 06:06:41.352: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371333ms
    Aug 27 06:06:43.355: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00673727s
    Aug 27 06:06:45.358: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008937909s
    STEP: Saw pod success 08/27/22 06:06:45.358
    Aug 27 06:06:45.358: INFO: Pod "downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61" satisfied condition "Succeeded or Failed"
    Aug 27 06:06:45.361: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61 container client-container: <nil>
    STEP: delete the pod 08/27/22 06:06:45.367
    Aug 27 06:06:45.378: INFO: Waiting for pod downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61 to disappear
    Aug 27 06:06:45.382: INFO: Pod downwardapi-volume-b5716298-29de-41dd-9bd3-1c1de10f9f61 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:06:45.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2615" for this suite. 08/27/22 06:06:45.385
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:45.394
Aug 27 06:06:45.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 06:06:45.395
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:45.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:45.42
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 08/27/22 06:06:45.424
STEP: delete the rc 08/27/22 06:06:50.436
STEP: wait for all pods to be garbage collected 08/27/22 06:06:50.441
STEP: Gathering metrics 08/27/22 06:06:55.449
Aug 27 06:06:55.466: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
Aug 27 06:06:55.470: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 3.715945ms
Aug 27 06:06:55.470: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
Aug 27 06:06:55.470: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
Aug 27 06:06:55.535: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 06:06:55.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4291" for this suite. 08/27/22 06:06:55.538
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":115,"skipped":2177,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.149 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:45.394
    Aug 27 06:06:45.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 06:06:45.395
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:45.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:45.42
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 08/27/22 06:06:45.424
    STEP: delete the rc 08/27/22 06:06:50.436
    STEP: wait for all pods to be garbage collected 08/27/22 06:06:50.441
    STEP: Gathering metrics 08/27/22 06:06:55.449
    Aug 27 06:06:55.466: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
    Aug 27 06:06:55.470: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 3.715945ms
    Aug 27 06:06:55.470: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
    Aug 27 06:06:55.470: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
    Aug 27 06:06:55.535: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 06:06:55.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4291" for this suite. 08/27/22 06:06:55.538
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:55.545
Aug 27 06:06:55.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:06:55.547
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:55.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:55.578
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Aug 27 06:06:55.587: INFO: Got root ca configmap in namespace "svcaccounts-5439"
Aug 27 06:06:55.591: INFO: Deleted root ca configmap in namespace "svcaccounts-5439"
STEP: waiting for a new root ca configmap created 08/27/22 06:06:56.093
Aug 27 06:06:56.096: INFO: Recreated root ca configmap in namespace "svcaccounts-5439"
Aug 27 06:06:56.105: INFO: Updated root ca configmap in namespace "svcaccounts-5439"
STEP: waiting for the root ca configmap reconciled 08/27/22 06:06:56.605
Aug 27 06:06:56.620: INFO: Reconciled root ca configmap in namespace "svcaccounts-5439"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 27 06:06:56.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5439" for this suite. 08/27/22 06:06:56.651
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":116,"skipped":2195,"failed":0}
------------------------------
â€¢ [1.138 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:55.545
    Aug 27 06:06:55.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:06:55.547
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:55.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:55.578
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Aug 27 06:06:55.587: INFO: Got root ca configmap in namespace "svcaccounts-5439"
    Aug 27 06:06:55.591: INFO: Deleted root ca configmap in namespace "svcaccounts-5439"
    STEP: waiting for a new root ca configmap created 08/27/22 06:06:56.093
    Aug 27 06:06:56.096: INFO: Recreated root ca configmap in namespace "svcaccounts-5439"
    Aug 27 06:06:56.105: INFO: Updated root ca configmap in namespace "svcaccounts-5439"
    STEP: waiting for the root ca configmap reconciled 08/27/22 06:06:56.605
    Aug 27 06:06:56.620: INFO: Reconciled root ca configmap in namespace "svcaccounts-5439"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 27 06:06:56.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5439" for this suite. 08/27/22 06:06:56.651
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:06:56.691
Aug 27 06:06:56.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:06:56.692
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:56.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:56.729
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 08/27/22 06:06:56.739
STEP: watching for Pod to be ready 08/27/22 06:06:56.749
Aug 27 06:06:56.754: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions []
Aug 27 06:06:56.760: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
Aug 27 06:06:56.790: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
Aug 27 06:06:57.309: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
Aug 27 06:06:58.010: INFO: Found Pod pod-test in namespace pods-3640 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 08/27/22 06:06:58.014
STEP: getting the Pod and ensuring that it's patched 08/27/22 06:06:58.024
STEP: replacing the Pod's status Ready condition to False 08/27/22 06:06:58.027
STEP: check the Pod again to ensure its Ready conditions are False 08/27/22 06:06:58.041
STEP: deleting the Pod via a Collection with a LabelSelector 08/27/22 06:06:58.041
STEP: watching for the Pod to be deleted 08/27/22 06:06:58.047
Aug 27 06:06:58.050: INFO: observed event type MODIFIED
Aug 27 06:07:00.029: INFO: observed event type MODIFIED
Aug 27 06:07:00.259: INFO: observed event type MODIFIED
Aug 27 06:07:01.021: INFO: observed event type MODIFIED
Aug 27 06:07:01.038: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:07:01.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3640" for this suite. 08/27/22 06:07:01.064
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":117,"skipped":2278,"failed":0}
------------------------------
â€¢ [4.393 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:06:56.691
    Aug 27 06:06:56.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:06:56.692
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:06:56.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:06:56.729
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 08/27/22 06:06:56.739
    STEP: watching for Pod to be ready 08/27/22 06:06:56.749
    Aug 27 06:06:56.754: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Aug 27 06:06:56.760: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
    Aug 27 06:06:56.790: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
    Aug 27 06:06:57.309: INFO: observed Pod pod-test in namespace pods-3640 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
    Aug 27 06:06:58.010: INFO: Found Pod pod-test in namespace pods-3640 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:06:56 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 08/27/22 06:06:58.014
    STEP: getting the Pod and ensuring that it's patched 08/27/22 06:06:58.024
    STEP: replacing the Pod's status Ready condition to False 08/27/22 06:06:58.027
    STEP: check the Pod again to ensure its Ready conditions are False 08/27/22 06:06:58.041
    STEP: deleting the Pod via a Collection with a LabelSelector 08/27/22 06:06:58.041
    STEP: watching for the Pod to be deleted 08/27/22 06:06:58.047
    Aug 27 06:06:58.050: INFO: observed event type MODIFIED
    Aug 27 06:07:00.029: INFO: observed event type MODIFIED
    Aug 27 06:07:00.259: INFO: observed event type MODIFIED
    Aug 27 06:07:01.021: INFO: observed event type MODIFIED
    Aug 27 06:07:01.038: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:07:01.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3640" for this suite. 08/27/22 06:07:01.064
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:07:01.087
Aug 27 06:07:01.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:07:01.088
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:07:01.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:07:01.139
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-3926/secret-test-05018b76-1115-4367-8e6b-e1387c73b1bf 08/27/22 06:07:01.143
STEP: Creating a pod to test consume secrets 08/27/22 06:07:01.148
Aug 27 06:07:01.180: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85" in namespace "secrets-3926" to be "Succeeded or Failed"
Aug 27 06:07:01.208: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85": Phase="Pending", Reason="", readiness=false. Elapsed: 28.127809ms
Aug 27 06:07:03.213: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032853333s
Aug 27 06:07:05.217: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037149381s
STEP: Saw pod success 08/27/22 06:07:05.217
Aug 27 06:07:05.218: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85" satisfied condition "Succeeded or Failed"
Aug 27 06:07:05.222: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85 container env-test: <nil>
STEP: delete the pod 08/27/22 06:07:05.231
Aug 27 06:07:05.246: INFO: Waiting for pod pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85 to disappear
Aug 27 06:07:05.249: INFO: Pod pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:07:05.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3926" for this suite. 08/27/22 06:07:05.252
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":118,"skipped":2295,"failed":0}
------------------------------
â€¢ [4.171 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:07:01.087
    Aug 27 06:07:01.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:07:01.088
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:07:01.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:07:01.139
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-3926/secret-test-05018b76-1115-4367-8e6b-e1387c73b1bf 08/27/22 06:07:01.143
    STEP: Creating a pod to test consume secrets 08/27/22 06:07:01.148
    Aug 27 06:07:01.180: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85" in namespace "secrets-3926" to be "Succeeded or Failed"
    Aug 27 06:07:01.208: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85": Phase="Pending", Reason="", readiness=false. Elapsed: 28.127809ms
    Aug 27 06:07:03.213: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032853333s
    Aug 27 06:07:05.217: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037149381s
    STEP: Saw pod success 08/27/22 06:07:05.217
    Aug 27 06:07:05.218: INFO: Pod "pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85" satisfied condition "Succeeded or Failed"
    Aug 27 06:07:05.222: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85 container env-test: <nil>
    STEP: delete the pod 08/27/22 06:07:05.231
    Aug 27 06:07:05.246: INFO: Waiting for pod pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85 to disappear
    Aug 27 06:07:05.249: INFO: Pod pod-configmaps-c6a628a3-70ae-44ab-ab69-1fa3edcfec85 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:07:05.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3926" for this suite. 08/27/22 06:07:05.252
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:07:05.259
Aug 27 06:07:05.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:07:05.261
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:07:05.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:07:05.333
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-2e37efa2-e165-4469-aec8-5fec22c762d0 in namespace container-probe-2977 08/27/22 06:07:05.337
Aug 27 06:07:05.350: INFO: Waiting up to 5m0s for pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0" in namespace "container-probe-2977" to be "not pending"
Aug 27 06:07:05.356: INFO: Pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.211727ms
Aug 27 06:07:07.359: INFO: Pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.009005476s
Aug 27 06:07:07.359: INFO: Pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0" satisfied condition "not pending"
Aug 27 06:07:07.359: INFO: Started pod busybox-2e37efa2-e165-4469-aec8-5fec22c762d0 in namespace container-probe-2977
STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:07:07.359
Aug 27 06:07:07.363: INFO: Initial restart count of pod busybox-2e37efa2-e165-4469-aec8-5fec22c762d0 is 0
STEP: deleting the pod 08/27/22 06:11:07.968
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:11:07.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2977" for this suite. 08/27/22 06:11:07.995
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":119,"skipped":2297,"failed":0}
------------------------------
â€¢ [SLOW TEST] [242.745 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:07:05.259
    Aug 27 06:07:05.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:07:05.261
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:07:05.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:07:05.333
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-2e37efa2-e165-4469-aec8-5fec22c762d0 in namespace container-probe-2977 08/27/22 06:07:05.337
    Aug 27 06:07:05.350: INFO: Waiting up to 5m0s for pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0" in namespace "container-probe-2977" to be "not pending"
    Aug 27 06:07:05.356: INFO: Pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.211727ms
    Aug 27 06:07:07.359: INFO: Pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.009005476s
    Aug 27 06:07:07.359: INFO: Pod "busybox-2e37efa2-e165-4469-aec8-5fec22c762d0" satisfied condition "not pending"
    Aug 27 06:07:07.359: INFO: Started pod busybox-2e37efa2-e165-4469-aec8-5fec22c762d0 in namespace container-probe-2977
    STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:07:07.359
    Aug 27 06:07:07.363: INFO: Initial restart count of pod busybox-2e37efa2-e165-4469-aec8-5fec22c762d0 is 0
    STEP: deleting the pod 08/27/22 06:11:07.968
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:11:07.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2977" for this suite. 08/27/22 06:11:07.995
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:11:08.006
Aug 27 06:11:08.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:11:08.007
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:08.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:08.031
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-3c9cbbb6-9e3d-4155-a034-e45724aedd2e 08/27/22 06:11:08.035
STEP: Creating a pod to test consume configMaps 08/27/22 06:11:08.039
Aug 27 06:11:08.054: INFO: Waiting up to 5m0s for pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af" in namespace "configmap-3200" to be "Succeeded or Failed"
Aug 27 06:11:08.067: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af": Phase="Pending", Reason="", readiness=false. Elapsed: 12.925686ms
Aug 27 06:11:10.072: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018490789s
Aug 27 06:11:12.072: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018159591s
STEP: Saw pod success 08/27/22 06:11:12.072
Aug 27 06:11:12.072: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af" satisfied condition "Succeeded or Failed"
Aug 27 06:11:12.075: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:11:12.096
Aug 27 06:11:12.115: INFO: Waiting for pod pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af to disappear
Aug 27 06:11:12.124: INFO: Pod pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:11:12.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3200" for this suite. 08/27/22 06:11:12.132
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":120,"skipped":2297,"failed":0}
------------------------------
â€¢ [4.132 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:11:08.006
    Aug 27 06:11:08.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:11:08.007
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:08.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:08.031
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-3c9cbbb6-9e3d-4155-a034-e45724aedd2e 08/27/22 06:11:08.035
    STEP: Creating a pod to test consume configMaps 08/27/22 06:11:08.039
    Aug 27 06:11:08.054: INFO: Waiting up to 5m0s for pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af" in namespace "configmap-3200" to be "Succeeded or Failed"
    Aug 27 06:11:08.067: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af": Phase="Pending", Reason="", readiness=false. Elapsed: 12.925686ms
    Aug 27 06:11:10.072: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018490789s
    Aug 27 06:11:12.072: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018159591s
    STEP: Saw pod success 08/27/22 06:11:12.072
    Aug 27 06:11:12.072: INFO: Pod "pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af" satisfied condition "Succeeded or Failed"
    Aug 27 06:11:12.075: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:11:12.096
    Aug 27 06:11:12.115: INFO: Waiting for pod pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af to disappear
    Aug 27 06:11:12.124: INFO: Pod pod-configmaps-62d0856b-3f3b-4fa3-b914-e7eca81d55af no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:11:12.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3200" for this suite. 08/27/22 06:11:12.132
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:11:12.142
Aug 27 06:11:12.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 06:11:12.143
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:12.158
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:12.165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 08/27/22 06:11:12.192
STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 06:11:12.196
Aug 27 06:11:12.203: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:11:12.208: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:11:12.208: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:11:13.213: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:11:13.216: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:11:13.216: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:11:14.212: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:11:14.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 06:11:14.215: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets 08/27/22 06:11:14.218
STEP: DeleteCollection of the DaemonSets 08/27/22 06:11:14.226
STEP: Verify that ReplicaSets have been deleted 08/27/22 06:11:14.232
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Aug 27 06:11:14.242: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13660"},"items":null}

Aug 27 06:11:14.247: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13660"},"items":[{"metadata":{"name":"daemon-set-d4xgj","generateName":"daemon-set-","namespace":"daemonsets-5736","uid":"27d5126a-5196-4d94-ad0a-fc18258a7950","resourceVersion":"13656","creationTimestamp":"2022-08-27T06:11:12Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f6177cd9138913aa7746c3a740e492a55e4e59a4c2a7558691be3b5c5ad76194","cni.projectcalico.org/podIP":"10.2.35.162/32","cni.projectcalico.org/podIPs":"10.2.35.162/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"791f0931-d012-42b6-8951-b02806d5612a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"791f0931-d012-42b6-8951-b02806d5612a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-dcr59","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-dcr59","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-10-0-47-192","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-10-0-47-192"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"}],"hostIP":"10.0.47.192","podIP":"10.2.35.162","podIPs":[{"ip":"10.2.35.162"}],"startTime":"2022-08-27T06:11:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-27T06:11:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://59081fc72ec89bc9b01d58a8d7fb439f19023fbe4bcd8741aa441a9cd30990b1","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-f8v9z","generateName":"daemon-set-","namespace":"daemonsets-5736","uid":"c46b48af-1f65-4202-8bd7-8d2b72640b22","resourceVersion":"13658","creationTimestamp":"2022-08-27T06:11:12Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a8502d9b0dd5afcecf21ed9b85a065f75bbcb302d1c24d4c45f067dc7d212e21","cni.projectcalico.org/podIP":"10.2.137.110/32","cni.projectcalico.org/podIPs":"10.2.137.110/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"791f0931-d012-42b6-8951-b02806d5612a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"791f0931-d012-42b6-8951-b02806d5612a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hqxgr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hqxgr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-10-0-31-158","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-10-0-31-158"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:14Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:14Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"}],"hostIP":"10.0.31.158","podIP":"10.2.137.110","podIPs":[{"ip":"10.2.137.110"}],"startTime":"2022-08-27T06:11:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-27T06:11:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://320103744798826e307e94870bb96852f122a5910d93bd3df3fbb8a2f1c92c37","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:11:14.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5736" for this suite. 08/27/22 06:11:14.279
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":121,"skipped":2329,"failed":0}
------------------------------
â€¢ [2.154 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:11:12.142
    Aug 27 06:11:12.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 06:11:12.143
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:12.158
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:12.165
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 08/27/22 06:11:12.192
    STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 06:11:12.196
    Aug 27 06:11:12.203: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:11:12.208: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:11:12.208: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:11:13.213: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:11:13.216: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:11:13.216: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:11:14.212: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:11:14.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 06:11:14.215: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: listing all DeamonSets 08/27/22 06:11:14.218
    STEP: DeleteCollection of the DaemonSets 08/27/22 06:11:14.226
    STEP: Verify that ReplicaSets have been deleted 08/27/22 06:11:14.232
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Aug 27 06:11:14.242: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13660"},"items":null}

    Aug 27 06:11:14.247: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13660"},"items":[{"metadata":{"name":"daemon-set-d4xgj","generateName":"daemon-set-","namespace":"daemonsets-5736","uid":"27d5126a-5196-4d94-ad0a-fc18258a7950","resourceVersion":"13656","creationTimestamp":"2022-08-27T06:11:12Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f6177cd9138913aa7746c3a740e492a55e4e59a4c2a7558691be3b5c5ad76194","cni.projectcalico.org/podIP":"10.2.35.162/32","cni.projectcalico.org/podIPs":"10.2.35.162/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"791f0931-d012-42b6-8951-b02806d5612a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"791f0931-d012-42b6-8951-b02806d5612a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:13Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-dcr59","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-dcr59","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-10-0-47-192","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-10-0-47-192"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:13Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:13Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"}],"hostIP":"10.0.47.192","podIP":"10.2.35.162","podIPs":[{"ip":"10.2.35.162"}],"startTime":"2022-08-27T06:11:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-27T06:11:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://59081fc72ec89bc9b01d58a8d7fb439f19023fbe4bcd8741aa441a9cd30990b1","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-f8v9z","generateName":"daemon-set-","namespace":"daemonsets-5736","uid":"c46b48af-1f65-4202-8bd7-8d2b72640b22","resourceVersion":"13658","creationTimestamp":"2022-08-27T06:11:12Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"a8502d9b0dd5afcecf21ed9b85a065f75bbcb302d1c24d4c45f067dc7d212e21","cni.projectcalico.org/podIP":"10.2.137.110/32","cni.projectcalico.org/podIPs":"10.2.137.110/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"791f0931-d012-42b6-8951-b02806d5612a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"791f0931-d012-42b6-8951-b02806d5612a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-27T06:11:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hqxgr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hqxgr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-10-0-31-158","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-10-0-31-158"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:14Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:14Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-27T06:11:12Z"}],"hostIP":"10.0.31.158","podIP":"10.2.137.110","podIPs":[{"ip":"10.2.137.110"}],"startTime":"2022-08-27T06:11:12Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-27T06:11:13Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://320103744798826e307e94870bb96852f122a5910d93bd3df3fbb8a2f1c92c37","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:11:14.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5736" for this suite. 08/27/22 06:11:14.279
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:11:14.297
Aug 27 06:11:14.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename hostport 08/27/22 06:11:14.299
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:14.313
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:14.316
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 08/27/22 06:11:14.334
Aug 27 06:11:14.344: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-15" to be "running and ready"
Aug 27 06:11:14.359: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.478963ms
Aug 27 06:11:14.359: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:11:16.363: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019249092s
Aug 27 06:11:16.363: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 27 06:11:16.364: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.0.47.192 on the node which pod1 resides and expect scheduled 08/27/22 06:11:16.364
Aug 27 06:11:16.368: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-15" to be "running and ready"
Aug 27 06:11:16.373: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.726419ms
Aug 27 06:11:16.373: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:11:18.377: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.007915785s
Aug 27 06:11:18.377: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 27 06:11:18.377: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.0.47.192 but use UDP protocol on the node which pod2 resides 08/27/22 06:11:18.377
Aug 27 06:11:18.382: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-15" to be "running and ready"
Aug 27 06:11:18.385: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.048124ms
Aug 27 06:11:18.385: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:11:20.389: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007387362s
Aug 27 06:11:20.389: INFO: The phase of Pod pod3 is Running (Ready = true)
Aug 27 06:11:20.389: INFO: Pod "pod3" satisfied condition "running and ready"
Aug 27 06:11:20.394: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-15" to be "running and ready"
Aug 27 06:11:20.397: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.573743ms
Aug 27 06:11:20.397: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:11:22.400: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.006429847s
Aug 27 06:11:22.401: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Aug 27 06:11:22.401: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 08/27/22 06:11:22.403
Aug 27 06:11:22.403: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.0.47.192 http://127.0.0.1:54323/hostname] Namespace:hostport-15 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:11:22.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:11:22.404: INFO: ExecWithOptions: Clientset creation
Aug 27 06:11:22.404: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-15/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.0.47.192+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.47.192, port: 54323 08/27/22 06:11:22.48
Aug 27 06:11:22.481: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.0.47.192:54323/hostname] Namespace:hostport-15 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:11:22.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:11:22.481: INFO: ExecWithOptions: Clientset creation
Aug 27 06:11:22.481: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-15/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.0.47.192%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.47.192, port: 54323 UDP 08/27/22 06:11:22.546
Aug 27 06:11:22.547: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.0.47.192 54323] Namespace:hostport-15 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:11:22.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:11:22.547: INFO: ExecWithOptions: Clientset creation
Aug 27 06:11:22.547: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-15/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.0.47.192+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Aug 27 06:11:27.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-15" for this suite. 08/27/22 06:11:27.632
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":122,"skipped":2332,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.354 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:11:14.297
    Aug 27 06:11:14.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename hostport 08/27/22 06:11:14.299
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:14.313
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:14.316
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 08/27/22 06:11:14.334
    Aug 27 06:11:14.344: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-15" to be "running and ready"
    Aug 27 06:11:14.359: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.478963ms
    Aug 27 06:11:14.359: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:11:16.363: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019249092s
    Aug 27 06:11:16.363: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 27 06:11:16.364: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.0.47.192 on the node which pod1 resides and expect scheduled 08/27/22 06:11:16.364
    Aug 27 06:11:16.368: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-15" to be "running and ready"
    Aug 27 06:11:16.373: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.726419ms
    Aug 27 06:11:16.373: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:11:18.377: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.007915785s
    Aug 27 06:11:18.377: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 27 06:11:18.377: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.0.47.192 but use UDP protocol on the node which pod2 resides 08/27/22 06:11:18.377
    Aug 27 06:11:18.382: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-15" to be "running and ready"
    Aug 27 06:11:18.385: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.048124ms
    Aug 27 06:11:18.385: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:11:20.389: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.007387362s
    Aug 27 06:11:20.389: INFO: The phase of Pod pod3 is Running (Ready = true)
    Aug 27 06:11:20.389: INFO: Pod "pod3" satisfied condition "running and ready"
    Aug 27 06:11:20.394: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-15" to be "running and ready"
    Aug 27 06:11:20.397: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.573743ms
    Aug 27 06:11:20.397: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:11:22.400: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.006429847s
    Aug 27 06:11:22.401: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Aug 27 06:11:22.401: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 08/27/22 06:11:22.403
    Aug 27 06:11:22.403: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.0.47.192 http://127.0.0.1:54323/hostname] Namespace:hostport-15 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:11:22.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:11:22.404: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:11:22.404: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-15/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.0.47.192+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.47.192, port: 54323 08/27/22 06:11:22.48
    Aug 27 06:11:22.481: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.0.47.192:54323/hostname] Namespace:hostport-15 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:11:22.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:11:22.481: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:11:22.481: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-15/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.0.47.192%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.0.47.192, port: 54323 UDP 08/27/22 06:11:22.546
    Aug 27 06:11:22.547: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.0.47.192 54323] Namespace:hostport-15 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:11:22.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:11:22.547: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:11:22.547: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/hostport-15/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.0.47.192+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Aug 27 06:11:27.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-15" for this suite. 08/27/22 06:11:27.632
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:11:27.658
Aug 27 06:11:27.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:11:27.66
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:27.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:27.696
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 08/27/22 06:11:27.728
STEP: waiting for available Endpoint 08/27/22 06:11:27.734
STEP: listing all Endpoints 08/27/22 06:11:27.747
STEP: updating the Endpoint 08/27/22 06:11:27.753
STEP: fetching the Endpoint 08/27/22 06:11:27.767
STEP: patching the Endpoint 08/27/22 06:11:27.774
STEP: fetching the Endpoint 08/27/22 06:11:27.788
STEP: deleting the Endpoint by Collection 08/27/22 06:11:27.8
STEP: waiting for Endpoint deletion 08/27/22 06:11:27.809
STEP: fetching the Endpoint 08/27/22 06:11:27.817
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:11:27.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1841" for this suite. 08/27/22 06:11:27.845
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":123,"skipped":2373,"failed":0}
------------------------------
â€¢ [0.195 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:11:27.658
    Aug 27 06:11:27.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:11:27.66
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:27.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:27.696
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 08/27/22 06:11:27.728
    STEP: waiting for available Endpoint 08/27/22 06:11:27.734
    STEP: listing all Endpoints 08/27/22 06:11:27.747
    STEP: updating the Endpoint 08/27/22 06:11:27.753
    STEP: fetching the Endpoint 08/27/22 06:11:27.767
    STEP: patching the Endpoint 08/27/22 06:11:27.774
    STEP: fetching the Endpoint 08/27/22 06:11:27.788
    STEP: deleting the Endpoint by Collection 08/27/22 06:11:27.8
    STEP: waiting for Endpoint deletion 08/27/22 06:11:27.809
    STEP: fetching the Endpoint 08/27/22 06:11:27.817
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:11:27.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1841" for this suite. 08/27/22 06:11:27.845
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:11:27.862
Aug 27 06:11:27.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename events 08/27/22 06:11:27.864
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:27.882
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:27.889
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 08/27/22 06:11:27.896
Aug 27 06:11:27.900: INFO: created test-event-1
Aug 27 06:11:27.904: INFO: created test-event-2
Aug 27 06:11:27.908: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 08/27/22 06:11:27.908
STEP: delete collection of events 08/27/22 06:11:27.911
Aug 27 06:11:27.912: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 08/27/22 06:11:27.923
Aug 27 06:11:27.923: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Aug 27 06:11:27.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1453" for this suite. 08/27/22 06:11:27.929
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":124,"skipped":2375,"failed":0}
------------------------------
â€¢ [0.073 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:11:27.862
    Aug 27 06:11:27.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename events 08/27/22 06:11:27.864
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:27.882
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:27.889
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 08/27/22 06:11:27.896
    Aug 27 06:11:27.900: INFO: created test-event-1
    Aug 27 06:11:27.904: INFO: created test-event-2
    Aug 27 06:11:27.908: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 08/27/22 06:11:27.908
    STEP: delete collection of events 08/27/22 06:11:27.911
    Aug 27 06:11:27.912: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 08/27/22 06:11:27.923
    Aug 27 06:11:27.923: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Aug 27 06:11:27.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1453" for this suite. 08/27/22 06:11:27.929
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:11:27.941
Aug 27 06:11:27.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:11:27.941
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:27.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:27.966
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 in namespace container-probe-3057 08/27/22 06:11:27.97
Aug 27 06:11:27.976: INFO: Waiting up to 5m0s for pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306" in namespace "container-probe-3057" to be "not pending"
Aug 27 06:11:27.982: INFO: Pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306": Phase="Pending", Reason="", readiness=false. Elapsed: 5.51785ms
Aug 27 06:11:29.987: INFO: Pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306": Phase="Running", Reason="", readiness=true. Elapsed: 2.010050669s
Aug 27 06:11:29.987: INFO: Pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306" satisfied condition "not pending"
Aug 27 06:11:29.987: INFO: Started pod busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 in namespace container-probe-3057
STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:11:29.987
Aug 27 06:11:29.991: INFO: Initial restart count of pod busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 is 0
Aug 27 06:12:20.138: INFO: Restart count of pod container-probe-3057/busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 is now 1 (50.147207067s elapsed)
STEP: deleting the pod 08/27/22 06:12:20.138
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:12:20.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3057" for this suite. 08/27/22 06:12:20.156
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":125,"skipped":2394,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.226 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:11:27.941
    Aug 27 06:11:27.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:11:27.941
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:11:27.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:11:27.966
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 in namespace container-probe-3057 08/27/22 06:11:27.97
    Aug 27 06:11:27.976: INFO: Waiting up to 5m0s for pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306" in namespace "container-probe-3057" to be "not pending"
    Aug 27 06:11:27.982: INFO: Pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306": Phase="Pending", Reason="", readiness=false. Elapsed: 5.51785ms
    Aug 27 06:11:29.987: INFO: Pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306": Phase="Running", Reason="", readiness=true. Elapsed: 2.010050669s
    Aug 27 06:11:29.987: INFO: Pod "busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306" satisfied condition "not pending"
    Aug 27 06:11:29.987: INFO: Started pod busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 in namespace container-probe-3057
    STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:11:29.987
    Aug 27 06:11:29.991: INFO: Initial restart count of pod busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 is 0
    Aug 27 06:12:20.138: INFO: Restart count of pod container-probe-3057/busybox-5b744349-bd7a-4dd8-ab67-b6b4ddcfb306 is now 1 (50.147207067s elapsed)
    STEP: deleting the pod 08/27/22 06:12:20.138
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:12:20.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3057" for this suite. 08/27/22 06:12:20.156
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:20.169
Aug 27 06:12:20.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:12:20.175
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:20.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:20.202
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 08/27/22 06:12:20.207
Aug 27 06:12:20.222: INFO: Waiting up to 5m0s for pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94" in namespace "downward-api-7276" to be "Succeeded or Failed"
Aug 27 06:12:20.233: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94": Phase="Pending", Reason="", readiness=false. Elapsed: 10.282777ms
Aug 27 06:12:22.238: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015228369s
Aug 27 06:12:24.237: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01458244s
STEP: Saw pod success 08/27/22 06:12:24.237
Aug 27 06:12:24.237: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94" satisfied condition "Succeeded or Failed"
Aug 27 06:12:24.240: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94 container dapi-container: <nil>
STEP: delete the pod 08/27/22 06:12:24.248
Aug 27 06:12:24.258: INFO: Waiting for pod downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94 to disappear
Aug 27 06:12:24.261: INFO: Pod downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 27 06:12:24.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7276" for this suite. 08/27/22 06:12:24.265
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":126,"skipped":2435,"failed":0}
------------------------------
â€¢ [4.103 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:20.169
    Aug 27 06:12:20.169: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:12:20.175
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:20.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:20.202
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 08/27/22 06:12:20.207
    Aug 27 06:12:20.222: INFO: Waiting up to 5m0s for pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94" in namespace "downward-api-7276" to be "Succeeded or Failed"
    Aug 27 06:12:20.233: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94": Phase="Pending", Reason="", readiness=false. Elapsed: 10.282777ms
    Aug 27 06:12:22.238: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015228369s
    Aug 27 06:12:24.237: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01458244s
    STEP: Saw pod success 08/27/22 06:12:24.237
    Aug 27 06:12:24.237: INFO: Pod "downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94" satisfied condition "Succeeded or Failed"
    Aug 27 06:12:24.240: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 06:12:24.248
    Aug 27 06:12:24.258: INFO: Waiting for pod downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94 to disappear
    Aug 27 06:12:24.261: INFO: Pod downward-api-107da7c5-1156-4a64-bec5-356fc1b84a94 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 27 06:12:24.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7276" for this suite. 08/27/22 06:12:24.265
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:24.274
Aug 27 06:12:24.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svc-latency 08/27/22 06:12:24.276
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:24.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:24.296
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Aug 27 06:12:24.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5479 08/27/22 06:12:24.3
I0827 06:12:24.305789      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5479, replica count: 1
I0827 06:12:25.356732      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0827 06:12:26.356899      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 06:12:26.474: INFO: Created: latency-svc-8twnc
Aug 27 06:12:26.481: INFO: Got endpoints: latency-svc-8twnc [23.6884ms]
Aug 27 06:12:26.502: INFO: Created: latency-svc-w4wzg
Aug 27 06:12:26.514: INFO: Created: latency-svc-d526h
Aug 27 06:12:26.514: INFO: Got endpoints: latency-svc-w4wzg [32.030814ms]
Aug 27 06:12:26.530: INFO: Got endpoints: latency-svc-d526h [48.545774ms]
Aug 27 06:12:26.542: INFO: Created: latency-svc-m9xkw
Aug 27 06:12:26.561: INFO: Got endpoints: latency-svc-m9xkw [77.889954ms]
Aug 27 06:12:26.564: INFO: Created: latency-svc-qgvrq
Aug 27 06:12:26.583: INFO: Got endpoints: latency-svc-qgvrq [100.2485ms]
Aug 27 06:12:26.633: INFO: Created: latency-svc-nl4wv
Aug 27 06:12:26.633: INFO: Created: latency-svc-v4fg8
Aug 27 06:12:26.634: INFO: Created: latency-svc-qbs77
Aug 27 06:12:26.634: INFO: Created: latency-svc-tj7vp
Aug 27 06:12:26.634: INFO: Created: latency-svc-fsh2l
Aug 27 06:12:26.634: INFO: Created: latency-svc-5hg85
Aug 27 06:12:26.634: INFO: Created: latency-svc-ncxxw
Aug 27 06:12:26.635: INFO: Created: latency-svc-c2m5p
Aug 27 06:12:26.635: INFO: Created: latency-svc-5nfrd
Aug 27 06:12:26.635: INFO: Created: latency-svc-gprtw
Aug 27 06:12:26.635: INFO: Created: latency-svc-4n77x
Aug 27 06:12:26.636: INFO: Created: latency-svc-tnfpr
Aug 27 06:12:26.636: INFO: Created: latency-svc-xdlkw
Aug 27 06:12:26.635: INFO: Created: latency-svc-msmz2
Aug 27 06:12:26.637: INFO: Created: latency-svc-hq82p
Aug 27 06:12:26.678: INFO: Got endpoints: latency-svc-nl4wv [194.254962ms]
Aug 27 06:12:26.700: INFO: Got endpoints: latency-svc-ncxxw [216.576999ms]
Aug 27 06:12:26.700: INFO: Got endpoints: latency-svc-v4fg8 [216.570267ms]
Aug 27 06:12:26.702: INFO: Got endpoints: latency-svc-qbs77 [114.057967ms]
Aug 27 06:12:26.703: INFO: Got endpoints: latency-svc-hq82p [219.382797ms]
Aug 27 06:12:26.722: INFO: Got endpoints: latency-svc-xdlkw [237.875761ms]
Aug 27 06:12:26.741: INFO: Got endpoints: latency-svc-msmz2 [256.285447ms]
Aug 27 06:12:26.741: INFO: Created: latency-svc-f7b2g
Aug 27 06:12:26.750: INFO: Got endpoints: latency-svc-4n77x [265.45976ms]
Aug 27 06:12:26.751: INFO: Got endpoints: latency-svc-gprtw [265.209947ms]
Aug 27 06:12:26.751: INFO: Got endpoints: latency-svc-tnfpr [266.398763ms]
Aug 27 06:12:26.766: INFO: Got endpoints: latency-svc-c2m5p [280.826151ms]
Aug 27 06:12:26.767: INFO: Got endpoints: latency-svc-5nfrd [281.881832ms]
Aug 27 06:12:26.768: INFO: Got endpoints: latency-svc-5hg85 [253.144399ms]
Aug 27 06:12:26.772: INFO: Created: latency-svc-mhc55
Aug 27 06:12:26.785: INFO: Got endpoints: latency-svc-f7b2g [106.609814ms]
Aug 27 06:12:26.785: INFO: Got endpoints: latency-svc-tj7vp [223.442826ms]
Aug 27 06:12:26.785: INFO: Got endpoints: latency-svc-fsh2l [254.427267ms]
Aug 27 06:12:26.790: INFO: Got endpoints: latency-svc-mhc55 [89.587756ms]
Aug 27 06:12:26.840: INFO: Created: latency-svc-gmm86
Aug 27 06:12:26.841: INFO: Created: latency-svc-qwsmx
Aug 27 06:12:26.843: INFO: Created: latency-svc-7vk92
Aug 27 06:12:26.843: INFO: Created: latency-svc-n8njs
Aug 27 06:12:26.841: INFO: Created: latency-svc-4lc9k
Aug 27 06:12:26.842: INFO: Created: latency-svc-b9tpg
Aug 27 06:12:26.842: INFO: Created: latency-svc-ttgvd
Aug 27 06:12:26.842: INFO: Created: latency-svc-4kcsd
Aug 27 06:12:26.842: INFO: Created: latency-svc-vswgk
Aug 27 06:12:26.842: INFO: Created: latency-svc-nxb6n
Aug 27 06:12:26.843: INFO: Created: latency-svc-dxdnr
Aug 27 06:12:26.843: INFO: Created: latency-svc-mfqb2
Aug 27 06:12:26.843: INFO: Created: latency-svc-pfsgj
Aug 27 06:12:26.841: INFO: Created: latency-svc-k8kv4
Aug 27 06:12:26.844: INFO: Created: latency-svc-2gblm
Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-qwsmx [197.833127ms]
Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-gmm86 [114.147803ms]
Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-k8kv4 [197.822162ms]
Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-vswgk [114.958941ms]
Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-nxb6n [109.042854ms]
Aug 27 06:12:26.945: INFO: Got endpoints: latency-svc-dxdnr [194.227215ms]
Aug 27 06:12:26.946: INFO: Got endpoints: latency-svc-ttgvd [194.631245ms]
Aug 27 06:12:26.947: INFO: Got endpoints: latency-svc-b9tpg [196.353885ms]
Aug 27 06:12:26.946: INFO: Got endpoints: latency-svc-mfqb2 [204.668051ms]
Aug 27 06:12:26.946: INFO: Got endpoints: latency-svc-4lc9k [223.582116ms]
Aug 27 06:12:26.969: INFO: Got endpoints: latency-svc-2gblm [266.350816ms]
Aug 27 06:12:26.971: INFO: Got endpoints: latency-svc-pfsgj [204.082489ms]
Aug 27 06:12:26.972: INFO: Got endpoints: latency-svc-n8njs [204.866176ms]
Aug 27 06:12:26.971: INFO: Created: latency-svc-blhc7
Aug 27 06:12:26.973: INFO: Got endpoints: latency-svc-4kcsd [187.868609ms]
Aug 27 06:12:26.973: INFO: Got endpoints: latency-svc-7vk92 [205.040544ms]
Aug 27 06:12:26.979: INFO: Got endpoints: latency-svc-blhc7 [79.364595ms]
Aug 27 06:12:26.980: INFO: Created: latency-svc-467pw
Aug 27 06:12:26.989: INFO: Created: latency-svc-7zbjr
Aug 27 06:12:27.004: INFO: Got endpoints: latency-svc-467pw [103.520135ms]
Aug 27 06:12:27.011: INFO: Got endpoints: latency-svc-7zbjr [110.233508ms]
Aug 27 06:12:27.071: INFO: Created: latency-svc-gnpg4
Aug 27 06:12:27.071: INFO: Created: latency-svc-scq94
Aug 27 06:12:27.071: INFO: Created: latency-svc-2gbrp
Aug 27 06:12:27.072: INFO: Created: latency-svc-vdk8k
Aug 27 06:12:27.072: INFO: Created: latency-svc-kzhsj
Aug 27 06:12:27.073: INFO: Created: latency-svc-8qlxz
Aug 27 06:12:27.073: INFO: Created: latency-svc-598ms
Aug 27 06:12:27.073: INFO: Created: latency-svc-jpn8w
Aug 27 06:12:27.074: INFO: Created: latency-svc-4ltx2
Aug 27 06:12:27.074: INFO: Created: latency-svc-bt7jc
Aug 27 06:12:27.075: INFO: Created: latency-svc-wkrn9
Aug 27 06:12:27.075: INFO: Created: latency-svc-rx28d
Aug 27 06:12:27.075: INFO: Created: latency-svc-5x6jp
Aug 27 06:12:27.076: INFO: Created: latency-svc-jkpmw
Aug 27 06:12:27.076: INFO: Created: latency-svc-q9t89
Aug 27 06:12:27.115: INFO: Got endpoints: latency-svc-8qlxz [214.451874ms]
Aug 27 06:12:27.115: INFO: Got endpoints: latency-svc-jpn8w [104.559763ms]
Aug 27 06:12:27.124: INFO: Created: latency-svc-zvx47
Aug 27 06:12:27.132: INFO: Created: latency-svc-4k8vb
Aug 27 06:12:27.140: INFO: Got endpoints: latency-svc-598ms [134.817271ms]
Aug 27 06:12:27.151: INFO: Created: latency-svc-p9rd2
Aug 27 06:12:27.179: INFO: Got endpoints: latency-svc-gnpg4 [278.853191ms]
Aug 27 06:12:27.189: INFO: Created: latency-svc-j7p2l
Aug 27 06:12:27.229: INFO: Got endpoints: latency-svc-scq94 [282.8005ms]
Aug 27 06:12:27.244: INFO: Created: latency-svc-bswzp
Aug 27 06:12:27.277: INFO: Got endpoints: latency-svc-2gbrp [330.253069ms]
Aug 27 06:12:27.293: INFO: Created: latency-svc-rqwmq
Aug 27 06:12:27.329: INFO: Got endpoints: latency-svc-vdk8k [382.037705ms]
Aug 27 06:12:27.343: INFO: Created: latency-svc-6qz4d
Aug 27 06:12:27.379: INFO: Got endpoints: latency-svc-q9t89 [432.126132ms]
Aug 27 06:12:27.392: INFO: Created: latency-svc-g4sb7
Aug 27 06:12:27.427: INFO: Got endpoints: latency-svc-bt7jc [479.653822ms]
Aug 27 06:12:27.440: INFO: Created: latency-svc-k2jtj
Aug 27 06:12:27.476: INFO: Got endpoints: latency-svc-wkrn9 [503.774873ms]
Aug 27 06:12:27.489: INFO: Created: latency-svc-ldpf2
Aug 27 06:12:27.528: INFO: Got endpoints: latency-svc-rx28d [548.935969ms]
Aug 27 06:12:27.538: INFO: Created: latency-svc-tv825
Aug 27 06:12:27.578: INFO: Got endpoints: latency-svc-5x6jp [605.604838ms]
Aug 27 06:12:27.596: INFO: Created: latency-svc-ftd97
Aug 27 06:12:27.627: INFO: Got endpoints: latency-svc-jkpmw [654.237469ms]
Aug 27 06:12:27.644: INFO: Created: latency-svc-7c9p9
Aug 27 06:12:27.676: INFO: Got endpoints: latency-svc-4ltx2 [703.050035ms]
Aug 27 06:12:27.689: INFO: Created: latency-svc-d9t7p
Aug 27 06:12:27.726: INFO: Got endpoints: latency-svc-kzhsj [755.049675ms]
Aug 27 06:12:27.740: INFO: Created: latency-svc-kds8m
Aug 27 06:12:27.776: INFO: Got endpoints: latency-svc-zvx47 [661.151941ms]
Aug 27 06:12:27.788: INFO: Created: latency-svc-q2gfl
Aug 27 06:12:27.828: INFO: Got endpoints: latency-svc-4k8vb [712.567388ms]
Aug 27 06:12:27.843: INFO: Created: latency-svc-nq8gw
Aug 27 06:12:27.880: INFO: Got endpoints: latency-svc-p9rd2 [739.929306ms]
Aug 27 06:12:27.892: INFO: Created: latency-svc-5nchz
Aug 27 06:12:27.926: INFO: Got endpoints: latency-svc-j7p2l [747.205072ms]
Aug 27 06:12:27.936: INFO: Created: latency-svc-hgz7f
Aug 27 06:12:27.977: INFO: Got endpoints: latency-svc-bswzp [748.087302ms]
Aug 27 06:12:27.990: INFO: Created: latency-svc-wpp5m
Aug 27 06:12:28.030: INFO: Got endpoints: latency-svc-rqwmq [752.257065ms]
Aug 27 06:12:28.039: INFO: Created: latency-svc-sqntj
Aug 27 06:12:28.077: INFO: Got endpoints: latency-svc-6qz4d [746.420419ms]
Aug 27 06:12:28.088: INFO: Created: latency-svc-sqtkr
Aug 27 06:12:28.128: INFO: Got endpoints: latency-svc-g4sb7 [748.41454ms]
Aug 27 06:12:28.139: INFO: Created: latency-svc-gzjt8
Aug 27 06:12:28.179: INFO: Got endpoints: latency-svc-k2jtj [751.371764ms]
Aug 27 06:12:28.189: INFO: Created: latency-svc-gb8nd
Aug 27 06:12:28.232: INFO: Got endpoints: latency-svc-ldpf2 [755.988686ms]
Aug 27 06:12:28.245: INFO: Created: latency-svc-86fhn
Aug 27 06:12:28.277: INFO: Got endpoints: latency-svc-tv825 [748.37926ms]
Aug 27 06:12:28.290: INFO: Created: latency-svc-5c7k5
Aug 27 06:12:28.338: INFO: Got endpoints: latency-svc-ftd97 [760.421038ms]
Aug 27 06:12:28.348: INFO: Created: latency-svc-z94fz
Aug 27 06:12:28.375: INFO: Got endpoints: latency-svc-7c9p9 [746.935646ms]
Aug 27 06:12:28.387: INFO: Created: latency-svc-2wlx7
Aug 27 06:12:28.429: INFO: Got endpoints: latency-svc-d9t7p [752.6225ms]
Aug 27 06:12:28.443: INFO: Created: latency-svc-h6pxv
Aug 27 06:12:28.480: INFO: Got endpoints: latency-svc-kds8m [752.296756ms]
Aug 27 06:12:28.490: INFO: Created: latency-svc-x4tjz
Aug 27 06:12:28.531: INFO: Got endpoints: latency-svc-q2gfl [754.698934ms]
Aug 27 06:12:28.543: INFO: Created: latency-svc-l8k7n
Aug 27 06:12:28.579: INFO: Got endpoints: latency-svc-nq8gw [751.034235ms]
Aug 27 06:12:28.591: INFO: Created: latency-svc-rqw7c
Aug 27 06:12:28.627: INFO: Got endpoints: latency-svc-5nchz [746.945471ms]
Aug 27 06:12:28.638: INFO: Created: latency-svc-cwkvq
Aug 27 06:12:28.676: INFO: Got endpoints: latency-svc-hgz7f [749.685713ms]
Aug 27 06:12:28.689: INFO: Created: latency-svc-zpzfn
Aug 27 06:12:28.729: INFO: Got endpoints: latency-svc-wpp5m [752.195209ms]
Aug 27 06:12:28.740: INFO: Created: latency-svc-tc6cx
Aug 27 06:12:28.777: INFO: Got endpoints: latency-svc-sqntj [747.043185ms]
Aug 27 06:12:28.799: INFO: Created: latency-svc-vcj74
Aug 27 06:12:28.826: INFO: Got endpoints: latency-svc-sqtkr [749.467754ms]
Aug 27 06:12:28.842: INFO: Created: latency-svc-6fp6n
Aug 27 06:12:28.881: INFO: Got endpoints: latency-svc-gzjt8 [752.589544ms]
Aug 27 06:12:28.889: INFO: Created: latency-svc-lw4c8
Aug 27 06:12:28.930: INFO: Got endpoints: latency-svc-gb8nd [751.15503ms]
Aug 27 06:12:28.940: INFO: Created: latency-svc-ds5jl
Aug 27 06:12:28.978: INFO: Got endpoints: latency-svc-86fhn [745.367754ms]
Aug 27 06:12:28.990: INFO: Created: latency-svc-qj9cf
Aug 27 06:12:29.035: INFO: Got endpoints: latency-svc-5c7k5 [758.155351ms]
Aug 27 06:12:29.043: INFO: Created: latency-svc-qjjph
Aug 27 06:12:29.075: INFO: Got endpoints: latency-svc-z94fz [736.662476ms]
Aug 27 06:12:29.087: INFO: Created: latency-svc-vdgm8
Aug 27 06:12:29.129: INFO: Got endpoints: latency-svc-2wlx7 [753.164134ms]
Aug 27 06:12:29.139: INFO: Created: latency-svc-ccml5
Aug 27 06:12:29.176: INFO: Got endpoints: latency-svc-h6pxv [746.654463ms]
Aug 27 06:12:29.188: INFO: Created: latency-svc-gr8h4
Aug 27 06:12:29.233: INFO: Got endpoints: latency-svc-x4tjz [752.455873ms]
Aug 27 06:12:29.243: INFO: Created: latency-svc-vg78m
Aug 27 06:12:29.277: INFO: Got endpoints: latency-svc-l8k7n [744.939795ms]
Aug 27 06:12:29.290: INFO: Created: latency-svc-sgr5t
Aug 27 06:12:29.336: INFO: Got endpoints: latency-svc-rqw7c [756.730695ms]
Aug 27 06:12:29.355: INFO: Created: latency-svc-czknr
Aug 27 06:12:29.379: INFO: Got endpoints: latency-svc-cwkvq [751.496256ms]
Aug 27 06:12:29.392: INFO: Created: latency-svc-grkg7
Aug 27 06:12:29.429: INFO: Got endpoints: latency-svc-zpzfn [752.588039ms]
Aug 27 06:12:29.441: INFO: Created: latency-svc-4mvvh
Aug 27 06:12:29.477: INFO: Got endpoints: latency-svc-tc6cx [747.441453ms]
Aug 27 06:12:29.491: INFO: Created: latency-svc-5t9dj
Aug 27 06:12:29.533: INFO: Got endpoints: latency-svc-vcj74 [755.938064ms]
Aug 27 06:12:29.543: INFO: Created: latency-svc-mjbgq
Aug 27 06:12:29.584: INFO: Got endpoints: latency-svc-6fp6n [757.264056ms]
Aug 27 06:12:29.595: INFO: Created: latency-svc-jtzxn
Aug 27 06:12:29.629: INFO: Got endpoints: latency-svc-lw4c8 [748.168366ms]
Aug 27 06:12:29.646: INFO: Created: latency-svc-c59nf
Aug 27 06:12:29.677: INFO: Got endpoints: latency-svc-ds5jl [746.648833ms]
Aug 27 06:12:29.687: INFO: Created: latency-svc-lksg8
Aug 27 06:12:29.731: INFO: Got endpoints: latency-svc-qj9cf [753.134513ms]
Aug 27 06:12:29.744: INFO: Created: latency-svc-5vsf9
Aug 27 06:12:29.777: INFO: Got endpoints: latency-svc-qjjph [741.027942ms]
Aug 27 06:12:29.788: INFO: Created: latency-svc-cglsx
Aug 27 06:12:29.827: INFO: Got endpoints: latency-svc-vdgm8 [751.246066ms]
Aug 27 06:12:29.839: INFO: Created: latency-svc-lq2tj
Aug 27 06:12:29.884: INFO: Got endpoints: latency-svc-ccml5 [755.382908ms]
Aug 27 06:12:29.898: INFO: Created: latency-svc-fjfpd
Aug 27 06:12:29.938: INFO: Got endpoints: latency-svc-gr8h4 [761.790032ms]
Aug 27 06:12:29.947: INFO: Created: latency-svc-mjqcx
Aug 27 06:12:29.976: INFO: Got endpoints: latency-svc-vg78m [743.174363ms]
Aug 27 06:12:29.987: INFO: Created: latency-svc-nx6qk
Aug 27 06:12:30.026: INFO: Got endpoints: latency-svc-sgr5t [749.045238ms]
Aug 27 06:12:30.041: INFO: Created: latency-svc-d4gnh
Aug 27 06:12:30.082: INFO: Got endpoints: latency-svc-czknr [745.579647ms]
Aug 27 06:12:30.092: INFO: Created: latency-svc-7xqx7
Aug 27 06:12:30.128: INFO: Got endpoints: latency-svc-grkg7 [748.73912ms]
Aug 27 06:12:30.142: INFO: Created: latency-svc-qpvr6
Aug 27 06:12:30.178: INFO: Got endpoints: latency-svc-4mvvh [749.003943ms]
Aug 27 06:12:30.190: INFO: Created: latency-svc-zfj5q
Aug 27 06:12:30.228: INFO: Got endpoints: latency-svc-5t9dj [750.614648ms]
Aug 27 06:12:30.239: INFO: Created: latency-svc-95t4n
Aug 27 06:12:30.278: INFO: Got endpoints: latency-svc-mjbgq [744.589144ms]
Aug 27 06:12:30.294: INFO: Created: latency-svc-94qh9
Aug 27 06:12:30.327: INFO: Got endpoints: latency-svc-jtzxn [743.110209ms]
Aug 27 06:12:30.339: INFO: Created: latency-svc-bzmmh
Aug 27 06:12:30.379: INFO: Got endpoints: latency-svc-c59nf [749.216521ms]
Aug 27 06:12:30.392: INFO: Created: latency-svc-h7ct2
Aug 27 06:12:30.427: INFO: Got endpoints: latency-svc-lksg8 [749.647477ms]
Aug 27 06:12:30.444: INFO: Created: latency-svc-bhv89
Aug 27 06:12:30.476: INFO: Got endpoints: latency-svc-5vsf9 [744.310001ms]
Aug 27 06:12:30.487: INFO: Created: latency-svc-wpzv9
Aug 27 06:12:30.528: INFO: Got endpoints: latency-svc-cglsx [750.828282ms]
Aug 27 06:12:30.543: INFO: Created: latency-svc-kh8hl
Aug 27 06:12:30.578: INFO: Got endpoints: latency-svc-lq2tj [750.889966ms]
Aug 27 06:12:30.591: INFO: Created: latency-svc-bt2rd
Aug 27 06:12:30.627: INFO: Got endpoints: latency-svc-fjfpd [742.467424ms]
Aug 27 06:12:30.641: INFO: Created: latency-svc-7hbvf
Aug 27 06:12:30.676: INFO: Got endpoints: latency-svc-mjqcx [738.068011ms]
Aug 27 06:12:30.688: INFO: Created: latency-svc-m6kfq
Aug 27 06:12:30.726: INFO: Got endpoints: latency-svc-nx6qk [750.021709ms]
Aug 27 06:12:30.737: INFO: Created: latency-svc-8m4cl
Aug 27 06:12:30.776: INFO: Got endpoints: latency-svc-d4gnh [749.448681ms]
Aug 27 06:12:30.791: INFO: Created: latency-svc-c5fz7
Aug 27 06:12:30.826: INFO: Got endpoints: latency-svc-7xqx7 [744.110207ms]
Aug 27 06:12:30.837: INFO: Created: latency-svc-fldqz
Aug 27 06:12:30.878: INFO: Got endpoints: latency-svc-qpvr6 [749.801102ms]
Aug 27 06:12:30.891: INFO: Created: latency-svc-dhn7x
Aug 27 06:12:30.926: INFO: Got endpoints: latency-svc-zfj5q [747.84947ms]
Aug 27 06:12:30.940: INFO: Created: latency-svc-67vvs
Aug 27 06:12:30.983: INFO: Got endpoints: latency-svc-95t4n [754.759468ms]
Aug 27 06:12:30.996: INFO: Created: latency-svc-9t5tr
Aug 27 06:12:31.028: INFO: Got endpoints: latency-svc-94qh9 [750.26913ms]
Aug 27 06:12:31.040: INFO: Created: latency-svc-q8dvb
Aug 27 06:12:31.083: INFO: Got endpoints: latency-svc-bzmmh [755.497822ms]
Aug 27 06:12:31.093: INFO: Created: latency-svc-tt4vz
Aug 27 06:12:31.127: INFO: Got endpoints: latency-svc-h7ct2 [748.318815ms]
Aug 27 06:12:31.140: INFO: Created: latency-svc-krbhb
Aug 27 06:12:31.178: INFO: Got endpoints: latency-svc-bhv89 [750.302483ms]
Aug 27 06:12:31.190: INFO: Created: latency-svc-b22x6
Aug 27 06:12:31.226: INFO: Got endpoints: latency-svc-wpzv9 [750.268306ms]
Aug 27 06:12:31.239: INFO: Created: latency-svc-bk29g
Aug 27 06:12:31.277: INFO: Got endpoints: latency-svc-kh8hl [749.095531ms]
Aug 27 06:12:31.290: INFO: Created: latency-svc-w8t2l
Aug 27 06:12:31.336: INFO: Got endpoints: latency-svc-bt2rd [758.125683ms]
Aug 27 06:12:31.361: INFO: Created: latency-svc-2l8q4
Aug 27 06:12:31.381: INFO: Got endpoints: latency-svc-7hbvf [753.682941ms]
Aug 27 06:12:31.408: INFO: Created: latency-svc-r585g
Aug 27 06:12:31.428: INFO: Got endpoints: latency-svc-m6kfq [751.311207ms]
Aug 27 06:12:31.452: INFO: Created: latency-svc-cmtzb
Aug 27 06:12:31.477: INFO: Got endpoints: latency-svc-8m4cl [750.040607ms]
Aug 27 06:12:31.490: INFO: Created: latency-svc-k8nbt
Aug 27 06:12:31.526: INFO: Got endpoints: latency-svc-c5fz7 [749.612843ms]
Aug 27 06:12:31.543: INFO: Created: latency-svc-58pgl
Aug 27 06:12:31.576: INFO: Got endpoints: latency-svc-fldqz [749.873959ms]
Aug 27 06:12:31.592: INFO: Created: latency-svc-l8956
Aug 27 06:12:31.628: INFO: Got endpoints: latency-svc-dhn7x [750.46915ms]
Aug 27 06:12:31.639: INFO: Created: latency-svc-xvhwx
Aug 27 06:12:31.677: INFO: Got endpoints: latency-svc-67vvs [749.185101ms]
Aug 27 06:12:31.692: INFO: Created: latency-svc-zp98n
Aug 27 06:12:31.726: INFO: Got endpoints: latency-svc-9t5tr [743.041807ms]
Aug 27 06:12:31.739: INFO: Created: latency-svc-lkv7c
Aug 27 06:12:31.778: INFO: Got endpoints: latency-svc-q8dvb [749.272704ms]
Aug 27 06:12:31.790: INFO: Created: latency-svc-5sg7d
Aug 27 06:12:31.826: INFO: Got endpoints: latency-svc-tt4vz [742.749046ms]
Aug 27 06:12:31.838: INFO: Created: latency-svc-jvpw8
Aug 27 06:12:31.876: INFO: Got endpoints: latency-svc-krbhb [748.31388ms]
Aug 27 06:12:31.888: INFO: Created: latency-svc-vgp9z
Aug 27 06:12:31.927: INFO: Got endpoints: latency-svc-b22x6 [748.921567ms]
Aug 27 06:12:31.941: INFO: Created: latency-svc-vzn7x
Aug 27 06:12:31.984: INFO: Got endpoints: latency-svc-bk29g [756.913545ms]
Aug 27 06:12:31.991: INFO: Created: latency-svc-2wgq4
Aug 27 06:12:32.029: INFO: Got endpoints: latency-svc-w8t2l [751.984399ms]
Aug 27 06:12:32.053: INFO: Created: latency-svc-hf6c7
Aug 27 06:12:32.082: INFO: Got endpoints: latency-svc-2l8q4 [745.61347ms]
Aug 27 06:12:32.097: INFO: Created: latency-svc-ljtc9
Aug 27 06:12:32.126: INFO: Got endpoints: latency-svc-r585g [745.12242ms]
Aug 27 06:12:32.142: INFO: Created: latency-svc-zs89s
Aug 27 06:12:32.177: INFO: Got endpoints: latency-svc-cmtzb [748.440563ms]
Aug 27 06:12:32.191: INFO: Created: latency-svc-c84lc
Aug 27 06:12:32.228: INFO: Got endpoints: latency-svc-k8nbt [750.74664ms]
Aug 27 06:12:32.240: INFO: Created: latency-svc-m2ljb
Aug 27 06:12:32.277: INFO: Got endpoints: latency-svc-58pgl [750.485298ms]
Aug 27 06:12:32.293: INFO: Created: latency-svc-nnbg8
Aug 27 06:12:32.329: INFO: Got endpoints: latency-svc-l8956 [752.224798ms]
Aug 27 06:12:32.343: INFO: Created: latency-svc-ncv2h
Aug 27 06:12:32.378: INFO: Got endpoints: latency-svc-xvhwx [749.438883ms]
Aug 27 06:12:32.392: INFO: Created: latency-svc-8qbg6
Aug 27 06:12:32.433: INFO: Got endpoints: latency-svc-zp98n [755.659776ms]
Aug 27 06:12:32.445: INFO: Created: latency-svc-24lgj
Aug 27 06:12:32.476: INFO: Got endpoints: latency-svc-lkv7c [749.755752ms]
Aug 27 06:12:32.491: INFO: Created: latency-svc-vp85l
Aug 27 06:12:32.527: INFO: Got endpoints: latency-svc-5sg7d [748.503454ms]
Aug 27 06:12:32.539: INFO: Created: latency-svc-pvxtc
Aug 27 06:12:32.576: INFO: Got endpoints: latency-svc-jvpw8 [749.346042ms]
Aug 27 06:12:32.587: INFO: Created: latency-svc-lfl7c
Aug 27 06:12:32.632: INFO: Got endpoints: latency-svc-vgp9z [755.55612ms]
Aug 27 06:12:32.644: INFO: Created: latency-svc-c5886
Aug 27 06:12:32.676: INFO: Got endpoints: latency-svc-vzn7x [749.21303ms]
Aug 27 06:12:32.693: INFO: Created: latency-svc-8qbt6
Aug 27 06:12:32.742: INFO: Got endpoints: latency-svc-2wgq4 [758.406521ms]
Aug 27 06:12:32.781: INFO: Got endpoints: latency-svc-hf6c7 [751.961445ms]
Aug 27 06:12:32.784: INFO: Created: latency-svc-twzdx
Aug 27 06:12:32.816: INFO: Created: latency-svc-9qj7d
Aug 27 06:12:32.833: INFO: Got endpoints: latency-svc-ljtc9 [750.607099ms]
Aug 27 06:12:32.850: INFO: Created: latency-svc-n42th
Aug 27 06:12:32.881: INFO: Got endpoints: latency-svc-zs89s [754.823666ms]
Aug 27 06:12:32.919: INFO: Created: latency-svc-7xc48
Aug 27 06:12:32.930: INFO: Got endpoints: latency-svc-c84lc [752.881467ms]
Aug 27 06:12:32.942: INFO: Created: latency-svc-4zgs5
Aug 27 06:12:32.982: INFO: Got endpoints: latency-svc-m2ljb [753.215111ms]
Aug 27 06:12:32.995: INFO: Created: latency-svc-dkf8p
Aug 27 06:12:33.034: INFO: Got endpoints: latency-svc-nnbg8 [757.218504ms]
Aug 27 06:12:33.048: INFO: Created: latency-svc-s2rz7
Aug 27 06:12:33.077: INFO: Got endpoints: latency-svc-ncv2h [748.38542ms]
Aug 27 06:12:33.087: INFO: Created: latency-svc-j2gnp
Aug 27 06:12:33.126: INFO: Got endpoints: latency-svc-8qbg6 [748.051578ms]
Aug 27 06:12:33.137: INFO: Created: latency-svc-h2plf
Aug 27 06:12:33.177: INFO: Got endpoints: latency-svc-24lgj [743.31256ms]
Aug 27 06:12:33.188: INFO: Created: latency-svc-c22b7
Aug 27 06:12:33.228: INFO: Got endpoints: latency-svc-vp85l [752.01271ms]
Aug 27 06:12:33.239: INFO: Created: latency-svc-fd2th
Aug 27 06:12:33.277: INFO: Got endpoints: latency-svc-pvxtc [750.478681ms]
Aug 27 06:12:33.287: INFO: Created: latency-svc-ldwr4
Aug 27 06:12:33.331: INFO: Got endpoints: latency-svc-lfl7c [754.697065ms]
Aug 27 06:12:33.340: INFO: Created: latency-svc-ckx6g
Aug 27 06:12:33.380: INFO: Got endpoints: latency-svc-c5886 [747.744198ms]
Aug 27 06:12:33.394: INFO: Created: latency-svc-b46nd
Aug 27 06:12:33.428: INFO: Got endpoints: latency-svc-8qbt6 [751.59631ms]
Aug 27 06:12:33.438: INFO: Created: latency-svc-rpmcd
Aug 27 06:12:33.479: INFO: Got endpoints: latency-svc-twzdx [736.782147ms]
Aug 27 06:12:33.491: INFO: Created: latency-svc-h5jzv
Aug 27 06:12:33.526: INFO: Got endpoints: latency-svc-9qj7d [744.426993ms]
Aug 27 06:12:33.538: INFO: Created: latency-svc-5wrbn
Aug 27 06:12:33.577: INFO: Got endpoints: latency-svc-n42th [743.260344ms]
Aug 27 06:12:33.587: INFO: Created: latency-svc-vqfnk
Aug 27 06:12:33.638: INFO: Got endpoints: latency-svc-7xc48 [756.125069ms]
Aug 27 06:12:33.650: INFO: Created: latency-svc-2md6w
Aug 27 06:12:33.677: INFO: Got endpoints: latency-svc-4zgs5 [747.147028ms]
Aug 27 06:12:33.690: INFO: Created: latency-svc-stktk
Aug 27 06:12:33.726: INFO: Got endpoints: latency-svc-dkf8p [744.095847ms]
Aug 27 06:12:33.737: INFO: Created: latency-svc-8zj7q
Aug 27 06:12:33.776: INFO: Got endpoints: latency-svc-s2rz7 [741.011398ms]
Aug 27 06:12:33.789: INFO: Created: latency-svc-s7prd
Aug 27 06:12:33.827: INFO: Got endpoints: latency-svc-j2gnp [749.416697ms]
Aug 27 06:12:33.841: INFO: Created: latency-svc-flbs2
Aug 27 06:12:33.877: INFO: Got endpoints: latency-svc-h2plf [750.352128ms]
Aug 27 06:12:33.890: INFO: Created: latency-svc-pbpkj
Aug 27 06:12:33.926: INFO: Got endpoints: latency-svc-c22b7 [749.682869ms]
Aug 27 06:12:33.937: INFO: Created: latency-svc-tqrgj
Aug 27 06:12:33.976: INFO: Got endpoints: latency-svc-fd2th [747.88834ms]
Aug 27 06:12:33.988: INFO: Created: latency-svc-qqgvl
Aug 27 06:12:34.032: INFO: Got endpoints: latency-svc-ldwr4 [754.928422ms]
Aug 27 06:12:34.041: INFO: Created: latency-svc-h2mv8
Aug 27 06:12:34.076: INFO: Got endpoints: latency-svc-ckx6g [745.533805ms]
Aug 27 06:12:34.088: INFO: Created: latency-svc-j7lh4
Aug 27 06:12:34.126: INFO: Got endpoints: latency-svc-b46nd [745.730047ms]
Aug 27 06:12:34.139: INFO: Created: latency-svc-vfxnj
Aug 27 06:12:34.177: INFO: Got endpoints: latency-svc-rpmcd [748.345407ms]
Aug 27 06:12:34.190: INFO: Created: latency-svc-slf4s
Aug 27 06:12:34.226: INFO: Got endpoints: latency-svc-h5jzv [746.972349ms]
Aug 27 06:12:34.239: INFO: Created: latency-svc-447wb
Aug 27 06:12:34.277: INFO: Got endpoints: latency-svc-5wrbn [750.469858ms]
Aug 27 06:12:34.290: INFO: Created: latency-svc-hwcwf
Aug 27 06:12:34.326: INFO: Got endpoints: latency-svc-vqfnk [749.386671ms]
Aug 27 06:12:34.379: INFO: Got endpoints: latency-svc-2md6w [741.241622ms]
Aug 27 06:12:34.431: INFO: Got endpoints: latency-svc-stktk [753.923269ms]
Aug 27 06:12:34.478: INFO: Got endpoints: latency-svc-8zj7q [752.052627ms]
Aug 27 06:12:34.530: INFO: Got endpoints: latency-svc-s7prd [753.95806ms]
Aug 27 06:12:34.577: INFO: Got endpoints: latency-svc-flbs2 [749.498331ms]
Aug 27 06:12:34.628: INFO: Got endpoints: latency-svc-pbpkj [751.157679ms]
Aug 27 06:12:34.676: INFO: Got endpoints: latency-svc-tqrgj [749.838304ms]
Aug 27 06:12:34.727: INFO: Got endpoints: latency-svc-qqgvl [750.889988ms]
Aug 27 06:12:34.776: INFO: Got endpoints: latency-svc-h2mv8 [743.882779ms]
Aug 27 06:12:34.826: INFO: Got endpoints: latency-svc-j7lh4 [749.624856ms]
Aug 27 06:12:34.877: INFO: Got endpoints: latency-svc-vfxnj [750.517399ms]
Aug 27 06:12:34.926: INFO: Got endpoints: latency-svc-slf4s [749.239158ms]
Aug 27 06:12:34.977: INFO: Got endpoints: latency-svc-447wb [750.471948ms]
Aug 27 06:12:35.028: INFO: Got endpoints: latency-svc-hwcwf [751.161987ms]
Aug 27 06:12:35.029: INFO: Latencies: [32.030814ms 48.545774ms 77.889954ms 79.364595ms 89.587756ms 100.2485ms 103.520135ms 104.559763ms 106.609814ms 109.042854ms 110.233508ms 114.057967ms 114.147803ms 114.958941ms 134.817271ms 187.868609ms 194.227215ms 194.254962ms 194.631245ms 196.353885ms 197.822162ms 197.833127ms 204.082489ms 204.668051ms 204.866176ms 205.040544ms 214.451874ms 216.570267ms 216.576999ms 219.382797ms 223.442826ms 223.582116ms 237.875761ms 253.144399ms 254.427267ms 256.285447ms 265.209947ms 265.45976ms 266.350816ms 266.398763ms 278.853191ms 280.826151ms 281.881832ms 282.8005ms 330.253069ms 382.037705ms 432.126132ms 479.653822ms 503.774873ms 548.935969ms 605.604838ms 654.237469ms 661.151941ms 703.050035ms 712.567388ms 736.662476ms 736.782147ms 738.068011ms 739.929306ms 741.011398ms 741.027942ms 741.241622ms 742.467424ms 742.749046ms 743.041807ms 743.110209ms 743.174363ms 743.260344ms 743.31256ms 743.882779ms 744.095847ms 744.110207ms 744.310001ms 744.426993ms 744.589144ms 744.939795ms 745.12242ms 745.367754ms 745.533805ms 745.579647ms 745.61347ms 745.730047ms 746.420419ms 746.648833ms 746.654463ms 746.935646ms 746.945471ms 746.972349ms 747.043185ms 747.147028ms 747.205072ms 747.441453ms 747.744198ms 747.84947ms 747.88834ms 748.051578ms 748.087302ms 748.168366ms 748.31388ms 748.318815ms 748.345407ms 748.37926ms 748.38542ms 748.41454ms 748.440563ms 748.503454ms 748.73912ms 748.921567ms 749.003943ms 749.045238ms 749.095531ms 749.185101ms 749.21303ms 749.216521ms 749.239158ms 749.272704ms 749.346042ms 749.386671ms 749.416697ms 749.438883ms 749.448681ms 749.467754ms 749.498331ms 749.612843ms 749.624856ms 749.647477ms 749.682869ms 749.685713ms 749.755752ms 749.801102ms 749.838304ms 749.873959ms 750.021709ms 750.040607ms 750.268306ms 750.26913ms 750.302483ms 750.352128ms 750.46915ms 750.469858ms 750.471948ms 750.478681ms 750.485298ms 750.517399ms 750.607099ms 750.614648ms 750.74664ms 750.828282ms 750.889966ms 750.889988ms 751.034235ms 751.15503ms 751.157679ms 751.161987ms 751.246066ms 751.311207ms 751.371764ms 751.496256ms 751.59631ms 751.961445ms 751.984399ms 752.01271ms 752.052627ms 752.195209ms 752.224798ms 752.257065ms 752.296756ms 752.455873ms 752.588039ms 752.589544ms 752.6225ms 752.881467ms 753.134513ms 753.164134ms 753.215111ms 753.682941ms 753.923269ms 753.95806ms 754.697065ms 754.698934ms 754.759468ms 754.823666ms 754.928422ms 755.049675ms 755.382908ms 755.497822ms 755.55612ms 755.659776ms 755.938064ms 755.988686ms 756.125069ms 756.730695ms 756.913545ms 757.218504ms 757.264056ms 758.125683ms 758.155351ms 758.406521ms 760.421038ms 761.790032ms]
Aug 27 06:12:35.030: INFO: 50 %ile: 748.345407ms
Aug 27 06:12:35.030: INFO: 90 %ile: 754.759468ms
Aug 27 06:12:35.030: INFO: 99 %ile: 760.421038ms
Aug 27 06:12:35.030: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Aug 27 06:12:35.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5479" for this suite. 08/27/22 06:12:35.044
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":127,"skipped":2469,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.777 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:24.274
    Aug 27 06:12:24.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svc-latency 08/27/22 06:12:24.276
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:24.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:24.296
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Aug 27 06:12:24.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-5479 08/27/22 06:12:24.3
    I0827 06:12:24.305789      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5479, replica count: 1
    I0827 06:12:25.356732      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0827 06:12:26.356899      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 06:12:26.474: INFO: Created: latency-svc-8twnc
    Aug 27 06:12:26.481: INFO: Got endpoints: latency-svc-8twnc [23.6884ms]
    Aug 27 06:12:26.502: INFO: Created: latency-svc-w4wzg
    Aug 27 06:12:26.514: INFO: Created: latency-svc-d526h
    Aug 27 06:12:26.514: INFO: Got endpoints: latency-svc-w4wzg [32.030814ms]
    Aug 27 06:12:26.530: INFO: Got endpoints: latency-svc-d526h [48.545774ms]
    Aug 27 06:12:26.542: INFO: Created: latency-svc-m9xkw
    Aug 27 06:12:26.561: INFO: Got endpoints: latency-svc-m9xkw [77.889954ms]
    Aug 27 06:12:26.564: INFO: Created: latency-svc-qgvrq
    Aug 27 06:12:26.583: INFO: Got endpoints: latency-svc-qgvrq [100.2485ms]
    Aug 27 06:12:26.633: INFO: Created: latency-svc-nl4wv
    Aug 27 06:12:26.633: INFO: Created: latency-svc-v4fg8
    Aug 27 06:12:26.634: INFO: Created: latency-svc-qbs77
    Aug 27 06:12:26.634: INFO: Created: latency-svc-tj7vp
    Aug 27 06:12:26.634: INFO: Created: latency-svc-fsh2l
    Aug 27 06:12:26.634: INFO: Created: latency-svc-5hg85
    Aug 27 06:12:26.634: INFO: Created: latency-svc-ncxxw
    Aug 27 06:12:26.635: INFO: Created: latency-svc-c2m5p
    Aug 27 06:12:26.635: INFO: Created: latency-svc-5nfrd
    Aug 27 06:12:26.635: INFO: Created: latency-svc-gprtw
    Aug 27 06:12:26.635: INFO: Created: latency-svc-4n77x
    Aug 27 06:12:26.636: INFO: Created: latency-svc-tnfpr
    Aug 27 06:12:26.636: INFO: Created: latency-svc-xdlkw
    Aug 27 06:12:26.635: INFO: Created: latency-svc-msmz2
    Aug 27 06:12:26.637: INFO: Created: latency-svc-hq82p
    Aug 27 06:12:26.678: INFO: Got endpoints: latency-svc-nl4wv [194.254962ms]
    Aug 27 06:12:26.700: INFO: Got endpoints: latency-svc-ncxxw [216.576999ms]
    Aug 27 06:12:26.700: INFO: Got endpoints: latency-svc-v4fg8 [216.570267ms]
    Aug 27 06:12:26.702: INFO: Got endpoints: latency-svc-qbs77 [114.057967ms]
    Aug 27 06:12:26.703: INFO: Got endpoints: latency-svc-hq82p [219.382797ms]
    Aug 27 06:12:26.722: INFO: Got endpoints: latency-svc-xdlkw [237.875761ms]
    Aug 27 06:12:26.741: INFO: Got endpoints: latency-svc-msmz2 [256.285447ms]
    Aug 27 06:12:26.741: INFO: Created: latency-svc-f7b2g
    Aug 27 06:12:26.750: INFO: Got endpoints: latency-svc-4n77x [265.45976ms]
    Aug 27 06:12:26.751: INFO: Got endpoints: latency-svc-gprtw [265.209947ms]
    Aug 27 06:12:26.751: INFO: Got endpoints: latency-svc-tnfpr [266.398763ms]
    Aug 27 06:12:26.766: INFO: Got endpoints: latency-svc-c2m5p [280.826151ms]
    Aug 27 06:12:26.767: INFO: Got endpoints: latency-svc-5nfrd [281.881832ms]
    Aug 27 06:12:26.768: INFO: Got endpoints: latency-svc-5hg85 [253.144399ms]
    Aug 27 06:12:26.772: INFO: Created: latency-svc-mhc55
    Aug 27 06:12:26.785: INFO: Got endpoints: latency-svc-f7b2g [106.609814ms]
    Aug 27 06:12:26.785: INFO: Got endpoints: latency-svc-tj7vp [223.442826ms]
    Aug 27 06:12:26.785: INFO: Got endpoints: latency-svc-fsh2l [254.427267ms]
    Aug 27 06:12:26.790: INFO: Got endpoints: latency-svc-mhc55 [89.587756ms]
    Aug 27 06:12:26.840: INFO: Created: latency-svc-gmm86
    Aug 27 06:12:26.841: INFO: Created: latency-svc-qwsmx
    Aug 27 06:12:26.843: INFO: Created: latency-svc-7vk92
    Aug 27 06:12:26.843: INFO: Created: latency-svc-n8njs
    Aug 27 06:12:26.841: INFO: Created: latency-svc-4lc9k
    Aug 27 06:12:26.842: INFO: Created: latency-svc-b9tpg
    Aug 27 06:12:26.842: INFO: Created: latency-svc-ttgvd
    Aug 27 06:12:26.842: INFO: Created: latency-svc-4kcsd
    Aug 27 06:12:26.842: INFO: Created: latency-svc-vswgk
    Aug 27 06:12:26.842: INFO: Created: latency-svc-nxb6n
    Aug 27 06:12:26.843: INFO: Created: latency-svc-dxdnr
    Aug 27 06:12:26.843: INFO: Created: latency-svc-mfqb2
    Aug 27 06:12:26.843: INFO: Created: latency-svc-pfsgj
    Aug 27 06:12:26.841: INFO: Created: latency-svc-k8kv4
    Aug 27 06:12:26.844: INFO: Created: latency-svc-2gblm
    Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-qwsmx [197.833127ms]
    Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-gmm86 [114.147803ms]
    Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-k8kv4 [197.822162ms]
    Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-vswgk [114.958941ms]
    Aug 27 06:12:26.900: INFO: Got endpoints: latency-svc-nxb6n [109.042854ms]
    Aug 27 06:12:26.945: INFO: Got endpoints: latency-svc-dxdnr [194.227215ms]
    Aug 27 06:12:26.946: INFO: Got endpoints: latency-svc-ttgvd [194.631245ms]
    Aug 27 06:12:26.947: INFO: Got endpoints: latency-svc-b9tpg [196.353885ms]
    Aug 27 06:12:26.946: INFO: Got endpoints: latency-svc-mfqb2 [204.668051ms]
    Aug 27 06:12:26.946: INFO: Got endpoints: latency-svc-4lc9k [223.582116ms]
    Aug 27 06:12:26.969: INFO: Got endpoints: latency-svc-2gblm [266.350816ms]
    Aug 27 06:12:26.971: INFO: Got endpoints: latency-svc-pfsgj [204.082489ms]
    Aug 27 06:12:26.972: INFO: Got endpoints: latency-svc-n8njs [204.866176ms]
    Aug 27 06:12:26.971: INFO: Created: latency-svc-blhc7
    Aug 27 06:12:26.973: INFO: Got endpoints: latency-svc-4kcsd [187.868609ms]
    Aug 27 06:12:26.973: INFO: Got endpoints: latency-svc-7vk92 [205.040544ms]
    Aug 27 06:12:26.979: INFO: Got endpoints: latency-svc-blhc7 [79.364595ms]
    Aug 27 06:12:26.980: INFO: Created: latency-svc-467pw
    Aug 27 06:12:26.989: INFO: Created: latency-svc-7zbjr
    Aug 27 06:12:27.004: INFO: Got endpoints: latency-svc-467pw [103.520135ms]
    Aug 27 06:12:27.011: INFO: Got endpoints: latency-svc-7zbjr [110.233508ms]
    Aug 27 06:12:27.071: INFO: Created: latency-svc-gnpg4
    Aug 27 06:12:27.071: INFO: Created: latency-svc-scq94
    Aug 27 06:12:27.071: INFO: Created: latency-svc-2gbrp
    Aug 27 06:12:27.072: INFO: Created: latency-svc-vdk8k
    Aug 27 06:12:27.072: INFO: Created: latency-svc-kzhsj
    Aug 27 06:12:27.073: INFO: Created: latency-svc-8qlxz
    Aug 27 06:12:27.073: INFO: Created: latency-svc-598ms
    Aug 27 06:12:27.073: INFO: Created: latency-svc-jpn8w
    Aug 27 06:12:27.074: INFO: Created: latency-svc-4ltx2
    Aug 27 06:12:27.074: INFO: Created: latency-svc-bt7jc
    Aug 27 06:12:27.075: INFO: Created: latency-svc-wkrn9
    Aug 27 06:12:27.075: INFO: Created: latency-svc-rx28d
    Aug 27 06:12:27.075: INFO: Created: latency-svc-5x6jp
    Aug 27 06:12:27.076: INFO: Created: latency-svc-jkpmw
    Aug 27 06:12:27.076: INFO: Created: latency-svc-q9t89
    Aug 27 06:12:27.115: INFO: Got endpoints: latency-svc-8qlxz [214.451874ms]
    Aug 27 06:12:27.115: INFO: Got endpoints: latency-svc-jpn8w [104.559763ms]
    Aug 27 06:12:27.124: INFO: Created: latency-svc-zvx47
    Aug 27 06:12:27.132: INFO: Created: latency-svc-4k8vb
    Aug 27 06:12:27.140: INFO: Got endpoints: latency-svc-598ms [134.817271ms]
    Aug 27 06:12:27.151: INFO: Created: latency-svc-p9rd2
    Aug 27 06:12:27.179: INFO: Got endpoints: latency-svc-gnpg4 [278.853191ms]
    Aug 27 06:12:27.189: INFO: Created: latency-svc-j7p2l
    Aug 27 06:12:27.229: INFO: Got endpoints: latency-svc-scq94 [282.8005ms]
    Aug 27 06:12:27.244: INFO: Created: latency-svc-bswzp
    Aug 27 06:12:27.277: INFO: Got endpoints: latency-svc-2gbrp [330.253069ms]
    Aug 27 06:12:27.293: INFO: Created: latency-svc-rqwmq
    Aug 27 06:12:27.329: INFO: Got endpoints: latency-svc-vdk8k [382.037705ms]
    Aug 27 06:12:27.343: INFO: Created: latency-svc-6qz4d
    Aug 27 06:12:27.379: INFO: Got endpoints: latency-svc-q9t89 [432.126132ms]
    Aug 27 06:12:27.392: INFO: Created: latency-svc-g4sb7
    Aug 27 06:12:27.427: INFO: Got endpoints: latency-svc-bt7jc [479.653822ms]
    Aug 27 06:12:27.440: INFO: Created: latency-svc-k2jtj
    Aug 27 06:12:27.476: INFO: Got endpoints: latency-svc-wkrn9 [503.774873ms]
    Aug 27 06:12:27.489: INFO: Created: latency-svc-ldpf2
    Aug 27 06:12:27.528: INFO: Got endpoints: latency-svc-rx28d [548.935969ms]
    Aug 27 06:12:27.538: INFO: Created: latency-svc-tv825
    Aug 27 06:12:27.578: INFO: Got endpoints: latency-svc-5x6jp [605.604838ms]
    Aug 27 06:12:27.596: INFO: Created: latency-svc-ftd97
    Aug 27 06:12:27.627: INFO: Got endpoints: latency-svc-jkpmw [654.237469ms]
    Aug 27 06:12:27.644: INFO: Created: latency-svc-7c9p9
    Aug 27 06:12:27.676: INFO: Got endpoints: latency-svc-4ltx2 [703.050035ms]
    Aug 27 06:12:27.689: INFO: Created: latency-svc-d9t7p
    Aug 27 06:12:27.726: INFO: Got endpoints: latency-svc-kzhsj [755.049675ms]
    Aug 27 06:12:27.740: INFO: Created: latency-svc-kds8m
    Aug 27 06:12:27.776: INFO: Got endpoints: latency-svc-zvx47 [661.151941ms]
    Aug 27 06:12:27.788: INFO: Created: latency-svc-q2gfl
    Aug 27 06:12:27.828: INFO: Got endpoints: latency-svc-4k8vb [712.567388ms]
    Aug 27 06:12:27.843: INFO: Created: latency-svc-nq8gw
    Aug 27 06:12:27.880: INFO: Got endpoints: latency-svc-p9rd2 [739.929306ms]
    Aug 27 06:12:27.892: INFO: Created: latency-svc-5nchz
    Aug 27 06:12:27.926: INFO: Got endpoints: latency-svc-j7p2l [747.205072ms]
    Aug 27 06:12:27.936: INFO: Created: latency-svc-hgz7f
    Aug 27 06:12:27.977: INFO: Got endpoints: latency-svc-bswzp [748.087302ms]
    Aug 27 06:12:27.990: INFO: Created: latency-svc-wpp5m
    Aug 27 06:12:28.030: INFO: Got endpoints: latency-svc-rqwmq [752.257065ms]
    Aug 27 06:12:28.039: INFO: Created: latency-svc-sqntj
    Aug 27 06:12:28.077: INFO: Got endpoints: latency-svc-6qz4d [746.420419ms]
    Aug 27 06:12:28.088: INFO: Created: latency-svc-sqtkr
    Aug 27 06:12:28.128: INFO: Got endpoints: latency-svc-g4sb7 [748.41454ms]
    Aug 27 06:12:28.139: INFO: Created: latency-svc-gzjt8
    Aug 27 06:12:28.179: INFO: Got endpoints: latency-svc-k2jtj [751.371764ms]
    Aug 27 06:12:28.189: INFO: Created: latency-svc-gb8nd
    Aug 27 06:12:28.232: INFO: Got endpoints: latency-svc-ldpf2 [755.988686ms]
    Aug 27 06:12:28.245: INFO: Created: latency-svc-86fhn
    Aug 27 06:12:28.277: INFO: Got endpoints: latency-svc-tv825 [748.37926ms]
    Aug 27 06:12:28.290: INFO: Created: latency-svc-5c7k5
    Aug 27 06:12:28.338: INFO: Got endpoints: latency-svc-ftd97 [760.421038ms]
    Aug 27 06:12:28.348: INFO: Created: latency-svc-z94fz
    Aug 27 06:12:28.375: INFO: Got endpoints: latency-svc-7c9p9 [746.935646ms]
    Aug 27 06:12:28.387: INFO: Created: latency-svc-2wlx7
    Aug 27 06:12:28.429: INFO: Got endpoints: latency-svc-d9t7p [752.6225ms]
    Aug 27 06:12:28.443: INFO: Created: latency-svc-h6pxv
    Aug 27 06:12:28.480: INFO: Got endpoints: latency-svc-kds8m [752.296756ms]
    Aug 27 06:12:28.490: INFO: Created: latency-svc-x4tjz
    Aug 27 06:12:28.531: INFO: Got endpoints: latency-svc-q2gfl [754.698934ms]
    Aug 27 06:12:28.543: INFO: Created: latency-svc-l8k7n
    Aug 27 06:12:28.579: INFO: Got endpoints: latency-svc-nq8gw [751.034235ms]
    Aug 27 06:12:28.591: INFO: Created: latency-svc-rqw7c
    Aug 27 06:12:28.627: INFO: Got endpoints: latency-svc-5nchz [746.945471ms]
    Aug 27 06:12:28.638: INFO: Created: latency-svc-cwkvq
    Aug 27 06:12:28.676: INFO: Got endpoints: latency-svc-hgz7f [749.685713ms]
    Aug 27 06:12:28.689: INFO: Created: latency-svc-zpzfn
    Aug 27 06:12:28.729: INFO: Got endpoints: latency-svc-wpp5m [752.195209ms]
    Aug 27 06:12:28.740: INFO: Created: latency-svc-tc6cx
    Aug 27 06:12:28.777: INFO: Got endpoints: latency-svc-sqntj [747.043185ms]
    Aug 27 06:12:28.799: INFO: Created: latency-svc-vcj74
    Aug 27 06:12:28.826: INFO: Got endpoints: latency-svc-sqtkr [749.467754ms]
    Aug 27 06:12:28.842: INFO: Created: latency-svc-6fp6n
    Aug 27 06:12:28.881: INFO: Got endpoints: latency-svc-gzjt8 [752.589544ms]
    Aug 27 06:12:28.889: INFO: Created: latency-svc-lw4c8
    Aug 27 06:12:28.930: INFO: Got endpoints: latency-svc-gb8nd [751.15503ms]
    Aug 27 06:12:28.940: INFO: Created: latency-svc-ds5jl
    Aug 27 06:12:28.978: INFO: Got endpoints: latency-svc-86fhn [745.367754ms]
    Aug 27 06:12:28.990: INFO: Created: latency-svc-qj9cf
    Aug 27 06:12:29.035: INFO: Got endpoints: latency-svc-5c7k5 [758.155351ms]
    Aug 27 06:12:29.043: INFO: Created: latency-svc-qjjph
    Aug 27 06:12:29.075: INFO: Got endpoints: latency-svc-z94fz [736.662476ms]
    Aug 27 06:12:29.087: INFO: Created: latency-svc-vdgm8
    Aug 27 06:12:29.129: INFO: Got endpoints: latency-svc-2wlx7 [753.164134ms]
    Aug 27 06:12:29.139: INFO: Created: latency-svc-ccml5
    Aug 27 06:12:29.176: INFO: Got endpoints: latency-svc-h6pxv [746.654463ms]
    Aug 27 06:12:29.188: INFO: Created: latency-svc-gr8h4
    Aug 27 06:12:29.233: INFO: Got endpoints: latency-svc-x4tjz [752.455873ms]
    Aug 27 06:12:29.243: INFO: Created: latency-svc-vg78m
    Aug 27 06:12:29.277: INFO: Got endpoints: latency-svc-l8k7n [744.939795ms]
    Aug 27 06:12:29.290: INFO: Created: latency-svc-sgr5t
    Aug 27 06:12:29.336: INFO: Got endpoints: latency-svc-rqw7c [756.730695ms]
    Aug 27 06:12:29.355: INFO: Created: latency-svc-czknr
    Aug 27 06:12:29.379: INFO: Got endpoints: latency-svc-cwkvq [751.496256ms]
    Aug 27 06:12:29.392: INFO: Created: latency-svc-grkg7
    Aug 27 06:12:29.429: INFO: Got endpoints: latency-svc-zpzfn [752.588039ms]
    Aug 27 06:12:29.441: INFO: Created: latency-svc-4mvvh
    Aug 27 06:12:29.477: INFO: Got endpoints: latency-svc-tc6cx [747.441453ms]
    Aug 27 06:12:29.491: INFO: Created: latency-svc-5t9dj
    Aug 27 06:12:29.533: INFO: Got endpoints: latency-svc-vcj74 [755.938064ms]
    Aug 27 06:12:29.543: INFO: Created: latency-svc-mjbgq
    Aug 27 06:12:29.584: INFO: Got endpoints: latency-svc-6fp6n [757.264056ms]
    Aug 27 06:12:29.595: INFO: Created: latency-svc-jtzxn
    Aug 27 06:12:29.629: INFO: Got endpoints: latency-svc-lw4c8 [748.168366ms]
    Aug 27 06:12:29.646: INFO: Created: latency-svc-c59nf
    Aug 27 06:12:29.677: INFO: Got endpoints: latency-svc-ds5jl [746.648833ms]
    Aug 27 06:12:29.687: INFO: Created: latency-svc-lksg8
    Aug 27 06:12:29.731: INFO: Got endpoints: latency-svc-qj9cf [753.134513ms]
    Aug 27 06:12:29.744: INFO: Created: latency-svc-5vsf9
    Aug 27 06:12:29.777: INFO: Got endpoints: latency-svc-qjjph [741.027942ms]
    Aug 27 06:12:29.788: INFO: Created: latency-svc-cglsx
    Aug 27 06:12:29.827: INFO: Got endpoints: latency-svc-vdgm8 [751.246066ms]
    Aug 27 06:12:29.839: INFO: Created: latency-svc-lq2tj
    Aug 27 06:12:29.884: INFO: Got endpoints: latency-svc-ccml5 [755.382908ms]
    Aug 27 06:12:29.898: INFO: Created: latency-svc-fjfpd
    Aug 27 06:12:29.938: INFO: Got endpoints: latency-svc-gr8h4 [761.790032ms]
    Aug 27 06:12:29.947: INFO: Created: latency-svc-mjqcx
    Aug 27 06:12:29.976: INFO: Got endpoints: latency-svc-vg78m [743.174363ms]
    Aug 27 06:12:29.987: INFO: Created: latency-svc-nx6qk
    Aug 27 06:12:30.026: INFO: Got endpoints: latency-svc-sgr5t [749.045238ms]
    Aug 27 06:12:30.041: INFO: Created: latency-svc-d4gnh
    Aug 27 06:12:30.082: INFO: Got endpoints: latency-svc-czknr [745.579647ms]
    Aug 27 06:12:30.092: INFO: Created: latency-svc-7xqx7
    Aug 27 06:12:30.128: INFO: Got endpoints: latency-svc-grkg7 [748.73912ms]
    Aug 27 06:12:30.142: INFO: Created: latency-svc-qpvr6
    Aug 27 06:12:30.178: INFO: Got endpoints: latency-svc-4mvvh [749.003943ms]
    Aug 27 06:12:30.190: INFO: Created: latency-svc-zfj5q
    Aug 27 06:12:30.228: INFO: Got endpoints: latency-svc-5t9dj [750.614648ms]
    Aug 27 06:12:30.239: INFO: Created: latency-svc-95t4n
    Aug 27 06:12:30.278: INFO: Got endpoints: latency-svc-mjbgq [744.589144ms]
    Aug 27 06:12:30.294: INFO: Created: latency-svc-94qh9
    Aug 27 06:12:30.327: INFO: Got endpoints: latency-svc-jtzxn [743.110209ms]
    Aug 27 06:12:30.339: INFO: Created: latency-svc-bzmmh
    Aug 27 06:12:30.379: INFO: Got endpoints: latency-svc-c59nf [749.216521ms]
    Aug 27 06:12:30.392: INFO: Created: latency-svc-h7ct2
    Aug 27 06:12:30.427: INFO: Got endpoints: latency-svc-lksg8 [749.647477ms]
    Aug 27 06:12:30.444: INFO: Created: latency-svc-bhv89
    Aug 27 06:12:30.476: INFO: Got endpoints: latency-svc-5vsf9 [744.310001ms]
    Aug 27 06:12:30.487: INFO: Created: latency-svc-wpzv9
    Aug 27 06:12:30.528: INFO: Got endpoints: latency-svc-cglsx [750.828282ms]
    Aug 27 06:12:30.543: INFO: Created: latency-svc-kh8hl
    Aug 27 06:12:30.578: INFO: Got endpoints: latency-svc-lq2tj [750.889966ms]
    Aug 27 06:12:30.591: INFO: Created: latency-svc-bt2rd
    Aug 27 06:12:30.627: INFO: Got endpoints: latency-svc-fjfpd [742.467424ms]
    Aug 27 06:12:30.641: INFO: Created: latency-svc-7hbvf
    Aug 27 06:12:30.676: INFO: Got endpoints: latency-svc-mjqcx [738.068011ms]
    Aug 27 06:12:30.688: INFO: Created: latency-svc-m6kfq
    Aug 27 06:12:30.726: INFO: Got endpoints: latency-svc-nx6qk [750.021709ms]
    Aug 27 06:12:30.737: INFO: Created: latency-svc-8m4cl
    Aug 27 06:12:30.776: INFO: Got endpoints: latency-svc-d4gnh [749.448681ms]
    Aug 27 06:12:30.791: INFO: Created: latency-svc-c5fz7
    Aug 27 06:12:30.826: INFO: Got endpoints: latency-svc-7xqx7 [744.110207ms]
    Aug 27 06:12:30.837: INFO: Created: latency-svc-fldqz
    Aug 27 06:12:30.878: INFO: Got endpoints: latency-svc-qpvr6 [749.801102ms]
    Aug 27 06:12:30.891: INFO: Created: latency-svc-dhn7x
    Aug 27 06:12:30.926: INFO: Got endpoints: latency-svc-zfj5q [747.84947ms]
    Aug 27 06:12:30.940: INFO: Created: latency-svc-67vvs
    Aug 27 06:12:30.983: INFO: Got endpoints: latency-svc-95t4n [754.759468ms]
    Aug 27 06:12:30.996: INFO: Created: latency-svc-9t5tr
    Aug 27 06:12:31.028: INFO: Got endpoints: latency-svc-94qh9 [750.26913ms]
    Aug 27 06:12:31.040: INFO: Created: latency-svc-q8dvb
    Aug 27 06:12:31.083: INFO: Got endpoints: latency-svc-bzmmh [755.497822ms]
    Aug 27 06:12:31.093: INFO: Created: latency-svc-tt4vz
    Aug 27 06:12:31.127: INFO: Got endpoints: latency-svc-h7ct2 [748.318815ms]
    Aug 27 06:12:31.140: INFO: Created: latency-svc-krbhb
    Aug 27 06:12:31.178: INFO: Got endpoints: latency-svc-bhv89 [750.302483ms]
    Aug 27 06:12:31.190: INFO: Created: latency-svc-b22x6
    Aug 27 06:12:31.226: INFO: Got endpoints: latency-svc-wpzv9 [750.268306ms]
    Aug 27 06:12:31.239: INFO: Created: latency-svc-bk29g
    Aug 27 06:12:31.277: INFO: Got endpoints: latency-svc-kh8hl [749.095531ms]
    Aug 27 06:12:31.290: INFO: Created: latency-svc-w8t2l
    Aug 27 06:12:31.336: INFO: Got endpoints: latency-svc-bt2rd [758.125683ms]
    Aug 27 06:12:31.361: INFO: Created: latency-svc-2l8q4
    Aug 27 06:12:31.381: INFO: Got endpoints: latency-svc-7hbvf [753.682941ms]
    Aug 27 06:12:31.408: INFO: Created: latency-svc-r585g
    Aug 27 06:12:31.428: INFO: Got endpoints: latency-svc-m6kfq [751.311207ms]
    Aug 27 06:12:31.452: INFO: Created: latency-svc-cmtzb
    Aug 27 06:12:31.477: INFO: Got endpoints: latency-svc-8m4cl [750.040607ms]
    Aug 27 06:12:31.490: INFO: Created: latency-svc-k8nbt
    Aug 27 06:12:31.526: INFO: Got endpoints: latency-svc-c5fz7 [749.612843ms]
    Aug 27 06:12:31.543: INFO: Created: latency-svc-58pgl
    Aug 27 06:12:31.576: INFO: Got endpoints: latency-svc-fldqz [749.873959ms]
    Aug 27 06:12:31.592: INFO: Created: latency-svc-l8956
    Aug 27 06:12:31.628: INFO: Got endpoints: latency-svc-dhn7x [750.46915ms]
    Aug 27 06:12:31.639: INFO: Created: latency-svc-xvhwx
    Aug 27 06:12:31.677: INFO: Got endpoints: latency-svc-67vvs [749.185101ms]
    Aug 27 06:12:31.692: INFO: Created: latency-svc-zp98n
    Aug 27 06:12:31.726: INFO: Got endpoints: latency-svc-9t5tr [743.041807ms]
    Aug 27 06:12:31.739: INFO: Created: latency-svc-lkv7c
    Aug 27 06:12:31.778: INFO: Got endpoints: latency-svc-q8dvb [749.272704ms]
    Aug 27 06:12:31.790: INFO: Created: latency-svc-5sg7d
    Aug 27 06:12:31.826: INFO: Got endpoints: latency-svc-tt4vz [742.749046ms]
    Aug 27 06:12:31.838: INFO: Created: latency-svc-jvpw8
    Aug 27 06:12:31.876: INFO: Got endpoints: latency-svc-krbhb [748.31388ms]
    Aug 27 06:12:31.888: INFO: Created: latency-svc-vgp9z
    Aug 27 06:12:31.927: INFO: Got endpoints: latency-svc-b22x6 [748.921567ms]
    Aug 27 06:12:31.941: INFO: Created: latency-svc-vzn7x
    Aug 27 06:12:31.984: INFO: Got endpoints: latency-svc-bk29g [756.913545ms]
    Aug 27 06:12:31.991: INFO: Created: latency-svc-2wgq4
    Aug 27 06:12:32.029: INFO: Got endpoints: latency-svc-w8t2l [751.984399ms]
    Aug 27 06:12:32.053: INFO: Created: latency-svc-hf6c7
    Aug 27 06:12:32.082: INFO: Got endpoints: latency-svc-2l8q4 [745.61347ms]
    Aug 27 06:12:32.097: INFO: Created: latency-svc-ljtc9
    Aug 27 06:12:32.126: INFO: Got endpoints: latency-svc-r585g [745.12242ms]
    Aug 27 06:12:32.142: INFO: Created: latency-svc-zs89s
    Aug 27 06:12:32.177: INFO: Got endpoints: latency-svc-cmtzb [748.440563ms]
    Aug 27 06:12:32.191: INFO: Created: latency-svc-c84lc
    Aug 27 06:12:32.228: INFO: Got endpoints: latency-svc-k8nbt [750.74664ms]
    Aug 27 06:12:32.240: INFO: Created: latency-svc-m2ljb
    Aug 27 06:12:32.277: INFO: Got endpoints: latency-svc-58pgl [750.485298ms]
    Aug 27 06:12:32.293: INFO: Created: latency-svc-nnbg8
    Aug 27 06:12:32.329: INFO: Got endpoints: latency-svc-l8956 [752.224798ms]
    Aug 27 06:12:32.343: INFO: Created: latency-svc-ncv2h
    Aug 27 06:12:32.378: INFO: Got endpoints: latency-svc-xvhwx [749.438883ms]
    Aug 27 06:12:32.392: INFO: Created: latency-svc-8qbg6
    Aug 27 06:12:32.433: INFO: Got endpoints: latency-svc-zp98n [755.659776ms]
    Aug 27 06:12:32.445: INFO: Created: latency-svc-24lgj
    Aug 27 06:12:32.476: INFO: Got endpoints: latency-svc-lkv7c [749.755752ms]
    Aug 27 06:12:32.491: INFO: Created: latency-svc-vp85l
    Aug 27 06:12:32.527: INFO: Got endpoints: latency-svc-5sg7d [748.503454ms]
    Aug 27 06:12:32.539: INFO: Created: latency-svc-pvxtc
    Aug 27 06:12:32.576: INFO: Got endpoints: latency-svc-jvpw8 [749.346042ms]
    Aug 27 06:12:32.587: INFO: Created: latency-svc-lfl7c
    Aug 27 06:12:32.632: INFO: Got endpoints: latency-svc-vgp9z [755.55612ms]
    Aug 27 06:12:32.644: INFO: Created: latency-svc-c5886
    Aug 27 06:12:32.676: INFO: Got endpoints: latency-svc-vzn7x [749.21303ms]
    Aug 27 06:12:32.693: INFO: Created: latency-svc-8qbt6
    Aug 27 06:12:32.742: INFO: Got endpoints: latency-svc-2wgq4 [758.406521ms]
    Aug 27 06:12:32.781: INFO: Got endpoints: latency-svc-hf6c7 [751.961445ms]
    Aug 27 06:12:32.784: INFO: Created: latency-svc-twzdx
    Aug 27 06:12:32.816: INFO: Created: latency-svc-9qj7d
    Aug 27 06:12:32.833: INFO: Got endpoints: latency-svc-ljtc9 [750.607099ms]
    Aug 27 06:12:32.850: INFO: Created: latency-svc-n42th
    Aug 27 06:12:32.881: INFO: Got endpoints: latency-svc-zs89s [754.823666ms]
    Aug 27 06:12:32.919: INFO: Created: latency-svc-7xc48
    Aug 27 06:12:32.930: INFO: Got endpoints: latency-svc-c84lc [752.881467ms]
    Aug 27 06:12:32.942: INFO: Created: latency-svc-4zgs5
    Aug 27 06:12:32.982: INFO: Got endpoints: latency-svc-m2ljb [753.215111ms]
    Aug 27 06:12:32.995: INFO: Created: latency-svc-dkf8p
    Aug 27 06:12:33.034: INFO: Got endpoints: latency-svc-nnbg8 [757.218504ms]
    Aug 27 06:12:33.048: INFO: Created: latency-svc-s2rz7
    Aug 27 06:12:33.077: INFO: Got endpoints: latency-svc-ncv2h [748.38542ms]
    Aug 27 06:12:33.087: INFO: Created: latency-svc-j2gnp
    Aug 27 06:12:33.126: INFO: Got endpoints: latency-svc-8qbg6 [748.051578ms]
    Aug 27 06:12:33.137: INFO: Created: latency-svc-h2plf
    Aug 27 06:12:33.177: INFO: Got endpoints: latency-svc-24lgj [743.31256ms]
    Aug 27 06:12:33.188: INFO: Created: latency-svc-c22b7
    Aug 27 06:12:33.228: INFO: Got endpoints: latency-svc-vp85l [752.01271ms]
    Aug 27 06:12:33.239: INFO: Created: latency-svc-fd2th
    Aug 27 06:12:33.277: INFO: Got endpoints: latency-svc-pvxtc [750.478681ms]
    Aug 27 06:12:33.287: INFO: Created: latency-svc-ldwr4
    Aug 27 06:12:33.331: INFO: Got endpoints: latency-svc-lfl7c [754.697065ms]
    Aug 27 06:12:33.340: INFO: Created: latency-svc-ckx6g
    Aug 27 06:12:33.380: INFO: Got endpoints: latency-svc-c5886 [747.744198ms]
    Aug 27 06:12:33.394: INFO: Created: latency-svc-b46nd
    Aug 27 06:12:33.428: INFO: Got endpoints: latency-svc-8qbt6 [751.59631ms]
    Aug 27 06:12:33.438: INFO: Created: latency-svc-rpmcd
    Aug 27 06:12:33.479: INFO: Got endpoints: latency-svc-twzdx [736.782147ms]
    Aug 27 06:12:33.491: INFO: Created: latency-svc-h5jzv
    Aug 27 06:12:33.526: INFO: Got endpoints: latency-svc-9qj7d [744.426993ms]
    Aug 27 06:12:33.538: INFO: Created: latency-svc-5wrbn
    Aug 27 06:12:33.577: INFO: Got endpoints: latency-svc-n42th [743.260344ms]
    Aug 27 06:12:33.587: INFO: Created: latency-svc-vqfnk
    Aug 27 06:12:33.638: INFO: Got endpoints: latency-svc-7xc48 [756.125069ms]
    Aug 27 06:12:33.650: INFO: Created: latency-svc-2md6w
    Aug 27 06:12:33.677: INFO: Got endpoints: latency-svc-4zgs5 [747.147028ms]
    Aug 27 06:12:33.690: INFO: Created: latency-svc-stktk
    Aug 27 06:12:33.726: INFO: Got endpoints: latency-svc-dkf8p [744.095847ms]
    Aug 27 06:12:33.737: INFO: Created: latency-svc-8zj7q
    Aug 27 06:12:33.776: INFO: Got endpoints: latency-svc-s2rz7 [741.011398ms]
    Aug 27 06:12:33.789: INFO: Created: latency-svc-s7prd
    Aug 27 06:12:33.827: INFO: Got endpoints: latency-svc-j2gnp [749.416697ms]
    Aug 27 06:12:33.841: INFO: Created: latency-svc-flbs2
    Aug 27 06:12:33.877: INFO: Got endpoints: latency-svc-h2plf [750.352128ms]
    Aug 27 06:12:33.890: INFO: Created: latency-svc-pbpkj
    Aug 27 06:12:33.926: INFO: Got endpoints: latency-svc-c22b7 [749.682869ms]
    Aug 27 06:12:33.937: INFO: Created: latency-svc-tqrgj
    Aug 27 06:12:33.976: INFO: Got endpoints: latency-svc-fd2th [747.88834ms]
    Aug 27 06:12:33.988: INFO: Created: latency-svc-qqgvl
    Aug 27 06:12:34.032: INFO: Got endpoints: latency-svc-ldwr4 [754.928422ms]
    Aug 27 06:12:34.041: INFO: Created: latency-svc-h2mv8
    Aug 27 06:12:34.076: INFO: Got endpoints: latency-svc-ckx6g [745.533805ms]
    Aug 27 06:12:34.088: INFO: Created: latency-svc-j7lh4
    Aug 27 06:12:34.126: INFO: Got endpoints: latency-svc-b46nd [745.730047ms]
    Aug 27 06:12:34.139: INFO: Created: latency-svc-vfxnj
    Aug 27 06:12:34.177: INFO: Got endpoints: latency-svc-rpmcd [748.345407ms]
    Aug 27 06:12:34.190: INFO: Created: latency-svc-slf4s
    Aug 27 06:12:34.226: INFO: Got endpoints: latency-svc-h5jzv [746.972349ms]
    Aug 27 06:12:34.239: INFO: Created: latency-svc-447wb
    Aug 27 06:12:34.277: INFO: Got endpoints: latency-svc-5wrbn [750.469858ms]
    Aug 27 06:12:34.290: INFO: Created: latency-svc-hwcwf
    Aug 27 06:12:34.326: INFO: Got endpoints: latency-svc-vqfnk [749.386671ms]
    Aug 27 06:12:34.379: INFO: Got endpoints: latency-svc-2md6w [741.241622ms]
    Aug 27 06:12:34.431: INFO: Got endpoints: latency-svc-stktk [753.923269ms]
    Aug 27 06:12:34.478: INFO: Got endpoints: latency-svc-8zj7q [752.052627ms]
    Aug 27 06:12:34.530: INFO: Got endpoints: latency-svc-s7prd [753.95806ms]
    Aug 27 06:12:34.577: INFO: Got endpoints: latency-svc-flbs2 [749.498331ms]
    Aug 27 06:12:34.628: INFO: Got endpoints: latency-svc-pbpkj [751.157679ms]
    Aug 27 06:12:34.676: INFO: Got endpoints: latency-svc-tqrgj [749.838304ms]
    Aug 27 06:12:34.727: INFO: Got endpoints: latency-svc-qqgvl [750.889988ms]
    Aug 27 06:12:34.776: INFO: Got endpoints: latency-svc-h2mv8 [743.882779ms]
    Aug 27 06:12:34.826: INFO: Got endpoints: latency-svc-j7lh4 [749.624856ms]
    Aug 27 06:12:34.877: INFO: Got endpoints: latency-svc-vfxnj [750.517399ms]
    Aug 27 06:12:34.926: INFO: Got endpoints: latency-svc-slf4s [749.239158ms]
    Aug 27 06:12:34.977: INFO: Got endpoints: latency-svc-447wb [750.471948ms]
    Aug 27 06:12:35.028: INFO: Got endpoints: latency-svc-hwcwf [751.161987ms]
    Aug 27 06:12:35.029: INFO: Latencies: [32.030814ms 48.545774ms 77.889954ms 79.364595ms 89.587756ms 100.2485ms 103.520135ms 104.559763ms 106.609814ms 109.042854ms 110.233508ms 114.057967ms 114.147803ms 114.958941ms 134.817271ms 187.868609ms 194.227215ms 194.254962ms 194.631245ms 196.353885ms 197.822162ms 197.833127ms 204.082489ms 204.668051ms 204.866176ms 205.040544ms 214.451874ms 216.570267ms 216.576999ms 219.382797ms 223.442826ms 223.582116ms 237.875761ms 253.144399ms 254.427267ms 256.285447ms 265.209947ms 265.45976ms 266.350816ms 266.398763ms 278.853191ms 280.826151ms 281.881832ms 282.8005ms 330.253069ms 382.037705ms 432.126132ms 479.653822ms 503.774873ms 548.935969ms 605.604838ms 654.237469ms 661.151941ms 703.050035ms 712.567388ms 736.662476ms 736.782147ms 738.068011ms 739.929306ms 741.011398ms 741.027942ms 741.241622ms 742.467424ms 742.749046ms 743.041807ms 743.110209ms 743.174363ms 743.260344ms 743.31256ms 743.882779ms 744.095847ms 744.110207ms 744.310001ms 744.426993ms 744.589144ms 744.939795ms 745.12242ms 745.367754ms 745.533805ms 745.579647ms 745.61347ms 745.730047ms 746.420419ms 746.648833ms 746.654463ms 746.935646ms 746.945471ms 746.972349ms 747.043185ms 747.147028ms 747.205072ms 747.441453ms 747.744198ms 747.84947ms 747.88834ms 748.051578ms 748.087302ms 748.168366ms 748.31388ms 748.318815ms 748.345407ms 748.37926ms 748.38542ms 748.41454ms 748.440563ms 748.503454ms 748.73912ms 748.921567ms 749.003943ms 749.045238ms 749.095531ms 749.185101ms 749.21303ms 749.216521ms 749.239158ms 749.272704ms 749.346042ms 749.386671ms 749.416697ms 749.438883ms 749.448681ms 749.467754ms 749.498331ms 749.612843ms 749.624856ms 749.647477ms 749.682869ms 749.685713ms 749.755752ms 749.801102ms 749.838304ms 749.873959ms 750.021709ms 750.040607ms 750.268306ms 750.26913ms 750.302483ms 750.352128ms 750.46915ms 750.469858ms 750.471948ms 750.478681ms 750.485298ms 750.517399ms 750.607099ms 750.614648ms 750.74664ms 750.828282ms 750.889966ms 750.889988ms 751.034235ms 751.15503ms 751.157679ms 751.161987ms 751.246066ms 751.311207ms 751.371764ms 751.496256ms 751.59631ms 751.961445ms 751.984399ms 752.01271ms 752.052627ms 752.195209ms 752.224798ms 752.257065ms 752.296756ms 752.455873ms 752.588039ms 752.589544ms 752.6225ms 752.881467ms 753.134513ms 753.164134ms 753.215111ms 753.682941ms 753.923269ms 753.95806ms 754.697065ms 754.698934ms 754.759468ms 754.823666ms 754.928422ms 755.049675ms 755.382908ms 755.497822ms 755.55612ms 755.659776ms 755.938064ms 755.988686ms 756.125069ms 756.730695ms 756.913545ms 757.218504ms 757.264056ms 758.125683ms 758.155351ms 758.406521ms 760.421038ms 761.790032ms]
    Aug 27 06:12:35.030: INFO: 50 %ile: 748.345407ms
    Aug 27 06:12:35.030: INFO: 90 %ile: 754.759468ms
    Aug 27 06:12:35.030: INFO: 99 %ile: 760.421038ms
    Aug 27 06:12:35.030: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Aug 27 06:12:35.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-5479" for this suite. 08/27/22 06:12:35.044
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:35.062
Aug 27 06:12:35.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename job 08/27/22 06:12:35.063
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:35.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:35.089
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 08/27/22 06:12:35.094
STEP: Ensuring job reaches completions 08/27/22 06:12:35.098
STEP: Ensuring pods with index for job exist 08/27/22 06:12:43.103
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 27 06:12:43.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3350" for this suite. 08/27/22 06:12:43.124
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":128,"skipped":2487,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.073 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:35.062
    Aug 27 06:12:35.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename job 08/27/22 06:12:35.063
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:35.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:35.089
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 08/27/22 06:12:35.094
    STEP: Ensuring job reaches completions 08/27/22 06:12:35.098
    STEP: Ensuring pods with index for job exist 08/27/22 06:12:43.103
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 27 06:12:43.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3350" for this suite. 08/27/22 06:12:43.124
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:43.144
Aug 27 06:12:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:12:43.146
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:43.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:43.186
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-16d64397-d6d4-4fe5-8e81-44066f70dedb 08/27/22 06:12:43.191
STEP: Creating a pod to test consume secrets 08/27/22 06:12:43.2
Aug 27 06:12:43.216: INFO: Waiting up to 5m0s for pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928" in namespace "secrets-8132" to be "Succeeded or Failed"
Aug 27 06:12:43.227: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928": Phase="Pending", Reason="", readiness=false. Elapsed: 10.720614ms
Aug 27 06:12:45.240: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023525398s
Aug 27 06:12:47.231: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014893822s
STEP: Saw pod success 08/27/22 06:12:47.231
Aug 27 06:12:47.231: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928" satisfied condition "Succeeded or Failed"
Aug 27 06:12:47.234: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928 container secret-env-test: <nil>
STEP: delete the pod 08/27/22 06:12:47.24
Aug 27 06:12:47.250: INFO: Waiting for pod pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928 to disappear
Aug 27 06:12:47.253: INFO: Pod pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:12:47.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8132" for this suite. 08/27/22 06:12:47.256
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":129,"skipped":2511,"failed":0}
------------------------------
â€¢ [4.119 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:43.144
    Aug 27 06:12:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:12:43.146
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:43.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:43.186
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-16d64397-d6d4-4fe5-8e81-44066f70dedb 08/27/22 06:12:43.191
    STEP: Creating a pod to test consume secrets 08/27/22 06:12:43.2
    Aug 27 06:12:43.216: INFO: Waiting up to 5m0s for pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928" in namespace "secrets-8132" to be "Succeeded or Failed"
    Aug 27 06:12:43.227: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928": Phase="Pending", Reason="", readiness=false. Elapsed: 10.720614ms
    Aug 27 06:12:45.240: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023525398s
    Aug 27 06:12:47.231: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014893822s
    STEP: Saw pod success 08/27/22 06:12:47.231
    Aug 27 06:12:47.231: INFO: Pod "pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928" satisfied condition "Succeeded or Failed"
    Aug 27 06:12:47.234: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928 container secret-env-test: <nil>
    STEP: delete the pod 08/27/22 06:12:47.24
    Aug 27 06:12:47.250: INFO: Waiting for pod pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928 to disappear
    Aug 27 06:12:47.253: INFO: Pod pod-secrets-c34fc539-79da-431c-9987-a71caa8f1928 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:12:47.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8132" for this suite. 08/27/22 06:12:47.256
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:47.266
Aug 27 06:12:47.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:12:47.267
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:47.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:47.301
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-0d2cb7ac-8125-4ce2-95c2-c8a8d88ed1cf 08/27/22 06:12:47.308
STEP: Creating secret with name s-test-opt-upd-619ae8f0-af2b-46c3-9421-f21167df22bc 08/27/22 06:12:47.313
STEP: Creating the pod 08/27/22 06:12:47.318
Aug 27 06:12:47.326: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b" in namespace "projected-4489" to be "running and ready"
Aug 27 06:12:47.333: INFO: Pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.094348ms
Aug 27 06:12:47.333: INFO: The phase of Pod pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:12:49.338: INFO: Pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011649519s
Aug 27 06:12:49.338: INFO: The phase of Pod pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b is Running (Ready = true)
Aug 27 06:12:49.338: INFO: Pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-0d2cb7ac-8125-4ce2-95c2-c8a8d88ed1cf 08/27/22 06:12:49.358
STEP: Updating secret s-test-opt-upd-619ae8f0-af2b-46c3-9421-f21167df22bc 08/27/22 06:12:49.364
STEP: Creating secret with name s-test-opt-create-7ed3c469-a5ac-4ed4-8cc0-bfb27cff65bf 08/27/22 06:12:49.368
STEP: waiting to observe update in volume 08/27/22 06:12:49.373
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 06:12:51.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4489" for this suite. 08/27/22 06:12:51.406
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":130,"skipped":2535,"failed":0}
------------------------------
â€¢ [4.151 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:47.266
    Aug 27 06:12:47.266: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:12:47.267
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:47.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:47.301
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-0d2cb7ac-8125-4ce2-95c2-c8a8d88ed1cf 08/27/22 06:12:47.308
    STEP: Creating secret with name s-test-opt-upd-619ae8f0-af2b-46c3-9421-f21167df22bc 08/27/22 06:12:47.313
    STEP: Creating the pod 08/27/22 06:12:47.318
    Aug 27 06:12:47.326: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b" in namespace "projected-4489" to be "running and ready"
    Aug 27 06:12:47.333: INFO: Pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.094348ms
    Aug 27 06:12:47.333: INFO: The phase of Pod pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:12:49.338: INFO: Pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011649519s
    Aug 27 06:12:49.338: INFO: The phase of Pod pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b is Running (Ready = true)
    Aug 27 06:12:49.338: INFO: Pod "pod-projected-secrets-4efc5d0f-a096-4b0c-ab2b-a92021e3561b" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-0d2cb7ac-8125-4ce2-95c2-c8a8d88ed1cf 08/27/22 06:12:49.358
    STEP: Updating secret s-test-opt-upd-619ae8f0-af2b-46c3-9421-f21167df22bc 08/27/22 06:12:49.364
    STEP: Creating secret with name s-test-opt-create-7ed3c469-a5ac-4ed4-8cc0-bfb27cff65bf 08/27/22 06:12:49.368
    STEP: waiting to observe update in volume 08/27/22 06:12:49.373
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 06:12:51.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4489" for this suite. 08/27/22 06:12:51.406
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:51.418
Aug 27 06:12:51.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:12:51.419
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:51.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:51.458
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Aug 27 06:12:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: creating the pod 08/27/22 06:12:51.467
STEP: submitting the pod to kubernetes 08/27/22 06:12:51.467
Aug 27 06:12:51.478: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1" in namespace "pods-7202" to be "running and ready"
Aug 27 06:12:51.485: INFO: Pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.866798ms
Aug 27 06:12:51.485: INFO: The phase of Pod pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:12:53.489: INFO: Pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011608215s
Aug 27 06:12:53.489: INFO: The phase of Pod pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1 is Running (Ready = true)
Aug 27 06:12:53.489: INFO: Pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:12:53.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7202" for this suite. 08/27/22 06:12:53.562
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":131,"skipped":2543,"failed":0}
------------------------------
â€¢ [2.151 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:51.418
    Aug 27 06:12:51.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:12:51.419
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:51.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:51.458
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Aug 27 06:12:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: creating the pod 08/27/22 06:12:51.467
    STEP: submitting the pod to kubernetes 08/27/22 06:12:51.467
    Aug 27 06:12:51.478: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1" in namespace "pods-7202" to be "running and ready"
    Aug 27 06:12:51.485: INFO: Pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.866798ms
    Aug 27 06:12:51.485: INFO: The phase of Pod pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:12:53.489: INFO: Pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011608215s
    Aug 27 06:12:53.489: INFO: The phase of Pod pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1 is Running (Ready = true)
    Aug 27 06:12:53.489: INFO: Pod "pod-exec-websocket-18d05223-599f-4db6-be08-615e5809bab1" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:12:53.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7202" for this suite. 08/27/22 06:12:53.562
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:12:53.57
Aug 27 06:12:53.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 06:12:53.571
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:53.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:53.591
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Aug 27 06:12:53.602: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 27 06:12:58.611: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/27/22 06:12:58.611
Aug 27 06:12:58.611: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 27 06:13:00.615: INFO: Creating deployment "test-rollover-deployment"
Aug 27 06:13:00.622: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 27 06:13:02.629: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 27 06:13:02.637: INFO: Ensure that both replica sets have 1 created replica
Aug 27 06:13:02.649: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 27 06:13:02.664: INFO: Updating deployment test-rollover-deployment
Aug 27 06:13:02.664: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 27 06:13:04.674: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 27 06:13:04.681: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 27 06:13:04.690: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 06:13:04.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:13:06.698: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 06:13:06.698: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:13:08.699: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 06:13:08.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:13:10.700: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 06:13:10.700: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:13:12.700: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 06:13:12.700: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:13:14.698: INFO: all replica sets need to contain the pod-template-hash label
Aug 27 06:13:14.698: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:13:16.699: INFO: 
Aug 27 06:13:16.699: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 06:13:16.711: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7431  ca763bb8-3b2c-4587-9a94-d54698e41a2f 16015 2 2022-08-27 06:13:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-27 06:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004675c28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-27 06:13:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-08-27 06:13:14 +0000 UTC,LastTransitionTime:2022-08-27 06:13:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 06:13:16.715: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7431  f84bc795-bc3f-4b04-b0d1-aff26b6c5cae 16005 2 2022-08-27 06:13:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ca763bb8-3b2c-4587-9a94-d54698e41a2f 0xc00488a227 0xc00488a228}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca763bb8-3b2c-4587-9a94-d54698e41a2f\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00488a2d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:13:16.715: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 27 06:13:16.715: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7431  c1c01038-0859-42cf-8be7-ebe3bb664a5e 16014 2 2022-08-27 06:12:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ca763bb8-3b2c-4587-9a94-d54698e41a2f 0xc004675fc7 0xc004675fc8}] [] [{e2e.test Update apps/v1 2022-08-27 06:12:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca763bb8-3b2c-4587-9a94-d54698e41a2f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00488a098 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:13:16.715: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7431  c2bbd7c1-a066-4abe-b056-b5560278c4be 15966 2 2022-08-27 06:13:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ca763bb8-3b2c-4587-9a94-d54698e41a2f 0xc00488a107 0xc00488a108}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca763bb8-3b2c-4587-9a94-d54698e41a2f\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00488a1b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:13:16.721: INFO: Pod "test-rollover-deployment-6d45fd857b-49fkh" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-49fkh test-rollover-deployment-6d45fd857b- deployment-7431  bab9f1e3-b8bd-47b9-b853-0f17d1a9cc6f 15988 0 2022-08-27 06:13:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:984db739a23637248f7014a359985c2f5d9ec25e6a2a88ead8a77ac3b9fd2689 cni.projectcalico.org/podIP:10.2.35.173/32 cni.projectcalico.org/podIPs:10.2.35.173/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b f84bc795-bc3f-4b04-b0d1-aff26b6c5cae 0xc00488a857 0xc00488a858}] [] [{Go-http-client Update v1 2022-08-27 06:13:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 06:13:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f84bc795-bc3f-4b04-b0d1-aff26b6c5cae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 06:13:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.173\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v6rgj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v6rgj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.173,StartTime:2022-08-27 06:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:13:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c9ff8a2f837af6ed9a19791325111d361df4c3d588a367c242f074d9b4218956,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.173,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 06:13:16.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7431" for this suite. 08/27/22 06:13:16.726
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":132,"skipped":2552,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.161 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:12:53.57
    Aug 27 06:12:53.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 06:12:53.571
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:12:53.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:12:53.591
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Aug 27 06:12:53.602: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Aug 27 06:12:58.611: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/27/22 06:12:58.611
    Aug 27 06:12:58.611: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Aug 27 06:13:00.615: INFO: Creating deployment "test-rollover-deployment"
    Aug 27 06:13:00.622: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Aug 27 06:13:02.629: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Aug 27 06:13:02.637: INFO: Ensure that both replica sets have 1 created replica
    Aug 27 06:13:02.649: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Aug 27 06:13:02.664: INFO: Updating deployment test-rollover-deployment
    Aug 27 06:13:02.664: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Aug 27 06:13:04.674: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Aug 27 06:13:04.681: INFO: Make sure deployment "test-rollover-deployment" is complete
    Aug 27 06:13:04.690: INFO: all replica sets need to contain the pod-template-hash label
    Aug 27 06:13:04.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:13:06.698: INFO: all replica sets need to contain the pod-template-hash label
    Aug 27 06:13:06.698: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:13:08.699: INFO: all replica sets need to contain the pod-template-hash label
    Aug 27 06:13:08.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:13:10.700: INFO: all replica sets need to contain the pod-template-hash label
    Aug 27 06:13:10.700: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:13:12.700: INFO: all replica sets need to contain the pod-template-hash label
    Aug 27 06:13:12.700: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:13:14.698: INFO: all replica sets need to contain the pod-template-hash label
    Aug 27 06:13:14.698: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 13, 4, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 13, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:13:16.699: INFO: 
    Aug 27 06:13:16.699: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 06:13:16.711: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7431  ca763bb8-3b2c-4587-9a94-d54698e41a2f 16015 2 2022-08-27 06:13:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-27 06:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004675c28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-27 06:13:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-08-27 06:13:14 +0000 UTC,LastTransitionTime:2022-08-27 06:13:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 27 06:13:16.715: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7431  f84bc795-bc3f-4b04-b0d1-aff26b6c5cae 16005 2 2022-08-27 06:13:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ca763bb8-3b2c-4587-9a94-d54698e41a2f 0xc00488a227 0xc00488a228}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca763bb8-3b2c-4587-9a94-d54698e41a2f\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00488a2d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:13:16.715: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Aug 27 06:13:16.715: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7431  c1c01038-0859-42cf-8be7-ebe3bb664a5e 16014 2 2022-08-27 06:12:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ca763bb8-3b2c-4587-9a94-d54698e41a2f 0xc004675fc7 0xc004675fc8}] [] [{e2e.test Update apps/v1 2022-08-27 06:12:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca763bb8-3b2c-4587-9a94-d54698e41a2f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:14 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00488a098 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:13:16.715: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7431  c2bbd7c1-a066-4abe-b056-b5560278c4be 15966 2 2022-08-27 06:13:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ca763bb8-3b2c-4587-9a94-d54698e41a2f 0xc00488a107 0xc00488a108}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:13:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca763bb8-3b2c-4587-9a94-d54698e41a2f\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:13:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00488a1b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:13:16.721: INFO: Pod "test-rollover-deployment-6d45fd857b-49fkh" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-49fkh test-rollover-deployment-6d45fd857b- deployment-7431  bab9f1e3-b8bd-47b9-b853-0f17d1a9cc6f 15988 0 2022-08-27 06:13:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:984db739a23637248f7014a359985c2f5d9ec25e6a2a88ead8a77ac3b9fd2689 cni.projectcalico.org/podIP:10.2.35.173/32 cni.projectcalico.org/podIPs:10.2.35.173/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b f84bc795-bc3f-4b04-b0d1-aff26b6c5cae 0xc00488a857 0xc00488a858}] [] [{Go-http-client Update v1 2022-08-27 06:13:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 06:13:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f84bc795-bc3f-4b04-b0d1-aff26b6c5cae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 06:13:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.173\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v6rgj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v6rgj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:13:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.173,StartTime:2022-08-27 06:13:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:13:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://c9ff8a2f837af6ed9a19791325111d361df4c3d588a367c242f074d9b4218956,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.173,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 06:13:16.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7431" for this suite. 08/27/22 06:13:16.726
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:13:16.735
Aug 27 06:13:16.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:13:16.738
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:16.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:16.764
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-931cefab-d2f3-4d9c-80a7-fe599250d58d 08/27/22 06:13:16.768
STEP: Creating a pod to test consume configMaps 08/27/22 06:13:16.772
Aug 27 06:13:16.779: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96" in namespace "projected-1359" to be "Succeeded or Failed"
Aug 27 06:13:16.785: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96": Phase="Pending", Reason="", readiness=false. Elapsed: 5.874137ms
Aug 27 06:13:18.789: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010019567s
Aug 27 06:13:20.790: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011007498s
STEP: Saw pod success 08/27/22 06:13:20.79
Aug 27 06:13:20.790: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96" satisfied condition "Succeeded or Failed"
Aug 27 06:13:20.793: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:13:20.799
Aug 27 06:13:20.807: INFO: Waiting for pod pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96 to disappear
Aug 27 06:13:20.811: INFO: Pod pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 06:13:20.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1359" for this suite. 08/27/22 06:13:20.814
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":133,"skipped":2585,"failed":0}
------------------------------
â€¢ [4.083 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:13:16.735
    Aug 27 06:13:16.735: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:13:16.738
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:16.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:16.764
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-931cefab-d2f3-4d9c-80a7-fe599250d58d 08/27/22 06:13:16.768
    STEP: Creating a pod to test consume configMaps 08/27/22 06:13:16.772
    Aug 27 06:13:16.779: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96" in namespace "projected-1359" to be "Succeeded or Failed"
    Aug 27 06:13:16.785: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96": Phase="Pending", Reason="", readiness=false. Elapsed: 5.874137ms
    Aug 27 06:13:18.789: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010019567s
    Aug 27 06:13:20.790: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011007498s
    STEP: Saw pod success 08/27/22 06:13:20.79
    Aug 27 06:13:20.790: INFO: Pod "pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96" satisfied condition "Succeeded or Failed"
    Aug 27 06:13:20.793: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:13:20.799
    Aug 27 06:13:20.807: INFO: Waiting for pod pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96 to disappear
    Aug 27 06:13:20.811: INFO: Pod pod-projected-configmaps-77eba679-2290-4a47-8344-912afd567a96 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 06:13:20.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1359" for this suite. 08/27/22 06:13:20.814
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:13:20.819
Aug 27 06:13:20.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:13:20.82
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:20.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:20.837
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Aug 27 06:13:20.857: INFO: created pod pod-service-account-defaultsa
Aug 27 06:13:20.858: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 27 06:13:20.867: INFO: created pod pod-service-account-mountsa
Aug 27 06:13:20.867: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 27 06:13:20.878: INFO: created pod pod-service-account-nomountsa
Aug 27 06:13:20.878: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 27 06:13:20.894: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 27 06:13:20.895: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 27 06:13:20.909: INFO: created pod pod-service-account-mountsa-mountspec
Aug 27 06:13:20.909: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 27 06:13:20.928: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 27 06:13:20.928: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 27 06:13:20.938: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 27 06:13:20.938: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 27 06:13:20.953: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 27 06:13:20.953: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 27 06:13:20.965: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 27 06:13:20.965: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 27 06:13:20.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2099" for this suite. 08/27/22 06:13:20.996
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":134,"skipped":2589,"failed":0}
------------------------------
â€¢ [0.191 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:13:20.819
    Aug 27 06:13:20.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:13:20.82
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:20.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:20.837
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Aug 27 06:13:20.857: INFO: created pod pod-service-account-defaultsa
    Aug 27 06:13:20.858: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Aug 27 06:13:20.867: INFO: created pod pod-service-account-mountsa
    Aug 27 06:13:20.867: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Aug 27 06:13:20.878: INFO: created pod pod-service-account-nomountsa
    Aug 27 06:13:20.878: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Aug 27 06:13:20.894: INFO: created pod pod-service-account-defaultsa-mountspec
    Aug 27 06:13:20.895: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Aug 27 06:13:20.909: INFO: created pod pod-service-account-mountsa-mountspec
    Aug 27 06:13:20.909: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Aug 27 06:13:20.928: INFO: created pod pod-service-account-nomountsa-mountspec
    Aug 27 06:13:20.928: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Aug 27 06:13:20.938: INFO: created pod pod-service-account-defaultsa-nomountspec
    Aug 27 06:13:20.938: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Aug 27 06:13:20.953: INFO: created pod pod-service-account-mountsa-nomountspec
    Aug 27 06:13:20.953: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Aug 27 06:13:20.965: INFO: created pod pod-service-account-nomountsa-nomountspec
    Aug 27 06:13:20.965: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 27 06:13:20.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2099" for this suite. 08/27/22 06:13:20.996
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:13:21.013
Aug 27 06:13:21.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:13:21.014
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:21.059
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:21.063
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 08/27/22 06:13:21.067
STEP: watching for the ServiceAccount to be added 08/27/22 06:13:21.077
STEP: patching the ServiceAccount 08/27/22 06:13:21.079
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 08/27/22 06:13:21.083
STEP: deleting the ServiceAccount 08/27/22 06:13:21.086
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 27 06:13:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6521" for this suite. 08/27/22 06:13:21.102
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":135,"skipped":2609,"failed":0}
------------------------------
â€¢ [0.100 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:13:21.013
    Aug 27 06:13:21.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:13:21.014
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:21.059
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:21.063
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 08/27/22 06:13:21.067
    STEP: watching for the ServiceAccount to be added 08/27/22 06:13:21.077
    STEP: patching the ServiceAccount 08/27/22 06:13:21.079
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 08/27/22 06:13:21.083
    STEP: deleting the ServiceAccount 08/27/22 06:13:21.086
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 27 06:13:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6521" for this suite. 08/27/22 06:13:21.102
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:13:21.115
Aug 27 06:13:21.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:13:21.118
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:21.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:21.161
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 08/27/22 06:13:21.167
Aug 27 06:13:21.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: mark a version not serverd 08/27/22 06:13:28.809
STEP: check the unserved version gets removed 08/27/22 06:13:28.847
STEP: check the other version is not changed 08/27/22 06:13:31.558
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:13:39.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2604" for this suite. 08/27/22 06:13:39.984
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":136,"skipped":2647,"failed":0}
------------------------------
â€¢ [SLOW TEST] [18.874 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:13:21.115
    Aug 27 06:13:21.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:13:21.118
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:21.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:21.161
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 08/27/22 06:13:21.167
    Aug 27 06:13:21.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: mark a version not serverd 08/27/22 06:13:28.809
    STEP: check the unserved version gets removed 08/27/22 06:13:28.847
    STEP: check the other version is not changed 08/27/22 06:13:31.558
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:13:39.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2604" for this suite. 08/27/22 06:13:39.984
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:13:39.994
Aug 27 06:13:39.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:13:39.995
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:40.03
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:40.035
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 08/27/22 06:13:40.051
STEP: Counting existing ResourceQuota 08/27/22 06:13:45.059
STEP: Creating a ResourceQuota 08/27/22 06:13:50.063
STEP: Ensuring resource quota status is calculated 08/27/22 06:13:50.067
STEP: Creating a Secret 08/27/22 06:13:52.072
STEP: Ensuring resource quota status captures secret creation 08/27/22 06:13:52.085
STEP: Deleting a secret 08/27/22 06:13:54.092
STEP: Ensuring resource quota status released usage 08/27/22 06:13:54.098
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:13:56.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1168" for this suite. 08/27/22 06:13:56.105
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":137,"skipped":2710,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.119 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:13:39.994
    Aug 27 06:13:39.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:13:39.995
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:40.03
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:40.035
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 08/27/22 06:13:40.051
    STEP: Counting existing ResourceQuota 08/27/22 06:13:45.059
    STEP: Creating a ResourceQuota 08/27/22 06:13:50.063
    STEP: Ensuring resource quota status is calculated 08/27/22 06:13:50.067
    STEP: Creating a Secret 08/27/22 06:13:52.072
    STEP: Ensuring resource quota status captures secret creation 08/27/22 06:13:52.085
    STEP: Deleting a secret 08/27/22 06:13:54.092
    STEP: Ensuring resource quota status released usage 08/27/22 06:13:54.098
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:13:56.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1168" for this suite. 08/27/22 06:13:56.105
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:13:56.113
Aug 27 06:13:56.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:13:56.114
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:56.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:56.138
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 08/27/22 06:13:56.149
Aug 27 06:13:56.149: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72" in namespace "kubelet-test-5355" to be "completed"
Aug 27 06:13:56.152: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.209708ms
Aug 27 06:13:58.155: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006413346s
Aug 27 06:14:00.156: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007744169s
Aug 27 06:14:00.156: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 27 06:14:00.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5355" for this suite. 08/27/22 06:14:00.187
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":138,"skipped":2714,"failed":0}
------------------------------
â€¢ [4.084 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:13:56.113
    Aug 27 06:13:56.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:13:56.114
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:13:56.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:13:56.138
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 08/27/22 06:13:56.149
    Aug 27 06:13:56.149: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72" in namespace "kubelet-test-5355" to be "completed"
    Aug 27 06:13:56.152: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72": Phase="Pending", Reason="", readiness=false. Elapsed: 3.209708ms
    Aug 27 06:13:58.155: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006413346s
    Aug 27 06:14:00.156: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007744169s
    Aug 27 06:14:00.156: INFO: Pod "agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 27 06:14:00.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5355" for this suite. 08/27/22 06:14:00.187
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:00.201
Aug 27 06:14:00.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:14:00.202
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:00.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:00.257
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 08/27/22 06:14:00.261
Aug 27 06:14:00.262: INFO: Creating e2e-svc-a-978s9
Aug 27 06:14:00.276: INFO: Creating e2e-svc-b-k5pmq
Aug 27 06:14:00.289: INFO: Creating e2e-svc-c-swk65
STEP: deleting service collection 08/27/22 06:14:00.302
Aug 27 06:14:00.333: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:14:00.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9221" for this suite. 08/27/22 06:14:00.338
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":139,"skipped":2721,"failed":0}
------------------------------
â€¢ [0.144 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:00.201
    Aug 27 06:14:00.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:14:00.202
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:00.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:00.257
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 08/27/22 06:14:00.261
    Aug 27 06:14:00.262: INFO: Creating e2e-svc-a-978s9
    Aug 27 06:14:00.276: INFO: Creating e2e-svc-b-k5pmq
    Aug 27 06:14:00.289: INFO: Creating e2e-svc-c-swk65
    STEP: deleting service collection 08/27/22 06:14:00.302
    Aug 27 06:14:00.333: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:14:00.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9221" for this suite. 08/27/22 06:14:00.338
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:00.35
Aug 27 06:14:00.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-pred 08/27/22 06:14:00.352
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:00.372
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:00.378
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 27 06:14:00.383: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 06:14:00.393: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 06:14:00.397: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
Aug 27 06:14:00.406: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.406: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 06:14:00.406: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.406: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 06:14:00.406: INFO: agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72 from kubelet-test-5355 started at 2022-08-27 06:13:56 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.406: INFO: 	Container agnhost-container ready: false, restart count 0
Aug 27 06:14:00.407: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 06:14:00.407: INFO: 	Container e2e ready: true, restart count 0
Aug 27 06:14:00.407: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 06:14:00.407: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 06:14:00.407: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 06:14:00.407: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 06:14:00.407: INFO: pod-service-account-mountsa-mountspec from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.407: INFO: 	Container token-test ready: false, restart count 0
Aug 27 06:14:00.407: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
Aug 27 06:14:00.418: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.418: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 06:14:00.418: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.418: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 06:14:00.418: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.418: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 06:14:00.419: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 06:14:00.419: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 06:14:00.419: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 06:14:00.419: INFO: pod-service-account-defaultsa from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
Aug 27 06:14:00.419: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
Aug 27 06:14:00.419: INFO: pod-service-account-mountsa from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
Aug 27 06:14:00.419: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/27/22 06:14:00.419
Aug 27 06:14:00.434: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8517" to be "running"
Aug 27 06:14:00.443: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 8.563107ms
Aug 27 06:14:02.447: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.012670052s
Aug 27 06:14:02.447: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/27/22 06:14:02.451
STEP: Trying to apply a random label on the found node. 08/27/22 06:14:02.486
STEP: verifying the node has the label kubernetes.io/e2e-6251f196-1336-4ea6-ab9f-e430bf534726 42 08/27/22 06:14:02.513
STEP: Trying to relaunch the pod, now with labels. 08/27/22 06:14:02.544
Aug 27 06:14:02.557: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8517" to be "not pending"
Aug 27 06:14:02.578: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 21.700117ms
Aug 27 06:14:04.586: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.02912501s
Aug 27 06:14:04.586: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-6251f196-1336-4ea6-ab9f-e430bf534726 off the node ip-10-0-31-158 08/27/22 06:14:04.591
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6251f196-1336-4ea6-ab9f-e430bf534726 08/27/22 06:14:04.621
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:14:04.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8517" for this suite. 08/27/22 06:14:04.634
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":140,"skipped":2728,"failed":0}
------------------------------
â€¢ [4.291 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:00.35
    Aug 27 06:14:00.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-pred 08/27/22 06:14:00.352
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:00.372
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:00.378
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 27 06:14:00.383: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 27 06:14:00.393: INFO: Waiting for terminating namespaces to be deleted...
    Aug 27 06:14:00.397: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
    Aug 27 06:14:00.406: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.406: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 06:14:00.406: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.406: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 06:14:00.406: INFO: agnhost-host-aliases3b71f364-834f-45e2-baf1-49a0340e9b72 from kubelet-test-5355 started at 2022-08-27 06:13:56 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.406: INFO: 	Container agnhost-container ready: false, restart count 0
    Aug 27 06:14:00.407: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 06:14:00.407: INFO: 	Container e2e ready: true, restart count 0
    Aug 27 06:14:00.407: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 06:14:00.407: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 06:14:00.407: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 06:14:00.407: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 27 06:14:00.407: INFO: pod-service-account-mountsa-mountspec from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.407: INFO: 	Container token-test ready: false, restart count 0
    Aug 27 06:14:00.407: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
    Aug 27 06:14:00.418: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.418: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 06:14:00.418: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.418: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 06:14:00.418: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.418: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 27 06:14:00.419: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 06:14:00.419: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 06:14:00.419: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 27 06:14:00.419: INFO: pod-service-account-defaultsa from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
    Aug 27 06:14:00.419: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
    Aug 27 06:14:00.419: INFO: pod-service-account-mountsa from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
    Aug 27 06:14:00.419: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-2099 started at 2022-08-27 06:13:20 +0000 UTC (1 container statuses recorded)
    Aug 27 06:14:00.419: INFO: 	Container token-test ready: false, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/27/22 06:14:00.419
    Aug 27 06:14:00.434: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8517" to be "running"
    Aug 27 06:14:00.443: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 8.563107ms
    Aug 27 06:14:02.447: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.012670052s
    Aug 27 06:14:02.447: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/27/22 06:14:02.451
    STEP: Trying to apply a random label on the found node. 08/27/22 06:14:02.486
    STEP: verifying the node has the label kubernetes.io/e2e-6251f196-1336-4ea6-ab9f-e430bf534726 42 08/27/22 06:14:02.513
    STEP: Trying to relaunch the pod, now with labels. 08/27/22 06:14:02.544
    Aug 27 06:14:02.557: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8517" to be "not pending"
    Aug 27 06:14:02.578: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 21.700117ms
    Aug 27 06:14:04.586: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.02912501s
    Aug 27 06:14:04.586: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-6251f196-1336-4ea6-ab9f-e430bf534726 off the node ip-10-0-31-158 08/27/22 06:14:04.591
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-6251f196-1336-4ea6-ab9f-e430bf534726 08/27/22 06:14:04.621
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:14:04.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8517" for this suite. 08/27/22 06:14:04.634
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:04.651
Aug 27 06:14:04.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 06:14:04.652
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:04.682
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:04.698
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Aug 27 06:14:04.712: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 27 06:14:04.735: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 27 06:14:09.740: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/27/22 06:14:09.74
Aug 27 06:14:09.740: INFO: Creating deployment "test-rolling-update-deployment"
Aug 27 06:14:09.747: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 27 06:14:09.758: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 27 06:14:11.765: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 27 06:14:11.768: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 06:14:11.775: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2118  2b8c66af-b93f-4139-93b4-a286c0c80b61 16484 1 2022-08-27 06:14:09 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-08-27 06:14:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004145e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-27 06:14:09 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-08-27 06:14:11 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 06:14:11.777: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-2118  3b004670-804f-40e7-83c2-d6f737963810 16474 1 2022-08-27 06:14:09 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 2b8c66af-b93f-4139-93b4-a286c0c80b61 0xc00416d537 0xc00416d538}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:14:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2b8c66af-b93f-4139-93b4-a286c0c80b61\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00416d608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:14:11.778: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 27 06:14:11.778: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2118  037445f9-3660-4a33-a075-78be4812dab3 16483 2 2022-08-27 06:14:04 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 2b8c66af-b93f-4139-93b4-a286c0c80b61 0xc00416d3c7 0xc00416d3c8}] [] [{e2e.test Update apps/v1 2022-08-27 06:14:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2b8c66af-b93f-4139-93b4-a286c0c80b61\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:11 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00416d4a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:14:11.780: INFO: Pod "test-rolling-update-deployment-78f575d8ff-kzf8j" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-kzf8j test-rolling-update-deployment-78f575d8ff- deployment-2118  7102953b-49ce-4c4a-a78f-dc5e48445c22 16473 0 2022-08-27 06:14:09 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:9519de4c17f4cae4682e14961fb46366b654ddb50dfb1f042a61a8fe8010a0b4 cni.projectcalico.org/podIP:10.2.35.176/32 cni.projectcalico.org/podIPs:10.2.35.176/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 3b004670-804f-40e7-83c2-d6f737963810 0xc0041a2357 0xc0041a2358}] [] [{kube-controller-manager Update v1 2022-08-27 06:14:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3b004670-804f-40e7-83c2-d6f737963810\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7t8rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7t8rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.176,StartTime:2022-08-27 06:14:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:14:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3895e022d524755184243ab87cc7b2ea419c23a75d82c5b0b97de596747efd6a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 06:14:11.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2118" for this suite. 08/27/22 06:14:11.783
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":141,"skipped":2741,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.136 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:04.651
    Aug 27 06:14:04.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 06:14:04.652
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:04.682
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:04.698
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Aug 27 06:14:04.712: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Aug 27 06:14:04.735: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 27 06:14:09.740: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/27/22 06:14:09.74
    Aug 27 06:14:09.740: INFO: Creating deployment "test-rolling-update-deployment"
    Aug 27 06:14:09.747: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Aug 27 06:14:09.758: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Aug 27 06:14:11.765: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Aug 27 06:14:11.768: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 06:14:11.775: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2118  2b8c66af-b93f-4139-93b4-a286c0c80b61 16484 1 2022-08-27 06:14:09 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-08-27 06:14:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004145e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-27 06:14:09 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-08-27 06:14:11 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 27 06:14:11.777: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-2118  3b004670-804f-40e7-83c2-d6f737963810 16474 1 2022-08-27 06:14:09 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 2b8c66af-b93f-4139-93b4-a286c0c80b61 0xc00416d537 0xc00416d538}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:14:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2b8c66af-b93f-4139-93b4-a286c0c80b61\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00416d608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:14:11.778: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Aug 27 06:14:11.778: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2118  037445f9-3660-4a33-a075-78be4812dab3 16483 2 2022-08-27 06:14:04 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 2b8c66af-b93f-4139-93b4-a286c0c80b61 0xc00416d3c7 0xc00416d3c8}] [] [{e2e.test Update apps/v1 2022-08-27 06:14:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2b8c66af-b93f-4139-93b4-a286c0c80b61\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:14:11 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00416d4a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:14:11.780: INFO: Pod "test-rolling-update-deployment-78f575d8ff-kzf8j" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-kzf8j test-rolling-update-deployment-78f575d8ff- deployment-2118  7102953b-49ce-4c4a-a78f-dc5e48445c22 16473 0 2022-08-27 06:14:09 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:9519de4c17f4cae4682e14961fb46366b654ddb50dfb1f042a61a8fe8010a0b4 cni.projectcalico.org/podIP:10.2.35.176/32 cni.projectcalico.org/podIPs:10.2.35.176/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 3b004670-804f-40e7-83c2-d6f737963810 0xc0041a2357 0xc0041a2358}] [] [{kube-controller-manager Update v1 2022-08-27 06:14:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3b004670-804f-40e7-83c2-d6f737963810\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:14:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.176\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7t8rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7t8rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:14:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.176,StartTime:2022-08-27 06:14:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:14:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3895e022d524755184243ab87cc7b2ea419c23a75d82c5b0b97de596747efd6a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 06:14:11.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2118" for this suite. 08/27/22 06:14:11.783
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:11.787
Aug 27 06:14:11.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename security-context 08/27/22 06:14:11.789
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:11.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:11.81
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/27/22 06:14:11.814
Aug 27 06:14:11.819: INFO: Waiting up to 5m0s for pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7" in namespace "security-context-3178" to be "Succeeded or Failed"
Aug 27 06:14:11.822: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549803ms
Aug 27 06:14:13.825: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006036874s
Aug 27 06:14:15.827: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00735484s
STEP: Saw pod success 08/27/22 06:14:15.827
Aug 27 06:14:15.827: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7" satisfied condition "Succeeded or Failed"
Aug 27 06:14:15.830: INFO: Trying to get logs from node ip-10-0-31-158 pod security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7 container test-container: <nil>
STEP: delete the pod 08/27/22 06:14:15.835
Aug 27 06:14:15.844: INFO: Waiting for pod security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7 to disappear
Aug 27 06:14:15.846: INFO: Pod security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 27 06:14:15.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3178" for this suite. 08/27/22 06:14:15.85
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":142,"skipped":2742,"failed":0}
------------------------------
â€¢ [4.067 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:11.787
    Aug 27 06:14:11.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename security-context 08/27/22 06:14:11.789
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:11.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:11.81
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 08/27/22 06:14:11.814
    Aug 27 06:14:11.819: INFO: Waiting up to 5m0s for pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7" in namespace "security-context-3178" to be "Succeeded or Failed"
    Aug 27 06:14:11.822: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.549803ms
    Aug 27 06:14:13.825: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006036874s
    Aug 27 06:14:15.827: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00735484s
    STEP: Saw pod success 08/27/22 06:14:15.827
    Aug 27 06:14:15.827: INFO: Pod "security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7" satisfied condition "Succeeded or Failed"
    Aug 27 06:14:15.830: INFO: Trying to get logs from node ip-10-0-31-158 pod security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7 container test-container: <nil>
    STEP: delete the pod 08/27/22 06:14:15.835
    Aug 27 06:14:15.844: INFO: Waiting for pod security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7 to disappear
    Aug 27 06:14:15.846: INFO: Pod security-context-03d7bfa7-e7c6-41e5-afcf-c1555bf8bfc7 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 27 06:14:15.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-3178" for this suite. 08/27/22 06:14:15.85
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:15.856
Aug 27 06:14:15.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:14:15.857
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:15.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:15.88
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-d7b2982c-1c6d-4c2d-a2a7-614559d67220 08/27/22 06:14:15.884
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:14:15.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2972" for this suite. 08/27/22 06:14:15.891
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":143,"skipped":2743,"failed":0}
------------------------------
â€¢ [0.038 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:15.856
    Aug 27 06:14:15.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:14:15.857
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:15.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:15.88
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-d7b2982c-1c6d-4c2d-a2a7-614559d67220 08/27/22 06:14:15.884
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:14:15.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2972" for this suite. 08/27/22 06:14:15.891
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:15.897
Aug 27 06:14:15.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:14:15.898
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:15.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:15.918
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 08/27/22 06:14:15.922
Aug 27 06:14:15.929: INFO: Waiting up to 5m0s for pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195" in namespace "downward-api-5825" to be "Succeeded or Failed"
Aug 27 06:14:15.939: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195": Phase="Pending", Reason="", readiness=false. Elapsed: 10.733087ms
Aug 27 06:14:17.943: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014055298s
Aug 27 06:14:19.943: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014664328s
STEP: Saw pod success 08/27/22 06:14:19.943
Aug 27 06:14:19.943: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195" satisfied condition "Succeeded or Failed"
Aug 27 06:14:19.946: INFO: Trying to get logs from node ip-10-0-31-158 pod downward-api-06735d50-a7a1-42cd-8026-7e95751fb195 container dapi-container: <nil>
STEP: delete the pod 08/27/22 06:14:19.952
Aug 27 06:14:19.964: INFO: Waiting for pod downward-api-06735d50-a7a1-42cd-8026-7e95751fb195 to disappear
Aug 27 06:14:19.967: INFO: Pod downward-api-06735d50-a7a1-42cd-8026-7e95751fb195 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 27 06:14:19.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5825" for this suite. 08/27/22 06:14:19.971
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":144,"skipped":2750,"failed":0}
------------------------------
â€¢ [4.078 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:15.897
    Aug 27 06:14:15.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:14:15.898
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:15.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:15.918
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 08/27/22 06:14:15.922
    Aug 27 06:14:15.929: INFO: Waiting up to 5m0s for pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195" in namespace "downward-api-5825" to be "Succeeded or Failed"
    Aug 27 06:14:15.939: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195": Phase="Pending", Reason="", readiness=false. Elapsed: 10.733087ms
    Aug 27 06:14:17.943: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014055298s
    Aug 27 06:14:19.943: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014664328s
    STEP: Saw pod success 08/27/22 06:14:19.943
    Aug 27 06:14:19.943: INFO: Pod "downward-api-06735d50-a7a1-42cd-8026-7e95751fb195" satisfied condition "Succeeded or Failed"
    Aug 27 06:14:19.946: INFO: Trying to get logs from node ip-10-0-31-158 pod downward-api-06735d50-a7a1-42cd-8026-7e95751fb195 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 06:14:19.952
    Aug 27 06:14:19.964: INFO: Waiting for pod downward-api-06735d50-a7a1-42cd-8026-7e95751fb195 to disappear
    Aug 27 06:14:19.967: INFO: Pod downward-api-06735d50-a7a1-42cd-8026-7e95751fb195 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 27 06:14:19.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5825" for this suite. 08/27/22 06:14:19.971
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:19.978
Aug 27 06:14:19.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:14:19.979
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:20.007
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:20.011
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 08/27/22 06:14:20.015
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1401;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1401;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +notcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_tcp@PTR;sleep 1; done
 08/27/22 06:14:20.037
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1401;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1401;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +notcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_tcp@PTR;sleep 1; done
 08/27/22 06:14:20.037
STEP: creating a pod to probe DNS 08/27/22 06:14:20.037
STEP: submitting the pod to kubernetes 08/27/22 06:14:20.038
Aug 27 06:14:20.067: INFO: Waiting up to 15m0s for pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869" in namespace "dns-1401" to be "running"
Aug 27 06:14:20.072: INFO: Pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869": Phase="Pending", Reason="", readiness=false. Elapsed: 4.557185ms
Aug 27 06:14:22.076: INFO: Pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869": Phase="Running", Reason="", readiness=true. Elapsed: 2.008537311s
Aug 27 06:14:22.076: INFO: Pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:14:22.076
STEP: looking for the results for each expected name from probers 08/27/22 06:14:22.079
Aug 27 06:14:22.083: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.087: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.090: INFO: Unable to read wheezy_udp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.093: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.097: INFO: Unable to read wheezy_udp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.100: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.103: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.107: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.123: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.126: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.130: INFO: Unable to read jessie_udp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.133: INFO: Unable to read jessie_tcp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.136: INFO: Unable to read jessie_udp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.140: INFO: Unable to read jessie_tcp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.143: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.147: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
Aug 27 06:14:22.160: INFO: Lookups using dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1401 wheezy_tcp@dns-test-service.dns-1401 wheezy_udp@dns-test-service.dns-1401.svc wheezy_tcp@dns-test-service.dns-1401.svc wheezy_udp@_http._tcp.dns-test-service.dns-1401.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1401.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1401 jessie_tcp@dns-test-service.dns-1401 jessie_udp@dns-test-service.dns-1401.svc jessie_tcp@dns-test-service.dns-1401.svc jessie_udp@_http._tcp.dns-test-service.dns-1401.svc jessie_tcp@_http._tcp.dns-test-service.dns-1401.svc]

Aug 27 06:14:27.333: INFO: DNS probes using dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869 succeeded

STEP: deleting the pod 08/27/22 06:14:27.333
STEP: deleting the test service 08/27/22 06:14:27.421
STEP: deleting the test headless service 08/27/22 06:14:27.53
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:14:27.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1401" for this suite. 08/27/22 06:14:27.663
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":145,"skipped":2757,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.712 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:19.978
    Aug 27 06:14:19.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:14:19.979
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:20.007
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:20.011
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 08/27/22 06:14:20.015
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1401;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1401;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +notcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_tcp@PTR;sleep 1; done
     08/27/22 06:14:20.037
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1401;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1401;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1401.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1401.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1401.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1401.svc;check="$$(dig +notcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_udp@PTR;check="$$(dig +tcp +noall +answer +search 5.134.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.134.5_tcp@PTR;sleep 1; done
     08/27/22 06:14:20.037
    STEP: creating a pod to probe DNS 08/27/22 06:14:20.037
    STEP: submitting the pod to kubernetes 08/27/22 06:14:20.038
    Aug 27 06:14:20.067: INFO: Waiting up to 15m0s for pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869" in namespace "dns-1401" to be "running"
    Aug 27 06:14:20.072: INFO: Pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869": Phase="Pending", Reason="", readiness=false. Elapsed: 4.557185ms
    Aug 27 06:14:22.076: INFO: Pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869": Phase="Running", Reason="", readiness=true. Elapsed: 2.008537311s
    Aug 27 06:14:22.076: INFO: Pod "dns-test-5c842737-68a7-4b58-bf9e-51a94a341869" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:14:22.076
    STEP: looking for the results for each expected name from probers 08/27/22 06:14:22.079
    Aug 27 06:14:22.083: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.087: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.090: INFO: Unable to read wheezy_udp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.093: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.097: INFO: Unable to read wheezy_udp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.100: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.103: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.107: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.123: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.126: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.130: INFO: Unable to read jessie_udp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.133: INFO: Unable to read jessie_tcp@dns-test-service.dns-1401 from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.136: INFO: Unable to read jessie_udp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.140: INFO: Unable to read jessie_tcp@dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.143: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.147: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1401.svc from pod dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869: the server could not find the requested resource (get pods dns-test-5c842737-68a7-4b58-bf9e-51a94a341869)
    Aug 27 06:14:22.160: INFO: Lookups using dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1401 wheezy_tcp@dns-test-service.dns-1401 wheezy_udp@dns-test-service.dns-1401.svc wheezy_tcp@dns-test-service.dns-1401.svc wheezy_udp@_http._tcp.dns-test-service.dns-1401.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1401.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1401 jessie_tcp@dns-test-service.dns-1401 jessie_udp@dns-test-service.dns-1401.svc jessie_tcp@dns-test-service.dns-1401.svc jessie_udp@_http._tcp.dns-test-service.dns-1401.svc jessie_tcp@_http._tcp.dns-test-service.dns-1401.svc]

    Aug 27 06:14:27.333: INFO: DNS probes using dns-1401/dns-test-5c842737-68a7-4b58-bf9e-51a94a341869 succeeded

    STEP: deleting the pod 08/27/22 06:14:27.333
    STEP: deleting the test service 08/27/22 06:14:27.421
    STEP: deleting the test headless service 08/27/22 06:14:27.53
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:14:27.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1401" for this suite. 08/27/22 06:14:27.663
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:14:27.704
Aug 27 06:14:27.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 06:14:27.705
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:27.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:27.765
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 08/27/22 06:14:27.775
Aug 27 06:14:27.781: INFO: Waiting up to 2m0s for pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" in namespace "var-expansion-8052" to be "running"
Aug 27 06:14:27.784: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155405ms
Aug 27 06:14:29.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006727716s
Aug 27 06:14:31.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007521508s
Aug 27 06:14:33.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007935252s
Aug 27 06:14:35.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008184466s
Aug 27 06:14:37.804: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022987902s
Aug 27 06:14:39.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008335921s
Aug 27 06:14:41.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007777592s
Aug 27 06:14:43.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.007639017s
Aug 27 06:14:45.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.007328547s
Aug 27 06:14:47.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.00721205s
Aug 27 06:14:49.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.008222504s
Aug 27 06:14:51.790: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.008857106s
Aug 27 06:14:53.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.006517338s
Aug 27 06:14:55.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 28.008624873s
Aug 27 06:14:57.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 30.007534231s
Aug 27 06:14:59.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 32.00779605s
Aug 27 06:15:01.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007343584s
Aug 27 06:15:03.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 36.008118565s
Aug 27 06:15:05.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 38.00862064s
Aug 27 06:15:07.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 40.008588522s
Aug 27 06:15:09.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007225196s
Aug 27 06:15:11.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 44.007083976s
Aug 27 06:15:13.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 46.006633319s
Aug 27 06:15:15.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 48.00759642s
Aug 27 06:15:17.794: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013022343s
Aug 27 06:15:19.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007300184s
Aug 27 06:15:21.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 54.00750887s
Aug 27 06:15:23.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 56.008164358s
Aug 27 06:15:25.790: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 58.008726442s
Aug 27 06:15:27.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.006667604s
Aug 27 06:15:29.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007876077s
Aug 27 06:15:31.794: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.012822078s
Aug 27 06:15:33.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.00826162s
Aug 27 06:15:35.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.007592548s
Aug 27 06:15:37.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.00749581s
Aug 27 06:15:39.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.007560142s
Aug 27 06:15:41.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.007568454s
Aug 27 06:15:43.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.007428015s
Aug 27 06:15:45.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.00644673s
Aug 27 06:15:47.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.007152993s
Aug 27 06:15:49.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.008291067s
Aug 27 06:15:51.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.006771697s
Aug 27 06:15:53.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.006340242s
Aug 27 06:15:55.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.007362871s
Aug 27 06:15:57.795: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.014538511s
Aug 27 06:15:59.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.007810831s
Aug 27 06:16:01.795: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013772658s
Aug 27 06:16:03.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.007456491s
Aug 27 06:16:05.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.007610144s
Aug 27 06:16:07.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.0072403s
Aug 27 06:16:09.790: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.009498719s
Aug 27 06:16:11.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.006347417s
Aug 27 06:16:13.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.007795148s
Aug 27 06:16:15.792: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.011306134s
Aug 27 06:16:17.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.008366619s
Aug 27 06:16:19.791: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.010312539s
Aug 27 06:16:21.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.007756811s
Aug 27 06:16:23.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.006738519s
Aug 27 06:16:25.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.007740851s
Aug 27 06:16:27.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007893983s
Aug 27 06:16:27.792: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.010733504s
STEP: updating the pod 08/27/22 06:16:27.792
Aug 27 06:16:28.305: INFO: Successfully updated pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6"
STEP: waiting for pod running 08/27/22 06:16:28.305
Aug 27 06:16:28.305: INFO: Waiting up to 2m0s for pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" in namespace "var-expansion-8052" to be "running"
Aug 27 06:16:28.311: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.476368ms
Aug 27 06:16:30.316: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010739843s
Aug 27 06:16:30.316: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" satisfied condition "running"
STEP: deleting the pod gracefully 08/27/22 06:16:30.316
Aug 27 06:16:30.316: INFO: Deleting pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" in namespace "var-expansion-8052"
Aug 27 06:16:30.332: INFO: Wait up to 5m0s for pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 06:17:02.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8052" for this suite. 08/27/22 06:17:02.373
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":146,"skipped":2801,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.676 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:14:27.704
    Aug 27 06:14:27.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 06:14:27.705
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:14:27.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:14:27.765
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 08/27/22 06:14:27.775
    Aug 27 06:14:27.781: INFO: Waiting up to 2m0s for pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" in namespace "var-expansion-8052" to be "running"
    Aug 27 06:14:27.784: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155405ms
    Aug 27 06:14:29.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006727716s
    Aug 27 06:14:31.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007521508s
    Aug 27 06:14:33.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007935252s
    Aug 27 06:14:35.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008184466s
    Aug 27 06:14:37.804: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022987902s
    Aug 27 06:14:39.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008335921s
    Aug 27 06:14:41.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007777592s
    Aug 27 06:14:43.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.007639017s
    Aug 27 06:14:45.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.007328547s
    Aug 27 06:14:47.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.00721205s
    Aug 27 06:14:49.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.008222504s
    Aug 27 06:14:51.790: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.008857106s
    Aug 27 06:14:53.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.006517338s
    Aug 27 06:14:55.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 28.008624873s
    Aug 27 06:14:57.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 30.007534231s
    Aug 27 06:14:59.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 32.00779605s
    Aug 27 06:15:01.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007343584s
    Aug 27 06:15:03.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 36.008118565s
    Aug 27 06:15:05.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 38.00862064s
    Aug 27 06:15:07.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 40.008588522s
    Aug 27 06:15:09.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007225196s
    Aug 27 06:15:11.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 44.007083976s
    Aug 27 06:15:13.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 46.006633319s
    Aug 27 06:15:15.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 48.00759642s
    Aug 27 06:15:17.794: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013022343s
    Aug 27 06:15:19.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007300184s
    Aug 27 06:15:21.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 54.00750887s
    Aug 27 06:15:23.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 56.008164358s
    Aug 27 06:15:25.790: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 58.008726442s
    Aug 27 06:15:27.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.006667604s
    Aug 27 06:15:29.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007876077s
    Aug 27 06:15:31.794: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.012822078s
    Aug 27 06:15:33.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.00826162s
    Aug 27 06:15:35.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.007592548s
    Aug 27 06:15:37.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.00749581s
    Aug 27 06:15:39.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.007560142s
    Aug 27 06:15:41.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.007568454s
    Aug 27 06:15:43.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.007428015s
    Aug 27 06:15:45.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.00644673s
    Aug 27 06:15:47.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.007152993s
    Aug 27 06:15:49.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.008291067s
    Aug 27 06:15:51.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.006771697s
    Aug 27 06:15:53.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.006340242s
    Aug 27 06:15:55.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.007362871s
    Aug 27 06:15:57.795: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.014538511s
    Aug 27 06:15:59.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.007810831s
    Aug 27 06:16:01.795: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013772658s
    Aug 27 06:16:03.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.007456491s
    Aug 27 06:16:05.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.007610144s
    Aug 27 06:16:07.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.0072403s
    Aug 27 06:16:09.790: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.009498719s
    Aug 27 06:16:11.787: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.006347417s
    Aug 27 06:16:13.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.007795148s
    Aug 27 06:16:15.792: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.011306134s
    Aug 27 06:16:17.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.008366619s
    Aug 27 06:16:19.791: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.010312539s
    Aug 27 06:16:21.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.007756811s
    Aug 27 06:16:23.788: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.006738519s
    Aug 27 06:16:25.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.007740851s
    Aug 27 06:16:27.789: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.007893983s
    Aug 27 06:16:27.792: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.010733504s
    STEP: updating the pod 08/27/22 06:16:27.792
    Aug 27 06:16:28.305: INFO: Successfully updated pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6"
    STEP: waiting for pod running 08/27/22 06:16:28.305
    Aug 27 06:16:28.305: INFO: Waiting up to 2m0s for pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" in namespace "var-expansion-8052" to be "running"
    Aug 27 06:16:28.311: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.476368ms
    Aug 27 06:16:30.316: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010739843s
    Aug 27 06:16:30.316: INFO: Pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" satisfied condition "running"
    STEP: deleting the pod gracefully 08/27/22 06:16:30.316
    Aug 27 06:16:30.316: INFO: Deleting pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" in namespace "var-expansion-8052"
    Aug 27 06:16:30.332: INFO: Wait up to 5m0s for pod "var-expansion-7a2c92ad-9bd3-4e51-a034-540c7295d1f6" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 06:17:02.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8052" for this suite. 08/27/22 06:17:02.373
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:02.384
Aug 27 06:17:02.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:17:02.388
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:02.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:02.433
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 08/27/22 06:17:02.437
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9270.svc.cluster.local;sleep 1; done
 08/27/22 06:17:02.442
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9270.svc.cluster.local;sleep 1; done
 08/27/22 06:17:02.442
STEP: creating a pod to probe DNS 08/27/22 06:17:02.442
STEP: submitting the pod to kubernetes 08/27/22 06:17:02.442
Aug 27 06:17:02.457: INFO: Waiting up to 15m0s for pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1" in namespace "dns-9270" to be "running"
Aug 27 06:17:02.481: INFO: Pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1": Phase="Pending", Reason="", readiness=false. Elapsed: 23.256475ms
Aug 27 06:17:04.485: INFO: Pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1": Phase="Running", Reason="", readiness=true. Elapsed: 2.027669981s
Aug 27 06:17:04.485: INFO: Pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:17:04.486
STEP: looking for the results for each expected name from probers 08/27/22 06:17:04.492
Aug 27 06:17:04.500: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.505: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.511: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.518: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.525: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.530: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.535: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.549: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
Aug 27 06:17:04.549: INFO: Lookups using dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9270.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9270.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local jessie_udp@dns-test-service-2.dns-9270.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9270.svc.cluster.local]

Aug 27 06:17:09.636: INFO: DNS probes using dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1 succeeded

STEP: deleting the pod 08/27/22 06:17:09.636
STEP: deleting the test headless service 08/27/22 06:17:09.674
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:17:09.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9270" for this suite. 08/27/22 06:17:09.795
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":147,"skipped":2805,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.441 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:02.384
    Aug 27 06:17:02.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:17:02.388
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:02.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:02.433
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 08/27/22 06:17:02.437
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9270.svc.cluster.local;sleep 1; done
     08/27/22 06:17:02.442
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9270.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9270.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9270.svc.cluster.local;sleep 1; done
     08/27/22 06:17:02.442
    STEP: creating a pod to probe DNS 08/27/22 06:17:02.442
    STEP: submitting the pod to kubernetes 08/27/22 06:17:02.442
    Aug 27 06:17:02.457: INFO: Waiting up to 15m0s for pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1" in namespace "dns-9270" to be "running"
    Aug 27 06:17:02.481: INFO: Pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1": Phase="Pending", Reason="", readiness=false. Elapsed: 23.256475ms
    Aug 27 06:17:04.485: INFO: Pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1": Phase="Running", Reason="", readiness=true. Elapsed: 2.027669981s
    Aug 27 06:17:04.485: INFO: Pod "dns-test-c5d6f374-0cbb-429d-8080-67048935ced1" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:17:04.486
    STEP: looking for the results for each expected name from probers 08/27/22 06:17:04.492
    Aug 27 06:17:04.500: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.505: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.511: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.518: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.525: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.530: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.535: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.549: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9270.svc.cluster.local from pod dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1: the server could not find the requested resource (get pods dns-test-c5d6f374-0cbb-429d-8080-67048935ced1)
    Aug 27 06:17:04.549: INFO: Lookups using dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9270.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9270.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9270.svc.cluster.local jessie_udp@dns-test-service-2.dns-9270.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9270.svc.cluster.local]

    Aug 27 06:17:09.636: INFO: DNS probes using dns-9270/dns-test-c5d6f374-0cbb-429d-8080-67048935ced1 succeeded

    STEP: deleting the pod 08/27/22 06:17:09.636
    STEP: deleting the test headless service 08/27/22 06:17:09.674
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:17:09.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9270" for this suite. 08/27/22 06:17:09.795
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:09.826
Aug 27 06:17:09.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:17:09.827
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:09.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:09.895
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Aug 27 06:17:09.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:17:16.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2270" for this suite. 08/27/22 06:17:16.649
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":148,"skipped":2809,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.827 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:09.826
    Aug 27 06:17:09.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:17:09.827
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:09.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:09.895
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Aug 27 06:17:09.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:17:16.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2270" for this suite. 08/27/22 06:17:16.649
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:16.654
Aug 27 06:17:16.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:17:16.655
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:16.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:16.674
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 08/27/22 06:17:16.678
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
 08/27/22 06:17:16.681
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
 08/27/22 06:17:16.681
STEP: creating a pod to probe DNS 08/27/22 06:17:16.681
STEP: submitting the pod to kubernetes 08/27/22 06:17:16.681
Aug 27 06:17:16.689: INFO: Waiting up to 15m0s for pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d" in namespace "dns-1861" to be "running"
Aug 27 06:17:16.692: INFO: Pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.423946ms
Aug 27 06:17:18.695: INFO: Pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d": Phase="Running", Reason="", readiness=true. Elapsed: 2.005812497s
Aug 27 06:17:18.695: INFO: Pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:17:18.695
STEP: looking for the results for each expected name from probers 08/27/22 06:17:18.698
Aug 27 06:17:18.715: INFO: DNS probes using dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d succeeded

STEP: deleting the pod 08/27/22 06:17:18.715
STEP: changing the externalName to bar.example.com 08/27/22 06:17:18.728
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
 08/27/22 06:17:18.735
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
 08/27/22 06:17:18.735
STEP: creating a second pod to probe DNS 08/27/22 06:17:18.735
STEP: submitting the pod to kubernetes 08/27/22 06:17:18.735
Aug 27 06:17:18.741: INFO: Waiting up to 15m0s for pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606" in namespace "dns-1861" to be "running"
Aug 27 06:17:18.744: INFO: Pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606": Phase="Pending", Reason="", readiness=false. Elapsed: 2.673793ms
Aug 27 06:17:20.748: INFO: Pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606": Phase="Running", Reason="", readiness=true. Elapsed: 2.006766957s
Aug 27 06:17:20.748: INFO: Pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:17:20.748
STEP: looking for the results for each expected name from probers 08/27/22 06:17:20.752
Aug 27 06:17:20.757: INFO: File wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local from pod  dns-1861/dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 06:17:20.762: INFO: File jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local from pod  dns-1861/dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 27 06:17:20.762: INFO: Lookups using dns-1861/dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 failed for: [wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local]

Aug 27 06:17:25.775: INFO: DNS probes using dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 succeeded

STEP: deleting the pod 08/27/22 06:17:25.775
STEP: changing the service to type=ClusterIP 08/27/22 06:17:25.788
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
 08/27/22 06:17:25.809
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
 08/27/22 06:17:25.81
STEP: creating a third pod to probe DNS 08/27/22 06:17:25.81
STEP: submitting the pod to kubernetes 08/27/22 06:17:25.818
Aug 27 06:17:25.829: INFO: Waiting up to 15m0s for pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce" in namespace "dns-1861" to be "running"
Aug 27 06:17:25.834: INFO: Pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054343ms
Aug 27 06:17:27.839: INFO: Pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce": Phase="Running", Reason="", readiness=true. Elapsed: 2.009121955s
Aug 27 06:17:27.839: INFO: Pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:17:27.839
STEP: looking for the results for each expected name from probers 08/27/22 06:17:27.842
Aug 27 06:17:27.855: INFO: DNS probes using dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce succeeded

STEP: deleting the pod 08/27/22 06:17:27.855
STEP: deleting the test externalName service 08/27/22 06:17:27.873
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:17:27.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1861" for this suite. 08/27/22 06:17:27.898
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":149,"skipped":2828,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.258 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:16.654
    Aug 27 06:17:16.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:17:16.655
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:16.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:16.674
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 08/27/22 06:17:16.678
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
     08/27/22 06:17:16.681
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
     08/27/22 06:17:16.681
    STEP: creating a pod to probe DNS 08/27/22 06:17:16.681
    STEP: submitting the pod to kubernetes 08/27/22 06:17:16.681
    Aug 27 06:17:16.689: INFO: Waiting up to 15m0s for pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d" in namespace "dns-1861" to be "running"
    Aug 27 06:17:16.692: INFO: Pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.423946ms
    Aug 27 06:17:18.695: INFO: Pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d": Phase="Running", Reason="", readiness=true. Elapsed: 2.005812497s
    Aug 27 06:17:18.695: INFO: Pod "dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:17:18.695
    STEP: looking for the results for each expected name from probers 08/27/22 06:17:18.698
    Aug 27 06:17:18.715: INFO: DNS probes using dns-test-d8f09f9e-1a65-452f-8a7d-be482bdad78d succeeded

    STEP: deleting the pod 08/27/22 06:17:18.715
    STEP: changing the externalName to bar.example.com 08/27/22 06:17:18.728
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
     08/27/22 06:17:18.735
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
     08/27/22 06:17:18.735
    STEP: creating a second pod to probe DNS 08/27/22 06:17:18.735
    STEP: submitting the pod to kubernetes 08/27/22 06:17:18.735
    Aug 27 06:17:18.741: INFO: Waiting up to 15m0s for pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606" in namespace "dns-1861" to be "running"
    Aug 27 06:17:18.744: INFO: Pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606": Phase="Pending", Reason="", readiness=false. Elapsed: 2.673793ms
    Aug 27 06:17:20.748: INFO: Pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606": Phase="Running", Reason="", readiness=true. Elapsed: 2.006766957s
    Aug 27 06:17:20.748: INFO: Pod "dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:17:20.748
    STEP: looking for the results for each expected name from probers 08/27/22 06:17:20.752
    Aug 27 06:17:20.757: INFO: File wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local from pod  dns-1861/dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 27 06:17:20.762: INFO: File jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local from pod  dns-1861/dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Aug 27 06:17:20.762: INFO: Lookups using dns-1861/dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 failed for: [wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local]

    Aug 27 06:17:25.775: INFO: DNS probes using dns-test-1fc5fcfd-4d00-47eb-9d9e-952d3f34e606 succeeded

    STEP: deleting the pod 08/27/22 06:17:25.775
    STEP: changing the service to type=ClusterIP 08/27/22 06:17:25.788
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
     08/27/22 06:17:25.809
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1861.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1861.svc.cluster.local; sleep 1; done
     08/27/22 06:17:25.81
    STEP: creating a third pod to probe DNS 08/27/22 06:17:25.81
    STEP: submitting the pod to kubernetes 08/27/22 06:17:25.818
    Aug 27 06:17:25.829: INFO: Waiting up to 15m0s for pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce" in namespace "dns-1861" to be "running"
    Aug 27 06:17:25.834: INFO: Pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054343ms
    Aug 27 06:17:27.839: INFO: Pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce": Phase="Running", Reason="", readiness=true. Elapsed: 2.009121955s
    Aug 27 06:17:27.839: INFO: Pod "dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:17:27.839
    STEP: looking for the results for each expected name from probers 08/27/22 06:17:27.842
    Aug 27 06:17:27.855: INFO: DNS probes using dns-test-f29e8489-15a8-4c67-b84b-60e9ef63b4ce succeeded

    STEP: deleting the pod 08/27/22 06:17:27.855
    STEP: deleting the test externalName service 08/27/22 06:17:27.873
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:17:27.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1861" for this suite. 08/27/22 06:17:27.898
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:27.913
Aug 27 06:17:27.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:17:27.915
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:27.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:27.95
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Aug 27 06:17:27.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: creating the pod 08/27/22 06:17:27.962
STEP: submitting the pod to kubernetes 08/27/22 06:17:27.963
Aug 27 06:17:28.020: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6" in namespace "pods-2116" to be "running and ready"
Aug 27 06:17:28.035: INFO: Pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.225979ms
Aug 27 06:17:28.035: INFO: The phase of Pod pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:17:30.039: INFO: Pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018989745s
Aug 27 06:17:30.039: INFO: The phase of Pod pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6 is Running (Ready = true)
Aug 27 06:17:30.039: INFO: Pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:17:30.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2116" for this suite. 08/27/22 06:17:30.095
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":150,"skipped":2839,"failed":0}
------------------------------
â€¢ [2.195 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:27.913
    Aug 27 06:17:27.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:17:27.915
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:27.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:27.95
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Aug 27 06:17:27.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: creating the pod 08/27/22 06:17:27.962
    STEP: submitting the pod to kubernetes 08/27/22 06:17:27.963
    Aug 27 06:17:28.020: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6" in namespace "pods-2116" to be "running and ready"
    Aug 27 06:17:28.035: INFO: Pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.225979ms
    Aug 27 06:17:28.035: INFO: The phase of Pod pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:17:30.039: INFO: Pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018989745s
    Aug 27 06:17:30.039: INFO: The phase of Pod pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6 is Running (Ready = true)
    Aug 27 06:17:30.039: INFO: Pod "pod-logs-websocket-0f0a160f-a14a-4812-8ee8-9151185641d6" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:17:30.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2116" for this suite. 08/27/22 06:17:30.095
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:30.11
Aug 27 06:17:30.110: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename disruption 08/27/22 06:17:30.111
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:30.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:30.169
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 08/27/22 06:17:30.178
STEP: Waiting for the pdb to be processed 08/27/22 06:17:30.192
STEP: First trying to evict a pod which shouldn't be evictable 08/27/22 06:17:32.205
STEP: Waiting for all pods to be running 08/27/22 06:17:32.206
Aug 27 06:17:32.208: INFO: pods: 0 < 3
Aug 27 06:17:34.213: INFO: running pods: 1 < 3
STEP: locating a running pod 08/27/22 06:17:36.215
STEP: Updating the pdb to allow a pod to be evicted 08/27/22 06:17:36.226
STEP: Waiting for the pdb to be processed 08/27/22 06:17:36.245
STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/27/22 06:17:36.25
STEP: Waiting for all pods to be running 08/27/22 06:17:36.251
STEP: Waiting for the pdb to observed all healthy pods 08/27/22 06:17:36.254
STEP: Patching the pdb to disallow a pod to be evicted 08/27/22 06:17:36.273
STEP: Waiting for the pdb to be processed 08/27/22 06:17:36.312
STEP: Waiting for all pods to be running 08/27/22 06:17:36.327
Aug 27 06:17:36.339: INFO: running pods: 2 < 3
STEP: locating a running pod 08/27/22 06:17:38.343
STEP: Deleting the pdb to allow a pod to be evicted 08/27/22 06:17:38.357
STEP: Waiting for the pdb to be deleted 08/27/22 06:17:38.37
STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/27/22 06:17:38.376
STEP: Waiting for all pods to be running 08/27/22 06:17:38.376
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 27 06:17:38.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4392" for this suite. 08/27/22 06:17:38.415
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":151,"skipped":2855,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.373 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:30.11
    Aug 27 06:17:30.110: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename disruption 08/27/22 06:17:30.111
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:30.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:30.169
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 08/27/22 06:17:30.178
    STEP: Waiting for the pdb to be processed 08/27/22 06:17:30.192
    STEP: First trying to evict a pod which shouldn't be evictable 08/27/22 06:17:32.205
    STEP: Waiting for all pods to be running 08/27/22 06:17:32.206
    Aug 27 06:17:32.208: INFO: pods: 0 < 3
    Aug 27 06:17:34.213: INFO: running pods: 1 < 3
    STEP: locating a running pod 08/27/22 06:17:36.215
    STEP: Updating the pdb to allow a pod to be evicted 08/27/22 06:17:36.226
    STEP: Waiting for the pdb to be processed 08/27/22 06:17:36.245
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/27/22 06:17:36.25
    STEP: Waiting for all pods to be running 08/27/22 06:17:36.251
    STEP: Waiting for the pdb to observed all healthy pods 08/27/22 06:17:36.254
    STEP: Patching the pdb to disallow a pod to be evicted 08/27/22 06:17:36.273
    STEP: Waiting for the pdb to be processed 08/27/22 06:17:36.312
    STEP: Waiting for all pods to be running 08/27/22 06:17:36.327
    Aug 27 06:17:36.339: INFO: running pods: 2 < 3
    STEP: locating a running pod 08/27/22 06:17:38.343
    STEP: Deleting the pdb to allow a pod to be evicted 08/27/22 06:17:38.357
    STEP: Waiting for the pdb to be deleted 08/27/22 06:17:38.37
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 08/27/22 06:17:38.376
    STEP: Waiting for all pods to be running 08/27/22 06:17:38.376
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 27 06:17:38.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4392" for this suite. 08/27/22 06:17:38.415
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:38.486
Aug 27 06:17:38.486: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:17:38.491
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:38.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:38.548
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Aug 27 06:17:38.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:17:39.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2151" for this suite. 08/27/22 06:17:39.614
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":152,"skipped":2858,"failed":0}
------------------------------
â€¢ [1.132 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:38.486
    Aug 27 06:17:38.486: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:17:38.491
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:38.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:38.548
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Aug 27 06:17:38.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:17:39.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2151" for this suite. 08/27/22 06:17:39.614
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:39.624
Aug 27 06:17:39.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename job 08/27/22 06:17:39.625
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:39.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:39.644
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 08/27/22 06:17:39.648
STEP: Ensuring active pods == parallelism 08/27/22 06:17:39.652
STEP: Orphaning one of the Job's Pods 08/27/22 06:17:43.657
Aug 27 06:17:44.173: INFO: Successfully updated pod "adopt-release-cbxbj"
STEP: Checking that the Job readopts the Pod 08/27/22 06:17:44.173
Aug 27 06:17:44.173: INFO: Waiting up to 15m0s for pod "adopt-release-cbxbj" in namespace "job-8280" to be "adopted"
Aug 27 06:17:44.179: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 5.764219ms
Aug 27 06:17:46.184: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 2.01011742s
Aug 27 06:17:46.184: INFO: Pod "adopt-release-cbxbj" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 08/27/22 06:17:46.184
Aug 27 06:17:46.693: INFO: Successfully updated pod "adopt-release-cbxbj"
STEP: Checking that the Job releases the Pod 08/27/22 06:17:46.694
Aug 27 06:17:46.695: INFO: Waiting up to 15m0s for pod "adopt-release-cbxbj" in namespace "job-8280" to be "released"
Aug 27 06:17:46.699: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 4.466834ms
Aug 27 06:17:48.703: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 2.008175521s
Aug 27 06:17:48.703: INFO: Pod "adopt-release-cbxbj" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 27 06:17:48.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8280" for this suite. 08/27/22 06:17:48.706
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":153,"skipped":2912,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.087 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:39.624
    Aug 27 06:17:39.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename job 08/27/22 06:17:39.625
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:39.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:39.644
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 08/27/22 06:17:39.648
    STEP: Ensuring active pods == parallelism 08/27/22 06:17:39.652
    STEP: Orphaning one of the Job's Pods 08/27/22 06:17:43.657
    Aug 27 06:17:44.173: INFO: Successfully updated pod "adopt-release-cbxbj"
    STEP: Checking that the Job readopts the Pod 08/27/22 06:17:44.173
    Aug 27 06:17:44.173: INFO: Waiting up to 15m0s for pod "adopt-release-cbxbj" in namespace "job-8280" to be "adopted"
    Aug 27 06:17:44.179: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 5.764219ms
    Aug 27 06:17:46.184: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 2.01011742s
    Aug 27 06:17:46.184: INFO: Pod "adopt-release-cbxbj" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 08/27/22 06:17:46.184
    Aug 27 06:17:46.693: INFO: Successfully updated pod "adopt-release-cbxbj"
    STEP: Checking that the Job releases the Pod 08/27/22 06:17:46.694
    Aug 27 06:17:46.695: INFO: Waiting up to 15m0s for pod "adopt-release-cbxbj" in namespace "job-8280" to be "released"
    Aug 27 06:17:46.699: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 4.466834ms
    Aug 27 06:17:48.703: INFO: Pod "adopt-release-cbxbj": Phase="Running", Reason="", readiness=true. Elapsed: 2.008175521s
    Aug 27 06:17:48.703: INFO: Pod "adopt-release-cbxbj" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 27 06:17:48.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8280" for this suite. 08/27/22 06:17:48.706
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:17:48.713
Aug 27 06:17:48.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 06:17:48.718
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:48.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:48.74
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7136 08/27/22 06:17:48.744
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Aug 27 06:17:48.770: INFO: Found 0 stateful pods, waiting for 1
Aug 27 06:17:58.776: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 08/27/22 06:17:58.787
W0827 06:17:58.797859      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 27 06:17:58.805: INFO: Found 1 stateful pods, waiting for 2
Aug 27 06:18:08.811: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 06:18:08.811: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 08/27/22 06:18:08.815
STEP: Delete all of the StatefulSets 08/27/22 06:18:08.817
STEP: Verify that StatefulSets have been deleted 08/27/22 06:18:08.822
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 06:18:08.825: INFO: Deleting all statefulset in ns statefulset-7136
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 06:18:08.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7136" for this suite. 08/27/22 06:18:08.86
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":154,"skipped":2926,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.154 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:17:48.713
    Aug 27 06:17:48.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 06:17:48.718
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:17:48.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:17:48.74
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7136 08/27/22 06:17:48.744
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Aug 27 06:17:48.770: INFO: Found 0 stateful pods, waiting for 1
    Aug 27 06:17:58.776: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 08/27/22 06:17:58.787
    W0827 06:17:58.797859      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 27 06:17:58.805: INFO: Found 1 stateful pods, waiting for 2
    Aug 27 06:18:08.811: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 06:18:08.811: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 08/27/22 06:18:08.815
    STEP: Delete all of the StatefulSets 08/27/22 06:18:08.817
    STEP: Verify that StatefulSets have been deleted 08/27/22 06:18:08.822
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 06:18:08.825: INFO: Deleting all statefulset in ns statefulset-7136
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 06:18:08.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7136" for this suite. 08/27/22 06:18:08.86
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:18:08.872
Aug 27 06:18:08.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:18:08.874
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:18:08.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:18:08.944
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-f07247fe-2761-4ebb-a9e9-e61b1caaf805 08/27/22 06:18:08.951
STEP: Creating a pod to test consume secrets 08/27/22 06:18:08.958
Aug 27 06:18:08.968: INFO: Waiting up to 5m0s for pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9" in namespace "secrets-1107" to be "Succeeded or Failed"
Aug 27 06:18:08.973: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.001764ms
Aug 27 06:18:10.976: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008231908s
Aug 27 06:18:12.977: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009067046s
STEP: Saw pod success 08/27/22 06:18:12.977
Aug 27 06:18:12.977: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9" satisfied condition "Succeeded or Failed"
Aug 27 06:18:12.981: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:18:12.988
Aug 27 06:18:13.000: INFO: Waiting for pod pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9 to disappear
Aug 27 06:18:13.004: INFO: Pod pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:18:13.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1107" for this suite. 08/27/22 06:18:13.008
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":155,"skipped":2934,"failed":0}
------------------------------
â€¢ [4.145 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:18:08.872
    Aug 27 06:18:08.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:18:08.874
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:18:08.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:18:08.944
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-f07247fe-2761-4ebb-a9e9-e61b1caaf805 08/27/22 06:18:08.951
    STEP: Creating a pod to test consume secrets 08/27/22 06:18:08.958
    Aug 27 06:18:08.968: INFO: Waiting up to 5m0s for pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9" in namespace "secrets-1107" to be "Succeeded or Failed"
    Aug 27 06:18:08.973: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.001764ms
    Aug 27 06:18:10.976: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008231908s
    Aug 27 06:18:12.977: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009067046s
    STEP: Saw pod success 08/27/22 06:18:12.977
    Aug 27 06:18:12.977: INFO: Pod "pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9" satisfied condition "Succeeded or Failed"
    Aug 27 06:18:12.981: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:18:12.988
    Aug 27 06:18:13.000: INFO: Waiting for pod pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9 to disappear
    Aug 27 06:18:13.004: INFO: Pod pod-secrets-845d195f-ef2d-4da8-bf1e-1396bf4617e9 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:18:13.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1107" for this suite. 08/27/22 06:18:13.008
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:18:13.019
Aug 27 06:18:13.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename job 08/27/22 06:18:13.02
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:18:13.069
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:18:13.089
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 08/27/22 06:18:13.113
STEP: Ensuring active pods == parallelism 08/27/22 06:18:13.129
STEP: delete a job 08/27/22 06:18:15.133
STEP: deleting Job.batch foo in namespace job-4788, will wait for the garbage collector to delete the pods 08/27/22 06:18:15.133
Aug 27 06:18:15.192: INFO: Deleting Job.batch foo took: 5.927952ms
Aug 27 06:18:15.293: INFO: Terminating Job.batch foo pods took: 101.030603ms
STEP: Ensuring job was deleted 08/27/22 06:18:47.597
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 27 06:18:47.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4788" for this suite. 08/27/22 06:18:47.61
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":156,"skipped":2968,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.596 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:18:13.019
    Aug 27 06:18:13.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename job 08/27/22 06:18:13.02
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:18:13.069
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:18:13.089
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 08/27/22 06:18:13.113
    STEP: Ensuring active pods == parallelism 08/27/22 06:18:13.129
    STEP: delete a job 08/27/22 06:18:15.133
    STEP: deleting Job.batch foo in namespace job-4788, will wait for the garbage collector to delete the pods 08/27/22 06:18:15.133
    Aug 27 06:18:15.192: INFO: Deleting Job.batch foo took: 5.927952ms
    Aug 27 06:18:15.293: INFO: Terminating Job.batch foo pods took: 101.030603ms
    STEP: Ensuring job was deleted 08/27/22 06:18:47.597
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 27 06:18:47.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4788" for this suite. 08/27/22 06:18:47.61
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:18:47.615
Aug 27 06:18:47.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:18:47.617
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:18:47.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:18:47.638
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 08/27/22 06:19:04.665
STEP: Creating a ResourceQuota 08/27/22 06:19:09.668
STEP: Ensuring resource quota status is calculated 08/27/22 06:19:09.672
STEP: Creating a ConfigMap 08/27/22 06:19:11.676
STEP: Ensuring resource quota status captures configMap creation 08/27/22 06:19:11.686
STEP: Deleting a ConfigMap 08/27/22 06:19:13.69
STEP: Ensuring resource quota status released usage 08/27/22 06:19:13.694
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:19:15.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6856" for this suite. 08/27/22 06:19:15.702
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":157,"skipped":2968,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.092 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:18:47.615
    Aug 27 06:18:47.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:18:47.617
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:18:47.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:18:47.638
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 08/27/22 06:19:04.665
    STEP: Creating a ResourceQuota 08/27/22 06:19:09.668
    STEP: Ensuring resource quota status is calculated 08/27/22 06:19:09.672
    STEP: Creating a ConfigMap 08/27/22 06:19:11.676
    STEP: Ensuring resource quota status captures configMap creation 08/27/22 06:19:11.686
    STEP: Deleting a ConfigMap 08/27/22 06:19:13.69
    STEP: Ensuring resource quota status released usage 08/27/22 06:19:13.694
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:19:15.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6856" for this suite. 08/27/22 06:19:15.702
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:19:15.709
Aug 27 06:19:15.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-runtime 08/27/22 06:19:15.71
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:19:15.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:19:15.748
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 08/27/22 06:19:15.753
STEP: wait for the container to reach Succeeded 08/27/22 06:19:15.759
STEP: get the container status 08/27/22 06:19:19.784
STEP: the container should be terminated 08/27/22 06:19:19.787
STEP: the termination message should be set 08/27/22 06:19:19.788
Aug 27 06:19:19.788: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 08/27/22 06:19:19.788
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 27 06:19:19.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5033" for this suite. 08/27/22 06:19:19.806
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":158,"skipped":2976,"failed":0}
------------------------------
â€¢ [4.101 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:19:15.709
    Aug 27 06:19:15.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-runtime 08/27/22 06:19:15.71
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:19:15.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:19:15.748
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 08/27/22 06:19:15.753
    STEP: wait for the container to reach Succeeded 08/27/22 06:19:15.759
    STEP: get the container status 08/27/22 06:19:19.784
    STEP: the container should be terminated 08/27/22 06:19:19.787
    STEP: the termination message should be set 08/27/22 06:19:19.788
    Aug 27 06:19:19.788: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 08/27/22 06:19:19.788
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 27 06:19:19.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5033" for this suite. 08/27/22 06:19:19.806
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:19:19.815
Aug 27 06:19:19.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename init-container 08/27/22 06:19:19.816
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:19:19.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:19:19.847
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 08/27/22 06:19:19.852
Aug 27 06:19:19.852: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 06:19:23.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-521" for this suite. 08/27/22 06:19:23.672
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":159,"skipped":2996,"failed":0}
------------------------------
â€¢ [3.862 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:19:19.815
    Aug 27 06:19:19.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename init-container 08/27/22 06:19:19.816
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:19:19.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:19:19.847
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 08/27/22 06:19:19.852
    Aug 27 06:19:19.852: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 06:19:23.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-521" for this suite. 08/27/22 06:19:23.672
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:19:23.679
Aug 27 06:19:23.679: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-preemption 08/27/22 06:19:23.68
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:19:23.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:19:23.713
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 27 06:19:23.730: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 06:20:23.752: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:23.754
Aug 27 06:20:23.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-preemption-path 08/27/22 06:20:23.755
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:23.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:23.773
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Aug 27 06:20:23.795: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Aug 27 06:20:23.797: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Aug 27 06:20:23.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8894" for this suite. 08/27/22 06:20:23.816
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:20:23.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-708" for this suite. 08/27/22 06:20:23.83
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":160,"skipped":3010,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.177 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:19:23.679
    Aug 27 06:19:23.679: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-preemption 08/27/22 06:19:23.68
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:19:23.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:19:23.713
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 27 06:19:23.730: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 27 06:20:23.752: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:23.754
    Aug 27 06:20:23.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-preemption-path 08/27/22 06:20:23.755
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:23.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:23.773
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Aug 27 06:20:23.795: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Aug 27 06:20:23.797: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Aug 27 06:20:23.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-8894" for this suite. 08/27/22 06:20:23.816
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:20:23.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-708" for this suite. 08/27/22 06:20:23.83
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:23.858
Aug 27 06:20:23.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:20:23.859
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:23.872
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:23.876
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 06:20:23.88
Aug 27 06:20:23.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 27 06:20:23.963: INFO: stderr: ""
Aug 27 06:20:23.963: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 08/27/22 06:20:23.963
STEP: verifying the pod e2e-test-httpd-pod was created 08/27/22 06:20:29.017
Aug 27 06:20:29.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 get pod e2e-test-httpd-pod -o json'
Aug 27 06:20:29.097: INFO: stderr: ""
Aug 27 06:20:29.097: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"c3f5f941e3f2dfa115a46e334ebbf4709079c34f0e4b64e93bce9d31c6b8ef88\",\n            \"cni.projectcalico.org/podIP\": \"10.2.35.190/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.2.35.190/32\"\n        },\n        \"creationTimestamp\": \"2022-08-27T06:20:23Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6365\",\n        \"resourceVersion\": \"18151\",\n        \"uid\": \"ff1f8a67-9516-4d86-a5be-7417120dc20a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tp974\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-47-192\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tp974\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:24Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:24Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ea945d871b9addaa10c3d80699c8181fd19e5a1b3a31ee1f9765659dc78a570c\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-27T06:20:24Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.47.192\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.35.190\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.35.190\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-27T06:20:23Z\"\n    }\n}\n"
STEP: replace the image in the pod 08/27/22 06:20:29.097
Aug 27 06:20:29.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 replace -f -'
Aug 27 06:20:30.577: INFO: stderr: ""
Aug 27 06:20:30.577: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 08/27/22 06:20:30.577
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Aug 27 06:20:30.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 delete pods e2e-test-httpd-pod'
Aug 27 06:20:31.820: INFO: stderr: ""
Aug 27 06:20:31.820: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:20:31.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6365" for this suite. 08/27/22 06:20:31.824
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":161,"skipped":3024,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.971 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:23.858
    Aug 27 06:20:23.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:20:23.859
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:23.872
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:23.876
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 06:20:23.88
    Aug 27 06:20:23.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Aug 27 06:20:23.963: INFO: stderr: ""
    Aug 27 06:20:23.963: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 08/27/22 06:20:23.963
    STEP: verifying the pod e2e-test-httpd-pod was created 08/27/22 06:20:29.017
    Aug 27 06:20:29.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 get pod e2e-test-httpd-pod -o json'
    Aug 27 06:20:29.097: INFO: stderr: ""
    Aug 27 06:20:29.097: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"c3f5f941e3f2dfa115a46e334ebbf4709079c34f0e4b64e93bce9d31c6b8ef88\",\n            \"cni.projectcalico.org/podIP\": \"10.2.35.190/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.2.35.190/32\"\n        },\n        \"creationTimestamp\": \"2022-08-27T06:20:23Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6365\",\n        \"resourceVersion\": \"18151\",\n        \"uid\": \"ff1f8a67-9516-4d86-a5be-7417120dc20a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tp974\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-47-192\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tp974\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:24Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:24Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-27T06:20:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://ea945d871b9addaa10c3d80699c8181fd19e5a1b3a31ee1f9765659dc78a570c\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-27T06:20:24Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.47.192\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.35.190\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.35.190\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-27T06:20:23Z\"\n    }\n}\n"
    STEP: replace the image in the pod 08/27/22 06:20:29.097
    Aug 27 06:20:29.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 replace -f -'
    Aug 27 06:20:30.577: INFO: stderr: ""
    Aug 27 06:20:30.577: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 08/27/22 06:20:30.577
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Aug 27 06:20:30.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6365 delete pods e2e-test-httpd-pod'
    Aug 27 06:20:31.820: INFO: stderr: ""
    Aug 27 06:20:31.820: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:20:31.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6365" for this suite. 08/27/22 06:20:31.824
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:31.83
Aug 27 06:20:31.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:20:31.831
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:31.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:31.854
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-0ff51b7d-9f69-4884-a438-98adbfe3bc12 08/27/22 06:20:31.857
STEP: Creating a pod to test consume secrets 08/27/22 06:20:31.861
Aug 27 06:20:31.867: INFO: Waiting up to 5m0s for pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9" in namespace "secrets-5027" to be "Succeeded or Failed"
Aug 27 06:20:31.875: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.530879ms
Aug 27 06:20:33.879: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011611398s
Aug 27 06:20:35.888: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020141921s
STEP: Saw pod success 08/27/22 06:20:35.888
Aug 27 06:20:35.888: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9" satisfied condition "Succeeded or Failed"
Aug 27 06:20:35.892: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:20:35.908
Aug 27 06:20:35.920: INFO: Waiting for pod pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9 to disappear
Aug 27 06:20:35.925: INFO: Pod pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:20:35.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5027" for this suite. 08/27/22 06:20:35.93
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":162,"skipped":3047,"failed":0}
------------------------------
â€¢ [4.107 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:31.83
    Aug 27 06:20:31.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:20:31.831
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:31.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:31.854
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-0ff51b7d-9f69-4884-a438-98adbfe3bc12 08/27/22 06:20:31.857
    STEP: Creating a pod to test consume secrets 08/27/22 06:20:31.861
    Aug 27 06:20:31.867: INFO: Waiting up to 5m0s for pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9" in namespace "secrets-5027" to be "Succeeded or Failed"
    Aug 27 06:20:31.875: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.530879ms
    Aug 27 06:20:33.879: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011611398s
    Aug 27 06:20:35.888: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020141921s
    STEP: Saw pod success 08/27/22 06:20:35.888
    Aug 27 06:20:35.888: INFO: Pod "pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9" satisfied condition "Succeeded or Failed"
    Aug 27 06:20:35.892: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:20:35.908
    Aug 27 06:20:35.920: INFO: Waiting for pod pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9 to disappear
    Aug 27 06:20:35.925: INFO: Pod pod-secrets-81bb6b6c-cbcb-444b-acfa-fae3ff0988e9 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:20:35.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5027" for this suite. 08/27/22 06:20:35.93
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:35.944
Aug 27 06:20:35.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:20:35.952
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:35.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:35.985
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:20:35.994
Aug 27 06:20:36.012: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7252" to be "running and ready"
Aug 27 06:20:36.016: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063055ms
Aug 27 06:20:36.016: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:20:38.020: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008611511s
Aug 27 06:20:38.021: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 27 06:20:38.021: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 08/27/22 06:20:38.023
Aug 27 06:20:38.028: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-7252" to be "running and ready"
Aug 27 06:20:38.032: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.216921ms
Aug 27 06:20:38.032: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:20:40.036: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007604766s
Aug 27 06:20:40.036: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Aug 27 06:20:40.037: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 08/27/22 06:20:40.042
Aug 27 06:20:40.049: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 06:20:40.053: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 06:20:42.054: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 06:20:42.058: INFO: Pod pod-with-prestop-http-hook still exists
Aug 27 06:20:44.055: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 27 06:20:44.061: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 08/27/22 06:20:44.061
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 27 06:20:44.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7252" for this suite. 08/27/22 06:20:44.089
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":163,"skipped":3067,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.162 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:35.944
    Aug 27 06:20:35.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:20:35.952
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:35.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:35.985
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:20:35.994
    Aug 27 06:20:36.012: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7252" to be "running and ready"
    Aug 27 06:20:36.016: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063055ms
    Aug 27 06:20:36.016: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:20:38.020: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008611511s
    Aug 27 06:20:38.021: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 27 06:20:38.021: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 08/27/22 06:20:38.023
    Aug 27 06:20:38.028: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-7252" to be "running and ready"
    Aug 27 06:20:38.032: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.216921ms
    Aug 27 06:20:38.032: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:20:40.036: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.007604766s
    Aug 27 06:20:40.036: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Aug 27 06:20:40.037: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 08/27/22 06:20:40.042
    Aug 27 06:20:40.049: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 27 06:20:40.053: INFO: Pod pod-with-prestop-http-hook still exists
    Aug 27 06:20:42.054: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 27 06:20:42.058: INFO: Pod pod-with-prestop-http-hook still exists
    Aug 27 06:20:44.055: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Aug 27 06:20:44.061: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 08/27/22 06:20:44.061
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 27 06:20:44.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7252" for this suite. 08/27/22 06:20:44.089
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:44.108
Aug 27 06:20:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename watch 08/27/22 06:20:44.112
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:44.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:44.135
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 08/27/22 06:20:44.139
STEP: creating a new configmap 08/27/22 06:20:44.14
STEP: modifying the configmap once 08/27/22 06:20:44.144
STEP: changing the label value of the configmap 08/27/22 06:20:44.152
STEP: Expecting to observe a delete notification for the watched object 08/27/22 06:20:44.161
Aug 27 06:20:44.162: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18288 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:20:44.162: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18289 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:20:44.162: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18290 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 08/27/22 06:20:44.163
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 08/27/22 06:20:44.169
STEP: changing the label value of the configmap back 08/27/22 06:20:54.171
STEP: modifying the configmap a third time 08/27/22 06:20:54.177
STEP: deleting the configmap 08/27/22 06:20:54.183
STEP: Expecting to observe an add notification for the watched object when the label value was restored 08/27/22 06:20:54.187
Aug 27 06:20:54.187: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18324 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:20:54.187: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18325 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:20:54.187: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18326 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 27 06:20:54.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2212" for this suite. 08/27/22 06:20:54.192
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":164,"skipped":3089,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.090 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:44.108
    Aug 27 06:20:44.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename watch 08/27/22 06:20:44.112
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:44.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:44.135
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 08/27/22 06:20:44.139
    STEP: creating a new configmap 08/27/22 06:20:44.14
    STEP: modifying the configmap once 08/27/22 06:20:44.144
    STEP: changing the label value of the configmap 08/27/22 06:20:44.152
    STEP: Expecting to observe a delete notification for the watched object 08/27/22 06:20:44.161
    Aug 27 06:20:44.162: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18288 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:20:44.162: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18289 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:20:44.162: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18290 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 08/27/22 06:20:44.163
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 08/27/22 06:20:44.169
    STEP: changing the label value of the configmap back 08/27/22 06:20:54.171
    STEP: modifying the configmap a third time 08/27/22 06:20:54.177
    STEP: deleting the configmap 08/27/22 06:20:54.183
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 08/27/22 06:20:54.187
    Aug 27 06:20:54.187: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18324 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:20:54.187: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18325 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:20:54.187: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2212  6c5ba3b9-ef72-4764-ab78-73d9eec32d4f 18326 0 2022-08-27 06:20:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-08-27 06:20:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 27 06:20:54.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2212" for this suite. 08/27/22 06:20:54.192
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:54.203
Aug 27 06:20:54.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:20:54.203
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:54.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:54.227
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 08/27/22 06:20:54.231
Aug 27 06:20:54.231: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6258 proxy --unix-socket=/tmp/kubectl-proxy-unix51735615/test'
STEP: retrieving proxy /api/ output 08/27/22 06:20:54.287
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:20:54.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6258" for this suite. 08/27/22 06:20:54.295
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":165,"skipped":3118,"failed":0}
------------------------------
â€¢ [0.097 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:54.203
    Aug 27 06:20:54.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:20:54.203
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:54.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:54.227
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 08/27/22 06:20:54.231
    Aug 27 06:20:54.231: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6258 proxy --unix-socket=/tmp/kubectl-proxy-unix51735615/test'
    STEP: retrieving proxy /api/ output 08/27/22 06:20:54.287
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:20:54.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6258" for this suite. 08/27/22 06:20:54.295
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:54.305
Aug 27 06:20:54.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:20:54.307
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:54.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:54.392
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 08/27/22 06:20:54.397
Aug 27 06:20:54.404: INFO: Waiting up to 5m0s for pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586" in namespace "emptydir-2360" to be "Succeeded or Failed"
Aug 27 06:20:54.408: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586": Phase="Pending", Reason="", readiness=false. Elapsed: 4.771904ms
Aug 27 06:20:56.414: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010508935s
Aug 27 06:20:58.414: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010855496s
STEP: Saw pod success 08/27/22 06:20:58.414
Aug 27 06:20:58.415: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586" satisfied condition "Succeeded or Failed"
Aug 27 06:20:58.417: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-5abd262d-51d7-4b0d-a131-824aa8555586 container test-container: <nil>
STEP: delete the pod 08/27/22 06:20:58.427
Aug 27 06:20:58.436: INFO: Waiting for pod pod-5abd262d-51d7-4b0d-a131-824aa8555586 to disappear
Aug 27 06:20:58.440: INFO: Pod pod-5abd262d-51d7-4b0d-a131-824aa8555586 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:20:58.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2360" for this suite. 08/27/22 06:20:58.444
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":166,"skipped":3155,"failed":0}
------------------------------
â€¢ [4.143 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:54.305
    Aug 27 06:20:54.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:20:54.307
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:54.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:54.392
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 08/27/22 06:20:54.397
    Aug 27 06:20:54.404: INFO: Waiting up to 5m0s for pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586" in namespace "emptydir-2360" to be "Succeeded or Failed"
    Aug 27 06:20:54.408: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586": Phase="Pending", Reason="", readiness=false. Elapsed: 4.771904ms
    Aug 27 06:20:56.414: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010508935s
    Aug 27 06:20:58.414: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010855496s
    STEP: Saw pod success 08/27/22 06:20:58.414
    Aug 27 06:20:58.415: INFO: Pod "pod-5abd262d-51d7-4b0d-a131-824aa8555586" satisfied condition "Succeeded or Failed"
    Aug 27 06:20:58.417: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-5abd262d-51d7-4b0d-a131-824aa8555586 container test-container: <nil>
    STEP: delete the pod 08/27/22 06:20:58.427
    Aug 27 06:20:58.436: INFO: Waiting for pod pod-5abd262d-51d7-4b0d-a131-824aa8555586 to disappear
    Aug 27 06:20:58.440: INFO: Pod pod-5abd262d-51d7-4b0d-a131-824aa8555586 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:20:58.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2360" for this suite. 08/27/22 06:20:58.444
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:20:58.451
Aug 27 06:20:58.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:20:58.452
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:58.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:58.474
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-3403517f-2d64-4178-9d2f-acc1df213976 08/27/22 06:20:58.478
STEP: Creating a pod to test consume configMaps 08/27/22 06:20:58.482
Aug 27 06:20:58.489: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145" in namespace "projected-9700" to be "Succeeded or Failed"
Aug 27 06:20:58.494: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145": Phase="Pending", Reason="", readiness=false. Elapsed: 5.605112ms
Aug 27 06:21:00.499: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009884709s
Aug 27 06:21:02.502: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013027641s
STEP: Saw pod success 08/27/22 06:21:02.502
Aug 27 06:21:02.502: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145" satisfied condition "Succeeded or Failed"
Aug 27 06:21:02.512: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:21:02.525
Aug 27 06:21:02.552: INFO: Waiting for pod pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145 to disappear
Aug 27 06:21:02.567: INFO: Pod pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 06:21:02.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9700" for this suite. 08/27/22 06:21:02.572
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":167,"skipped":3165,"failed":0}
------------------------------
â€¢ [4.131 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:20:58.451
    Aug 27 06:20:58.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:20:58.452
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:20:58.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:20:58.474
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-3403517f-2d64-4178-9d2f-acc1df213976 08/27/22 06:20:58.478
    STEP: Creating a pod to test consume configMaps 08/27/22 06:20:58.482
    Aug 27 06:20:58.489: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145" in namespace "projected-9700" to be "Succeeded or Failed"
    Aug 27 06:20:58.494: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145": Phase="Pending", Reason="", readiness=false. Elapsed: 5.605112ms
    Aug 27 06:21:00.499: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009884709s
    Aug 27 06:21:02.502: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013027641s
    STEP: Saw pod success 08/27/22 06:21:02.502
    Aug 27 06:21:02.502: INFO: Pod "pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145" satisfied condition "Succeeded or Failed"
    Aug 27 06:21:02.512: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:21:02.525
    Aug 27 06:21:02.552: INFO: Waiting for pod pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145 to disappear
    Aug 27 06:21:02.567: INFO: Pod pod-projected-configmaps-5c2d75f5-e2a2-4ffd-9804-da8da1c1e145 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 06:21:02.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9700" for this suite. 08/27/22 06:21:02.572
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:02.583
Aug 27 06:21:02.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:21:02.584
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:02.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:02.647
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:21:02.654
Aug 27 06:21:02.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c" in namespace "projected-6205" to be "Succeeded or Failed"
Aug 27 06:21:02.680: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.254624ms
Aug 27 06:21:04.683: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013642289s
Aug 27 06:21:06.683: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013387273s
Aug 27 06:21:08.684: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013938306s
STEP: Saw pod success 08/27/22 06:21:08.684
Aug 27 06:21:08.684: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c" satisfied condition "Succeeded or Failed"
Aug 27 06:21:08.687: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c container client-container: <nil>
STEP: delete the pod 08/27/22 06:21:08.692
Aug 27 06:21:08.704: INFO: Waiting for pod downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c to disappear
Aug 27 06:21:08.708: INFO: Pod downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:21:08.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6205" for this suite. 08/27/22 06:21:08.712
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":168,"skipped":3173,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.133 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:02.583
    Aug 27 06:21:02.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:21:02.584
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:02.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:02.647
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:21:02.654
    Aug 27 06:21:02.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c" in namespace "projected-6205" to be "Succeeded or Failed"
    Aug 27 06:21:02.680: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.254624ms
    Aug 27 06:21:04.683: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013642289s
    Aug 27 06:21:06.683: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013387273s
    Aug 27 06:21:08.684: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013938306s
    STEP: Saw pod success 08/27/22 06:21:08.684
    Aug 27 06:21:08.684: INFO: Pod "downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c" satisfied condition "Succeeded or Failed"
    Aug 27 06:21:08.687: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c container client-container: <nil>
    STEP: delete the pod 08/27/22 06:21:08.692
    Aug 27 06:21:08.704: INFO: Waiting for pod downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c to disappear
    Aug 27 06:21:08.708: INFO: Pod downwardapi-volume-9fa4de14-2c24-4668-bde3-a3bfce195e9c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:21:08.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6205" for this suite. 08/27/22 06:21:08.712
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:08.717
Aug 27 06:21:08.718: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:21:08.719
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:08.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:08.741
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 08/27/22 06:21:08.746
Aug 27 06:21:08.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 create -f -'
Aug 27 06:21:09.015: INFO: stderr: ""
Aug 27 06:21:09.015: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:21:09.015
Aug 27 06:21:09.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:21:09.110: INFO: stderr: ""
Aug 27 06:21:09.110: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-jlskp "
Aug 27 06:21:09.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:21:09.193: INFO: stderr: ""
Aug 27 06:21:09.193: INFO: stdout: ""
Aug 27 06:21:09.193: INFO: update-demo-nautilus-82x6c is created but not running
Aug 27 06:21:14.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:21:14.265: INFO: stderr: ""
Aug 27 06:21:14.265: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-jlskp "
Aug 27 06:21:14.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:21:14.330: INFO: stderr: ""
Aug 27 06:21:14.330: INFO: stdout: "true"
Aug 27 06:21:14.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:21:14.393: INFO: stderr: ""
Aug 27 06:21:14.393: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:21:14.393: INFO: validating pod update-demo-nautilus-82x6c
Aug 27 06:21:14.398: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:21:14.398: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:21:14.398: INFO: update-demo-nautilus-82x6c is verified up and running
Aug 27 06:21:14.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-jlskp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:21:14.463: INFO: stderr: ""
Aug 27 06:21:14.463: INFO: stdout: "true"
Aug 27 06:21:14.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-jlskp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:21:14.536: INFO: stderr: ""
Aug 27 06:21:14.536: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:21:14.536: INFO: validating pod update-demo-nautilus-jlskp
Aug 27 06:21:14.543: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:21:14.543: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:21:14.543: INFO: update-demo-nautilus-jlskp is verified up and running
STEP: scaling down the replication controller 08/27/22 06:21:14.543
Aug 27 06:21:14.544: INFO: scanned /root for discovery docs: <nil>
Aug 27 06:21:14.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Aug 27 06:21:15.643: INFO: stderr: ""
Aug 27 06:21:15.643: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:21:15.643
Aug 27 06:21:15.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:21:15.720: INFO: stderr: ""
Aug 27 06:21:15.720: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-jlskp "
STEP: Replicas for name=update-demo: expected=1 actual=2 08/27/22 06:21:15.72
Aug 27 06:21:20.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:21:20.800: INFO: stderr: ""
Aug 27 06:21:20.800: INFO: stdout: "update-demo-nautilus-82x6c "
Aug 27 06:21:20.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:21:20.886: INFO: stderr: ""
Aug 27 06:21:20.886: INFO: stdout: "true"
Aug 27 06:21:20.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:21:20.964: INFO: stderr: ""
Aug 27 06:21:20.964: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:21:20.964: INFO: validating pod update-demo-nautilus-82x6c
Aug 27 06:21:20.969: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:21:20.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:21:20.969: INFO: update-demo-nautilus-82x6c is verified up and running
STEP: scaling up the replication controller 08/27/22 06:21:20.969
Aug 27 06:21:20.970: INFO: scanned /root for discovery docs: <nil>
Aug 27 06:21:20.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Aug 27 06:21:22.101: INFO: stderr: ""
Aug 27 06:21:22.101: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:21:22.101
Aug 27 06:21:22.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:21:22.172: INFO: stderr: ""
Aug 27 06:21:22.172: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-zvpfl "
Aug 27 06:21:22.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:21:22.249: INFO: stderr: ""
Aug 27 06:21:22.249: INFO: stdout: "true"
Aug 27 06:21:22.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:21:22.325: INFO: stderr: ""
Aug 27 06:21:22.325: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:21:22.325: INFO: validating pod update-demo-nautilus-82x6c
Aug 27 06:21:22.329: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:21:22.329: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:21:22.329: INFO: update-demo-nautilus-82x6c is verified up and running
Aug 27 06:21:22.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-zvpfl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:21:22.398: INFO: stderr: ""
Aug 27 06:21:22.398: INFO: stdout: "true"
Aug 27 06:21:22.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-zvpfl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:21:22.477: INFO: stderr: ""
Aug 27 06:21:22.477: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:21:22.477: INFO: validating pod update-demo-nautilus-zvpfl
Aug 27 06:21:22.482: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:21:22.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:21:22.483: INFO: update-demo-nautilus-zvpfl is verified up and running
STEP: using delete to clean up resources 08/27/22 06:21:22.483
Aug 27 06:21:22.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 delete --grace-period=0 --force -f -'
Aug 27 06:21:22.565: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 06:21:22.566: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 27 06:21:22.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get rc,svc -l name=update-demo --no-headers'
Aug 27 06:21:22.739: INFO: stderr: "No resources found in kubectl-7390 namespace.\n"
Aug 27 06:21:22.739: INFO: stdout: ""
Aug 27 06:21:22.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 06:21:22.859: INFO: stderr: ""
Aug 27 06:21:22.859: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:21:22.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7390" for this suite. 08/27/22 06:21:22.867
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":169,"skipped":3173,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.159 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:08.717
    Aug 27 06:21:08.718: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:21:08.719
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:08.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:08.741
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 08/27/22 06:21:08.746
    Aug 27 06:21:08.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 create -f -'
    Aug 27 06:21:09.015: INFO: stderr: ""
    Aug 27 06:21:09.015: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:21:09.015
    Aug 27 06:21:09.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:21:09.110: INFO: stderr: ""
    Aug 27 06:21:09.110: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-jlskp "
    Aug 27 06:21:09.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:21:09.193: INFO: stderr: ""
    Aug 27 06:21:09.193: INFO: stdout: ""
    Aug 27 06:21:09.193: INFO: update-demo-nautilus-82x6c is created but not running
    Aug 27 06:21:14.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:21:14.265: INFO: stderr: ""
    Aug 27 06:21:14.265: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-jlskp "
    Aug 27 06:21:14.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:21:14.330: INFO: stderr: ""
    Aug 27 06:21:14.330: INFO: stdout: "true"
    Aug 27 06:21:14.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:21:14.393: INFO: stderr: ""
    Aug 27 06:21:14.393: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:21:14.393: INFO: validating pod update-demo-nautilus-82x6c
    Aug 27 06:21:14.398: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:21:14.398: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:21:14.398: INFO: update-demo-nautilus-82x6c is verified up and running
    Aug 27 06:21:14.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-jlskp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:21:14.463: INFO: stderr: ""
    Aug 27 06:21:14.463: INFO: stdout: "true"
    Aug 27 06:21:14.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-jlskp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:21:14.536: INFO: stderr: ""
    Aug 27 06:21:14.536: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:21:14.536: INFO: validating pod update-demo-nautilus-jlskp
    Aug 27 06:21:14.543: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:21:14.543: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:21:14.543: INFO: update-demo-nautilus-jlskp is verified up and running
    STEP: scaling down the replication controller 08/27/22 06:21:14.543
    Aug 27 06:21:14.544: INFO: scanned /root for discovery docs: <nil>
    Aug 27 06:21:14.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Aug 27 06:21:15.643: INFO: stderr: ""
    Aug 27 06:21:15.643: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:21:15.643
    Aug 27 06:21:15.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:21:15.720: INFO: stderr: ""
    Aug 27 06:21:15.720: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-jlskp "
    STEP: Replicas for name=update-demo: expected=1 actual=2 08/27/22 06:21:15.72
    Aug 27 06:21:20.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:21:20.800: INFO: stderr: ""
    Aug 27 06:21:20.800: INFO: stdout: "update-demo-nautilus-82x6c "
    Aug 27 06:21:20.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:21:20.886: INFO: stderr: ""
    Aug 27 06:21:20.886: INFO: stdout: "true"
    Aug 27 06:21:20.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:21:20.964: INFO: stderr: ""
    Aug 27 06:21:20.964: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:21:20.964: INFO: validating pod update-demo-nautilus-82x6c
    Aug 27 06:21:20.969: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:21:20.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:21:20.969: INFO: update-demo-nautilus-82x6c is verified up and running
    STEP: scaling up the replication controller 08/27/22 06:21:20.969
    Aug 27 06:21:20.970: INFO: scanned /root for discovery docs: <nil>
    Aug 27 06:21:20.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Aug 27 06:21:22.101: INFO: stderr: ""
    Aug 27 06:21:22.101: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:21:22.101
    Aug 27 06:21:22.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:21:22.172: INFO: stderr: ""
    Aug 27 06:21:22.172: INFO: stdout: "update-demo-nautilus-82x6c update-demo-nautilus-zvpfl "
    Aug 27 06:21:22.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:21:22.249: INFO: stderr: ""
    Aug 27 06:21:22.249: INFO: stdout: "true"
    Aug 27 06:21:22.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-82x6c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:21:22.325: INFO: stderr: ""
    Aug 27 06:21:22.325: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:21:22.325: INFO: validating pod update-demo-nautilus-82x6c
    Aug 27 06:21:22.329: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:21:22.329: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:21:22.329: INFO: update-demo-nautilus-82x6c is verified up and running
    Aug 27 06:21:22.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-zvpfl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:21:22.398: INFO: stderr: ""
    Aug 27 06:21:22.398: INFO: stdout: "true"
    Aug 27 06:21:22.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods update-demo-nautilus-zvpfl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:21:22.477: INFO: stderr: ""
    Aug 27 06:21:22.477: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:21:22.477: INFO: validating pod update-demo-nautilus-zvpfl
    Aug 27 06:21:22.482: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:21:22.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:21:22.483: INFO: update-demo-nautilus-zvpfl is verified up and running
    STEP: using delete to clean up resources 08/27/22 06:21:22.483
    Aug 27 06:21:22.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 delete --grace-period=0 --force -f -'
    Aug 27 06:21:22.565: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 06:21:22.566: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Aug 27 06:21:22.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get rc,svc -l name=update-demo --no-headers'
    Aug 27 06:21:22.739: INFO: stderr: "No resources found in kubectl-7390 namespace.\n"
    Aug 27 06:21:22.739: INFO: stdout: ""
    Aug 27 06:21:22.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-7390 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 27 06:21:22.859: INFO: stderr: ""
    Aug 27 06:21:22.859: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:21:22.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7390" for this suite. 08/27/22 06:21:22.867
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:22.877
Aug 27 06:21:22.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename podtemplate 08/27/22 06:21:22.878
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:22.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:22.926
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 08/27/22 06:21:22.942
Aug 27 06:21:22.955: INFO: created test-podtemplate-1
Aug 27 06:21:22.963: INFO: created test-podtemplate-2
Aug 27 06:21:22.976: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 08/27/22 06:21:22.976
STEP: delete collection of pod templates 08/27/22 06:21:22.993
Aug 27 06:21:22.993: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 08/27/22 06:21:23.037
Aug 27 06:21:23.038: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 27 06:21:23.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5283" for this suite. 08/27/22 06:21:23.054
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":170,"skipped":3182,"failed":0}
------------------------------
â€¢ [0.185 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:22.877
    Aug 27 06:21:22.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename podtemplate 08/27/22 06:21:22.878
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:22.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:22.926
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 08/27/22 06:21:22.942
    Aug 27 06:21:22.955: INFO: created test-podtemplate-1
    Aug 27 06:21:22.963: INFO: created test-podtemplate-2
    Aug 27 06:21:22.976: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 08/27/22 06:21:22.976
    STEP: delete collection of pod templates 08/27/22 06:21:22.993
    Aug 27 06:21:22.993: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 08/27/22 06:21:23.037
    Aug 27 06:21:23.038: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 27 06:21:23.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5283" for this suite. 08/27/22 06:21:23.054
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:23.071
Aug 27 06:21:23.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:21:23.073
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:23.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:23.101
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-54dbf909-37ea-47f9-804d-2c4e8ba5120c 08/27/22 06:21:23.11
STEP: Creating the pod 08/27/22 06:21:23.116
Aug 27 06:21:23.128: INFO: Waiting up to 5m0s for pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70" in namespace "configmap-5064" to be "running and ready"
Aug 27 06:21:23.134: INFO: Pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70": Phase="Pending", Reason="", readiness=false. Elapsed: 5.570413ms
Aug 27 06:21:23.134: INFO: The phase of Pod pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:21:25.138: INFO: Pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70": Phase="Running", Reason="", readiness=true. Elapsed: 2.010066017s
Aug 27 06:21:25.138: INFO: The phase of Pod pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70 is Running (Ready = true)
Aug 27 06:21:25.138: INFO: Pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-54dbf909-37ea-47f9-804d-2c4e8ba5120c 08/27/22 06:21:25.15
STEP: waiting to observe update in volume 08/27/22 06:21:25.155
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:21:29.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5064" for this suite. 08/27/22 06:21:29.183
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":171,"skipped":3221,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.117 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:23.071
    Aug 27 06:21:23.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:21:23.073
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:23.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:23.101
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-54dbf909-37ea-47f9-804d-2c4e8ba5120c 08/27/22 06:21:23.11
    STEP: Creating the pod 08/27/22 06:21:23.116
    Aug 27 06:21:23.128: INFO: Waiting up to 5m0s for pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70" in namespace "configmap-5064" to be "running and ready"
    Aug 27 06:21:23.134: INFO: Pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70": Phase="Pending", Reason="", readiness=false. Elapsed: 5.570413ms
    Aug 27 06:21:23.134: INFO: The phase of Pod pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:21:25.138: INFO: Pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70": Phase="Running", Reason="", readiness=true. Elapsed: 2.010066017s
    Aug 27 06:21:25.138: INFO: The phase of Pod pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70 is Running (Ready = true)
    Aug 27 06:21:25.138: INFO: Pod "pod-configmaps-40a6d9df-7086-4ee3-8ad3-48af5c54cc70" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-54dbf909-37ea-47f9-804d-2c4e8ba5120c 08/27/22 06:21:25.15
    STEP: waiting to observe update in volume 08/27/22 06:21:25.155
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:21:29.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5064" for this suite. 08/27/22 06:21:29.183
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:29.193
Aug 27 06:21:29.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename prestop 08/27/22 06:21:29.197
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:29.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:29.22
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-6318 08/27/22 06:21:29.223
STEP: Waiting for pods to come up. 08/27/22 06:21:29.234
Aug 27 06:21:29.235: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6318" to be "running"
Aug 27 06:21:29.239: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.332231ms
Aug 27 06:21:31.242: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.007029932s
Aug 27 06:21:31.243: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-6318 08/27/22 06:21:31.246
Aug 27 06:21:31.252: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6318" to be "running"
Aug 27 06:21:31.255: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.127254ms
Aug 27 06:21:33.260: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.007440011s
Aug 27 06:21:33.260: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 08/27/22 06:21:33.26
Aug 27 06:21:38.276: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 08/27/22 06:21:38.276
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Aug 27 06:21:38.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6318" for this suite. 08/27/22 06:21:38.38
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":172,"skipped":3268,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.211 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:29.193
    Aug 27 06:21:29.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename prestop 08/27/22 06:21:29.197
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:29.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:29.22
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-6318 08/27/22 06:21:29.223
    STEP: Waiting for pods to come up. 08/27/22 06:21:29.234
    Aug 27 06:21:29.235: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6318" to be "running"
    Aug 27 06:21:29.239: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.332231ms
    Aug 27 06:21:31.242: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.007029932s
    Aug 27 06:21:31.243: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-6318 08/27/22 06:21:31.246
    Aug 27 06:21:31.252: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6318" to be "running"
    Aug 27 06:21:31.255: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.127254ms
    Aug 27 06:21:33.260: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.007440011s
    Aug 27 06:21:33.260: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 08/27/22 06:21:33.26
    Aug 27 06:21:38.276: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 08/27/22 06:21:38.276
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Aug 27 06:21:38.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-6318" for this suite. 08/27/22 06:21:38.38
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:38.412
Aug 27 06:21:38.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:21:38.419
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:38.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:38.484
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 08/27/22 06:21:38.487
STEP: Creating a ResourceQuota 08/27/22 06:21:43.493
STEP: Ensuring resource quota status is calculated 08/27/22 06:21:43.501
STEP: Creating a Service 08/27/22 06:21:45.507
STEP: Creating a NodePort Service 08/27/22 06:21:45.523
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 08/27/22 06:21:45.542
STEP: Ensuring resource quota status captures service creation 08/27/22 06:21:45.559
STEP: Deleting Services 08/27/22 06:21:47.564
STEP: Ensuring resource quota status released usage 08/27/22 06:21:47.792
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:21:49.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8989" for this suite. 08/27/22 06:21:49.8
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":173,"skipped":3271,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.395 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:38.412
    Aug 27 06:21:38.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:21:38.419
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:38.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:38.484
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 08/27/22 06:21:38.487
    STEP: Creating a ResourceQuota 08/27/22 06:21:43.493
    STEP: Ensuring resource quota status is calculated 08/27/22 06:21:43.501
    STEP: Creating a Service 08/27/22 06:21:45.507
    STEP: Creating a NodePort Service 08/27/22 06:21:45.523
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 08/27/22 06:21:45.542
    STEP: Ensuring resource quota status captures service creation 08/27/22 06:21:45.559
    STEP: Deleting Services 08/27/22 06:21:47.564
    STEP: Ensuring resource quota status released usage 08/27/22 06:21:47.792
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:21:49.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8989" for this suite. 08/27/22 06:21:49.8
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:49.809
Aug 27 06:21:49.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:21:49.81
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:49.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:49.841
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:21:49.844
Aug 27 06:21:49.850: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc" in namespace "projected-626" to be "Succeeded or Failed"
Aug 27 06:21:49.856: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.527232ms
Aug 27 06:21:51.859: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009225296s
Aug 27 06:21:53.864: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014087488s
STEP: Saw pod success 08/27/22 06:21:53.864
Aug 27 06:21:53.865: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc" satisfied condition "Succeeded or Failed"
Aug 27 06:21:53.870: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc container client-container: <nil>
STEP: delete the pod 08/27/22 06:21:53.884
Aug 27 06:21:53.896: INFO: Waiting for pod downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc to disappear
Aug 27 06:21:53.899: INFO: Pod downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:21:53.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-626" for this suite. 08/27/22 06:21:53.902
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":174,"skipped":3325,"failed":0}
------------------------------
â€¢ [4.096 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:49.809
    Aug 27 06:21:49.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:21:49.81
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:49.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:49.841
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:21:49.844
    Aug 27 06:21:49.850: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc" in namespace "projected-626" to be "Succeeded or Failed"
    Aug 27 06:21:49.856: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.527232ms
    Aug 27 06:21:51.859: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009225296s
    Aug 27 06:21:53.864: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014087488s
    STEP: Saw pod success 08/27/22 06:21:53.864
    Aug 27 06:21:53.865: INFO: Pod "downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc" satisfied condition "Succeeded or Failed"
    Aug 27 06:21:53.870: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc container client-container: <nil>
    STEP: delete the pod 08/27/22 06:21:53.884
    Aug 27 06:21:53.896: INFO: Waiting for pod downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc to disappear
    Aug 27 06:21:53.899: INFO: Pod downwardapi-volume-4a84489a-0360-4d94-bf1a-543e6e7870bc no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:21:53.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-626" for this suite. 08/27/22 06:21:53.902
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:53.909
Aug 27 06:21:53.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:21:53.91
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:53.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:53.928
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 08/27/22 06:21:53.931
Aug 27 06:21:53.937: INFO: Waiting up to 5m0s for pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd" in namespace "emptydir-919" to be "Succeeded or Failed"
Aug 27 06:21:53.941: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.672426ms
Aug 27 06:21:55.945: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008578467s
Aug 27 06:21:57.946: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008995881s
STEP: Saw pod success 08/27/22 06:21:57.946
Aug 27 06:21:57.946: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd" satisfied condition "Succeeded or Failed"
Aug 27 06:21:57.949: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd container test-container: <nil>
STEP: delete the pod 08/27/22 06:21:57.955
Aug 27 06:21:57.966: INFO: Waiting for pod pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd to disappear
Aug 27 06:21:57.968: INFO: Pod pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:21:57.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-919" for this suite. 08/27/22 06:21:57.971
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":175,"skipped":3348,"failed":0}
------------------------------
â€¢ [4.066 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:53.909
    Aug 27 06:21:53.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:21:53.91
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:53.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:53.928
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 08/27/22 06:21:53.931
    Aug 27 06:21:53.937: INFO: Waiting up to 5m0s for pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd" in namespace "emptydir-919" to be "Succeeded or Failed"
    Aug 27 06:21:53.941: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.672426ms
    Aug 27 06:21:55.945: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008578467s
    Aug 27 06:21:57.946: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008995881s
    STEP: Saw pod success 08/27/22 06:21:57.946
    Aug 27 06:21:57.946: INFO: Pod "pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd" satisfied condition "Succeeded or Failed"
    Aug 27 06:21:57.949: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd container test-container: <nil>
    STEP: delete the pod 08/27/22 06:21:57.955
    Aug 27 06:21:57.966: INFO: Waiting for pod pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd to disappear
    Aug 27 06:21:57.968: INFO: Pod pod-b860d6bf-95d6-48a8-ab8c-5442673b4bdd no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:21:57.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-919" for this suite. 08/27/22 06:21:57.971
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:21:57.978
Aug 27 06:21:57.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:21:57.979
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:57.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:57.997
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:21:58
Aug 27 06:21:58.008: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b" in namespace "projected-6080" to be "Succeeded or Failed"
Aug 27 06:21:58.014: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.411552ms
Aug 27 06:22:00.018: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010039883s
Aug 27 06:22:02.018: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009142542s
STEP: Saw pod success 08/27/22 06:22:02.018
Aug 27 06:22:02.018: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b" satisfied condition "Succeeded or Failed"
Aug 27 06:22:02.022: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b container client-container: <nil>
STEP: delete the pod 08/27/22 06:22:02.051
Aug 27 06:22:02.096: INFO: Waiting for pod downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b to disappear
Aug 27 06:22:02.114: INFO: Pod downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:22:02.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6080" for this suite. 08/27/22 06:22:02.127
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":176,"skipped":3356,"failed":0}
------------------------------
â€¢ [4.181 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:21:57.978
    Aug 27 06:21:57.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:21:57.979
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:21:57.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:21:57.997
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:21:58
    Aug 27 06:21:58.008: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b" in namespace "projected-6080" to be "Succeeded or Failed"
    Aug 27 06:21:58.014: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.411552ms
    Aug 27 06:22:00.018: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010039883s
    Aug 27 06:22:02.018: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009142542s
    STEP: Saw pod success 08/27/22 06:22:02.018
    Aug 27 06:22:02.018: INFO: Pod "downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b" satisfied condition "Succeeded or Failed"
    Aug 27 06:22:02.022: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b container client-container: <nil>
    STEP: delete the pod 08/27/22 06:22:02.051
    Aug 27 06:22:02.096: INFO: Waiting for pod downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b to disappear
    Aug 27 06:22:02.114: INFO: Pod downwardapi-volume-e0fcebb2-f700-45a2-a018-93996903fd2b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:22:02.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6080" for this suite. 08/27/22 06:22:02.127
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:22:02.16
Aug 27 06:22:02.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:22:02.162
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:22:02.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:22:02.284
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-43c4f794-9ef1-4cab-8458-1a7bd130b14d 08/27/22 06:22:02.349
STEP: Creating secret with name s-test-opt-upd-fd1e8675-5b83-4ab8-b65e-78c97eda0aef 08/27/22 06:22:02.397
STEP: Creating the pod 08/27/22 06:22:02.412
Aug 27 06:22:02.461: INFO: Waiting up to 5m0s for pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4" in namespace "secrets-4990" to be "running and ready"
Aug 27 06:22:02.496: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.034352ms
Aug 27 06:22:02.496: INFO: The phase of Pod pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:22:04.500: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038371759s
Aug 27 06:22:04.500: INFO: The phase of Pod pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:22:06.500: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4": Phase="Running", Reason="", readiness=true. Elapsed: 4.038788027s
Aug 27 06:22:06.500: INFO: The phase of Pod pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4 is Running (Ready = true)
Aug 27 06:22:06.500: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-43c4f794-9ef1-4cab-8458-1a7bd130b14d 08/27/22 06:22:06.521
STEP: Updating secret s-test-opt-upd-fd1e8675-5b83-4ab8-b65e-78c97eda0aef 08/27/22 06:22:06.525
STEP: Creating secret with name s-test-opt-create-5d24d7d8-c0c3-48f7-b789-48dc8af5869e 08/27/22 06:22:06.53
STEP: waiting to observe update in volume 08/27/22 06:22:06.534
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:23:10.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4990" for this suite. 08/27/22 06:23:10.856
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":177,"skipped":3356,"failed":0}
------------------------------
â€¢ [SLOW TEST] [68.702 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:22:02.16
    Aug 27 06:22:02.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:22:02.162
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:22:02.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:22:02.284
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-43c4f794-9ef1-4cab-8458-1a7bd130b14d 08/27/22 06:22:02.349
    STEP: Creating secret with name s-test-opt-upd-fd1e8675-5b83-4ab8-b65e-78c97eda0aef 08/27/22 06:22:02.397
    STEP: Creating the pod 08/27/22 06:22:02.412
    Aug 27 06:22:02.461: INFO: Waiting up to 5m0s for pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4" in namespace "secrets-4990" to be "running and ready"
    Aug 27 06:22:02.496: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.034352ms
    Aug 27 06:22:02.496: INFO: The phase of Pod pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:22:04.500: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038371759s
    Aug 27 06:22:04.500: INFO: The phase of Pod pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:22:06.500: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4": Phase="Running", Reason="", readiness=true. Elapsed: 4.038788027s
    Aug 27 06:22:06.500: INFO: The phase of Pod pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4 is Running (Ready = true)
    Aug 27 06:22:06.500: INFO: Pod "pod-secrets-626d8a76-aecd-48e7-8797-885350c363e4" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-43c4f794-9ef1-4cab-8458-1a7bd130b14d 08/27/22 06:22:06.521
    STEP: Updating secret s-test-opt-upd-fd1e8675-5b83-4ab8-b65e-78c97eda0aef 08/27/22 06:22:06.525
    STEP: Creating secret with name s-test-opt-create-5d24d7d8-c0c3-48f7-b789-48dc8af5869e 08/27/22 06:22:06.53
    STEP: waiting to observe update in volume 08/27/22 06:22:06.534
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:23:10.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4990" for this suite. 08/27/22 06:23:10.856
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:10.872
Aug 27 06:23:10.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 06:23:10.874
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:10.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:10.899
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Aug 27 06:23:10.909: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 27 06:23:15.922: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/27/22 06:23:15.922
Aug 27 06:23:15.922: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 08/27/22 06:23:15.935
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 06:23:15.957: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-402  423d9207-c5ae-4c7b-a690-85a498adef88 19007 1 2022-08-27 06:23:15 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-08-27 06:23:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e81418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Aug 27 06:23:15.975: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 06:23:15.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-402" for this suite. 08/27/22 06:23:15.991
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":178,"skipped":3384,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.144 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:10.872
    Aug 27 06:23:10.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 06:23:10.874
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:10.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:10.899
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Aug 27 06:23:10.909: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Aug 27 06:23:15.922: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/27/22 06:23:15.922
    Aug 27 06:23:15.922: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 08/27/22 06:23:15.935
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 06:23:15.957: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-402  423d9207-c5ae-4c7b-a690-85a498adef88 19007 1 2022-08-27 06:23:15 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-08-27 06:23:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e81418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Aug 27 06:23:15.975: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 06:23:15.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-402" for this suite. 08/27/22 06:23:15.991
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:16.017
Aug 27 06:23:16.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:23:16.018
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:16.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:16.056
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6218-delete-me 08/27/22 06:23:16.068
STEP: Waiting for the RuntimeClass to disappear 08/27/22 06:23:16.075
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 27 06:23:16.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6218" for this suite. 08/27/22 06:23:16.093
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":179,"skipped":3385,"failed":0}
------------------------------
â€¢ [0.083 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:16.017
    Aug 27 06:23:16.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:23:16.018
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:16.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:16.056
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6218-delete-me 08/27/22 06:23:16.068
    STEP: Waiting for the RuntimeClass to disappear 08/27/22 06:23:16.075
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 27 06:23:16.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6218" for this suite. 08/27/22 06:23:16.093
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:16.102
Aug 27 06:23:16.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename podtemplate 08/27/22 06:23:16.104
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:16.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:16.159
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 08/27/22 06:23:16.171
STEP: Replace a pod template 08/27/22 06:23:16.189
Aug 27 06:23:16.226: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 27 06:23:16.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-656" for this suite. 08/27/22 06:23:16.234
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":180,"skipped":3413,"failed":0}
------------------------------
â€¢ [0.191 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:16.102
    Aug 27 06:23:16.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename podtemplate 08/27/22 06:23:16.104
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:16.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:16.159
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 08/27/22 06:23:16.171
    STEP: Replace a pod template 08/27/22 06:23:16.189
    Aug 27 06:23:16.226: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 27 06:23:16.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-656" for this suite. 08/27/22 06:23:16.234
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:16.294
Aug 27 06:23:16.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:23:16.295
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:16.367
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:16.385
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-93d649d4-a079-435a-a273-553f503e17fa 08/27/22 06:23:16.4
STEP: Creating a pod to test consume secrets 08/27/22 06:23:16.412
Aug 27 06:23:16.440: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5" in namespace "projected-9640" to be "Succeeded or Failed"
Aug 27 06:23:16.453: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.587875ms
Aug 27 06:23:18.456: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016012234s
Aug 27 06:23:20.456: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016179616s
STEP: Saw pod success 08/27/22 06:23:20.456
Aug 27 06:23:20.456: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5" satisfied condition "Succeeded or Failed"
Aug 27 06:23:20.459: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:23:20.484
Aug 27 06:23:20.510: INFO: Waiting for pod pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5 to disappear
Aug 27 06:23:20.518: INFO: Pod pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 06:23:20.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9640" for this suite. 08/27/22 06:23:20.524
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":181,"skipped":3426,"failed":0}
------------------------------
â€¢ [4.241 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:16.294
    Aug 27 06:23:16.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:23:16.295
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:16.367
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:16.385
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-93d649d4-a079-435a-a273-553f503e17fa 08/27/22 06:23:16.4
    STEP: Creating a pod to test consume secrets 08/27/22 06:23:16.412
    Aug 27 06:23:16.440: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5" in namespace "projected-9640" to be "Succeeded or Failed"
    Aug 27 06:23:16.453: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.587875ms
    Aug 27 06:23:18.456: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016012234s
    Aug 27 06:23:20.456: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016179616s
    STEP: Saw pod success 08/27/22 06:23:20.456
    Aug 27 06:23:20.456: INFO: Pod "pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5" satisfied condition "Succeeded or Failed"
    Aug 27 06:23:20.459: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:23:20.484
    Aug 27 06:23:20.510: INFO: Waiting for pod pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5 to disappear
    Aug 27 06:23:20.518: INFO: Pod pod-projected-secrets-b8b71616-edad-417d-b804-6f86aab65ed5 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 06:23:20.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9640" for this suite. 08/27/22 06:23:20.524
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:20.537
Aug 27 06:23:20.537: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:23:20.538
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:20.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:20.643
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 08/27/22 06:23:20.648
STEP: Creating a ResourceQuota 08/27/22 06:23:25.656
STEP: Ensuring resource quota status is calculated 08/27/22 06:23:25.662
STEP: Creating a Pod that fits quota 08/27/22 06:23:27.669
STEP: Ensuring ResourceQuota status captures the pod usage 08/27/22 06:23:27.684
STEP: Not allowing a pod to be created that exceeds remaining quota 08/27/22 06:23:29.689
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 08/27/22 06:23:29.694
STEP: Ensuring a pod cannot update its resource requirements 08/27/22 06:23:29.699
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 08/27/22 06:23:29.703
STEP: Deleting the pod 08/27/22 06:23:31.707
STEP: Ensuring resource quota status released the pod usage 08/27/22 06:23:31.724
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:23:33.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6000" for this suite. 08/27/22 06:23:33.732
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":182,"skipped":3461,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.201 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:20.537
    Aug 27 06:23:20.537: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:23:20.538
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:20.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:20.643
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 08/27/22 06:23:20.648
    STEP: Creating a ResourceQuota 08/27/22 06:23:25.656
    STEP: Ensuring resource quota status is calculated 08/27/22 06:23:25.662
    STEP: Creating a Pod that fits quota 08/27/22 06:23:27.669
    STEP: Ensuring ResourceQuota status captures the pod usage 08/27/22 06:23:27.684
    STEP: Not allowing a pod to be created that exceeds remaining quota 08/27/22 06:23:29.689
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 08/27/22 06:23:29.694
    STEP: Ensuring a pod cannot update its resource requirements 08/27/22 06:23:29.699
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 08/27/22 06:23:29.703
    STEP: Deleting the pod 08/27/22 06:23:31.707
    STEP: Ensuring resource quota status released the pod usage 08/27/22 06:23:31.724
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:23:33.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6000" for this suite. 08/27/22 06:23:33.732
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:33.742
Aug 27 06:23:33.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename endpointslice 08/27/22 06:23:33.746
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:33.764
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:33.769
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Aug 27 06:23:33.779: INFO: Endpoints addresses: [10.0.13.52] , ports: [6443]
Aug 27 06:23:33.780: INFO: EndpointSlices addresses: [10.0.13.52] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 27 06:23:33.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8674" for this suite. 08/27/22 06:23:33.782
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":183,"skipped":3472,"failed":0}
------------------------------
â€¢ [0.044 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:33.742
    Aug 27 06:23:33.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename endpointslice 08/27/22 06:23:33.746
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:33.764
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:33.769
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Aug 27 06:23:33.779: INFO: Endpoints addresses: [10.0.13.52] , ports: [6443]
    Aug 27 06:23:33.780: INFO: EndpointSlices addresses: [10.0.13.52] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 27 06:23:33.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8674" for this suite. 08/27/22 06:23:33.782
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:33.787
Aug 27 06:23:33.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:23:33.789
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:33.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:33.808
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:23:33.812
Aug 27 06:23:33.818: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e" in namespace "downward-api-9360" to be "Succeeded or Failed"
Aug 27 06:23:33.820: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258358ms
Aug 27 06:23:35.825: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006741184s
Aug 27 06:23:37.825: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007469085s
STEP: Saw pod success 08/27/22 06:23:37.826
Aug 27 06:23:37.826: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e" satisfied condition "Succeeded or Failed"
Aug 27 06:23:37.829: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e container client-container: <nil>
STEP: delete the pod 08/27/22 06:23:37.847
Aug 27 06:23:37.866: INFO: Waiting for pod downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e to disappear
Aug 27 06:23:37.871: INFO: Pod downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:23:37.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9360" for this suite. 08/27/22 06:23:37.874
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":184,"skipped":3472,"failed":0}
------------------------------
â€¢ [4.097 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:33.787
    Aug 27 06:23:33.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:23:33.789
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:33.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:33.808
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:23:33.812
    Aug 27 06:23:33.818: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e" in namespace "downward-api-9360" to be "Succeeded or Failed"
    Aug 27 06:23:33.820: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258358ms
    Aug 27 06:23:35.825: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006741184s
    Aug 27 06:23:37.825: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007469085s
    STEP: Saw pod success 08/27/22 06:23:37.826
    Aug 27 06:23:37.826: INFO: Pod "downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e" satisfied condition "Succeeded or Failed"
    Aug 27 06:23:37.829: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e container client-container: <nil>
    STEP: delete the pod 08/27/22 06:23:37.847
    Aug 27 06:23:37.866: INFO: Waiting for pod downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e to disappear
    Aug 27 06:23:37.871: INFO: Pod downwardapi-volume-0e2db3fa-80ca-4d9d-9481-7560fc993f7e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:23:37.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9360" for this suite. 08/27/22 06:23:37.874
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:37.896
Aug 27 06:23:37.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:23:37.899
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:37.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:37.934
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 08/27/22 06:23:37.937
Aug 27 06:23:37.943: INFO: Waiting up to 5m0s for pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04" in namespace "projected-5648" to be "running and ready"
Aug 27 06:23:37.948: INFO: Pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04": Phase="Pending", Reason="", readiness=false. Elapsed: 5.35894ms
Aug 27 06:23:37.948: INFO: The phase of Pod labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:23:39.951: INFO: Pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04": Phase="Running", Reason="", readiness=true. Elapsed: 2.008487329s
Aug 27 06:23:39.951: INFO: The phase of Pod labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04 is Running (Ready = true)
Aug 27 06:23:39.951: INFO: Pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04" satisfied condition "running and ready"
Aug 27 06:23:40.470: INFO: Successfully updated pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:23:44.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5648" for this suite. 08/27/22 06:23:44.499
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":185,"skipped":3500,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.617 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:37.896
    Aug 27 06:23:37.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:23:37.899
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:37.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:37.934
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 08/27/22 06:23:37.937
    Aug 27 06:23:37.943: INFO: Waiting up to 5m0s for pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04" in namespace "projected-5648" to be "running and ready"
    Aug 27 06:23:37.948: INFO: Pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04": Phase="Pending", Reason="", readiness=false. Elapsed: 5.35894ms
    Aug 27 06:23:37.948: INFO: The phase of Pod labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:23:39.951: INFO: Pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04": Phase="Running", Reason="", readiness=true. Elapsed: 2.008487329s
    Aug 27 06:23:39.951: INFO: The phase of Pod labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04 is Running (Ready = true)
    Aug 27 06:23:39.951: INFO: Pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04" satisfied condition "running and ready"
    Aug 27 06:23:40.470: INFO: Successfully updated pod "labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:23:44.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5648" for this suite. 08/27/22 06:23:44.499
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:44.518
Aug 27 06:23:44.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:23:44.519
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:44.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:44.557
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-af11802e-7b31-496e-8e3e-be4c3f55b92b 08/27/22 06:23:44.566
STEP: Creating configMap with name cm-test-opt-upd-af94c8fe-5ae5-4f75-a182-7322c35e6e50 08/27/22 06:23:44.57
STEP: Creating the pod 08/27/22 06:23:44.573
Aug 27 06:23:44.580: INFO: Waiting up to 5m0s for pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef" in namespace "configmap-4603" to be "running and ready"
Aug 27 06:23:44.582: INFO: Pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.301033ms
Aug 27 06:23:44.582: INFO: The phase of Pod pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:23:46.585: INFO: Pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef": Phase="Running", Reason="", readiness=true. Elapsed: 2.005464511s
Aug 27 06:23:46.585: INFO: The phase of Pod pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef is Running (Ready = true)
Aug 27 06:23:46.585: INFO: Pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-af11802e-7b31-496e-8e3e-be4c3f55b92b 08/27/22 06:23:46.603
STEP: Updating configmap cm-test-opt-upd-af94c8fe-5ae5-4f75-a182-7322c35e6e50 08/27/22 06:23:46.607
STEP: Creating configMap with name cm-test-opt-create-1a721cc5-8c20-469a-8212-fd7e198ec12b 08/27/22 06:23:46.611
STEP: waiting to observe update in volume 08/27/22 06:23:46.614
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:23:48.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4603" for this suite. 08/27/22 06:23:48.648
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":186,"skipped":3517,"failed":0}
------------------------------
â€¢ [4.135 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:44.518
    Aug 27 06:23:44.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:23:44.519
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:44.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:44.557
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-af11802e-7b31-496e-8e3e-be4c3f55b92b 08/27/22 06:23:44.566
    STEP: Creating configMap with name cm-test-opt-upd-af94c8fe-5ae5-4f75-a182-7322c35e6e50 08/27/22 06:23:44.57
    STEP: Creating the pod 08/27/22 06:23:44.573
    Aug 27 06:23:44.580: INFO: Waiting up to 5m0s for pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef" in namespace "configmap-4603" to be "running and ready"
    Aug 27 06:23:44.582: INFO: Pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.301033ms
    Aug 27 06:23:44.582: INFO: The phase of Pod pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:23:46.585: INFO: Pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef": Phase="Running", Reason="", readiness=true. Elapsed: 2.005464511s
    Aug 27 06:23:46.585: INFO: The phase of Pod pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef is Running (Ready = true)
    Aug 27 06:23:46.585: INFO: Pod "pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-af11802e-7b31-496e-8e3e-be4c3f55b92b 08/27/22 06:23:46.603
    STEP: Updating configmap cm-test-opt-upd-af94c8fe-5ae5-4f75-a182-7322c35e6e50 08/27/22 06:23:46.607
    STEP: Creating configMap with name cm-test-opt-create-1a721cc5-8c20-469a-8212-fd7e198ec12b 08/27/22 06:23:46.611
    STEP: waiting to observe update in volume 08/27/22 06:23:46.614
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:23:48.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4603" for this suite. 08/27/22 06:23:48.648
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:48.656
Aug 27 06:23:48.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename lease-test 08/27/22 06:23:48.657
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:48.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:48.69
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Aug 27 06:23:48.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-6463" for this suite. 08/27/22 06:23:48.76
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":187,"skipped":3528,"failed":0}
------------------------------
â€¢ [0.109 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:48.656
    Aug 27 06:23:48.656: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename lease-test 08/27/22 06:23:48.657
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:48.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:48.69
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Aug 27 06:23:48.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-6463" for this suite. 08/27/22 06:23:48.76
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:48.767
Aug 27 06:23:48.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-pred 08/27/22 06:23:48.768
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:48.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:48.807
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Aug 27 06:23:48.812: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 27 06:23:48.825: INFO: Waiting for terminating namespaces to be deleted...
Aug 27 06:23:48.835: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
Aug 27 06:23:48.849: INFO: pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef from configmap-4603 started at 2022-08-27 06:23:44 +0000 UTC (3 container statuses recorded)
Aug 27 06:23:48.850: INFO: 	Container createcm-volume-test ready: true, restart count 0
Aug 27 06:23:48.850: INFO: 	Container delcm-volume-test ready: true, restart count 0
Aug 27 06:23:48.850: INFO: 	Container updcm-volume-test ready: true, restart count 0
Aug 27 06:23:48.850: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 06:23:48.850: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 06:23:48.850: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
Aug 27 06:23:48.850: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 06:23:48.850: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 06:23:48.850: INFO: 	Container e2e ready: true, restart count 0
Aug 27 06:23:48.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 06:23:48.850: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 06:23:48.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 06:23:48.850: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 27 06:23:48.850: INFO: 
Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
Aug 27 06:23:48.860: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 06:23:48.860: INFO: 	Container calico-node ready: true, restart count 0
Aug 27 06:23:48.860: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
Aug 27 06:23:48.860: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 27 06:23:48.860: INFO: labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04 from projected-5648 started at 2022-08-27 06:23:37 +0000 UTC (1 container statuses recorded)
Aug 27 06:23:48.860: INFO: 	Container client-container ready: true, restart count 0
Aug 27 06:23:48.860: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
Aug 27 06:23:48.860: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 27 06:23:48.860: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
Aug 27 06:23:48.860: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 27 06:23:48.860: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 08/27/22 06:23:48.861
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.170f1f8192619007], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/controller: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 08/27/22 06:23:48.907
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:23:49.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4534" for this suite. 08/27/22 06:23:49.896
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":188,"skipped":3550,"failed":0}
------------------------------
â€¢ [1.134 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:48.767
    Aug 27 06:23:48.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-pred 08/27/22 06:23:48.768
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:48.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:48.807
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Aug 27 06:23:48.812: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Aug 27 06:23:48.825: INFO: Waiting for terminating namespaces to be deleted...
    Aug 27 06:23:48.835: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-31-158 before test
    Aug 27 06:23:48.849: INFO: pod-configmaps-5847497e-7a15-44ca-a8ea-b81c0f2799ef from configmap-4603 started at 2022-08-27 06:23:44 +0000 UTC (3 container statuses recorded)
    Aug 27 06:23:48.850: INFO: 	Container createcm-volume-test ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: 	Container delcm-volume-test ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: 	Container updcm-volume-test ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: calico-node-gc879 from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 06:23:48.850: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: kube-proxy-wmg2x from kube-system started at 2022-08-27 05:28:17 +0000 UTC (1 container statuses recorded)
    Aug 27 06:23:48.850: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: sonobuoy-e2e-job-a7872b18ebcd44d0 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 06:23:48.850: INFO: 	Container e2e ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-fjmmj from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 06:23:48.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: 	Container systemd-logs ready: true, restart count 0
    Aug 27 06:23:48.850: INFO: 
    Logging pods the apiserver thinks is on node ip-10-0-47-192 before test
    Aug 27 06:23:48.860: INFO: calico-node-tj9v9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 06:23:48.860: INFO: 	Container calico-node ready: true, restart count 0
    Aug 27 06:23:48.860: INFO: kube-proxy-jnlr9 from kube-system started at 2022-08-27 05:27:43 +0000 UTC (1 container statuses recorded)
    Aug 27 06:23:48.860: INFO: 	Container kube-proxy ready: true, restart count 0
    Aug 27 06:23:48.860: INFO: labelsupdate3f7ee478-f92a-40e3-ab2f-7ee749d9fc04 from projected-5648 started at 2022-08-27 06:23:37 +0000 UTC (1 container statuses recorded)
    Aug 27 06:23:48.860: INFO: 	Container client-container ready: true, restart count 0
    Aug 27 06:23:48.860: INFO: sonobuoy from sonobuoy started at 2022-08-27 05:29:28 +0000 UTC (1 container statuses recorded)
    Aug 27 06:23:48.860: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Aug 27 06:23:48.860: INFO: sonobuoy-systemd-logs-daemon-set-97026c89e9db4386-rl4r9 from sonobuoy started at 2022-08-27 05:29:30 +0000 UTC (2 container statuses recorded)
    Aug 27 06:23:48.860: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Aug 27 06:23:48.860: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 08/27/22 06:23:48.861
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.170f1f8192619007], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/controller: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 08/27/22 06:23:48.907
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:23:49.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4534" for this suite. 08/27/22 06:23:49.896
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:49.902
Aug 27 06:23:49.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename disruption 08/27/22 06:23:49.904
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:49.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:49.924
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:49.927
Aug 27 06:23:49.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename disruption-2 08/27/22 06:23:49.928
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:49.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:49.947
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 08/27/22 06:23:49.955
STEP: Waiting for the pdb to be processed 08/27/22 06:23:51.971
STEP: Waiting for the pdb to be processed 08/27/22 06:23:53.993
STEP: listing a collection of PDBs across all namespaces 08/27/22 06:23:56.007
STEP: listing a collection of PDBs in namespace disruption-4258 08/27/22 06:23:56.012
STEP: deleting a collection of PDBs 08/27/22 06:23:56.016
STEP: Waiting for the PDB collection to be deleted 08/27/22 06:23:56.023
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Aug 27 06:23:56.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-2382" for this suite. 08/27/22 06:23:56.029
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 27 06:23:56.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4258" for this suite. 08/27/22 06:23:56.039
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":189,"skipped":3559,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.140 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:49.902
    Aug 27 06:23:49.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename disruption 08/27/22 06:23:49.904
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:49.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:49.924
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:49.927
    Aug 27 06:23:49.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename disruption-2 08/27/22 06:23:49.928
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:49.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:49.947
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 08/27/22 06:23:49.955
    STEP: Waiting for the pdb to be processed 08/27/22 06:23:51.971
    STEP: Waiting for the pdb to be processed 08/27/22 06:23:53.993
    STEP: listing a collection of PDBs across all namespaces 08/27/22 06:23:56.007
    STEP: listing a collection of PDBs in namespace disruption-4258 08/27/22 06:23:56.012
    STEP: deleting a collection of PDBs 08/27/22 06:23:56.016
    STEP: Waiting for the PDB collection to be deleted 08/27/22 06:23:56.023
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Aug 27 06:23:56.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-2382" for this suite. 08/27/22 06:23:56.029
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 27 06:23:56.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4258" for this suite. 08/27/22 06:23:56.039
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:23:56.044
Aug 27 06:23:56.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:23:56.046
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:56.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:56.065
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:23:56.069
Aug 27 06:23:56.074: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99" in namespace "downward-api-4360" to be "Succeeded or Failed"
Aug 27 06:23:56.078: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3888ms
Aug 27 06:23:58.082: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007358353s
Aug 27 06:24:00.082: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007534442s
STEP: Saw pod success 08/27/22 06:24:00.082
Aug 27 06:24:00.082: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99" satisfied condition "Succeeded or Failed"
Aug 27 06:24:00.089: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99 container client-container: <nil>
STEP: delete the pod 08/27/22 06:24:00.1
Aug 27 06:24:00.125: INFO: Waiting for pod downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99 to disappear
Aug 27 06:24:00.128: INFO: Pod downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:24:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4360" for this suite. 08/27/22 06:24:00.132
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":190,"skipped":3570,"failed":0}
------------------------------
â€¢ [4.100 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:23:56.044
    Aug 27 06:23:56.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:23:56.046
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:23:56.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:23:56.065
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:23:56.069
    Aug 27 06:23:56.074: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99" in namespace "downward-api-4360" to be "Succeeded or Failed"
    Aug 27 06:23:56.078: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3888ms
    Aug 27 06:23:58.082: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007358353s
    Aug 27 06:24:00.082: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007534442s
    STEP: Saw pod success 08/27/22 06:24:00.082
    Aug 27 06:24:00.082: INFO: Pod "downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99" satisfied condition "Succeeded or Failed"
    Aug 27 06:24:00.089: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99 container client-container: <nil>
    STEP: delete the pod 08/27/22 06:24:00.1
    Aug 27 06:24:00.125: INFO: Waiting for pod downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99 to disappear
    Aug 27 06:24:00.128: INFO: Pod downwardapi-volume-fc2f755c-cdfd-456e-9cbb-cb3437c6fd99 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:24:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4360" for this suite. 08/27/22 06:24:00.132
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:00.144
Aug 27 06:24:00.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename containers 08/27/22 06:24:00.145
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:00.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:00.19
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Aug 27 06:24:00.213: INFO: Waiting up to 5m0s for pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8" in namespace "containers-477" to be "running"
Aug 27 06:24:00.217: INFO: Pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.222528ms
Aug 27 06:24:02.220: INFO: Pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006973437s
Aug 27 06:24:02.220: INFO: Pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 27 06:24:02.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-477" for this suite. 08/27/22 06:24:02.245
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":191,"skipped":3571,"failed":0}
------------------------------
â€¢ [2.131 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:00.144
    Aug 27 06:24:00.144: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename containers 08/27/22 06:24:00.145
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:00.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:00.19
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Aug 27 06:24:00.213: INFO: Waiting up to 5m0s for pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8" in namespace "containers-477" to be "running"
    Aug 27 06:24:00.217: INFO: Pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.222528ms
    Aug 27 06:24:02.220: INFO: Pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006973437s
    Aug 27 06:24:02.220: INFO: Pod "client-containers-888152b9-3842-4a82-9c41-ab14714be3d8" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 27 06:24:02.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-477" for this suite. 08/27/22 06:24:02.245
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:02.297
Aug 27 06:24:02.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:24:02.298
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:02.367
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:02.395
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-545f6a16-0a8a-4f91-ba23-c465b2fb65c9 08/27/22 06:24:02.404
STEP: Creating secret with name secret-projected-all-test-volume-12a162eb-5fc7-4e76-aa13-8d1601c30403 08/27/22 06:24:02.409
STEP: Creating a pod to test Check all projections for projected volume plugin 08/27/22 06:24:02.438
Aug 27 06:24:02.456: INFO: Waiting up to 5m0s for pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba" in namespace "projected-5984" to be "Succeeded or Failed"
Aug 27 06:24:02.471: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba": Phase="Pending", Reason="", readiness=false. Elapsed: 14.433188ms
Aug 27 06:24:04.474: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018393415s
Aug 27 06:24:06.475: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01917235s
STEP: Saw pod success 08/27/22 06:24:06.475
Aug 27 06:24:06.475: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba" satisfied condition "Succeeded or Failed"
Aug 27 06:24:06.479: INFO: Trying to get logs from node ip-10-0-47-192 pod projected-volume-ef949e45-ae44-4b73-8721-bda962987aba container projected-all-volume-test: <nil>
STEP: delete the pod 08/27/22 06:24:06.485
Aug 27 06:24:06.502: INFO: Waiting for pod projected-volume-ef949e45-ae44-4b73-8721-bda962987aba to disappear
Aug 27 06:24:06.508: INFO: Pod projected-volume-ef949e45-ae44-4b73-8721-bda962987aba no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Aug 27 06:24:06.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5984" for this suite. 08/27/22 06:24:06.512
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":192,"skipped":3614,"failed":0}
------------------------------
â€¢ [4.221 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:02.297
    Aug 27 06:24:02.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:24:02.298
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:02.367
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:02.395
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-545f6a16-0a8a-4f91-ba23-c465b2fb65c9 08/27/22 06:24:02.404
    STEP: Creating secret with name secret-projected-all-test-volume-12a162eb-5fc7-4e76-aa13-8d1601c30403 08/27/22 06:24:02.409
    STEP: Creating a pod to test Check all projections for projected volume plugin 08/27/22 06:24:02.438
    Aug 27 06:24:02.456: INFO: Waiting up to 5m0s for pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba" in namespace "projected-5984" to be "Succeeded or Failed"
    Aug 27 06:24:02.471: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba": Phase="Pending", Reason="", readiness=false. Elapsed: 14.433188ms
    Aug 27 06:24:04.474: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018393415s
    Aug 27 06:24:06.475: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01917235s
    STEP: Saw pod success 08/27/22 06:24:06.475
    Aug 27 06:24:06.475: INFO: Pod "projected-volume-ef949e45-ae44-4b73-8721-bda962987aba" satisfied condition "Succeeded or Failed"
    Aug 27 06:24:06.479: INFO: Trying to get logs from node ip-10-0-47-192 pod projected-volume-ef949e45-ae44-4b73-8721-bda962987aba container projected-all-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:24:06.485
    Aug 27 06:24:06.502: INFO: Waiting for pod projected-volume-ef949e45-ae44-4b73-8721-bda962987aba to disappear
    Aug 27 06:24:06.508: INFO: Pod projected-volume-ef949e45-ae44-4b73-8721-bda962987aba no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Aug 27 06:24:06.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5984" for this suite. 08/27/22 06:24:06.512
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:06.519
Aug 27 06:24:06.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-runtime 08/27/22 06:24:06.52
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:06.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:06.556
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 08/27/22 06:24:06.567
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 08/27/22 06:24:25.667
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 08/27/22 06:24:25.671
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 08/27/22 06:24:25.68
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 08/27/22 06:24:25.68
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 08/27/22 06:24:25.703
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 08/27/22 06:24:28.72
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 08/27/22 06:24:30.731
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 08/27/22 06:24:30.737
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 08/27/22 06:24:30.737
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 08/27/22 06:24:30.753
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 08/27/22 06:24:31.761
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 08/27/22 06:24:34.793
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 08/27/22 06:24:34.799
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 08/27/22 06:24:34.799
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 27 06:24:34.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-738" for this suite. 08/27/22 06:24:34.873
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":193,"skipped":3615,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.366 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:06.519
    Aug 27 06:24:06.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-runtime 08/27/22 06:24:06.52
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:06.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:06.556
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 08/27/22 06:24:06.567
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 08/27/22 06:24:25.667
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 08/27/22 06:24:25.671
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 08/27/22 06:24:25.68
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 08/27/22 06:24:25.68
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 08/27/22 06:24:25.703
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 08/27/22 06:24:28.72
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 08/27/22 06:24:30.731
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 08/27/22 06:24:30.737
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 08/27/22 06:24:30.737
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 08/27/22 06:24:30.753
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 08/27/22 06:24:31.761
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 08/27/22 06:24:34.793
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 08/27/22 06:24:34.799
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 08/27/22 06:24:34.799
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 27 06:24:34.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-738" for this suite. 08/27/22 06:24:34.873
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:34.887
Aug 27 06:24:34.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:24:34.888
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:34.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:34.928
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 08/27/22 06:24:34.941
STEP: Creating a ResourceQuota 08/27/22 06:24:39.944
STEP: Ensuring resource quota status is calculated 08/27/22 06:24:39.951
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:24:41.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9317" for this suite. 08/27/22 06:24:41.957
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":194,"skipped":3625,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.074 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:34.887
    Aug 27 06:24:34.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:24:34.888
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:34.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:34.928
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 08/27/22 06:24:34.941
    STEP: Creating a ResourceQuota 08/27/22 06:24:39.944
    STEP: Ensuring resource quota status is calculated 08/27/22 06:24:39.951
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:24:41.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9317" for this suite. 08/27/22 06:24:41.957
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:41.964
Aug 27 06:24:41.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename security-context-test 08/27/22 06:24:41.965
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:41.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:41.993
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Aug 27 06:24:42.008: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999" in namespace "security-context-test-8789" to be "Succeeded or Failed"
Aug 27 06:24:42.012: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379407ms
Aug 27 06:24:44.016: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008191537s
Aug 27 06:24:46.016: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008052977s
Aug 27 06:24:48.017: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008621669s
Aug 27 06:24:48.017: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Aug 27 06:24:48.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8789" for this suite. 08/27/22 06:24:48.024
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":195,"skipped":3647,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.066 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:41.964
    Aug 27 06:24:41.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename security-context-test 08/27/22 06:24:41.965
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:41.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:41.993
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Aug 27 06:24:42.008: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999" in namespace "security-context-test-8789" to be "Succeeded or Failed"
    Aug 27 06:24:42.012: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379407ms
    Aug 27 06:24:44.016: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008191537s
    Aug 27 06:24:46.016: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008052977s
    Aug 27 06:24:48.017: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008621669s
    Aug 27 06:24:48.017: INFO: Pod "alpine-nnp-false-32da2495-0680-4240-b878-aad0f190f999" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Aug 27 06:24:48.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8789" for this suite. 08/27/22 06:24:48.024
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:48.032
Aug 27 06:24:48.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:24:48.033
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:48.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:48.055
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 27 06:24:48.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1287" for this suite. 08/27/22 06:24:48.068
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":196,"skipped":3660,"failed":0}
------------------------------
â€¢ [0.041 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:48.032
    Aug 27 06:24:48.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:24:48.033
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:48.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:48.055
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 27 06:24:48.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1287" for this suite. 08/27/22 06:24:48.068
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:48.077
Aug 27 06:24:48.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:24:48.08
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:48.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:48.1
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 08/27/22 06:24:48.103
Aug 27 06:24:48.104: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-3389 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 08/27/22 06:24:48.153
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:24:48.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3389" for this suite. 08/27/22 06:24:48.171
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":197,"skipped":3673,"failed":0}
------------------------------
â€¢ [0.098 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:48.077
    Aug 27 06:24:48.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:24:48.08
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:48.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:48.1
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 08/27/22 06:24:48.103
    Aug 27 06:24:48.104: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-3389 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 08/27/22 06:24:48.153
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:24:48.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3389" for this suite. 08/27/22 06:24:48.171
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:48.176
Aug 27 06:24:48.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:24:48.177
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:48.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:48.199
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 08/27/22 06:24:48.203
Aug 27 06:24:48.208: INFO: Waiting up to 5m0s for pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db" in namespace "projected-2095" to be "running and ready"
Aug 27 06:24:48.215: INFO: Pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.715997ms
Aug 27 06:24:48.215: INFO: The phase of Pod annotationupdate6e469b86-d83a-44df-808a-3731bec316db is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:24:50.220: INFO: Pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db": Phase="Running", Reason="", readiness=true. Elapsed: 2.011200593s
Aug 27 06:24:50.220: INFO: The phase of Pod annotationupdate6e469b86-d83a-44df-808a-3731bec316db is Running (Ready = true)
Aug 27 06:24:50.220: INFO: Pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db" satisfied condition "running and ready"
Aug 27 06:24:50.743: INFO: Successfully updated pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:24:54.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2095" for this suite. 08/27/22 06:24:54.793
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":198,"skipped":3696,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.625 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:48.176
    Aug 27 06:24:48.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:24:48.177
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:48.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:48.199
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 08/27/22 06:24:48.203
    Aug 27 06:24:48.208: INFO: Waiting up to 5m0s for pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db" in namespace "projected-2095" to be "running and ready"
    Aug 27 06:24:48.215: INFO: Pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.715997ms
    Aug 27 06:24:48.215: INFO: The phase of Pod annotationupdate6e469b86-d83a-44df-808a-3731bec316db is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:24:50.220: INFO: Pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db": Phase="Running", Reason="", readiness=true. Elapsed: 2.011200593s
    Aug 27 06:24:50.220: INFO: The phase of Pod annotationupdate6e469b86-d83a-44df-808a-3731bec316db is Running (Ready = true)
    Aug 27 06:24:50.220: INFO: Pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db" satisfied condition "running and ready"
    Aug 27 06:24:50.743: INFO: Successfully updated pod "annotationupdate6e469b86-d83a-44df-808a-3731bec316db"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:24:54.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2095" for this suite. 08/27/22 06:24:54.793
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:24:54.805
Aug 27 06:24:54.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 06:24:54.806
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:54.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:54.827
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 08/27/22 06:24:54.833
STEP: waiting for Deployment to be created 08/27/22 06:24:54.838
STEP: waiting for all Replicas to be Ready 08/27/22 06:24:54.841
Aug 27 06:24:54.847: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.848: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.859: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.859: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.903: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.903: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.964: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:54.964: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 27 06:24:56.531: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 27 06:24:56.531: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 27 06:24:58.089: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 08/27/22 06:24:58.089
W0827 06:24:58.100411      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 27 06:24:58.105: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 08/27/22 06:24:58.105
Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.125: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.125: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.155: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.155: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:58.209: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:24:58.209: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:24:59.550: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:59.550: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:24:59.589: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
STEP: listing Deployments 08/27/22 06:24:59.589
Aug 27 06:24:59.593: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 08/27/22 06:24:59.593
Aug 27 06:24:59.620: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 08/27/22 06:24:59.62
Aug 27 06:24:59.639: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:24:59.648: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:24:59.727: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:24:59.780: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:24:59.807: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:25:01.244: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:25:01.285: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:25:01.342: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 27 06:25:02.638: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 08/27/22 06:25:02.827
STEP: fetching the DeploymentStatus 08/27/22 06:25:02.861
Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:25:02.895: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:25:02.895: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
Aug 27 06:25:02.895: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 3
STEP: deleting the Deployment 08/27/22 06:25:02.895
Aug 27 06:25:03.043: INFO: observed event type MODIFIED
Aug 27 06:25:03.043: INFO: observed event type MODIFIED
Aug 27 06:25:03.043: INFO: observed event type MODIFIED
Aug 27 06:25:03.044: INFO: observed event type MODIFIED
Aug 27 06:25:03.044: INFO: observed event type MODIFIED
Aug 27 06:25:03.044: INFO: observed event type MODIFIED
Aug 27 06:25:03.044: INFO: observed event type MODIFIED
Aug 27 06:25:03.045: INFO: observed event type MODIFIED
Aug 27 06:25:03.045: INFO: observed event type MODIFIED
Aug 27 06:25:03.045: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 06:25:03.124: INFO: Log out all the ReplicaSets if there is no deployment created
Aug 27 06:25:03.241: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-2937  4801f320-5aaa-4fec-9396-1437a38392cc 19897 4 2022-08-27 06:24:58 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment b07972b1-e39a-44ee-89d5-bb2ee22a7f6d 0xc003ee41b7 0xc003ee41b8}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b07972b1-e39a-44ee-89d5-bb2ee22a7f6d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ee4240 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Aug 27 06:25:03.256: INFO: pod: "test-deployment-54cc775c4b-frplz":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-frplz test-deployment-54cc775c4b- deployment-2937  c078418d-7a6c-4dae-b806-4545baac4d85 19893 0 2022-08-27 06:24:58 +0000 UTC 2022-08-27 06:25:03 +0000 UTC 0xc003a70840 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:b749660a272e4663f8e253692f92b1bdeb7ff91834047497da0eb8440ef46657 cni.projectcalico.org/podIP:10.2.35.212/32 cni.projectcalico.org/podIPs:10.2.35.212/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 4801f320-5aaa-4fec-9396-1437a38392cc 0xc003a708b7 0xc003a708b8}] [] [{Go-http-client Update v1 2022-08-27 06:24:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 06:24:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4801f320-5aaa-4fec-9396-1437a38392cc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.212\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wzfhb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wzfhb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.212,StartTime:2022-08-27 06:24:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:24:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://0127056e5476676df5f22b3ef571a07f39a42c864027a05e859c116a113d3a69,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.212,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 27 06:25:03.256: INFO: pod: "test-deployment-54cc775c4b-hs97j":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-hs97j test-deployment-54cc775c4b- deployment-2937  a0f771c5-ec94-4b5e-9b4e-1e3ac6e6dc59 19864 0 2022-08-27 06:24:59 +0000 UTC 2022-08-27 06:25:02 +0000 UTC 0xc003a70ab0 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:a66561dbfbc57a5c0ce41c08c9af22be79a6cf581d19393de63817ce4b028233 cni.projectcalico.org/podIP:10.2.137.144/32 cni.projectcalico.org/podIPs:10.2.137.144/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 4801f320-5aaa-4fec-9396-1437a38392cc 0xc003a70b07 0xc003a70b08}] [] [{kube-controller-manager Update v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4801f320-5aaa-4fec-9396-1437a38392cc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:25:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59bgt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59bgt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.144,StartTime:2022-08-27 06:24:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:25:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://9cd72f4205007e4ece6fc70a418b32aa7c23311b7101771744604cf14c7c3d30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 27 06:25:03.256: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-2937  e2bb9172-e974-4f7d-aa82-b20e86f2770a 19889 2 2022-08-27 06:24:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment b07972b1-e39a-44ee-89d5-bb2ee22a7f6d 0xc003ee42a7 0xc003ee42a8}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b07972b1-e39a-44ee-89d5-bb2ee22a7f6d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ee4330 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Aug 27 06:25:03.343: INFO: pod: "test-deployment-7c7d8d58c8-bgtpn":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-bgtpn test-deployment-7c7d8d58c8- deployment-2937  3b87df9b-dfe1-4ab3-bf34-4a007b0f7860 19888 0 2022-08-27 06:25:01 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:c78b10daa85ee9f4614295623331a087097dfe19fc6c0f901f1ab685c3d70fb6 cni.projectcalico.org/podIP:10.2.35.213/32 cni.projectcalico.org/podIPs:10.2.35.213/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e2bb9172-e974-4f7d-aa82-b20e86f2770a 0xc003ee4707 0xc003ee4708}] [] [{kube-controller-manager Update v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e2bb9172-e974-4f7d-aa82-b20e86f2770a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.213\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwzhq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwzhq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.213,StartTime:2022-08-27 06:25:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:25:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e12198ff47c4b5d4faef2b8c01e6a99a5197efb64d307ccb06a66f397f242d73,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 27 06:25:03.346: INFO: pod: "test-deployment-7c7d8d58c8-kccd2":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-kccd2 test-deployment-7c7d8d58c8- deployment-2937  d2b31765-9778-4376-8ae9-d7473e640c84 19858 0 2022-08-27 06:24:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:d0c955d0591ef2bb97076be9f05d1ddce260ce331ab34d3a8c50f599cdc02c05 cni.projectcalico.org/podIP:10.2.137.145/32 cni.projectcalico.org/podIPs:10.2.137.145/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e2bb9172-e974-4f7d-aa82-b20e86f2770a 0xc003ee4957 0xc003ee4958}] [] [{kube-controller-manager Update v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e2bb9172-e974-4f7d-aa82-b20e86f2770a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:25:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5g554,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5g554,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.145,StartTime:2022-08-27 06:24:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:25:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f39471a120eecccac30ec00fd85fb78778515c05d402902a1142199ed4686eb6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 27 06:25:03.346: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-2937  092022d7-d7d1-479e-8a12-782a5f0fa6b5 19790 3 2022-08-27 06:24:54 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment b07972b1-e39a-44ee-89d5-bb2ee22a7f6d 0xc003ee4397 0xc003ee4398}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b07972b1-e39a-44ee-89d5-bb2ee22a7f6d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ee4430 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 06:25:03.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2937" for this suite. 08/27/22 06:25:03.397
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":199,"skipped":3709,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.689 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:24:54.805
    Aug 27 06:24:54.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 06:24:54.806
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:24:54.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:24:54.827
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 08/27/22 06:24:54.833
    STEP: waiting for Deployment to be created 08/27/22 06:24:54.838
    STEP: waiting for all Replicas to be Ready 08/27/22 06:24:54.841
    Aug 27 06:24:54.847: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.848: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.859: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.859: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.903: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.903: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.964: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:54.964: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Aug 27 06:24:56.531: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Aug 27 06:24:56.531: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Aug 27 06:24:58.089: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 08/27/22 06:24:58.089
    W0827 06:24:58.100411      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 27 06:24:58.105: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 08/27/22 06:24:58.105
    Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.117: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 0
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.118: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.125: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.125: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.155: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.155: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:58.209: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:24:58.209: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:24:59.550: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:59.550: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:24:59.589: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    STEP: listing Deployments 08/27/22 06:24:59.589
    Aug 27 06:24:59.593: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 08/27/22 06:24:59.593
    Aug 27 06:24:59.620: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 08/27/22 06:24:59.62
    Aug 27 06:24:59.639: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:24:59.648: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:24:59.727: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:24:59.780: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:24:59.807: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:25:01.244: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:25:01.285: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:25:01.342: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Aug 27 06:25:02.638: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 08/27/22 06:25:02.827
    STEP: fetching the DeploymentStatus 08/27/22 06:25:02.861
    Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 1
    Aug 27 06:25:02.894: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:25:02.895: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:25:02.895: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 2
    Aug 27 06:25:02.895: INFO: observed Deployment test-deployment in namespace deployment-2937 with ReadyReplicas 3
    STEP: deleting the Deployment 08/27/22 06:25:02.895
    Aug 27 06:25:03.043: INFO: observed event type MODIFIED
    Aug 27 06:25:03.043: INFO: observed event type MODIFIED
    Aug 27 06:25:03.043: INFO: observed event type MODIFIED
    Aug 27 06:25:03.044: INFO: observed event type MODIFIED
    Aug 27 06:25:03.044: INFO: observed event type MODIFIED
    Aug 27 06:25:03.044: INFO: observed event type MODIFIED
    Aug 27 06:25:03.044: INFO: observed event type MODIFIED
    Aug 27 06:25:03.045: INFO: observed event type MODIFIED
    Aug 27 06:25:03.045: INFO: observed event type MODIFIED
    Aug 27 06:25:03.045: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 06:25:03.124: INFO: Log out all the ReplicaSets if there is no deployment created
    Aug 27 06:25:03.241: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-2937  4801f320-5aaa-4fec-9396-1437a38392cc 19897 4 2022-08-27 06:24:58 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment b07972b1-e39a-44ee-89d5-bb2ee22a7f6d 0xc003ee41b7 0xc003ee41b8}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b07972b1-e39a-44ee-89d5-bb2ee22a7f6d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ee4240 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Aug 27 06:25:03.256: INFO: pod: "test-deployment-54cc775c4b-frplz":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-frplz test-deployment-54cc775c4b- deployment-2937  c078418d-7a6c-4dae-b806-4545baac4d85 19893 0 2022-08-27 06:24:58 +0000 UTC 2022-08-27 06:25:03 +0000 UTC 0xc003a70840 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:b749660a272e4663f8e253692f92b1bdeb7ff91834047497da0eb8440ef46657 cni.projectcalico.org/podIP:10.2.35.212/32 cni.projectcalico.org/podIPs:10.2.35.212/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 4801f320-5aaa-4fec-9396-1437a38392cc 0xc003a708b7 0xc003a708b8}] [] [{Go-http-client Update v1 2022-08-27 06:24:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 06:24:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4801f320-5aaa-4fec-9396-1437a38392cc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.212\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wzfhb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wzfhb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.212,StartTime:2022-08-27 06:24:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:24:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://0127056e5476676df5f22b3ef571a07f39a42c864027a05e859c116a113d3a69,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.212,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 27 06:25:03.256: INFO: pod: "test-deployment-54cc775c4b-hs97j":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-hs97j test-deployment-54cc775c4b- deployment-2937  a0f771c5-ec94-4b5e-9b4e-1e3ac6e6dc59 19864 0 2022-08-27 06:24:59 +0000 UTC 2022-08-27 06:25:02 +0000 UTC 0xc003a70ab0 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:a66561dbfbc57a5c0ce41c08c9af22be79a6cf581d19393de63817ce4b028233 cni.projectcalico.org/podIP:10.2.137.144/32 cni.projectcalico.org/podIPs:10.2.137.144/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 4801f320-5aaa-4fec-9396-1437a38392cc 0xc003a70b07 0xc003a70b08}] [] [{kube-controller-manager Update v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4801f320-5aaa-4fec-9396-1437a38392cc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:25:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-59bgt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-59bgt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.144,StartTime:2022-08-27 06:24:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:25:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://9cd72f4205007e4ece6fc70a418b32aa7c23311b7101771744604cf14c7c3d30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 27 06:25:03.256: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-2937  e2bb9172-e974-4f7d-aa82-b20e86f2770a 19889 2 2022-08-27 06:24:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment b07972b1-e39a-44ee-89d5-bb2ee22a7f6d 0xc003ee42a7 0xc003ee42a8}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b07972b1-e39a-44ee-89d5-bb2ee22a7f6d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ee4330 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Aug 27 06:25:03.343: INFO: pod: "test-deployment-7c7d8d58c8-bgtpn":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-bgtpn test-deployment-7c7d8d58c8- deployment-2937  3b87df9b-dfe1-4ab3-bf34-4a007b0f7860 19888 0 2022-08-27 06:25:01 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:c78b10daa85ee9f4614295623331a087097dfe19fc6c0f901f1ab685c3d70fb6 cni.projectcalico.org/podIP:10.2.35.213/32 cni.projectcalico.org/podIPs:10.2.35.213/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e2bb9172-e974-4f7d-aa82-b20e86f2770a 0xc003ee4707 0xc003ee4708}] [] [{kube-controller-manager Update v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e2bb9172-e974-4f7d-aa82-b20e86f2770a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:25:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.213\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwzhq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwzhq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.213,StartTime:2022-08-27 06:25:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:25:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://e12198ff47c4b5d4faef2b8c01e6a99a5197efb64d307ccb06a66f397f242d73,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 27 06:25:03.346: INFO: pod: "test-deployment-7c7d8d58c8-kccd2":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-kccd2 test-deployment-7c7d8d58c8- deployment-2937  d2b31765-9778-4376-8ae9-d7473e640c84 19858 0 2022-08-27 06:24:59 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:d0c955d0591ef2bb97076be9f05d1ddce260ce331ab34d3a8c50f599cdc02c05 cni.projectcalico.org/podIP:10.2.137.145/32 cni.projectcalico.org/podIPs:10.2.137.145/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 e2bb9172-e974-4f7d-aa82-b20e86f2770a 0xc003ee4957 0xc003ee4958}] [] [{kube-controller-manager Update v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e2bb9172-e974-4f7d-aa82-b20e86f2770a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 06:25:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 06:25:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5g554,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5g554,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:25:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:24:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.145,StartTime:2022-08-27 06:24:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 06:25:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f39471a120eecccac30ec00fd85fb78778515c05d402902a1142199ed4686eb6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Aug 27 06:25:03.346: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-2937  092022d7-d7d1-479e-8a12-782a5f0fa6b5 19790 3 2022-08-27 06:24:54 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment b07972b1-e39a-44ee-89d5-bb2ee22a7f6d 0xc003ee4397 0xc003ee4398}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b07972b1-e39a-44ee-89d5-bb2ee22a7f6d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:24:59 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003ee4430 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 06:25:03.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2937" for this suite. 08/27/22 06:25:03.397
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:25:03.5
Aug 27 06:25:03.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 06:25:03.501
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:25:03.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:25:03.691
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Aug 27 06:25:03.760: INFO: Waiting up to 2m0s for pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" in namespace "var-expansion-3810" to be "container 0 failed with reason CreateContainerConfigError"
Aug 27 06:25:03.774: INFO: Pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195": Phase="Pending", Reason="", readiness=false. Elapsed: 13.751158ms
Aug 27 06:25:05.781: INFO: Pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020911744s
Aug 27 06:25:05.781: INFO: Pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Aug 27 06:25:05.781: INFO: Deleting pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" in namespace "var-expansion-3810"
Aug 27 06:25:05.788: INFO: Wait up to 5m0s for pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 06:25:09.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3810" for this suite. 08/27/22 06:25:09.799
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":200,"skipped":3720,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.309 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:25:03.5
    Aug 27 06:25:03.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 06:25:03.501
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:25:03.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:25:03.691
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Aug 27 06:25:03.760: INFO: Waiting up to 2m0s for pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" in namespace "var-expansion-3810" to be "container 0 failed with reason CreateContainerConfigError"
    Aug 27 06:25:03.774: INFO: Pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195": Phase="Pending", Reason="", readiness=false. Elapsed: 13.751158ms
    Aug 27 06:25:05.781: INFO: Pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020911744s
    Aug 27 06:25:05.781: INFO: Pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Aug 27 06:25:05.781: INFO: Deleting pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" in namespace "var-expansion-3810"
    Aug 27 06:25:05.788: INFO: Wait up to 5m0s for pod "var-expansion-b062f1cf-9267-4106-9a73-2e00526e4195" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 06:25:09.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3810" for this suite. 08/27/22 06:25:09.799
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:25:09.814
Aug 27 06:25:09.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 06:25:09.814
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:25:09.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:25:09.835
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Aug 27 06:25:09.852: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 06:25:09.858
Aug 27 06:25:09.862: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:09.864: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:25:09.864: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:25:10.871: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:10.874: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:25:10.875: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:25:11.872: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:11.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 06:25:11.883: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image. 08/27/22 06:25:11.895
STEP: Check that daemon pods images are updated. 08/27/22 06:25:11.909
Aug 27 06:25:11.916: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 27 06:25:11.916: INFO: Wrong image for pod: daemon-set-p2vgc. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 27 06:25:11.921: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:12.939: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 27 06:25:12.954: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:13.926: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 27 06:25:13.930: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:14.925: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Aug 27 06:25:14.925: INFO: Pod daemon-set-jvtnh is not available
Aug 27 06:25:14.928: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:15.934: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:16.941: INFO: Pod daemon-set-wbxrc is not available
Aug 27 06:25:16.946: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 08/27/22 06:25:16.946
Aug 27 06:25:16.957: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:16.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 06:25:16.966: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:25:17.969: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:25:17.972: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 06:25:17.972: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/27/22 06:25:17.984
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9415, will wait for the garbage collector to delete the pods 08/27/22 06:25:17.984
Aug 27 06:25:18.042: INFO: Deleting DaemonSet.extensions daemon-set took: 4.611067ms
Aug 27 06:25:18.142: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.743093ms
Aug 27 06:25:20.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:25:20.347: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 27 06:25:20.356: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20156"},"items":null}

Aug 27 06:25:20.360: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20156"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:25:20.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9415" for this suite. 08/27/22 06:25:20.374
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":201,"skipped":3775,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.565 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:25:09.814
    Aug 27 06:25:09.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 06:25:09.814
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:25:09.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:25:09.835
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Aug 27 06:25:09.852: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 08/27/22 06:25:09.858
    Aug 27 06:25:09.862: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:09.864: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:25:09.864: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:25:10.871: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:10.874: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:25:10.875: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:25:11.872: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:11.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 06:25:11.883: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Update daemon pods image. 08/27/22 06:25:11.895
    STEP: Check that daemon pods images are updated. 08/27/22 06:25:11.909
    Aug 27 06:25:11.916: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 27 06:25:11.916: INFO: Wrong image for pod: daemon-set-p2vgc. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 27 06:25:11.921: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:12.939: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 27 06:25:12.954: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:13.926: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 27 06:25:13.930: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:14.925: INFO: Wrong image for pod: daemon-set-8ndzx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Aug 27 06:25:14.925: INFO: Pod daemon-set-jvtnh is not available
    Aug 27 06:25:14.928: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:15.934: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:16.941: INFO: Pod daemon-set-wbxrc is not available
    Aug 27 06:25:16.946: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 08/27/22 06:25:16.946
    Aug 27 06:25:16.957: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:16.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 06:25:16.966: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:25:17.969: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:25:17.972: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 06:25:17.972: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/27/22 06:25:17.984
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9415, will wait for the garbage collector to delete the pods 08/27/22 06:25:17.984
    Aug 27 06:25:18.042: INFO: Deleting DaemonSet.extensions daemon-set took: 4.611067ms
    Aug 27 06:25:18.142: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.743093ms
    Aug 27 06:25:20.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:25:20.347: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 27 06:25:20.356: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20156"},"items":null}

    Aug 27 06:25:20.360: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20156"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:25:20.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9415" for this suite. 08/27/22 06:25:20.374
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:25:20.379
Aug 27 06:25:20.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename taint-single-pod 08/27/22 06:25:20.38
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:25:20.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:25:20.406
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Aug 27 06:25:20.411: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 06:26:20.430: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Aug 27 06:26:20.433: INFO: Starting informer...
STEP: Starting pod... 08/27/22 06:26:20.434
Aug 27 06:26:20.658: INFO: Pod is running on ip-10-0-47-192. Tainting Node
STEP: Trying to apply a taint on the Node 08/27/22 06:26:20.658
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 06:26:20.672
STEP: Waiting short time to make sure Pod is queued for deletion 08/27/22 06:26:20.689
Aug 27 06:26:20.689: INFO: Pod wasn't evicted. Proceeding
Aug 27 06:26:20.689: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 06:26:20.755
STEP: Waiting some time to make sure that toleration time passed. 08/27/22 06:26:20.783
Aug 27 06:27:35.786: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:27:35.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-6221" for this suite. 08/27/22 06:27:35.79
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":202,"skipped":3776,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.421 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:25:20.379
    Aug 27 06:25:20.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename taint-single-pod 08/27/22 06:25:20.38
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:25:20.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:25:20.406
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Aug 27 06:25:20.411: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 27 06:26:20.430: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Aug 27 06:26:20.433: INFO: Starting informer...
    STEP: Starting pod... 08/27/22 06:26:20.434
    Aug 27 06:26:20.658: INFO: Pod is running on ip-10-0-47-192. Tainting Node
    STEP: Trying to apply a taint on the Node 08/27/22 06:26:20.658
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 06:26:20.672
    STEP: Waiting short time to make sure Pod is queued for deletion 08/27/22 06:26:20.689
    Aug 27 06:26:20.689: INFO: Pod wasn't evicted. Proceeding
    Aug 27 06:26:20.689: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 06:26:20.755
    STEP: Waiting some time to make sure that toleration time passed. 08/27/22 06:26:20.783
    Aug 27 06:27:35.786: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:27:35.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-6221" for this suite. 08/27/22 06:27:35.79
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:35.804
Aug 27 06:27:35.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:27:35.805
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:35.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:35.849
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 27 06:27:39.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4981" for this suite. 08/27/22 06:27:39.898
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":203,"skipped":3807,"failed":0}
------------------------------
â€¢ [4.098 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:35.804
    Aug 27 06:27:35.805: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:27:35.805
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:35.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:35.849
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 27 06:27:39.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4981" for this suite. 08/27/22 06:27:39.898
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:39.905
Aug 27 06:27:39.905: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename tables 08/27/22 06:27:39.906
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:39.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:39.925
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Aug 27 06:27:39.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9952" for this suite. 08/27/22 06:27:39.941
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":204,"skipped":3861,"failed":0}
------------------------------
â€¢ [0.042 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:39.905
    Aug 27 06:27:39.905: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename tables 08/27/22 06:27:39.906
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:39.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:39.925
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Aug 27 06:27:39.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-9952" for this suite. 08/27/22 06:27:39.941
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:39.948
Aug 27 06:27:39.949: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-runtime 08/27/22 06:27:39.949
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:39.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:39.997
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 08/27/22 06:27:40.015
STEP: wait for the container to reach Succeeded 08/27/22 06:27:40.035
STEP: get the container status 08/27/22 06:27:44.06
STEP: the container should be terminated 08/27/22 06:27:44.062
STEP: the termination message should be set 08/27/22 06:27:44.062
Aug 27 06:27:44.063: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 08/27/22 06:27:44.063
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 27 06:27:44.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-767" for this suite. 08/27/22 06:27:44.077
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":205,"skipped":3875,"failed":0}
------------------------------
â€¢ [4.133 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:39.948
    Aug 27 06:27:39.949: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-runtime 08/27/22 06:27:39.949
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:39.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:39.997
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 08/27/22 06:27:40.015
    STEP: wait for the container to reach Succeeded 08/27/22 06:27:40.035
    STEP: get the container status 08/27/22 06:27:44.06
    STEP: the container should be terminated 08/27/22 06:27:44.062
    STEP: the termination message should be set 08/27/22 06:27:44.062
    Aug 27 06:27:44.063: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 08/27/22 06:27:44.063
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 27 06:27:44.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-767" for this suite. 08/27/22 06:27:44.077
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:44.094
Aug 27 06:27:44.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir-wrapper 08/27/22 06:27:44.095
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:44.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:44.119
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Aug 27 06:27:44.139: INFO: Waiting up to 5m0s for pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8" in namespace "emptydir-wrapper-2126" to be "running and ready"
Aug 27 06:27:44.142: INFO: Pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.438174ms
Aug 27 06:27:44.142: INFO: The phase of Pod pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:27:46.146: INFO: Pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006635735s
Aug 27 06:27:46.146: INFO: The phase of Pod pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8 is Running (Ready = true)
Aug 27 06:27:46.146: INFO: Pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8" satisfied condition "running and ready"
STEP: Cleaning up the secret 08/27/22 06:27:46.15
STEP: Cleaning up the configmap 08/27/22 06:27:46.155
STEP: Cleaning up the pod 08/27/22 06:27:46.159
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Aug 27 06:27:46.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2126" for this suite. 08/27/22 06:27:46.174
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":206,"skipped":3900,"failed":0}
------------------------------
â€¢ [2.092 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:44.094
    Aug 27 06:27:44.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir-wrapper 08/27/22 06:27:44.095
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:44.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:44.119
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Aug 27 06:27:44.139: INFO: Waiting up to 5m0s for pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8" in namespace "emptydir-wrapper-2126" to be "running and ready"
    Aug 27 06:27:44.142: INFO: Pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.438174ms
    Aug 27 06:27:44.142: INFO: The phase of Pod pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:27:46.146: INFO: Pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006635735s
    Aug 27 06:27:46.146: INFO: The phase of Pod pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8 is Running (Ready = true)
    Aug 27 06:27:46.146: INFO: Pod "pod-secrets-9e60239d-b192-4ca9-b3bb-ffa97ccfc9e8" satisfied condition "running and ready"
    STEP: Cleaning up the secret 08/27/22 06:27:46.15
    STEP: Cleaning up the configmap 08/27/22 06:27:46.155
    STEP: Cleaning up the pod 08/27/22 06:27:46.159
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:27:46.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-2126" for this suite. 08/27/22 06:27:46.174
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:46.192
Aug 27 06:27:46.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename job 08/27/22 06:27:46.193
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:46.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:46.222
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 08/27/22 06:27:46.237
STEP: Patching the Job 08/27/22 06:27:46.241
STEP: Watching for Job to be patched 08/27/22 06:27:46.25
Aug 27 06:27:46.255: INFO: Event ADDED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd] and annotations: map[batch.kubernetes.io/job-tracking:]
Aug 27 06:27:46.255: INFO: Event MODIFIED found for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 08/27/22 06:27:46.255
STEP: Watching for Job to be updated 08/27/22 06:27:46.272
Aug 27 06:27:46.278: INFO: Event MODIFIED found for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:46.278: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 08/27/22 06:27:46.278
Aug 27 06:27:46.287: INFO: Job: e2e-ldjmd as labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched]
STEP: Waiting for job to complete 08/27/22 06:27:46.287
STEP: Delete a job collection with a labelselector 08/27/22 06:27:54.292
STEP: Watching for Job to be deleted 08/27/22 06:27:54.297
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Aug 27 06:27:54.305: INFO: Event DELETED found for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 08/27/22 06:27:54.305
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 27 06:27:54.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-467" for this suite. 08/27/22 06:27:54.331
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":207,"skipped":3959,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.153 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:46.192
    Aug 27 06:27:46.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename job 08/27/22 06:27:46.193
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:46.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:46.222
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 08/27/22 06:27:46.237
    STEP: Patching the Job 08/27/22 06:27:46.241
    STEP: Watching for Job to be patched 08/27/22 06:27:46.25
    Aug 27 06:27:46.255: INFO: Event ADDED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd] and annotations: map[batch.kubernetes.io/job-tracking:]
    Aug 27 06:27:46.255: INFO: Event MODIFIED found for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 08/27/22 06:27:46.255
    STEP: Watching for Job to be updated 08/27/22 06:27:46.272
    Aug 27 06:27:46.278: INFO: Event MODIFIED found for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:46.278: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 08/27/22 06:27:46.278
    Aug 27 06:27:46.287: INFO: Job: e2e-ldjmd as labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched]
    STEP: Waiting for job to complete 08/27/22 06:27:46.287
    STEP: Delete a job collection with a labelselector 08/27/22 06:27:54.292
    STEP: Watching for Job to be deleted 08/27/22 06:27:54.297
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.304: INFO: Event MODIFIED observed for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Aug 27 06:27:54.305: INFO: Event DELETED found for Job e2e-ldjmd in namespace job-467 with labels: map[e2e-job-label:e2e-ldjmd e2e-ldjmd:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 08/27/22 06:27:54.305
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 27 06:27:54.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-467" for this suite. 08/27/22 06:27:54.331
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:54.347
Aug 27 06:27:54.347: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:27:54.349
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:54.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:54.381
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-f9df036f-ec0e-4b8e-a53a-d03fdb048f51 08/27/22 06:27:54.385
STEP: Creating a pod to test consume secrets 08/27/22 06:27:54.389
Aug 27 06:27:54.395: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f" in namespace "projected-6791" to be "Succeeded or Failed"
Aug 27 06:27:54.402: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.96007ms
Aug 27 06:27:56.405: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009756495s
Aug 27 06:27:58.407: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011823944s
STEP: Saw pod success 08/27/22 06:27:58.407
Aug 27 06:27:58.407: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f" satisfied condition "Succeeded or Failed"
Aug 27 06:27:58.410: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f container projected-secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:27:58.425
Aug 27 06:27:58.434: INFO: Waiting for pod pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f to disappear
Aug 27 06:27:58.437: INFO: Pod pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 06:27:58.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6791" for this suite. 08/27/22 06:27:58.442
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":208,"skipped":3968,"failed":0}
------------------------------
â€¢ [4.101 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:54.347
    Aug 27 06:27:54.347: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:27:54.349
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:54.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:54.381
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-f9df036f-ec0e-4b8e-a53a-d03fdb048f51 08/27/22 06:27:54.385
    STEP: Creating a pod to test consume secrets 08/27/22 06:27:54.389
    Aug 27 06:27:54.395: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f" in namespace "projected-6791" to be "Succeeded or Failed"
    Aug 27 06:27:54.402: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.96007ms
    Aug 27 06:27:56.405: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009756495s
    Aug 27 06:27:58.407: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011823944s
    STEP: Saw pod success 08/27/22 06:27:58.407
    Aug 27 06:27:58.407: INFO: Pod "pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f" satisfied condition "Succeeded or Failed"
    Aug 27 06:27:58.410: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:27:58.425
    Aug 27 06:27:58.434: INFO: Waiting for pod pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f to disappear
    Aug 27 06:27:58.437: INFO: Pod pod-projected-secrets-e009e505-b6e7-41cf-8f29-5e05cc73f11f no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 06:27:58.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6791" for this suite. 08/27/22 06:27:58.442
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:27:58.451
Aug 27 06:27:58.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:27:58.451
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:58.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:58.475
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-fea29aa8-9ea8-4cee-964b-baecc54c6de0 08/27/22 06:27:58.479
STEP: Creating a pod to test consume configMaps 08/27/22 06:27:58.482
Aug 27 06:27:58.491: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3" in namespace "configmap-7466" to be "Succeeded or Failed"
Aug 27 06:27:58.498: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.382014ms
Aug 27 06:28:00.503: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011583053s
Aug 27 06:28:02.502: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010802776s
STEP: Saw pod success 08/27/22 06:28:02.502
Aug 27 06:28:02.502: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3" satisfied condition "Succeeded or Failed"
Aug 27 06:28:02.506: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:28:02.523
Aug 27 06:28:02.555: INFO: Waiting for pod pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3 to disappear
Aug 27 06:28:02.565: INFO: Pod pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:28:02.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7466" for this suite. 08/27/22 06:28:02.59
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":209,"skipped":3999,"failed":0}
------------------------------
â€¢ [4.156 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:27:58.451
    Aug 27 06:27:58.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:27:58.451
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:27:58.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:27:58.475
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-fea29aa8-9ea8-4cee-964b-baecc54c6de0 08/27/22 06:27:58.479
    STEP: Creating a pod to test consume configMaps 08/27/22 06:27:58.482
    Aug 27 06:27:58.491: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3" in namespace "configmap-7466" to be "Succeeded or Failed"
    Aug 27 06:27:58.498: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.382014ms
    Aug 27 06:28:00.503: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011583053s
    Aug 27 06:28:02.502: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010802776s
    STEP: Saw pod success 08/27/22 06:28:02.502
    Aug 27 06:28:02.502: INFO: Pod "pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3" satisfied condition "Succeeded or Failed"
    Aug 27 06:28:02.506: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:28:02.523
    Aug 27 06:28:02.555: INFO: Waiting for pod pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3 to disappear
    Aug 27 06:28:02.565: INFO: Pod pod-configmaps-bcde104c-8122-4114-9c30-de909c833ad3 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:28:02.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7466" for this suite. 08/27/22 06:28:02.59
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:28:02.607
Aug 27 06:28:02.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename disruption 08/27/22 06:28:02.609
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:02.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:02.691
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 08/27/22 06:28:02.712
STEP: Waiting for all pods to be running 08/27/22 06:28:04.828
Aug 27 06:28:04.857: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 27 06:28:06.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3325" for this suite. 08/27/22 06:28:06.867
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":210,"skipped":3999,"failed":0}
------------------------------
â€¢ [4.264 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:28:02.607
    Aug 27 06:28:02.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename disruption 08/27/22 06:28:02.609
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:02.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:02.691
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 08/27/22 06:28:02.712
    STEP: Waiting for all pods to be running 08/27/22 06:28:04.828
    Aug 27 06:28:04.857: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 27 06:28:06.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3325" for this suite. 08/27/22 06:28:06.867
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:28:06.871
Aug 27 06:28:06.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:28:06.873
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:06.887
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:06.891
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Aug 27 06:28:06.906: INFO: Waiting up to 5m0s for pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7" in namespace "svcaccounts-9470" to be "running"
Aug 27 06:28:06.912: INFO: Pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.301153ms
Aug 27 06:28:08.915: INFO: Pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7": Phase="Running", Reason="", readiness=true. Elapsed: 2.00868198s
Aug 27 06:28:08.915: INFO: Pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7" satisfied condition "running"
STEP: reading a file in the container 08/27/22 06:28:08.915
Aug 27 06:28:08.916: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9470 pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 08/27/22 06:28:09.064
Aug 27 06:28:09.064: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9470 pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 08/27/22 06:28:09.369
Aug 27 06:28:09.369: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9470 pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Aug 27 06:28:09.612: INFO: Got root ca configmap in namespace "svcaccounts-9470"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 27 06:28:09.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9470" for this suite. 08/27/22 06:28:09.624
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":211,"skipped":4011,"failed":0}
------------------------------
â€¢ [2.758 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:28:06.871
    Aug 27 06:28:06.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:28:06.873
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:06.887
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:06.891
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Aug 27 06:28:06.906: INFO: Waiting up to 5m0s for pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7" in namespace "svcaccounts-9470" to be "running"
    Aug 27 06:28:06.912: INFO: Pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.301153ms
    Aug 27 06:28:08.915: INFO: Pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7": Phase="Running", Reason="", readiness=true. Elapsed: 2.00868198s
    Aug 27 06:28:08.915: INFO: Pod "pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7" satisfied condition "running"
    STEP: reading a file in the container 08/27/22 06:28:08.915
    Aug 27 06:28:08.916: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9470 pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 08/27/22 06:28:09.064
    Aug 27 06:28:09.064: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9470 pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 08/27/22 06:28:09.369
    Aug 27 06:28:09.369: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9470 pod-service-account-84e00ca6-4f5a-4db7-b568-6b1f4d3d14a7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Aug 27 06:28:09.612: INFO: Got root ca configmap in namespace "svcaccounts-9470"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 27 06:28:09.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9470" for this suite. 08/27/22 06:28:09.624
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:28:09.629
Aug 27 06:28:09.629: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:28:09.63
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:09.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:09.658
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 08/27/22 06:28:09.662
Aug 27 06:28:09.662: INFO: namespace kubectl-383
Aug 27 06:28:09.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 create -f -'
Aug 27 06:28:10.013: INFO: stderr: ""
Aug 27 06:28:10.013: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 08/27/22 06:28:10.013
Aug 27 06:28:11.017: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 06:28:11.017: INFO: Found 1 / 1
Aug 27 06:28:11.017: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 27 06:28:11.019: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 27 06:28:11.019: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 27 06:28:11.020: INFO: wait on agnhost-primary startup in kubectl-383 
Aug 27 06:28:11.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 logs agnhost-primary-ctkg8 agnhost-primary'
Aug 27 06:28:11.132: INFO: stderr: ""
Aug 27 06:28:11.132: INFO: stdout: "Paused\n"
STEP: exposing RC 08/27/22 06:28:11.132
Aug 27 06:28:11.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Aug 27 06:28:11.254: INFO: stderr: ""
Aug 27 06:28:11.255: INFO: stdout: "service/rm2 exposed\n"
Aug 27 06:28:11.284: INFO: Service rm2 in namespace kubectl-383 found.
STEP: exposing service 08/27/22 06:28:13.29
Aug 27 06:28:13.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Aug 27 06:28:13.410: INFO: stderr: ""
Aug 27 06:28:13.410: INFO: stdout: "service/rm3 exposed\n"
Aug 27 06:28:13.419: INFO: Service rm3 in namespace kubectl-383 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:28:15.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-383" for this suite. 08/27/22 06:28:15.429
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":212,"skipped":4014,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.805 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:28:09.629
    Aug 27 06:28:09.629: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:28:09.63
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:09.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:09.658
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 08/27/22 06:28:09.662
    Aug 27 06:28:09.662: INFO: namespace kubectl-383
    Aug 27 06:28:09.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 create -f -'
    Aug 27 06:28:10.013: INFO: stderr: ""
    Aug 27 06:28:10.013: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 08/27/22 06:28:10.013
    Aug 27 06:28:11.017: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 06:28:11.017: INFO: Found 1 / 1
    Aug 27 06:28:11.017: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Aug 27 06:28:11.019: INFO: Selector matched 1 pods for map[app:agnhost]
    Aug 27 06:28:11.019: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Aug 27 06:28:11.020: INFO: wait on agnhost-primary startup in kubectl-383 
    Aug 27 06:28:11.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 logs agnhost-primary-ctkg8 agnhost-primary'
    Aug 27 06:28:11.132: INFO: stderr: ""
    Aug 27 06:28:11.132: INFO: stdout: "Paused\n"
    STEP: exposing RC 08/27/22 06:28:11.132
    Aug 27 06:28:11.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Aug 27 06:28:11.254: INFO: stderr: ""
    Aug 27 06:28:11.255: INFO: stdout: "service/rm2 exposed\n"
    Aug 27 06:28:11.284: INFO: Service rm2 in namespace kubectl-383 found.
    STEP: exposing service 08/27/22 06:28:13.29
    Aug 27 06:28:13.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-383 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Aug 27 06:28:13.410: INFO: stderr: ""
    Aug 27 06:28:13.410: INFO: stdout: "service/rm3 exposed\n"
    Aug 27 06:28:13.419: INFO: Service rm3 in namespace kubectl-383 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:28:15.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-383" for this suite. 08/27/22 06:28:15.429
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:28:15.44
Aug 27 06:28:15.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename events 08/27/22 06:28:15.443
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:15.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:15.465
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 08/27/22 06:28:15.472
STEP: get a list of Events with a label in the current namespace 08/27/22 06:28:15.505
STEP: delete a list of events 08/27/22 06:28:15.51
Aug 27 06:28:15.510: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 08/27/22 06:28:15.546
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Aug 27 06:28:15.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2770" for this suite. 08/27/22 06:28:15.555
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":213,"skipped":4037,"failed":0}
------------------------------
â€¢ [0.133 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:28:15.44
    Aug 27 06:28:15.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename events 08/27/22 06:28:15.443
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:15.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:15.465
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 08/27/22 06:28:15.472
    STEP: get a list of Events with a label in the current namespace 08/27/22 06:28:15.505
    STEP: delete a list of events 08/27/22 06:28:15.51
    Aug 27 06:28:15.510: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 08/27/22 06:28:15.546
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Aug 27 06:28:15.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-2770" for this suite. 08/27/22 06:28:15.555
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:28:15.574
Aug 27 06:28:15.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename cronjob 08/27/22 06:28:15.575
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:15.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:15.621
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 08/27/22 06:28:15.63
STEP: Ensuring no jobs are scheduled 08/27/22 06:28:15.634
STEP: Ensuring no job exists by listing jobs explicitly 08/27/22 06:33:15.642
STEP: Removing cronjob 08/27/22 06:33:15.646
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 27 06:33:15.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6063" for this suite. 08/27/22 06:33:15.672
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":214,"skipped":4045,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.103 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:28:15.574
    Aug 27 06:28:15.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename cronjob 08/27/22 06:28:15.575
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:28:15.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:28:15.621
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 08/27/22 06:28:15.63
    STEP: Ensuring no jobs are scheduled 08/27/22 06:28:15.634
    STEP: Ensuring no job exists by listing jobs explicitly 08/27/22 06:33:15.642
    STEP: Removing cronjob 08/27/22 06:33:15.646
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 27 06:33:15.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6063" for this suite. 08/27/22 06:33:15.672
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:33:15.678
Aug 27 06:33:15.679: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename subpath 08/27/22 06:33:15.679
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:15.715
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:15.72
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/27/22 06:33:15.724
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-q9ct 08/27/22 06:33:15.734
STEP: Creating a pod to test atomic-volume-subpath 08/27/22 06:33:15.735
Aug 27 06:33:15.745: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-q9ct" in namespace "subpath-1753" to be "Succeeded or Failed"
Aug 27 06:33:15.756: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Pending", Reason="", readiness=false. Elapsed: 10.880033ms
Aug 27 06:33:17.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 2.015671985s
Aug 27 06:33:19.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 4.014201335s
Aug 27 06:33:21.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 6.014452685s
Aug 27 06:33:23.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 8.01508353s
Aug 27 06:33:25.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 10.015118685s
Aug 27 06:33:27.784: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 12.039154573s
Aug 27 06:33:29.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 14.015445528s
Aug 27 06:33:31.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 16.014114589s
Aug 27 06:33:33.761: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 18.015877224s
Aug 27 06:33:35.761: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 20.01620118s
Aug 27 06:33:37.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=false. Elapsed: 22.015512478s
Aug 27 06:33:39.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.014424743s
STEP: Saw pod success 08/27/22 06:33:39.759
Aug 27 06:33:39.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct" satisfied condition "Succeeded or Failed"
Aug 27 06:33:39.763: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-subpath-test-downwardapi-q9ct container test-container-subpath-downwardapi-q9ct: <nil>
STEP: delete the pod 08/27/22 06:33:39.779
Aug 27 06:33:39.789: INFO: Waiting for pod pod-subpath-test-downwardapi-q9ct to disappear
Aug 27 06:33:39.792: INFO: Pod pod-subpath-test-downwardapi-q9ct no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-q9ct 08/27/22 06:33:39.792
Aug 27 06:33:39.792: INFO: Deleting pod "pod-subpath-test-downwardapi-q9ct" in namespace "subpath-1753"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 27 06:33:39.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1753" for this suite. 08/27/22 06:33:39.799
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":215,"skipped":4054,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.139 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:33:15.678
    Aug 27 06:33:15.679: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename subpath 08/27/22 06:33:15.679
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:15.715
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:15.72
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/27/22 06:33:15.724
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-q9ct 08/27/22 06:33:15.734
    STEP: Creating a pod to test atomic-volume-subpath 08/27/22 06:33:15.735
    Aug 27 06:33:15.745: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-q9ct" in namespace "subpath-1753" to be "Succeeded or Failed"
    Aug 27 06:33:15.756: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Pending", Reason="", readiness=false. Elapsed: 10.880033ms
    Aug 27 06:33:17.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 2.015671985s
    Aug 27 06:33:19.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 4.014201335s
    Aug 27 06:33:21.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 6.014452685s
    Aug 27 06:33:23.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 8.01508353s
    Aug 27 06:33:25.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 10.015118685s
    Aug 27 06:33:27.784: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 12.039154573s
    Aug 27 06:33:29.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 14.015445528s
    Aug 27 06:33:31.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 16.014114589s
    Aug 27 06:33:33.761: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 18.015877224s
    Aug 27 06:33:35.761: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=true. Elapsed: 20.01620118s
    Aug 27 06:33:37.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Running", Reason="", readiness=false. Elapsed: 22.015512478s
    Aug 27 06:33:39.759: INFO: Pod "pod-subpath-test-downwardapi-q9ct": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.014424743s
    STEP: Saw pod success 08/27/22 06:33:39.759
    Aug 27 06:33:39.760: INFO: Pod "pod-subpath-test-downwardapi-q9ct" satisfied condition "Succeeded or Failed"
    Aug 27 06:33:39.763: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-subpath-test-downwardapi-q9ct container test-container-subpath-downwardapi-q9ct: <nil>
    STEP: delete the pod 08/27/22 06:33:39.779
    Aug 27 06:33:39.789: INFO: Waiting for pod pod-subpath-test-downwardapi-q9ct to disappear
    Aug 27 06:33:39.792: INFO: Pod pod-subpath-test-downwardapi-q9ct no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-q9ct 08/27/22 06:33:39.792
    Aug 27 06:33:39.792: INFO: Deleting pod "pod-subpath-test-downwardapi-q9ct" in namespace "subpath-1753"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 27 06:33:39.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1753" for this suite. 08/27/22 06:33:39.799
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:33:39.819
Aug 27 06:33:39.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 06:33:39.82
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:39.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:39.841
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Aug 27 06:33:39.844: INFO: Creating deployment "test-recreate-deployment"
Aug 27 06:33:39.849: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 27 06:33:39.858: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 27 06:33:41.866: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 27 06:33:41.869: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 27 06:33:41.878: INFO: Updating deployment test-recreate-deployment
Aug 27 06:33:41.878: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 06:33:42.173: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4710  6cbd3f73-5604-4d3a-98a1-2372350654c5 21547 2 2022-08-27 06:33:39 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-27 06:33:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00198ec68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-27 06:33:42 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-08-27 06:33:42 +0000 UTC,LastTransitionTime:2022-08-27 06:33:39 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug 27 06:33:42.181: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4710  f1a0c27a-f1c8-47bd-b27b-5a6ec0637099 21546 1 2022-08-27 06:33:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 6cbd3f73-5604-4d3a-98a1-2372350654c5 0xc0036986e0 0xc0036986e1}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6cbd3f73-5604-4d3a-98a1-2372350654c5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003698778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:33:42.181: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 27 06:33:42.181: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4710  8d4347c9-5e6c-4cb4-b78f-10591939e725 21535 2 2022-08-27 06:33:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 6cbd3f73-5604-4d3a-98a1-2372350654c5 0xc0036985b7 0xc0036985b8}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:33:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6cbd3f73-5604-4d3a-98a1-2372350654c5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:33:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003698678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 27 06:33:42.188: INFO: Pod "test-recreate-deployment-9d58999df-4f8k8" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-4f8k8 test-recreate-deployment-9d58999df- deployment-4710  731ebb5e-e237-4cc9-9e3f-f696f3e2c1e6 21545 0 2022-08-27 06:33:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f1a0c27a-f1c8-47bd-b27b-5a6ec0637099 0xc003698c00 0xc003698c01}] [] [{kube-controller-manager Update v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f1a0c27a-f1c8-47bd-b27b-5a6ec0637099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-568tv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-568tv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 06:33:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 06:33:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4710" for this suite. 08/27/22 06:33:42.193
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":216,"skipped":4079,"failed":0}
------------------------------
â€¢ [2.379 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:33:39.819
    Aug 27 06:33:39.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 06:33:39.82
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:39.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:39.841
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Aug 27 06:33:39.844: INFO: Creating deployment "test-recreate-deployment"
    Aug 27 06:33:39.849: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Aug 27 06:33:39.858: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Aug 27 06:33:41.866: INFO: Waiting deployment "test-recreate-deployment" to complete
    Aug 27 06:33:41.869: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Aug 27 06:33:41.878: INFO: Updating deployment test-recreate-deployment
    Aug 27 06:33:41.878: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 06:33:42.173: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-4710  6cbd3f73-5604-4d3a-98a1-2372350654c5 21547 2 2022-08-27 06:33:39 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-08-27 06:33:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00198ec68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-27 06:33:42 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-08-27 06:33:42 +0000 UTC,LastTransitionTime:2022-08-27 06:33:39 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Aug 27 06:33:42.181: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4710  f1a0c27a-f1c8-47bd-b27b-5a6ec0637099 21546 1 2022-08-27 06:33:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 6cbd3f73-5604-4d3a-98a1-2372350654c5 0xc0036986e0 0xc0036986e1}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6cbd3f73-5604-4d3a-98a1-2372350654c5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003698778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:33:42.181: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Aug 27 06:33:42.181: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4710  8d4347c9-5e6c-4cb4-b78f-10591939e725 21535 2 2022-08-27 06:33:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 6cbd3f73-5604-4d3a-98a1-2372350654c5 0xc0036985b7 0xc0036985b8}] [] [{kube-controller-manager Update apps/v1 2022-08-27 06:33:41 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6cbd3f73-5604-4d3a-98a1-2372350654c5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 06:33:41 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003698678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 06:33:42.188: INFO: Pod "test-recreate-deployment-9d58999df-4f8k8" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-4f8k8 test-recreate-deployment-9d58999df- deployment-4710  731ebb5e-e237-4cc9-9e3f-f696f3e2c1e6 21545 0 2022-08-27 06:33:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f1a0c27a-f1c8-47bd-b27b-5a6ec0637099 0xc003698c00 0xc003698c01}] [] [{kube-controller-manager Update v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f1a0c27a-f1c8-47bd-b27b-5a6ec0637099\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 06:33:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-568tv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-568tv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 06:33:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:,StartTime:2022-08-27 06:33:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 06:33:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4710" for this suite. 08/27/22 06:33:42.193
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:33:42.201
Aug 27 06:33:42.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:33:42.202
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:42.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:42.242
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 08/27/22 06:33:42.245
Aug 27 06:33:42.251: INFO: Waiting up to 5m0s for pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3" in namespace "emptydir-9766" to be "Succeeded or Failed"
Aug 27 06:33:42.256: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.896914ms
Aug 27 06:33:44.262: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010273864s
Aug 27 06:33:46.261: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009622278s
STEP: Saw pod success 08/27/22 06:33:46.261
Aug 27 06:33:46.261: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3" satisfied condition "Succeeded or Failed"
Aug 27 06:33:46.264: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-4021ce1d-fa22-4e90-b40e-a87740a681b3 container test-container: <nil>
STEP: delete the pod 08/27/22 06:33:46.282
Aug 27 06:33:46.291: INFO: Waiting for pod pod-4021ce1d-fa22-4e90-b40e-a87740a681b3 to disappear
Aug 27 06:33:46.295: INFO: Pod pod-4021ce1d-fa22-4e90-b40e-a87740a681b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:33:46.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9766" for this suite. 08/27/22 06:33:46.299
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":217,"skipped":4094,"failed":0}
------------------------------
â€¢ [4.103 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:33:42.201
    Aug 27 06:33:42.201: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:33:42.202
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:42.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:42.242
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 08/27/22 06:33:42.245
    Aug 27 06:33:42.251: INFO: Waiting up to 5m0s for pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3" in namespace "emptydir-9766" to be "Succeeded or Failed"
    Aug 27 06:33:42.256: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.896914ms
    Aug 27 06:33:44.262: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010273864s
    Aug 27 06:33:46.261: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009622278s
    STEP: Saw pod success 08/27/22 06:33:46.261
    Aug 27 06:33:46.261: INFO: Pod "pod-4021ce1d-fa22-4e90-b40e-a87740a681b3" satisfied condition "Succeeded or Failed"
    Aug 27 06:33:46.264: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-4021ce1d-fa22-4e90-b40e-a87740a681b3 container test-container: <nil>
    STEP: delete the pod 08/27/22 06:33:46.282
    Aug 27 06:33:46.291: INFO: Waiting for pod pod-4021ce1d-fa22-4e90-b40e-a87740a681b3 to disappear
    Aug 27 06:33:46.295: INFO: Pod pod-4021ce1d-fa22-4e90-b40e-a87740a681b3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:33:46.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9766" for this suite. 08/27/22 06:33:46.299
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:33:46.308
Aug 27 06:33:46.308: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 06:33:46.309
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:46.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:46.34
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5542 08/27/22 06:33:46.344
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-5542 08/27/22 06:33:46.349
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5542 08/27/22 06:33:46.36
Aug 27 06:33:46.372: INFO: Found 0 stateful pods, waiting for 1
Aug 27 06:33:56.379: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 08/27/22 06:33:56.379
Aug 27 06:33:56.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 06:33:56.680: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 06:33:56.680: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 06:33:56.680: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 06:33:56.684: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 27 06:34:06.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 06:34:06.688: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 06:34:06.706: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 06:34:06.707: INFO: ss-0  ip-10-0-47-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  }]
Aug 27 06:34:06.707: INFO: 
Aug 27 06:34:06.707: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 27 06:34:07.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992857497s
Aug 27 06:34:08.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972002294s
Aug 27 06:34:09.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967985819s
Aug 27 06:34:10.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963797971s
Aug 27 06:34:11.745: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.959359954s
Aug 27 06:34:12.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.954532009s
Aug 27 06:34:13.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.948311727s
Aug 27 06:34:14.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943718177s
Aug 27 06:34:15.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.056844ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5542 08/27/22 06:34:16.765
Aug 27 06:34:16.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 06:34:16.915: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 06:34:16.915: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 06:34:16.915: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 06:34:16.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 06:34:17.114: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 27 06:34:17.114: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 06:34:17.114: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 06:34:17.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 06:34:17.373: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 27 06:34:17.373: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 06:34:17.373: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 27 06:34:17.376: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 27 06:34:27.381: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 06:34:27.381: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 06:34:27.381: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 08/27/22 06:34:27.381
Aug 27 06:34:27.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 06:34:27.573: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 06:34:27.573: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 06:34:27.573: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 06:34:27.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 06:34:27.861: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 06:34:27.861: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 06:34:27.861: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 06:34:27.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 06:34:28.020: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 06:34:28.020: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 06:34:28.020: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 06:34:28.020: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 06:34:28.023: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 27 06:34:38.034: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 06:34:38.034: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 06:34:38.034: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 27 06:34:38.070: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 06:34:38.070: INFO: ss-0  ip-10-0-47-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  }]
Aug 27 06:34:38.070: INFO: ss-1  ip-10-0-31-158  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
Aug 27 06:34:38.071: INFO: ss-2  ip-10-0-47-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
Aug 27 06:34:38.071: INFO: 
Aug 27 06:34:38.071: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 06:34:39.074: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 27 06:34:39.074: INFO: ss-0  ip-10-0-47-192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  }]
Aug 27 06:34:39.074: INFO: ss-1  ip-10-0-31-158  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
Aug 27 06:34:39.074: INFO: ss-2  ip-10-0-47-192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
Aug 27 06:34:39.074: INFO: 
Aug 27 06:34:39.074: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 27 06:34:40.077: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.979942941s
Aug 27 06:34:41.080: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.977052024s
Aug 27 06:34:42.083: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974095115s
Aug 27 06:34:43.087: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.970877443s
Aug 27 06:34:44.090: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.967077488s
Aug 27 06:34:45.094: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.963848583s
Aug 27 06:34:46.097: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.960246459s
Aug 27 06:34:47.101: INFO: Verifying statefulset ss doesn't scale past 0 for another 956.847839ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5542 08/27/22 06:34:48.101
Aug 27 06:34:48.104: INFO: Scaling statefulset ss to 0
Aug 27 06:34:48.116: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 06:34:48.119: INFO: Deleting all statefulset in ns statefulset-5542
Aug 27 06:34:48.121: INFO: Scaling statefulset ss to 0
Aug 27 06:34:48.130: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 06:34:48.133: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 06:34:48.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5542" for this suite. 08/27/22 06:34:48.146
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":218,"skipped":4105,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.845 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:33:46.308
    Aug 27 06:33:46.308: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 06:33:46.309
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:33:46.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:33:46.34
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5542 08/27/22 06:33:46.344
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-5542 08/27/22 06:33:46.349
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5542 08/27/22 06:33:46.36
    Aug 27 06:33:46.372: INFO: Found 0 stateful pods, waiting for 1
    Aug 27 06:33:56.379: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 08/27/22 06:33:56.379
    Aug 27 06:33:56.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 06:33:56.680: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 06:33:56.680: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 06:33:56.680: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 06:33:56.684: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Aug 27 06:34:06.688: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 06:34:06.688: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 06:34:06.706: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Aug 27 06:34:06.707: INFO: ss-0  ip-10-0-47-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  }]
    Aug 27 06:34:06.707: INFO: 
    Aug 27 06:34:06.707: INFO: StatefulSet ss has not reached scale 3, at 1
    Aug 27 06:34:07.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992857497s
    Aug 27 06:34:08.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972002294s
    Aug 27 06:34:09.736: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967985819s
    Aug 27 06:34:10.740: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963797971s
    Aug 27 06:34:11.745: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.959359954s
    Aug 27 06:34:12.751: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.954532009s
    Aug 27 06:34:13.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.948311727s
    Aug 27 06:34:14.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943718177s
    Aug 27 06:34:15.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.056844ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5542 08/27/22 06:34:16.765
    Aug 27 06:34:16.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 06:34:16.915: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 06:34:16.915: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 06:34:16.915: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 06:34:16.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 06:34:17.114: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Aug 27 06:34:17.114: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 06:34:17.114: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 06:34:17.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 06:34:17.373: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Aug 27 06:34:17.373: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 06:34:17.373: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Aug 27 06:34:17.376: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Aug 27 06:34:27.381: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 06:34:27.381: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 06:34:27.381: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 08/27/22 06:34:27.381
    Aug 27 06:34:27.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 06:34:27.573: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 06:34:27.573: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 06:34:27.573: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 06:34:27.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 06:34:27.861: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 06:34:27.861: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 06:34:27.861: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 06:34:27.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-5542 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 06:34:28.020: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 06:34:28.020: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 06:34:28.020: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 06:34:28.020: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 06:34:28.023: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Aug 27 06:34:38.034: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 06:34:38.034: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 06:34:38.034: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Aug 27 06:34:38.070: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Aug 27 06:34:38.070: INFO: ss-0  ip-10-0-47-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  }]
    Aug 27 06:34:38.070: INFO: ss-1  ip-10-0-31-158  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
    Aug 27 06:34:38.071: INFO: ss-2  ip-10-0-47-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
    Aug 27 06:34:38.071: INFO: 
    Aug 27 06:34:38.071: INFO: StatefulSet ss has not reached scale 0, at 3
    Aug 27 06:34:39.074: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Aug 27 06:34:39.074: INFO: ss-0  ip-10-0-47-192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:33:46 +0000 UTC  }]
    Aug 27 06:34:39.074: INFO: ss-1  ip-10-0-31-158  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
    Aug 27 06:34:39.074: INFO: ss-2  ip-10-0-47-192  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 06:34:06 +0000 UTC  }]
    Aug 27 06:34:39.074: INFO: 
    Aug 27 06:34:39.074: INFO: StatefulSet ss has not reached scale 0, at 3
    Aug 27 06:34:40.077: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.979942941s
    Aug 27 06:34:41.080: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.977052024s
    Aug 27 06:34:42.083: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974095115s
    Aug 27 06:34:43.087: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.970877443s
    Aug 27 06:34:44.090: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.967077488s
    Aug 27 06:34:45.094: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.963848583s
    Aug 27 06:34:46.097: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.960246459s
    Aug 27 06:34:47.101: INFO: Verifying statefulset ss doesn't scale past 0 for another 956.847839ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5542 08/27/22 06:34:48.101
    Aug 27 06:34:48.104: INFO: Scaling statefulset ss to 0
    Aug 27 06:34:48.116: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 06:34:48.119: INFO: Deleting all statefulset in ns statefulset-5542
    Aug 27 06:34:48.121: INFO: Scaling statefulset ss to 0
    Aug 27 06:34:48.130: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 06:34:48.133: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 06:34:48.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5542" for this suite. 08/27/22 06:34:48.146
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:34:48.155
Aug 27 06:34:48.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:34:48.156
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:34:48.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:34:48.193
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f in namespace container-probe-5778 08/27/22 06:34:48.2
Aug 27 06:34:48.207: INFO: Waiting up to 5m0s for pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f" in namespace "container-probe-5778" to be "not pending"
Aug 27 06:34:48.211: INFO: Pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.671882ms
Aug 27 06:34:50.214: INFO: Pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007192287s
Aug 27 06:34:50.214: INFO: Pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f" satisfied condition "not pending"
Aug 27 06:34:50.214: INFO: Started pod test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f in namespace container-probe-5778
STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:34:50.214
Aug 27 06:34:50.217: INFO: Initial restart count of pod test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f is 0
STEP: deleting the pod 08/27/22 06:38:50.789
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:38:50.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5778" for this suite. 08/27/22 06:38:50.808
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":219,"skipped":4125,"failed":0}
------------------------------
â€¢ [SLOW TEST] [242.660 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:34:48.155
    Aug 27 06:34:48.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:34:48.156
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:34:48.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:34:48.193
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f in namespace container-probe-5778 08/27/22 06:34:48.2
    Aug 27 06:34:48.207: INFO: Waiting up to 5m0s for pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f" in namespace "container-probe-5778" to be "not pending"
    Aug 27 06:34:48.211: INFO: Pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.671882ms
    Aug 27 06:34:50.214: INFO: Pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007192287s
    Aug 27 06:34:50.214: INFO: Pod "test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f" satisfied condition "not pending"
    Aug 27 06:34:50.214: INFO: Started pod test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f in namespace container-probe-5778
    STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:34:50.214
    Aug 27 06:34:50.217: INFO: Initial restart count of pod test-webserver-19c96db3-0e66-43aa-953b-cfb8f9a6a83f is 0
    STEP: deleting the pod 08/27/22 06:38:50.789
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:38:50.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5778" for this suite. 08/27/22 06:38:50.808
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:38:50.827
Aug 27 06:38:50.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-preemption 08/27/22 06:38:50.834
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:38:50.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:38:50.859
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Aug 27 06:38:50.873: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 06:39:50.895: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:39:50.898
Aug 27 06:39:50.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sched-preemption-path 08/27/22 06:39:50.899
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:39:50.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:39:50.927
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 08/27/22 06:39:50.932
STEP: Trying to launch a pod without a label to get a node which can launch it. 08/27/22 06:39:50.932
Aug 27 06:39:50.942: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8517" to be "running"
Aug 27 06:39:50.945: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.036605ms
Aug 27 06:39:52.950: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.008452489s
Aug 27 06:39:52.950: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 08/27/22 06:39:52.953
Aug 27 06:39:52.961: INFO: found a healthy node: ip-10-0-47-192
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Aug 27 06:40:07.065: INFO: pods created so far: [1 1 1]
Aug 27 06:40:07.065: INFO: length of pods created so far: 3
Aug 27 06:40:11.079: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Aug 27 06:40:18.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8517" for this suite. 08/27/22 06:40:18.085
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:40:18.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5426" for this suite. 08/27/22 06:40:18.126
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":220,"skipped":4178,"failed":0}
------------------------------
â€¢ [SLOW TEST] [87.348 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:38:50.827
    Aug 27 06:38:50.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-preemption 08/27/22 06:38:50.834
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:38:50.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:38:50.859
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Aug 27 06:38:50.873: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 27 06:39:50.895: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:39:50.898
    Aug 27 06:39:50.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sched-preemption-path 08/27/22 06:39:50.899
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:39:50.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:39:50.927
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 08/27/22 06:39:50.932
    STEP: Trying to launch a pod without a label to get a node which can launch it. 08/27/22 06:39:50.932
    Aug 27 06:39:50.942: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-8517" to be "running"
    Aug 27 06:39:50.945: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.036605ms
    Aug 27 06:39:52.950: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.008452489s
    Aug 27 06:39:52.950: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 08/27/22 06:39:52.953
    Aug 27 06:39:52.961: INFO: found a healthy node: ip-10-0-47-192
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Aug 27 06:40:07.065: INFO: pods created so far: [1 1 1]
    Aug 27 06:40:07.065: INFO: length of pods created so far: 3
    Aug 27 06:40:11.079: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Aug 27 06:40:18.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-8517" for this suite. 08/27/22 06:40:18.085
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:40:18.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5426" for this suite. 08/27/22 06:40:18.126
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:18.177
Aug 27 06:40:18.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 06:40:18.178
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:18.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:18.223
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Aug 27 06:40:18.244: INFO: Create a RollingUpdate DaemonSet
Aug 27 06:40:18.249: INFO: Check that daemon pods launch on every node of the cluster
Aug 27 06:40:18.253: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:40:18.258: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:40:18.258: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:40:19.262: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:40:19.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:40:19.266: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
Aug 27 06:40:20.264: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:40:20.267: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 27 06:40:20.267: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Aug 27 06:40:20.267: INFO: Update the DaemonSet to trigger a rollout
Aug 27 06:40:20.275: INFO: Updating DaemonSet daemon-set
Aug 27 06:40:23.346: INFO: Roll back the DaemonSet before rollout is complete
Aug 27 06:40:23.374: INFO: Updating DaemonSet daemon-set
Aug 27 06:40:23.374: INFO: Make sure DaemonSet rollback is complete
Aug 27 06:40:23.385: INFO: Wrong image for pod: daemon-set-mvfcm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Aug 27 06:40:23.385: INFO: Pod daemon-set-mvfcm is not available
Aug 27 06:40:23.392: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:40:24.398: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:40:25.399: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 27 06:40:26.396: INFO: Pod daemon-set-bllpt is not available
Aug 27 06:40:26.401: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/27/22 06:40:26.407
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-273, will wait for the garbage collector to delete the pods 08/27/22 06:40:26.408
Aug 27 06:40:26.466: INFO: Deleting DaemonSet.extensions daemon-set took: 5.201591ms
Aug 27 06:40:26.569: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.687355ms
Aug 27 06:40:28.572: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 06:40:28.572: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 27 06:40:28.577: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22746"},"items":null}

Aug 27 06:40:28.580: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22746"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 06:40:28.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-273" for this suite. 08/27/22 06:40:28.594
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":221,"skipped":4184,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.422 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:18.177
    Aug 27 06:40:18.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 06:40:18.178
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:18.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:18.223
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Aug 27 06:40:18.244: INFO: Create a RollingUpdate DaemonSet
    Aug 27 06:40:18.249: INFO: Check that daemon pods launch on every node of the cluster
    Aug 27 06:40:18.253: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:40:18.258: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:40:18.258: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:40:19.262: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:40:19.266: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:40:19.266: INFO: Node ip-10-0-31-158 is running 0 daemon pod, expected 1
    Aug 27 06:40:20.264: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:40:20.267: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Aug 27 06:40:20.267: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    Aug 27 06:40:20.267: INFO: Update the DaemonSet to trigger a rollout
    Aug 27 06:40:20.275: INFO: Updating DaemonSet daemon-set
    Aug 27 06:40:23.346: INFO: Roll back the DaemonSet before rollout is complete
    Aug 27 06:40:23.374: INFO: Updating DaemonSet daemon-set
    Aug 27 06:40:23.374: INFO: Make sure DaemonSet rollback is complete
    Aug 27 06:40:23.385: INFO: Wrong image for pod: daemon-set-mvfcm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Aug 27 06:40:23.385: INFO: Pod daemon-set-mvfcm is not available
    Aug 27 06:40:23.392: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:40:24.398: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:40:25.399: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Aug 27 06:40:26.396: INFO: Pod daemon-set-bllpt is not available
    Aug 27 06:40:26.401: INFO: DaemonSet pods can't tolerate node ip-10-0-13-52 with taints [{Key:node-role.kubernetes.io/controller Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/27/22 06:40:26.407
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-273, will wait for the garbage collector to delete the pods 08/27/22 06:40:26.408
    Aug 27 06:40:26.466: INFO: Deleting DaemonSet.extensions daemon-set took: 5.201591ms
    Aug 27 06:40:26.569: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.687355ms
    Aug 27 06:40:28.572: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 06:40:28.572: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 27 06:40:28.577: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22746"},"items":null}

    Aug 27 06:40:28.580: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22746"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 06:40:28.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-273" for this suite. 08/27/22 06:40:28.594
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:28.601
Aug 27 06:40:28.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:40:28.602
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:28.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:28.624
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 08/27/22 06:40:28.628
Aug 27 06:40:28.634: INFO: Waiting up to 5m0s for pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c" in namespace "emptydir-2395" to be "Succeeded or Failed"
Aug 27 06:40:28.641: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.542681ms
Aug 27 06:40:30.648: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01367221s
Aug 27 06:40:32.644: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010378804s
STEP: Saw pod success 08/27/22 06:40:32.645
Aug 27 06:40:32.645: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c" satisfied condition "Succeeded or Failed"
Aug 27 06:40:32.648: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c container test-container: <nil>
STEP: delete the pod 08/27/22 06:40:32.664
Aug 27 06:40:32.674: INFO: Waiting for pod pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c to disappear
Aug 27 06:40:32.678: INFO: Pod pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:40:32.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2395" for this suite. 08/27/22 06:40:32.681
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":222,"skipped":4184,"failed":0}
------------------------------
â€¢ [4.089 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:28.601
    Aug 27 06:40:28.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:40:28.602
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:28.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:28.624
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 08/27/22 06:40:28.628
    Aug 27 06:40:28.634: INFO: Waiting up to 5m0s for pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c" in namespace "emptydir-2395" to be "Succeeded or Failed"
    Aug 27 06:40:28.641: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.542681ms
    Aug 27 06:40:30.648: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01367221s
    Aug 27 06:40:32.644: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010378804s
    STEP: Saw pod success 08/27/22 06:40:32.645
    Aug 27 06:40:32.645: INFO: Pod "pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c" satisfied condition "Succeeded or Failed"
    Aug 27 06:40:32.648: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c container test-container: <nil>
    STEP: delete the pod 08/27/22 06:40:32.664
    Aug 27 06:40:32.674: INFO: Waiting for pod pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c to disappear
    Aug 27 06:40:32.678: INFO: Pod pod-b68e62b8-4ea1-4cb9-95fa-e604f30b2d2c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:40:32.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2395" for this suite. 08/27/22 06:40:32.681
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:32.701
Aug 27 06:40:32.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename containers 08/27/22 06:40:32.704
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:32.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:32.741
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 08/27/22 06:40:32.757
Aug 27 06:40:32.784: INFO: Waiting up to 5m0s for pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523" in namespace "containers-2248" to be "Succeeded or Failed"
Aug 27 06:40:32.790: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523": Phase="Pending", Reason="", readiness=false. Elapsed: 6.201789ms
Aug 27 06:40:34.794: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00928355s
Aug 27 06:40:36.793: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009248596s
STEP: Saw pod success 08/27/22 06:40:36.794
Aug 27 06:40:36.794: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523" satisfied condition "Succeeded or Failed"
Aug 27 06:40:36.796: INFO: Trying to get logs from node ip-10-0-47-192 pod client-containers-e46d1e24-f55e-4ada-bd32-72160f894523 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:40:36.802
Aug 27 06:40:36.813: INFO: Waiting for pod client-containers-e46d1e24-f55e-4ada-bd32-72160f894523 to disappear
Aug 27 06:40:36.817: INFO: Pod client-containers-e46d1e24-f55e-4ada-bd32-72160f894523 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 27 06:40:36.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2248" for this suite. 08/27/22 06:40:36.821
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":223,"skipped":4212,"failed":0}
------------------------------
â€¢ [4.124 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:32.701
    Aug 27 06:40:32.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename containers 08/27/22 06:40:32.704
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:32.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:32.741
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 08/27/22 06:40:32.757
    Aug 27 06:40:32.784: INFO: Waiting up to 5m0s for pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523" in namespace "containers-2248" to be "Succeeded or Failed"
    Aug 27 06:40:32.790: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523": Phase="Pending", Reason="", readiness=false. Elapsed: 6.201789ms
    Aug 27 06:40:34.794: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00928355s
    Aug 27 06:40:36.793: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009248596s
    STEP: Saw pod success 08/27/22 06:40:36.794
    Aug 27 06:40:36.794: INFO: Pod "client-containers-e46d1e24-f55e-4ada-bd32-72160f894523" satisfied condition "Succeeded or Failed"
    Aug 27 06:40:36.796: INFO: Trying to get logs from node ip-10-0-47-192 pod client-containers-e46d1e24-f55e-4ada-bd32-72160f894523 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:40:36.802
    Aug 27 06:40:36.813: INFO: Waiting for pod client-containers-e46d1e24-f55e-4ada-bd32-72160f894523 to disappear
    Aug 27 06:40:36.817: INFO: Pod client-containers-e46d1e24-f55e-4ada-bd32-72160f894523 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 27 06:40:36.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2248" for this suite. 08/27/22 06:40:36.821
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:36.826
Aug 27 06:40:36.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 06:40:36.827
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:36.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:36.853
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 06:40:36.869
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:40:37.309
STEP: Deploying the webhook pod 08/27/22 06:40:37.319
STEP: Wait for the deployment to be ready 08/27/22 06:40:37.335
Aug 27 06:40:37.348: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 06:40:39.359
STEP: Verifying the service has paired with the endpoint 08/27/22 06:40:39.37
Aug 27 06:40:40.371: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 08/27/22 06:40:40.374
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 08/27/22 06:40:40.376
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 08/27/22 06:40:40.376
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 08/27/22 06:40:40.376
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 08/27/22 06:40:40.38
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 08/27/22 06:40:40.38
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 08/27/22 06:40:40.382
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:40:40.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7201" for this suite. 08/27/22 06:40:40.385
STEP: Destroying namespace "webhook-7201-markers" for this suite. 08/27/22 06:40:40.389
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":224,"skipped":4220,"failed":0}
------------------------------
â€¢ [3.607 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:36.826
    Aug 27 06:40:36.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 06:40:36.827
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:36.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:36.853
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 06:40:36.869
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:40:37.309
    STEP: Deploying the webhook pod 08/27/22 06:40:37.319
    STEP: Wait for the deployment to be ready 08/27/22 06:40:37.335
    Aug 27 06:40:37.348: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 06:40:39.359
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:40:39.37
    Aug 27 06:40:40.371: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 08/27/22 06:40:40.374
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 08/27/22 06:40:40.376
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 08/27/22 06:40:40.376
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 08/27/22 06:40:40.376
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 08/27/22 06:40:40.38
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 08/27/22 06:40:40.38
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 08/27/22 06:40:40.382
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:40:40.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7201" for this suite. 08/27/22 06:40:40.385
    STEP: Destroying namespace "webhook-7201-markers" for this suite. 08/27/22 06:40:40.389
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:40.435
Aug 27 06:40:40.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replicaset 08/27/22 06:40:40.436
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:40.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:40.472
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Aug 27 06:40:40.489: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 27 06:40:45.497: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/27/22 06:40:45.497
STEP: Scaling up "test-rs" replicaset  08/27/22 06:40:45.497
Aug 27 06:40:45.510: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 08/27/22 06:40:45.51
W0827 06:40:45.519625      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Aug 27 06:40:45.525: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
Aug 27 06:40:45.575: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
Aug 27 06:40:45.653: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
Aug 27 06:40:45.694: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
Aug 27 06:40:47.093: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 2, AvailableReplicas 2
Aug 27 06:40:47.580: INFO: observed Replicaset test-rs in namespace replicaset-9173 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 27 06:40:47.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9173" for this suite. 08/27/22 06:40:47.588
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":225,"skipped":4234,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.163 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:40.435
    Aug 27 06:40:40.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replicaset 08/27/22 06:40:40.436
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:40.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:40.472
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Aug 27 06:40:40.489: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 27 06:40:45.497: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/27/22 06:40:45.497
    STEP: Scaling up "test-rs" replicaset  08/27/22 06:40:45.497
    Aug 27 06:40:45.510: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 08/27/22 06:40:45.51
    W0827 06:40:45.519625      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Aug 27 06:40:45.525: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
    Aug 27 06:40:45.575: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
    Aug 27 06:40:45.653: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
    Aug 27 06:40:45.694: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 1, AvailableReplicas 1
    Aug 27 06:40:47.093: INFO: observed ReplicaSet test-rs in namespace replicaset-9173 with ReadyReplicas 2, AvailableReplicas 2
    Aug 27 06:40:47.580: INFO: observed Replicaset test-rs in namespace replicaset-9173 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 27 06:40:47.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9173" for this suite. 08/27/22 06:40:47.588
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:47.623
Aug 27 06:40:47.626: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 06:40:47.627
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:47.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:47.663
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 06:40:47.682
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:40:48.427
STEP: Deploying the webhook pod 08/27/22 06:40:48.432
STEP: Wait for the deployment to be ready 08/27/22 06:40:48.442
Aug 27 06:40:48.447: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/27/22 06:40:50.458
STEP: Verifying the service has paired with the endpoint 08/27/22 06:40:50.47
Aug 27 06:40:51.471: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 08/27/22 06:40:51.473
STEP: create a configmap that should be updated by the webhook 08/27/22 06:40:51.496
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:40:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7258" for this suite. 08/27/22 06:40:51.524
STEP: Destroying namespace "webhook-7258-markers" for this suite. 08/27/22 06:40:51.527
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":226,"skipped":4270,"failed":0}
------------------------------
â€¢ [3.961 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:47.623
    Aug 27 06:40:47.626: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 06:40:47.627
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:47.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:47.663
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 06:40:47.682
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:40:48.427
    STEP: Deploying the webhook pod 08/27/22 06:40:48.432
    STEP: Wait for the deployment to be ready 08/27/22 06:40:48.442
    Aug 27 06:40:48.447: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/27/22 06:40:50.458
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:40:50.47
    Aug 27 06:40:51.471: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 08/27/22 06:40:51.473
    STEP: create a configmap that should be updated by the webhook 08/27/22 06:40:51.496
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:40:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7258" for this suite. 08/27/22 06:40:51.524
    STEP: Destroying namespace "webhook-7258-markers" for this suite. 08/27/22 06:40:51.527
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:51.597
Aug 27 06:40:51.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:40:51.599
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:51.627
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:51.635
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:40:51.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8443" for this suite. 08/27/22 06:40:51.659
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":227,"skipped":4360,"failed":0}
------------------------------
â€¢ [0.068 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:51.597
    Aug 27 06:40:51.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:40:51.599
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:51.627
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:51.635
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:40:51.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8443" for this suite. 08/27/22 06:40:51.659
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:51.691
Aug 27 06:40:51.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:40:51.693
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:51.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:51.712
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-0619bc3b-d770-4482-8c42-7914a973a2a3 08/27/22 06:40:51.718
STEP: Creating a pod to test consume secrets 08/27/22 06:40:51.721
Aug 27 06:40:51.737: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2" in namespace "projected-7739" to be "Succeeded or Failed"
Aug 27 06:40:51.761: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.621102ms
Aug 27 06:40:53.765: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028747883s
Aug 27 06:40:55.766: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029356829s
STEP: Saw pod success 08/27/22 06:40:55.766
Aug 27 06:40:55.766: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2" satisfied condition "Succeeded or Failed"
Aug 27 06:40:55.770: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:40:55.789
Aug 27 06:40:55.800: INFO: Waiting for pod pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2 to disappear
Aug 27 06:40:55.804: INFO: Pod pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 06:40:55.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7739" for this suite. 08/27/22 06:40:55.807
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":228,"skipped":4438,"failed":0}
------------------------------
â€¢ [4.120 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:51.691
    Aug 27 06:40:51.692: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:40:51.693
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:51.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:51.712
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-0619bc3b-d770-4482-8c42-7914a973a2a3 08/27/22 06:40:51.718
    STEP: Creating a pod to test consume secrets 08/27/22 06:40:51.721
    Aug 27 06:40:51.737: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2" in namespace "projected-7739" to be "Succeeded or Failed"
    Aug 27 06:40:51.761: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.621102ms
    Aug 27 06:40:53.765: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028747883s
    Aug 27 06:40:55.766: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029356829s
    STEP: Saw pod success 08/27/22 06:40:55.766
    Aug 27 06:40:55.766: INFO: Pod "pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2" satisfied condition "Succeeded or Failed"
    Aug 27 06:40:55.770: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:40:55.789
    Aug 27 06:40:55.800: INFO: Waiting for pod pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2 to disappear
    Aug 27 06:40:55.804: INFO: Pod pod-projected-secrets-50d0acdd-38e7-4a53-be78-c9c632674ba2 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 06:40:55.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7739" for this suite. 08/27/22 06:40:55.807
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:55.812
Aug 27 06:40:55.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replicaset 08/27/22 06:40:55.815
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:55.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:55.841
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 08/27/22 06:40:55.851
Aug 27 06:40:55.857: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-1476" to be "running and ready"
Aug 27 06:40:55.860: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.83751ms
Aug 27 06:40:55.860: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:40:57.863: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.00587832s
Aug 27 06:40:57.863: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Aug 27 06:40:57.863: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 08/27/22 06:40:57.865
STEP: Then the orphan pod is adopted 08/27/22 06:40:57.869
STEP: When the matched label of one of its pods change 08/27/22 06:40:58.876
Aug 27 06:40:58.879: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 08/27/22 06:40:58.889
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 27 06:40:58.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1476" for this suite. 08/27/22 06:40:58.911
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":229,"skipped":4442,"failed":0}
------------------------------
â€¢ [3.112 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:55.812
    Aug 27 06:40:55.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replicaset 08/27/22 06:40:55.815
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:55.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:55.841
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 08/27/22 06:40:55.851
    Aug 27 06:40:55.857: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-1476" to be "running and ready"
    Aug 27 06:40:55.860: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.83751ms
    Aug 27 06:40:55.860: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:40:57.863: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.00587832s
    Aug 27 06:40:57.863: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Aug 27 06:40:57.863: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 08/27/22 06:40:57.865
    STEP: Then the orphan pod is adopted 08/27/22 06:40:57.869
    STEP: When the matched label of one of its pods change 08/27/22 06:40:58.876
    Aug 27 06:40:58.879: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 08/27/22 06:40:58.889
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 27 06:40:58.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1476" for this suite. 08/27/22 06:40:58.911
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:40:58.929
Aug 27 06:40:58.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 06:40:58.93
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:58.972
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:58.976
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 06:40:58.992
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:40:59.596
STEP: Deploying the webhook pod 08/27/22 06:40:59.6
STEP: Wait for the deployment to be ready 08/27/22 06:40:59.608
Aug 27 06:40:59.617: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 06:41:01.636
STEP: Verifying the service has paired with the endpoint 08/27/22 06:41:01.66
Aug 27 06:41:02.660: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Aug 27 06:41:02.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6775-crds.webhook.example.com via the AdmissionRegistration API 08/27/22 06:41:03.22
Aug 27 06:41:03.654: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook 08/27/22 06:41:03.777
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:41:06.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7620" for this suite. 08/27/22 06:41:06.392
STEP: Destroying namespace "webhook-7620-markers" for this suite. 08/27/22 06:41:06.396
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":230,"skipped":4448,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.522 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:40:58.929
    Aug 27 06:40:58.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 06:40:58.93
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:40:58.972
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:40:58.976
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 06:40:58.992
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:40:59.596
    STEP: Deploying the webhook pod 08/27/22 06:40:59.6
    STEP: Wait for the deployment to be ready 08/27/22 06:40:59.608
    Aug 27 06:40:59.617: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 06:41:01.636
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:41:01.66
    Aug 27 06:41:02.660: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Aug 27 06:41:02.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6775-crds.webhook.example.com via the AdmissionRegistration API 08/27/22 06:41:03.22
    Aug 27 06:41:03.654: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource that should be mutated by the webhook 08/27/22 06:41:03.777
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:41:06.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7620" for this suite. 08/27/22 06:41:06.392
    STEP: Destroying namespace "webhook-7620-markers" for this suite. 08/27/22 06:41:06.396
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:06.454
Aug 27 06:41:06.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename server-version 08/27/22 06:41:06.455
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:06.499
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:06.525
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 08/27/22 06:41:06.538
STEP: Confirm major version 08/27/22 06:41:06.544
Aug 27 06:41:06.544: INFO: Major version: 1
STEP: Confirm minor version 08/27/22 06:41:06.544
Aug 27 06:41:06.544: INFO: cleanMinorVersion: 25
Aug 27 06:41:06.545: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Aug 27 06:41:06.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-2593" for this suite. 08/27/22 06:41:06.554
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":231,"skipped":4479,"failed":0}
------------------------------
â€¢ [0.106 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:06.454
    Aug 27 06:41:06.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename server-version 08/27/22 06:41:06.455
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:06.499
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:06.525
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 08/27/22 06:41:06.538
    STEP: Confirm major version 08/27/22 06:41:06.544
    Aug 27 06:41:06.544: INFO: Major version: 1
    STEP: Confirm minor version 08/27/22 06:41:06.544
    Aug 27 06:41:06.544: INFO: cleanMinorVersion: 25
    Aug 27 06:41:06.545: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Aug 27 06:41:06.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-2593" for this suite. 08/27/22 06:41:06.554
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:06.563
Aug 27 06:41:06.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:41:06.565
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:06.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:06.606
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 08/27/22 06:41:06.615
Aug 27 06:41:06.626: INFO: Waiting up to 5m0s for pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e" in namespace "emptydir-3150" to be "Succeeded or Failed"
Aug 27 06:41:06.632: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.818276ms
Aug 27 06:41:08.635: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008940062s
Aug 27 06:41:10.635: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009474037s
Aug 27 06:41:12.635: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009562297s
STEP: Saw pod success 08/27/22 06:41:12.635
Aug 27 06:41:12.636: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e" satisfied condition "Succeeded or Failed"
Aug 27 06:41:12.638: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-3528c458-768f-4b38-baa4-1b30fdb3e64e container test-container: <nil>
STEP: delete the pod 08/27/22 06:41:12.643
Aug 27 06:41:12.654: INFO: Waiting for pod pod-3528c458-768f-4b38-baa4-1b30fdb3e64e to disappear
Aug 27 06:41:12.656: INFO: Pod pod-3528c458-768f-4b38-baa4-1b30fdb3e64e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:41:12.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3150" for this suite. 08/27/22 06:41:12.659
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":232,"skipped":4485,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.100 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:06.563
    Aug 27 06:41:06.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:41:06.565
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:06.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:06.606
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 08/27/22 06:41:06.615
    Aug 27 06:41:06.626: INFO: Waiting up to 5m0s for pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e" in namespace "emptydir-3150" to be "Succeeded or Failed"
    Aug 27 06:41:06.632: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.818276ms
    Aug 27 06:41:08.635: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008940062s
    Aug 27 06:41:10.635: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009474037s
    Aug 27 06:41:12.635: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009562297s
    STEP: Saw pod success 08/27/22 06:41:12.635
    Aug 27 06:41:12.636: INFO: Pod "pod-3528c458-768f-4b38-baa4-1b30fdb3e64e" satisfied condition "Succeeded or Failed"
    Aug 27 06:41:12.638: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-3528c458-768f-4b38-baa4-1b30fdb3e64e container test-container: <nil>
    STEP: delete the pod 08/27/22 06:41:12.643
    Aug 27 06:41:12.654: INFO: Waiting for pod pod-3528c458-768f-4b38-baa4-1b30fdb3e64e to disappear
    Aug 27 06:41:12.656: INFO: Pod pod-3528c458-768f-4b38-baa4-1b30fdb3e64e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:41:12.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3150" for this suite. 08/27/22 06:41:12.659
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:12.668
Aug 27 06:41:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename subpath 08/27/22 06:41:12.669
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:12.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:12.695
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 08/27/22 06:41:12.698
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-wszd 08/27/22 06:41:12.705
STEP: Creating a pod to test atomic-volume-subpath 08/27/22 06:41:12.705
Aug 27 06:41:12.710: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wszd" in namespace "subpath-2691" to be "Succeeded or Failed"
Aug 27 06:41:12.713: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.446779ms
Aug 27 06:41:14.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 2.007004238s
Aug 27 06:41:16.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 4.006334971s
Aug 27 06:41:18.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 6.006625519s
Aug 27 06:41:20.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 8.007802052s
Aug 27 06:41:22.716: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 10.006166867s
Aug 27 06:41:24.719: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 12.008369988s
Aug 27 06:41:26.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 14.006695918s
Aug 27 06:41:28.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 16.007733244s
Aug 27 06:41:30.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 18.007731372s
Aug 27 06:41:32.716: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 20.005953154s
Aug 27 06:41:34.716: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=false. Elapsed: 22.005786033s
Aug 27 06:41:36.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.00781291s
STEP: Saw pod success 08/27/22 06:41:36.718
Aug 27 06:41:36.718: INFO: Pod "pod-subpath-test-configmap-wszd" satisfied condition "Succeeded or Failed"
Aug 27 06:41:36.722: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-subpath-test-configmap-wszd container test-container-subpath-configmap-wszd: <nil>
STEP: delete the pod 08/27/22 06:41:36.728
Aug 27 06:41:36.742: INFO: Waiting for pod pod-subpath-test-configmap-wszd to disappear
Aug 27 06:41:36.746: INFO: Pod pod-subpath-test-configmap-wszd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wszd 08/27/22 06:41:36.746
Aug 27 06:41:36.746: INFO: Deleting pod "pod-subpath-test-configmap-wszd" in namespace "subpath-2691"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Aug 27 06:41:36.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2691" for this suite. 08/27/22 06:41:36.755
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":233,"skipped":4516,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.093 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:12.668
    Aug 27 06:41:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename subpath 08/27/22 06:41:12.669
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:12.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:12.695
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 08/27/22 06:41:12.698
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-wszd 08/27/22 06:41:12.705
    STEP: Creating a pod to test atomic-volume-subpath 08/27/22 06:41:12.705
    Aug 27 06:41:12.710: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wszd" in namespace "subpath-2691" to be "Succeeded or Failed"
    Aug 27 06:41:12.713: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.446779ms
    Aug 27 06:41:14.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 2.007004238s
    Aug 27 06:41:16.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 4.006334971s
    Aug 27 06:41:18.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 6.006625519s
    Aug 27 06:41:20.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 8.007802052s
    Aug 27 06:41:22.716: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 10.006166867s
    Aug 27 06:41:24.719: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 12.008369988s
    Aug 27 06:41:26.717: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 14.006695918s
    Aug 27 06:41:28.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 16.007733244s
    Aug 27 06:41:30.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 18.007731372s
    Aug 27 06:41:32.716: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=true. Elapsed: 20.005953154s
    Aug 27 06:41:34.716: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Running", Reason="", readiness=false. Elapsed: 22.005786033s
    Aug 27 06:41:36.718: INFO: Pod "pod-subpath-test-configmap-wszd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.00781291s
    STEP: Saw pod success 08/27/22 06:41:36.718
    Aug 27 06:41:36.718: INFO: Pod "pod-subpath-test-configmap-wszd" satisfied condition "Succeeded or Failed"
    Aug 27 06:41:36.722: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-subpath-test-configmap-wszd container test-container-subpath-configmap-wszd: <nil>
    STEP: delete the pod 08/27/22 06:41:36.728
    Aug 27 06:41:36.742: INFO: Waiting for pod pod-subpath-test-configmap-wszd to disappear
    Aug 27 06:41:36.746: INFO: Pod pod-subpath-test-configmap-wszd no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-wszd 08/27/22 06:41:36.746
    Aug 27 06:41:36.746: INFO: Deleting pod "pod-subpath-test-configmap-wszd" in namespace "subpath-2691"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Aug 27 06:41:36.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2691" for this suite. 08/27/22 06:41:36.755
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:36.763
Aug 27 06:41:36.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sysctl 08/27/22 06:41:36.764
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:36.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:36.789
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 08/27/22 06:41:36.793
STEP: Watching for error events or started pod 08/27/22 06:41:36.8
STEP: Waiting for pod completion 08/27/22 06:41:38.808
Aug 27 06:41:38.808: INFO: Waiting up to 3m0s for pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483" in namespace "sysctl-5021" to be "completed"
Aug 27 06:41:38.812: INFO: Pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483": Phase="Pending", Reason="", readiness=false. Elapsed: 3.670218ms
Aug 27 06:41:40.816: INFO: Pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00783591s
Aug 27 06:41:40.816: INFO: Pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483" satisfied condition "completed"
STEP: Checking that the pod succeeded 08/27/22 06:41:40.818
STEP: Getting logs from the pod 08/27/22 06:41:40.819
STEP: Checking that the sysctl is actually updated 08/27/22 06:41:40.825
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 06:41:40.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5021" for this suite. 08/27/22 06:41:40.828
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":234,"skipped":4529,"failed":0}
------------------------------
â€¢ [4.070 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:36.763
    Aug 27 06:41:36.764: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sysctl 08/27/22 06:41:36.764
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:36.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:36.789
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 08/27/22 06:41:36.793
    STEP: Watching for error events or started pod 08/27/22 06:41:36.8
    STEP: Waiting for pod completion 08/27/22 06:41:38.808
    Aug 27 06:41:38.808: INFO: Waiting up to 3m0s for pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483" in namespace "sysctl-5021" to be "completed"
    Aug 27 06:41:38.812: INFO: Pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483": Phase="Pending", Reason="", readiness=false. Elapsed: 3.670218ms
    Aug 27 06:41:40.816: INFO: Pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00783591s
    Aug 27 06:41:40.816: INFO: Pod "sysctl-626ba113-3412-4a4a-92d0-913d4dd10483" satisfied condition "completed"
    STEP: Checking that the pod succeeded 08/27/22 06:41:40.818
    STEP: Getting logs from the pod 08/27/22 06:41:40.819
    STEP: Checking that the sysctl is actually updated 08/27/22 06:41:40.825
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 06:41:40.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5021" for this suite. 08/27/22 06:41:40.828
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:40.835
Aug 27 06:41:40.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:41:40.836
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:40.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:40.854
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 08/27/22 06:41:40.858
Aug 27 06:41:40.866: INFO: Waiting up to 5m0s for pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3" in namespace "downward-api-3215" to be "Succeeded or Failed"
Aug 27 06:41:40.869: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.77879ms
Aug 27 06:41:42.875: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008783388s
Aug 27 06:41:44.874: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007508953s
STEP: Saw pod success 08/27/22 06:41:44.874
Aug 27 06:41:44.875: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3" satisfied condition "Succeeded or Failed"
Aug 27 06:41:44.879: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3 container dapi-container: <nil>
STEP: delete the pod 08/27/22 06:41:44.886
Aug 27 06:41:44.896: INFO: Waiting for pod downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3 to disappear
Aug 27 06:41:44.900: INFO: Pod downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 27 06:41:44.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3215" for this suite. 08/27/22 06:41:44.903
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":235,"skipped":4536,"failed":0}
------------------------------
â€¢ [4.072 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:40.835
    Aug 27 06:41:40.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:41:40.836
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:40.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:40.854
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 08/27/22 06:41:40.858
    Aug 27 06:41:40.866: INFO: Waiting up to 5m0s for pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3" in namespace "downward-api-3215" to be "Succeeded or Failed"
    Aug 27 06:41:40.869: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.77879ms
    Aug 27 06:41:42.875: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008783388s
    Aug 27 06:41:44.874: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007508953s
    STEP: Saw pod success 08/27/22 06:41:44.874
    Aug 27 06:41:44.875: INFO: Pod "downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3" satisfied condition "Succeeded or Failed"
    Aug 27 06:41:44.879: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 06:41:44.886
    Aug 27 06:41:44.896: INFO: Waiting for pod downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3 to disappear
    Aug 27 06:41:44.900: INFO: Pod downward-api-141ec099-a3e4-4558-959d-4cfa105b37c3 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 27 06:41:44.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3215" for this suite. 08/27/22 06:41:44.903
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:44.917
Aug 27 06:41:44.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:41:44.928
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:44.944
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:44.949
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8999 08/27/22 06:41:44.955
STEP: changing the ExternalName service to type=ClusterIP 08/27/22 06:41:44.961
STEP: creating replication controller externalname-service in namespace services-8999 08/27/22 06:41:44.985
I0827 06:41:44.995377      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8999, replica count: 2
I0827 06:41:48.046796      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 06:41:48.046: INFO: Creating new exec pod
Aug 27 06:41:48.056: INFO: Waiting up to 5m0s for pod "execpodrsvpt" in namespace "services-8999" to be "running"
Aug 27 06:41:48.064: INFO: Pod "execpodrsvpt": Phase="Pending", Reason="", readiness=false. Elapsed: 7.467121ms
Aug 27 06:41:50.074: INFO: Pod "execpodrsvpt": Phase="Running", Reason="", readiness=true. Elapsed: 2.017540614s
Aug 27 06:41:50.074: INFO: Pod "execpodrsvpt" satisfied condition "running"
Aug 27 06:41:51.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 27 06:41:51.339: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 27 06:41:51.339: INFO: stdout: ""
Aug 27 06:41:52.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 27 06:41:52.500: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 27 06:41:52.500: INFO: stdout: "externalname-service-rg7hb"
Aug 27 06:41:52.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
Aug 27 06:41:52.672: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
Aug 27 06:41:52.672: INFO: stdout: ""
Aug 27 06:41:53.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
Aug 27 06:41:53.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
Aug 27 06:41:53.822: INFO: stdout: ""
Aug 27 06:41:54.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
Aug 27 06:41:54.832: INFO: stderr: "+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Aug 27 06:41:54.832: INFO: stdout: ""
Aug 27 06:41:55.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
Aug 27 06:41:55.875: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
Aug 27 06:41:55.875: INFO: stdout: ""
Aug 27 06:41:56.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
Aug 27 06:41:56.841: INFO: stderr: "+ nc+ echo hostName\n -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
Aug 27 06:41:56.841: INFO: stdout: "externalname-service-pqmxt"
Aug 27 06:41:56.841: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:41:56.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8999" for this suite. 08/27/22 06:41:56.885
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":236,"skipped":4555,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.977 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:44.917
    Aug 27 06:41:44.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:41:44.928
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:44.944
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:44.949
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-8999 08/27/22 06:41:44.955
    STEP: changing the ExternalName service to type=ClusterIP 08/27/22 06:41:44.961
    STEP: creating replication controller externalname-service in namespace services-8999 08/27/22 06:41:44.985
    I0827 06:41:44.995377      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8999, replica count: 2
    I0827 06:41:48.046796      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 06:41:48.046: INFO: Creating new exec pod
    Aug 27 06:41:48.056: INFO: Waiting up to 5m0s for pod "execpodrsvpt" in namespace "services-8999" to be "running"
    Aug 27 06:41:48.064: INFO: Pod "execpodrsvpt": Phase="Pending", Reason="", readiness=false. Elapsed: 7.467121ms
    Aug 27 06:41:50.074: INFO: Pod "execpodrsvpt": Phase="Running", Reason="", readiness=true. Elapsed: 2.017540614s
    Aug 27 06:41:50.074: INFO: Pod "execpodrsvpt" satisfied condition "running"
    Aug 27 06:41:51.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 27 06:41:51.339: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 27 06:41:51.339: INFO: stdout: ""
    Aug 27 06:41:52.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Aug 27 06:41:52.500: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Aug 27 06:41:52.500: INFO: stdout: "externalname-service-rg7hb"
    Aug 27 06:41:52.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
    Aug 27 06:41:52.672: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
    Aug 27 06:41:52.672: INFO: stdout: ""
    Aug 27 06:41:53.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
    Aug 27 06:41:53.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
    Aug 27 06:41:53.822: INFO: stdout: ""
    Aug 27 06:41:54.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
    Aug 27 06:41:54.832: INFO: stderr: "+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Aug 27 06:41:54.832: INFO: stdout: ""
    Aug 27 06:41:55.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
    Aug 27 06:41:55.875: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
    Aug 27 06:41:55.875: INFO: stdout: ""
    Aug 27 06:41:56.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-8999 exec execpodrsvpt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.215.193 80'
    Aug 27 06:41:56.841: INFO: stderr: "+ nc+ echo hostName\n -v -t -w 2 10.3.215.193 80\nConnection to 10.3.215.193 80 port [tcp/http] succeeded!\n"
    Aug 27 06:41:56.841: INFO: stdout: "externalname-service-pqmxt"
    Aug 27 06:41:56.841: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:41:56.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8999" for this suite. 08/27/22 06:41:56.885
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:56.899
Aug 27 06:41:56.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:41:56.904
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:56.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:56.933
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 08/27/22 06:41:56.938
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 08/27/22 06:41:56.944
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 08/27/22 06:41:56.944
STEP: creating a pod to probe DNS 08/27/22 06:41:56.945
STEP: submitting the pod to kubernetes 08/27/22 06:41:56.956
Aug 27 06:41:56.966: INFO: Waiting up to 15m0s for pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1" in namespace "dns-7421" to be "running"
Aug 27 06:41:56.974: INFO: Pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.175697ms
Aug 27 06:41:58.978: INFO: Pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011998965s
Aug 27 06:41:58.978: INFO: Pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:41:58.978
STEP: looking for the results for each expected name from probers 08/27/22 06:41:58.982
Aug 27 06:41:58.997: INFO: DNS probes using dns-7421/dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1 succeeded

STEP: deleting the pod 08/27/22 06:41:58.997
STEP: deleting the test headless service 08/27/22 06:41:59.02
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:41:59.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7421" for this suite. 08/27/22 06:41:59.066
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":237,"skipped":4563,"failed":0}
------------------------------
â€¢ [2.173 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:56.899
    Aug 27 06:41:56.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:41:56.904
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:56.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:56.933
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 08/27/22 06:41:56.938
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     08/27/22 06:41:56.944
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7421.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     08/27/22 06:41:56.944
    STEP: creating a pod to probe DNS 08/27/22 06:41:56.945
    STEP: submitting the pod to kubernetes 08/27/22 06:41:56.956
    Aug 27 06:41:56.966: INFO: Waiting up to 15m0s for pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1" in namespace "dns-7421" to be "running"
    Aug 27 06:41:56.974: INFO: Pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.175697ms
    Aug 27 06:41:58.978: INFO: Pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011998965s
    Aug 27 06:41:58.978: INFO: Pod "dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:41:58.978
    STEP: looking for the results for each expected name from probers 08/27/22 06:41:58.982
    Aug 27 06:41:58.997: INFO: DNS probes using dns-7421/dns-test-2fac9170-9803-4113-bec3-250c4aa0d8e1 succeeded

    STEP: deleting the pod 08/27/22 06:41:58.997
    STEP: deleting the test headless service 08/27/22 06:41:59.02
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:41:59.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7421" for this suite. 08/27/22 06:41:59.066
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:41:59.077
Aug 27 06:41:59.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replication-controller 08/27/22 06:41:59.078
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:59.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:59.105
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 08/27/22 06:41:59.111
Aug 27 06:41:59.120: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-9973" to be "running and ready"
Aug 27 06:41:59.126: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 5.08937ms
Aug 27 06:41:59.126: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:42:01.138: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.01736077s
Aug 27 06:42:01.138: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Aug 27 06:42:01.138: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 08/27/22 06:42:01.156
STEP: Then the orphan pod is adopted 08/27/22 06:42:01.181
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 27 06:42:02.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9973" for this suite. 08/27/22 06:42:02.227
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":238,"skipped":4583,"failed":0}
------------------------------
â€¢ [3.171 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:41:59.077
    Aug 27 06:41:59.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replication-controller 08/27/22 06:41:59.078
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:41:59.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:41:59.105
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 08/27/22 06:41:59.111
    Aug 27 06:41:59.120: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-9973" to be "running and ready"
    Aug 27 06:41:59.126: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 5.08937ms
    Aug 27 06:41:59.126: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:42:01.138: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.01736077s
    Aug 27 06:42:01.138: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Aug 27 06:42:01.138: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 08/27/22 06:42:01.156
    STEP: Then the orphan pod is adopted 08/27/22 06:42:01.181
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 27 06:42:02.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9973" for this suite. 08/27/22 06:42:02.227
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:42:02.248
Aug 27 06:42:02.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 06:42:02.249
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:42:02.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:42:02.322
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4831 08/27/22 06:42:02.334
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 08/27/22 06:42:02.347
Aug 27 06:42:02.416: INFO: Found 0 stateful pods, waiting for 3
Aug 27 06:42:12.420: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 06:42:12.420: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 06:42:12.420: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 27 06:42:12.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 06:42:12.674: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 06:42:12.674: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 06:42:12.674: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/27/22 06:42:22.699
Aug 27 06:42:22.719: INFO: Updating stateful set ss2
STEP: Creating a new revision 08/27/22 06:42:22.72
STEP: Updating Pods in reverse ordinal order 08/27/22 06:42:32.841
Aug 27 06:42:32.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 06:42:33.054: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 06:42:33.054: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 06:42:33.054: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 08/27/22 06:42:43.08
Aug 27 06:42:43.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 27 06:42:43.255: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 27 06:42:43.255: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 27 06:42:43.255: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 27 06:42:53.286: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 08/27/22 06:43:03.303
Aug 27 06:43:03.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 27 06:43:03.511: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 27 06:43:03.511: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 27 06:43:03.511: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 06:43:13.553: INFO: Deleting all statefulset in ns statefulset-4831
Aug 27 06:43:13.559: INFO: Scaling statefulset ss2 to 0
Aug 27 06:43:23.596: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 06:43:23.598: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 06:43:23.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4831" for this suite. 08/27/22 06:43:23.614
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":239,"skipped":4595,"failed":0}
------------------------------
â€¢ [SLOW TEST] [81.380 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:42:02.248
    Aug 27 06:42:02.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 06:42:02.249
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:42:02.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:42:02.322
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4831 08/27/22 06:42:02.334
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 08/27/22 06:42:02.347
    Aug 27 06:42:02.416: INFO: Found 0 stateful pods, waiting for 3
    Aug 27 06:42:12.420: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 06:42:12.420: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 06:42:12.420: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Aug 27 06:42:12.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 06:42:12.674: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 06:42:12.674: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 06:42:12.674: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 08/27/22 06:42:22.699
    Aug 27 06:42:22.719: INFO: Updating stateful set ss2
    STEP: Creating a new revision 08/27/22 06:42:22.72
    STEP: Updating Pods in reverse ordinal order 08/27/22 06:42:32.841
    Aug 27 06:42:32.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 06:42:33.054: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 06:42:33.054: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 06:42:33.054: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 08/27/22 06:42:43.08
    Aug 27 06:42:43.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Aug 27 06:42:43.255: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Aug 27 06:42:43.255: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Aug 27 06:42:43.255: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Aug 27 06:42:53.286: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 08/27/22 06:43:03.303
    Aug 27 06:43:03.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=statefulset-4831 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Aug 27 06:43:03.511: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Aug 27 06:43:03.511: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Aug 27 06:43:03.511: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 06:43:13.553: INFO: Deleting all statefulset in ns statefulset-4831
    Aug 27 06:43:13.559: INFO: Scaling statefulset ss2 to 0
    Aug 27 06:43:23.596: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 06:43:23.598: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 06:43:23.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4831" for this suite. 08/27/22 06:43:23.614
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:43:23.63
Aug 27 06:43:23.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 06:43:23.631
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:23.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:23.659
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 06:43:23.673
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:43:24.103
STEP: Deploying the webhook pod 08/27/22 06:43:24.109
STEP: Wait for the deployment to be ready 08/27/22 06:43:24.117
Aug 27 06:43:24.129: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 06:43:26.138
STEP: Verifying the service has paired with the endpoint 08/27/22 06:43:26.148
Aug 27 06:43:27.148: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Aug 27 06:43:27.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Registering the custom resource webhook via the AdmissionRegistration API 08/27/22 06:43:27.677
STEP: Creating a custom resource that should be denied by the webhook 08/27/22 06:43:27.72
STEP: Creating a custom resource whose deletion would be denied by the webhook 08/27/22 06:43:29.775
STEP: Updating the custom resource with disallowed data should be denied 08/27/22 06:43:29.785
STEP: Deleting the custom resource should be denied 08/27/22 06:43:29.794
STEP: Remove the offending key and value from the custom resource data 08/27/22 06:43:29.801
STEP: Deleting the updated custom resource should be successful 08/27/22 06:43:29.812
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:43:30.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9319" for this suite. 08/27/22 06:43:30.343
STEP: Destroying namespace "webhook-9319-markers" for this suite. 08/27/22 06:43:30.352
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":240,"skipped":4609,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.774 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:43:23.63
    Aug 27 06:43:23.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 06:43:23.631
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:23.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:23.659
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 06:43:23.673
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:43:24.103
    STEP: Deploying the webhook pod 08/27/22 06:43:24.109
    STEP: Wait for the deployment to be ready 08/27/22 06:43:24.117
    Aug 27 06:43:24.129: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 06:43:26.138
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:43:26.148
    Aug 27 06:43:27.148: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Aug 27 06:43:27.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 08/27/22 06:43:27.677
    STEP: Creating a custom resource that should be denied by the webhook 08/27/22 06:43:27.72
    STEP: Creating a custom resource whose deletion would be denied by the webhook 08/27/22 06:43:29.775
    STEP: Updating the custom resource with disallowed data should be denied 08/27/22 06:43:29.785
    STEP: Deleting the custom resource should be denied 08/27/22 06:43:29.794
    STEP: Remove the offending key and value from the custom resource data 08/27/22 06:43:29.801
    STEP: Deleting the updated custom resource should be successful 08/27/22 06:43:29.812
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:43:30.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9319" for this suite. 08/27/22 06:43:30.343
    STEP: Destroying namespace "webhook-9319-markers" for this suite. 08/27/22 06:43:30.352
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:43:30.421
Aug 27 06:43:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replication-controller 08/27/22 06:43:30.428
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:30.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:30.466
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 08/27/22 06:43:30.473
STEP: When the matched label of one of its pods change 08/27/22 06:43:30.478
Aug 27 06:43:30.483: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 27 06:43:35.494: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 08/27/22 06:43:35.508
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 27 06:43:36.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-617" for this suite. 08/27/22 06:43:36.549
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":241,"skipped":4610,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.133 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:43:30.421
    Aug 27 06:43:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replication-controller 08/27/22 06:43:30.428
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:30.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:30.466
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 08/27/22 06:43:30.473
    STEP: When the matched label of one of its pods change 08/27/22 06:43:30.478
    Aug 27 06:43:30.483: INFO: Pod name pod-release: Found 0 pods out of 1
    Aug 27 06:43:35.494: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 08/27/22 06:43:35.508
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 27 06:43:36.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-617" for this suite. 08/27/22 06:43:36.549
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:43:36.554
Aug 27 06:43:36.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:43:36.555
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:36.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:36.577
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 08/27/22 06:43:36.58
STEP: Creating a ResourceQuota 08/27/22 06:43:41.583
STEP: Ensuring resource quota status is calculated 08/27/22 06:43:41.59
STEP: Creating a ReplicaSet 08/27/22 06:43:43.593
STEP: Ensuring resource quota status captures replicaset creation 08/27/22 06:43:43.601
STEP: Deleting a ReplicaSet 08/27/22 06:43:45.608
STEP: Ensuring resource quota status released usage 08/27/22 06:43:45.613
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:43:47.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-653" for this suite. 08/27/22 06:43:47.634
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":242,"skipped":4621,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.088 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:43:36.554
    Aug 27 06:43:36.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:43:36.555
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:36.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:36.577
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 08/27/22 06:43:36.58
    STEP: Creating a ResourceQuota 08/27/22 06:43:41.583
    STEP: Ensuring resource quota status is calculated 08/27/22 06:43:41.59
    STEP: Creating a ReplicaSet 08/27/22 06:43:43.593
    STEP: Ensuring resource quota status captures replicaset creation 08/27/22 06:43:43.601
    STEP: Deleting a ReplicaSet 08/27/22 06:43:45.608
    STEP: Ensuring resource quota status released usage 08/27/22 06:43:45.613
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:43:47.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-653" for this suite. 08/27/22 06:43:47.634
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:43:47.643
Aug 27 06:43:47.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:43:47.646
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:47.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:47.67
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 08/27/22 06:43:47.675
STEP: Creating a ResourceQuota 08/27/22 06:43:52.679
STEP: Ensuring resource quota status is calculated 08/27/22 06:43:52.685
STEP: Creating a ReplicationController 08/27/22 06:43:54.69
STEP: Ensuring resource quota status captures replication controller creation 08/27/22 06:43:54.698
STEP: Deleting a ReplicationController 08/27/22 06:43:56.705
STEP: Ensuring resource quota status released usage 08/27/22 06:43:56.719
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:43:58.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9927" for this suite. 08/27/22 06:43:58.729
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":243,"skipped":4637,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.091 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:43:47.643
    Aug 27 06:43:47.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:43:47.646
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:47.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:47.67
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 08/27/22 06:43:47.675
    STEP: Creating a ResourceQuota 08/27/22 06:43:52.679
    STEP: Ensuring resource quota status is calculated 08/27/22 06:43:52.685
    STEP: Creating a ReplicationController 08/27/22 06:43:54.69
    STEP: Ensuring resource quota status captures replication controller creation 08/27/22 06:43:54.698
    STEP: Deleting a ReplicationController 08/27/22 06:43:56.705
    STEP: Ensuring resource quota status released usage 08/27/22 06:43:56.719
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:43:58.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9927" for this suite. 08/27/22 06:43:58.729
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:43:58.738
Aug 27 06:43:58.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename cronjob 08/27/22 06:43:58.739
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:58.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:58.761
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 08/27/22 06:43:58.764
STEP: Ensuring a job is scheduled 08/27/22 06:43:58.769
STEP: Ensuring exactly one is scheduled 08/27/22 06:44:00.775
STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/27/22 06:44:00.78
STEP: Ensuring the job is replaced with a new one 08/27/22 06:44:00.783
STEP: Removing cronjob 08/27/22 06:45:00.79
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Aug 27 06:45:00.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3892" for this suite. 08/27/22 06:45:00.812
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":244,"skipped":4683,"failed":0}
------------------------------
â€¢ [SLOW TEST] [62.111 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:43:58.738
    Aug 27 06:43:58.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename cronjob 08/27/22 06:43:58.739
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:43:58.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:43:58.761
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 08/27/22 06:43:58.764
    STEP: Ensuring a job is scheduled 08/27/22 06:43:58.769
    STEP: Ensuring exactly one is scheduled 08/27/22 06:44:00.775
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 08/27/22 06:44:00.78
    STEP: Ensuring the job is replaced with a new one 08/27/22 06:44:00.783
    STEP: Removing cronjob 08/27/22 06:45:00.79
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Aug 27 06:45:00.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3892" for this suite. 08/27/22 06:45:00.812
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:45:00.859
Aug 27 06:45:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:45:00.861
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:01.013
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:01.08
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 08/27/22 06:45:01.092
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:45:01.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7685" for this suite. 08/27/22 06:45:01.128
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":245,"skipped":4742,"failed":0}
------------------------------
â€¢ [0.284 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:45:00.859
    Aug 27 06:45:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:45:00.861
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:01.013
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:01.08
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 08/27/22 06:45:01.092
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:45:01.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7685" for this suite. 08/27/22 06:45:01.128
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:45:01.144
Aug 27 06:45:01.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename statefulset 08/27/22 06:45:01.145
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:01.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:01.27
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1186 08/27/22 06:45:01.299
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-1186 08/27/22 06:45:01.354
Aug 27 06:45:01.815: INFO: Found 0 stateful pods, waiting for 1
Aug 27 06:45:11.820: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 08/27/22 06:45:11.826
STEP: updating a scale subresource 08/27/22 06:45:11.829
STEP: verifying the statefulset Spec.Replicas was modified 08/27/22 06:45:11.834
STEP: Patch a scale subresource 08/27/22 06:45:11.838
STEP: verifying the statefulset Spec.Replicas was modified 08/27/22 06:45:11.852
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Aug 27 06:45:11.859: INFO: Deleting all statefulset in ns statefulset-1186
Aug 27 06:45:11.864: INFO: Scaling statefulset ss to 0
Aug 27 06:45:21.904: INFO: Waiting for statefulset status.replicas updated to 0
Aug 27 06:45:21.910: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Aug 27 06:45:21.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1186" for this suite. 08/27/22 06:45:21.933
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":246,"skipped":4757,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.805 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:45:01.144
    Aug 27 06:45:01.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename statefulset 08/27/22 06:45:01.145
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:01.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:01.27
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1186 08/27/22 06:45:01.299
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-1186 08/27/22 06:45:01.354
    Aug 27 06:45:01.815: INFO: Found 0 stateful pods, waiting for 1
    Aug 27 06:45:11.820: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 08/27/22 06:45:11.826
    STEP: updating a scale subresource 08/27/22 06:45:11.829
    STEP: verifying the statefulset Spec.Replicas was modified 08/27/22 06:45:11.834
    STEP: Patch a scale subresource 08/27/22 06:45:11.838
    STEP: verifying the statefulset Spec.Replicas was modified 08/27/22 06:45:11.852
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Aug 27 06:45:11.859: INFO: Deleting all statefulset in ns statefulset-1186
    Aug 27 06:45:11.864: INFO: Scaling statefulset ss to 0
    Aug 27 06:45:21.904: INFO: Waiting for statefulset status.replicas updated to 0
    Aug 27 06:45:21.910: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Aug 27 06:45:21.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1186" for this suite. 08/27/22 06:45:21.933
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:45:21.954
Aug 27 06:45:21.954: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:45:21.955
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:21.979
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:21.983
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 in namespace container-probe-1148 08/27/22 06:45:21.988
Aug 27 06:45:21.996: INFO: Waiting up to 5m0s for pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9" in namespace "container-probe-1148" to be "not pending"
Aug 27 06:45:21.999: INFO: Pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.433628ms
Aug 27 06:45:24.005: INFO: Pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.009461392s
Aug 27 06:45:24.005: INFO: Pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9" satisfied condition "not pending"
Aug 27 06:45:24.005: INFO: Started pod liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 in namespace container-probe-1148
STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:45:24.006
Aug 27 06:45:24.009: INFO: Initial restart count of pod liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 is 0
Aug 27 06:45:44.064: INFO: Restart count of pod container-probe-1148/liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 is now 1 (20.055245521s elapsed)
STEP: deleting the pod 08/27/22 06:45:44.064
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:45:44.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1148" for this suite. 08/27/22 06:45:44.111
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":247,"skipped":4805,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.162 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:45:21.954
    Aug 27 06:45:21.954: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:45:21.955
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:21.979
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:21.983
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 in namespace container-probe-1148 08/27/22 06:45:21.988
    Aug 27 06:45:21.996: INFO: Waiting up to 5m0s for pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9" in namespace "container-probe-1148" to be "not pending"
    Aug 27 06:45:21.999: INFO: Pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.433628ms
    Aug 27 06:45:24.005: INFO: Pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.009461392s
    Aug 27 06:45:24.005: INFO: Pod "liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9" satisfied condition "not pending"
    Aug 27 06:45:24.005: INFO: Started pod liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 in namespace container-probe-1148
    STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:45:24.006
    Aug 27 06:45:24.009: INFO: Initial restart count of pod liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 is 0
    Aug 27 06:45:44.064: INFO: Restart count of pod container-probe-1148/liveness-3eb87d01-406a-45ee-9ebf-3c2b17800fd9 is now 1 (20.055245521s elapsed)
    STEP: deleting the pod 08/27/22 06:45:44.064
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:45:44.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1148" for this suite. 08/27/22 06:45:44.111
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:45:44.119
Aug 27 06:45:44.119: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:45:44.12
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:44.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:44.211
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Aug 27 06:45:44.231: INFO: Waiting up to 5m0s for pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4" in namespace "pods-9096" to be "running and ready"
Aug 27 06:45:44.239: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.371681ms
Aug 27 06:45:44.239: INFO: The phase of Pod server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:45:46.243: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012170045s
Aug 27 06:45:46.244: INFO: The phase of Pod server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:45:48.245: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4": Phase="Running", Reason="", readiness=true. Elapsed: 4.013779782s
Aug 27 06:45:48.245: INFO: The phase of Pod server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4 is Running (Ready = true)
Aug 27 06:45:48.245: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4" satisfied condition "running and ready"
Aug 27 06:45:48.268: INFO: Waiting up to 5m0s for pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b" in namespace "pods-9096" to be "Succeeded or Failed"
Aug 27 06:45:48.276: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.196847ms
Aug 27 06:45:50.279: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010241105s
Aug 27 06:45:52.280: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011498009s
STEP: Saw pod success 08/27/22 06:45:52.28
Aug 27 06:45:52.280: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b" satisfied condition "Succeeded or Failed"
Aug 27 06:45:52.283: INFO: Trying to get logs from node ip-10-0-31-158 pod client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b container env3cont: <nil>
STEP: delete the pod 08/27/22 06:45:52.297
Aug 27 06:45:52.308: INFO: Waiting for pod client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b to disappear
Aug 27 06:45:52.314: INFO: Pod client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:45:52.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9096" for this suite. 08/27/22 06:45:52.317
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":248,"skipped":4818,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.203 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:45:44.119
    Aug 27 06:45:44.119: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:45:44.12
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:44.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:44.211
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Aug 27 06:45:44.231: INFO: Waiting up to 5m0s for pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4" in namespace "pods-9096" to be "running and ready"
    Aug 27 06:45:44.239: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.371681ms
    Aug 27 06:45:44.239: INFO: The phase of Pod server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:45:46.243: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012170045s
    Aug 27 06:45:46.244: INFO: The phase of Pod server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:45:48.245: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4": Phase="Running", Reason="", readiness=true. Elapsed: 4.013779782s
    Aug 27 06:45:48.245: INFO: The phase of Pod server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4 is Running (Ready = true)
    Aug 27 06:45:48.245: INFO: Pod "server-envvars-d39e0390-9a47-47c3-b4c7-9508754296b4" satisfied condition "running and ready"
    Aug 27 06:45:48.268: INFO: Waiting up to 5m0s for pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b" in namespace "pods-9096" to be "Succeeded or Failed"
    Aug 27 06:45:48.276: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.196847ms
    Aug 27 06:45:50.279: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010241105s
    Aug 27 06:45:52.280: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011498009s
    STEP: Saw pod success 08/27/22 06:45:52.28
    Aug 27 06:45:52.280: INFO: Pod "client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b" satisfied condition "Succeeded or Failed"
    Aug 27 06:45:52.283: INFO: Trying to get logs from node ip-10-0-31-158 pod client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b container env3cont: <nil>
    STEP: delete the pod 08/27/22 06:45:52.297
    Aug 27 06:45:52.308: INFO: Waiting for pod client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b to disappear
    Aug 27 06:45:52.314: INFO: Pod client-envvars-aa10c6f6-8a2f-4722-90be-77f11255aa7b no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:45:52.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9096" for this suite. 08/27/22 06:45:52.317
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:45:52.327
Aug 27 06:45:52.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:45:52.328
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:52.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:52.349
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Aug 27 06:45:52.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:45:55.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8823" for this suite. 08/27/22 06:45:55.637
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":249,"skipped":4881,"failed":0}
------------------------------
â€¢ [3.314 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:45:52.327
    Aug 27 06:45:52.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:45:52.328
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:52.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:52.349
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Aug 27 06:45:52.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:45:55.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8823" for this suite. 08/27/22 06:45:55.637
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:45:55.643
Aug 27 06:45:55.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:45:55.644
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:55.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:55.665
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Aug 27 06:45:55.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/27/22 06:46:00.056
Aug 27 06:46:00.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 create -f -'
Aug 27 06:46:01.235: INFO: stderr: ""
Aug 27 06:46:01.235: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 27 06:46:01.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 delete e2e-test-crd-publish-openapi-9144-crds test-cr'
Aug 27 06:46:01.346: INFO: stderr: ""
Aug 27 06:46:01.346: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug 27 06:46:01.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 apply -f -'
Aug 27 06:46:01.982: INFO: stderr: ""
Aug 27 06:46:01.982: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 27 06:46:01.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 delete e2e-test-crd-publish-openapi-9144-crds test-cr'
Aug 27 06:46:02.202: INFO: stderr: ""
Aug 27 06:46:02.202: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 08/27/22 06:46:02.202
Aug 27 06:46:02.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 explain e2e-test-crd-publish-openapi-9144-crds'
Aug 27 06:46:02.822: INFO: stderr: ""
Aug 27 06:46:02.822: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9144-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:46:06.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8621" for this suite. 08/27/22 06:46:06.894
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":250,"skipped":4885,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.255 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:45:55.643
    Aug 27 06:45:55.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:45:55.644
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:45:55.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:45:55.665
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Aug 27 06:45:55.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/27/22 06:46:00.056
    Aug 27 06:46:00.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 create -f -'
    Aug 27 06:46:01.235: INFO: stderr: ""
    Aug 27 06:46:01.235: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Aug 27 06:46:01.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 delete e2e-test-crd-publish-openapi-9144-crds test-cr'
    Aug 27 06:46:01.346: INFO: stderr: ""
    Aug 27 06:46:01.346: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Aug 27 06:46:01.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 apply -f -'
    Aug 27 06:46:01.982: INFO: stderr: ""
    Aug 27 06:46:01.982: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Aug 27 06:46:01.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 --namespace=crd-publish-openapi-8621 delete e2e-test-crd-publish-openapi-9144-crds test-cr'
    Aug 27 06:46:02.202: INFO: stderr: ""
    Aug 27 06:46:02.202: INFO: stdout: "e2e-test-crd-publish-openapi-9144-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 08/27/22 06:46:02.202
    Aug 27 06:46:02.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-8621 explain e2e-test-crd-publish-openapi-9144-crds'
    Aug 27 06:46:02.822: INFO: stderr: ""
    Aug 27 06:46:02.822: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9144-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:46:06.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8621" for this suite. 08/27/22 06:46:06.894
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:46:06.9
Aug 27 06:46:06.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:46:06.901
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:06.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:06.936
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-a38fc869-1efe-473e-ac09-f0c93f11098b 08/27/22 06:46:06.939
STEP: Creating a pod to test consume secrets 08/27/22 06:46:06.943
Aug 27 06:46:06.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621" in namespace "projected-9605" to be "Succeeded or Failed"
Aug 27 06:46:06.952: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.737444ms
Aug 27 06:46:08.957: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007493276s
Aug 27 06:46:10.969: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019660415s
STEP: Saw pod success 08/27/22 06:46:10.969
Aug 27 06:46:10.969: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621" satisfied condition "Succeeded or Failed"
Aug 27 06:46:10.976: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:46:11.02
Aug 27 06:46:11.078: INFO: Waiting for pod pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621 to disappear
Aug 27 06:46:11.156: INFO: Pod pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 06:46:11.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9605" for this suite. 08/27/22 06:46:11.18
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":251,"skipped":4900,"failed":0}
------------------------------
â€¢ [4.285 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:46:06.9
    Aug 27 06:46:06.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:46:06.901
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:06.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:06.936
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-a38fc869-1efe-473e-ac09-f0c93f11098b 08/27/22 06:46:06.939
    STEP: Creating a pod to test consume secrets 08/27/22 06:46:06.943
    Aug 27 06:46:06.949: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621" in namespace "projected-9605" to be "Succeeded or Failed"
    Aug 27 06:46:06.952: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.737444ms
    Aug 27 06:46:08.957: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007493276s
    Aug 27 06:46:10.969: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019660415s
    STEP: Saw pod success 08/27/22 06:46:10.969
    Aug 27 06:46:10.969: INFO: Pod "pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621" satisfied condition "Succeeded or Failed"
    Aug 27 06:46:10.976: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:46:11.02
    Aug 27 06:46:11.078: INFO: Waiting for pod pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621 to disappear
    Aug 27 06:46:11.156: INFO: Pod pod-projected-secrets-377a237f-a8b1-46a4-9ec0-6eb8c4e44621 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 06:46:11.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9605" for this suite. 08/27/22 06:46:11.18
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:46:11.192
Aug 27 06:46:11.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename init-container 08/27/22 06:46:11.193
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:11.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:11.228
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 08/27/22 06:46:11.233
Aug 27 06:46:11.234: INFO: PodSpec: initContainers in spec.initContainers
Aug 27 06:46:53.512: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c5584e99-0417-465b-8869-cbe05aab4585", GenerateName:"", Namespace:"init-container-781", SelfLink:"", UID:"1cd1f5fe-d696-44de-8e83-7c56235251a8", ResourceVersion:"25118", Generation:0, CreationTimestamp:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"234079382"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"6d320aa34e5a465484987b52cbda9420f61cecbbc48739f80003fd8af50f71d8", "cni.projectcalico.org/podIP":"10.2.35.11/32", "cni.projectcalico.org/podIPs":"10.2.35.11/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f26030), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f26060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 27, 6, 46, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f26090), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-ll94l", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0035f7c60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ll94l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ll94l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ll94l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00611c128), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-47-192", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000487e30), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00611c1c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00611c1e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00611c1e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00611c1ec), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0053d38d0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.47.192", PodIP:"10.2.35.11", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.35.11"}}, StartTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000487f10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000487f80)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://42b1c22e5584676794463f6b5febb198fc962845a69110ed6f213da6a6bdc71d", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035f7ce0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035f7cc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00611c29f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 06:46:53.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-781" for this suite. 08/27/22 06:46:53.517
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":252,"skipped":4924,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.331 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:46:11.192
    Aug 27 06:46:11.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename init-container 08/27/22 06:46:11.193
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:11.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:11.228
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 08/27/22 06:46:11.233
    Aug 27 06:46:11.234: INFO: PodSpec: initContainers in spec.initContainers
    Aug 27 06:46:53.512: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c5584e99-0417-465b-8869-cbe05aab4585", GenerateName:"", Namespace:"init-container-781", SelfLink:"", UID:"1cd1f5fe-d696-44de-8e83-7c56235251a8", ResourceVersion:"25118", Generation:0, CreationTimestamp:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"234079382"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"6d320aa34e5a465484987b52cbda9420f61cecbbc48739f80003fd8af50f71d8", "cni.projectcalico.org/podIP":"10.2.35.11/32", "cni.projectcalico.org/podIPs":"10.2.35.11/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f26030), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f26060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 27, 6, 46, 53, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000f26090), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-ll94l", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0035f7c60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ll94l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ll94l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-ll94l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00611c128), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-47-192", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000487e30), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00611c1c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00611c1e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00611c1e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00611c1ec), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0053d38d0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.47.192", PodIP:"10.2.35.11", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.35.11"}}, StartTime:time.Date(2022, time.August, 27, 6, 46, 11, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000487f10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000487f80)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://42b1c22e5584676794463f6b5febb198fc962845a69110ed6f213da6a6bdc71d", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035f7ce0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0035f7cc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc00611c29f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 06:46:53.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-781" for this suite. 08/27/22 06:46:53.517
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:46:53.525
Aug 27 06:46:53.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 06:46:53.526
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:53.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:53.55
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 06:46:53.569
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:46:53.885
STEP: Deploying the webhook pod 08/27/22 06:46:53.891
STEP: Wait for the deployment to be ready 08/27/22 06:46:53.9
Aug 27 06:46:53.906: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/27/22 06:46:55.924
STEP: Verifying the service has paired with the endpoint 08/27/22 06:46:55.95
Aug 27 06:46:56.951: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 08/27/22 06:46:56.956
STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:46:56.971
STEP: Updating a validating webhook configuration's rules to not include the create operation 08/27/22 06:46:56.981
STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:46:56.992
STEP: Patching a validating webhook configuration's rules to include the create operation 08/27/22 06:46:57.002
STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:46:57.009
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:46:57.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3033" for this suite. 08/27/22 06:46:57.02
STEP: Destroying namespace "webhook-3033-markers" for this suite. 08/27/22 06:46:57.026
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":253,"skipped":4926,"failed":0}
------------------------------
â€¢ [3.586 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:46:53.525
    Aug 27 06:46:53.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 06:46:53.526
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:53.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:53.55
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 06:46:53.569
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:46:53.885
    STEP: Deploying the webhook pod 08/27/22 06:46:53.891
    STEP: Wait for the deployment to be ready 08/27/22 06:46:53.9
    Aug 27 06:46:53.906: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/27/22 06:46:55.924
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:46:55.95
    Aug 27 06:46:56.951: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 08/27/22 06:46:56.956
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:46:56.971
    STEP: Updating a validating webhook configuration's rules to not include the create operation 08/27/22 06:46:56.981
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:46:56.992
    STEP: Patching a validating webhook configuration's rules to include the create operation 08/27/22 06:46:57.002
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:46:57.009
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:46:57.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3033" for this suite. 08/27/22 06:46:57.02
    STEP: Destroying namespace "webhook-3033-markers" for this suite. 08/27/22 06:46:57.026
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:46:57.118
Aug 27 06:46:57.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:46:57.119
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:57.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:57.165
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Aug 27 06:46:57.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 08/27/22 06:46:59.502
Aug 27 06:46:59.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
Aug 27 06:47:00.397: INFO: stderr: ""
Aug 27 06:47:00.397: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 27 06:47:00.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 delete e2e-test-crd-publish-openapi-258-crds test-foo'
Aug 27 06:47:00.464: INFO: stderr: ""
Aug 27 06:47:00.464: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug 27 06:47:00.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 apply -f -'
Aug 27 06:47:00.663: INFO: stderr: ""
Aug 27 06:47:00.663: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 27 06:47:00.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 delete e2e-test-crd-publish-openapi-258-crds test-foo'
Aug 27 06:47:00.756: INFO: stderr: ""
Aug 27 06:47:00.756: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 08/27/22 06:47:00.756
Aug 27 06:47:00.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
Aug 27 06:47:01.037: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 08/27/22 06:47:01.038
Aug 27 06:47:01.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
Aug 27 06:47:01.300: INFO: rc: 1
Aug 27 06:47:01.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 apply -f -'
Aug 27 06:47:02.050: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 08/27/22 06:47:02.05
Aug 27 06:47:02.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
Aug 27 06:47:02.609: INFO: rc: 1
Aug 27 06:47:02.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 apply -f -'
Aug 27 06:47:03.018: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 08/27/22 06:47:03.018
Aug 27 06:47:03.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds'
Aug 27 06:47:03.284: INFO: stderr: ""
Aug 27 06:47:03.284: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 08/27/22 06:47:03.284
Aug 27 06:47:03.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.metadata'
Aug 27 06:47:03.532: INFO: stderr: ""
Aug 27 06:47:03.532: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug 27 06:47:03.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.spec'
Aug 27 06:47:03.739: INFO: stderr: ""
Aug 27 06:47:03.739: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug 27 06:47:03.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.spec.bars'
Aug 27 06:47:03.938: INFO: stderr: ""
Aug 27 06:47:03.938: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 08/27/22 06:47:03.938
Aug 27 06:47:03.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.spec.bars2'
Aug 27 06:47:04.170: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:47:07.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2495" for this suite. 08/27/22 06:47:07.484
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":254,"skipped":4926,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.381 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:46:57.118
    Aug 27 06:46:57.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:46:57.119
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:46:57.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:46:57.165
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Aug 27 06:46:57.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 08/27/22 06:46:59.502
    Aug 27 06:46:59.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
    Aug 27 06:47:00.397: INFO: stderr: ""
    Aug 27 06:47:00.397: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Aug 27 06:47:00.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 delete e2e-test-crd-publish-openapi-258-crds test-foo'
    Aug 27 06:47:00.464: INFO: stderr: ""
    Aug 27 06:47:00.464: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Aug 27 06:47:00.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 apply -f -'
    Aug 27 06:47:00.663: INFO: stderr: ""
    Aug 27 06:47:00.663: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Aug 27 06:47:00.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 delete e2e-test-crd-publish-openapi-258-crds test-foo'
    Aug 27 06:47:00.756: INFO: stderr: ""
    Aug 27 06:47:00.756: INFO: stdout: "e2e-test-crd-publish-openapi-258-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 08/27/22 06:47:00.756
    Aug 27 06:47:00.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
    Aug 27 06:47:01.037: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 08/27/22 06:47:01.038
    Aug 27 06:47:01.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
    Aug 27 06:47:01.300: INFO: rc: 1
    Aug 27 06:47:01.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 apply -f -'
    Aug 27 06:47:02.050: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 08/27/22 06:47:02.05
    Aug 27 06:47:02.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 create -f -'
    Aug 27 06:47:02.609: INFO: rc: 1
    Aug 27 06:47:02.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 --namespace=crd-publish-openapi-2495 apply -f -'
    Aug 27 06:47:03.018: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 08/27/22 06:47:03.018
    Aug 27 06:47:03.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds'
    Aug 27 06:47:03.284: INFO: stderr: ""
    Aug 27 06:47:03.284: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 08/27/22 06:47:03.284
    Aug 27 06:47:03.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.metadata'
    Aug 27 06:47:03.532: INFO: stderr: ""
    Aug 27 06:47:03.532: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Aug 27 06:47:03.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.spec'
    Aug 27 06:47:03.739: INFO: stderr: ""
    Aug 27 06:47:03.739: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Aug 27 06:47:03.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.spec.bars'
    Aug 27 06:47:03.938: INFO: stderr: ""
    Aug 27 06:47:03.938: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-258-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 08/27/22 06:47:03.938
    Aug 27 06:47:03.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-2495 explain e2e-test-crd-publish-openapi-258-crds.spec.bars2'
    Aug 27 06:47:04.170: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:47:07.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2495" for this suite. 08/27/22 06:47:07.484
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:47:07.501
Aug 27 06:47:07.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:47:07.501
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:47:07.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:47:07.553
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-9244/configmap-test-da221cd8-8af4-4b61-8a65-5c8f07dbe690 08/27/22 06:47:07.559
STEP: Creating a pod to test consume configMaps 08/27/22 06:47:07.582
Aug 27 06:47:07.599: INFO: Waiting up to 5m0s for pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9" in namespace "configmap-9244" to be "Succeeded or Failed"
Aug 27 06:47:07.609: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.353787ms
Aug 27 06:47:09.613: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9": Phase="Running", Reason="", readiness=false. Elapsed: 2.01439518s
Aug 27 06:47:11.629: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029906317s
STEP: Saw pod success 08/27/22 06:47:11.629
Aug 27 06:47:11.629: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9" satisfied condition "Succeeded or Failed"
Aug 27 06:47:11.648: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9 container env-test: <nil>
STEP: delete the pod 08/27/22 06:47:11.657
Aug 27 06:47:11.668: INFO: Waiting for pod pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9 to disappear
Aug 27 06:47:11.676: INFO: Pod pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:47:11.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9244" for this suite. 08/27/22 06:47:11.68
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":255,"skipped":4950,"failed":0}
------------------------------
â€¢ [4.184 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:47:07.501
    Aug 27 06:47:07.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:47:07.501
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:47:07.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:47:07.553
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-9244/configmap-test-da221cd8-8af4-4b61-8a65-5c8f07dbe690 08/27/22 06:47:07.559
    STEP: Creating a pod to test consume configMaps 08/27/22 06:47:07.582
    Aug 27 06:47:07.599: INFO: Waiting up to 5m0s for pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9" in namespace "configmap-9244" to be "Succeeded or Failed"
    Aug 27 06:47:07.609: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.353787ms
    Aug 27 06:47:09.613: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9": Phase="Running", Reason="", readiness=false. Elapsed: 2.01439518s
    Aug 27 06:47:11.629: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029906317s
    STEP: Saw pod success 08/27/22 06:47:11.629
    Aug 27 06:47:11.629: INFO: Pod "pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9" satisfied condition "Succeeded or Failed"
    Aug 27 06:47:11.648: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9 container env-test: <nil>
    STEP: delete the pod 08/27/22 06:47:11.657
    Aug 27 06:47:11.668: INFO: Waiting for pod pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9 to disappear
    Aug 27 06:47:11.676: INFO: Pod pod-configmaps-5211ff01-daf2-4ce4-8f00-515fcbf7dbb9 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:47:11.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9244" for this suite. 08/27/22 06:47:11.68
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:47:11.686
Aug 27 06:47:11.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename resourcequota 08/27/22 06:47:11.688
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:47:11.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:47:11.718
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 08/27/22 06:47:11.722
STEP: Ensuring ResourceQuota status is calculated 08/27/22 06:47:11.729
STEP: Creating a ResourceQuota with not best effort scope 08/27/22 06:47:13.734
STEP: Ensuring ResourceQuota status is calculated 08/27/22 06:47:13.738
STEP: Creating a best-effort pod 08/27/22 06:47:15.742
STEP: Ensuring resource quota with best effort scope captures the pod usage 08/27/22 06:47:15.753
STEP: Ensuring resource quota with not best effort ignored the pod usage 08/27/22 06:47:17.758
STEP: Deleting the pod 08/27/22 06:47:19.762
STEP: Ensuring resource quota status released the pod usage 08/27/22 06:47:19.773
STEP: Creating a not best-effort pod 08/27/22 06:47:21.814
STEP: Ensuring resource quota with not best effort scope captures the pod usage 08/27/22 06:47:21.826
STEP: Ensuring resource quota with best effort scope ignored the pod usage 08/27/22 06:47:23.83
STEP: Deleting the pod 08/27/22 06:47:25.835
STEP: Ensuring resource quota status released the pod usage 08/27/22 06:47:25.844
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Aug 27 06:47:27.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7891" for this suite. 08/27/22 06:47:27.851
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":256,"skipped":4967,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.170 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:47:11.686
    Aug 27 06:47:11.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename resourcequota 08/27/22 06:47:11.688
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:47:11.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:47:11.718
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 08/27/22 06:47:11.722
    STEP: Ensuring ResourceQuota status is calculated 08/27/22 06:47:11.729
    STEP: Creating a ResourceQuota with not best effort scope 08/27/22 06:47:13.734
    STEP: Ensuring ResourceQuota status is calculated 08/27/22 06:47:13.738
    STEP: Creating a best-effort pod 08/27/22 06:47:15.742
    STEP: Ensuring resource quota with best effort scope captures the pod usage 08/27/22 06:47:15.753
    STEP: Ensuring resource quota with not best effort ignored the pod usage 08/27/22 06:47:17.758
    STEP: Deleting the pod 08/27/22 06:47:19.762
    STEP: Ensuring resource quota status released the pod usage 08/27/22 06:47:19.773
    STEP: Creating a not best-effort pod 08/27/22 06:47:21.814
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 08/27/22 06:47:21.826
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 08/27/22 06:47:23.83
    STEP: Deleting the pod 08/27/22 06:47:25.835
    STEP: Ensuring resource quota status released the pod usage 08/27/22 06:47:25.844
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Aug 27 06:47:27.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7891" for this suite. 08/27/22 06:47:27.851
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:47:27.864
Aug 27 06:47:27.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir-wrapper 08/27/22 06:47:27.868
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:47:27.883
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:47:27.887
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 08/27/22 06:47:27.89
STEP: Creating RC which spawns configmap-volume pods 08/27/22 06:47:28.123
Aug 27 06:47:28.274: INFO: Pod name wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2: Found 3 pods out of 5
Aug 27 06:47:33.281: INFO: Pod name wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/27/22 06:47:33.281
Aug 27 06:47:33.282: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:47:33.285: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137769ms
Aug 27 06:47:35.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008047567s
Aug 27 06:47:37.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008012465s
Aug 27 06:47:39.292: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009880252s
Aug 27 06:47:41.331: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 8.049595638s
Aug 27 06:47:43.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Running", Reason="", readiness=true. Elapsed: 10.007970481s
Aug 27 06:47:43.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp" satisfied condition "running"
Aug 27 06:47:43.290: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-6c7tk" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:47:43.293: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-6c7tk": Phase="Running", Reason="", readiness=true. Elapsed: 2.98604ms
Aug 27 06:47:43.293: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-6c7tk" satisfied condition "running"
Aug 27 06:47:43.293: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-dv85l" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:47:43.296: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-dv85l": Phase="Running", Reason="", readiness=true. Elapsed: 2.788932ms
Aug 27 06:47:43.296: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-dv85l" satisfied condition "running"
Aug 27 06:47:43.296: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-njt8f" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:47:43.301: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-njt8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.991707ms
Aug 27 06:47:43.301: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-njt8f" satisfied condition "running"
Aug 27 06:47:43.301: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:47:43.304: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230632ms
Aug 27 06:47:45.309: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd": Phase="Running", Reason="", readiness=true. Elapsed: 2.007878502s
Aug 27 06:47:45.309: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2 in namespace emptydir-wrapper-4128, will wait for the garbage collector to delete the pods 08/27/22 06:47:45.309
Aug 27 06:47:45.371: INFO: Deleting ReplicationController wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2 took: 5.473633ms
Aug 27 06:47:45.471: INFO: Terminating ReplicationController wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2 pods took: 100.277332ms
STEP: Creating RC which spawns configmap-volume pods 08/27/22 06:47:48.275
Aug 27 06:47:48.298: INFO: Pod name wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1: Found 0 pods out of 5
Aug 27 06:47:53.305: INFO: Pod name wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/27/22 06:47:53.305
Aug 27 06:47:53.305: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:47:53.309: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617339ms
Aug 27 06:47:55.314: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008990823s
Aug 27 06:47:57.315: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010506709s
Aug 27 06:47:59.313: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008600356s
Aug 27 06:48:01.355: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05067758s
Aug 27 06:48:03.375: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Running", Reason="", readiness=true. Elapsed: 10.070542858s
Aug 27 06:48:03.375: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f" satisfied condition "running"
Aug 27 06:48:03.375: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:03.525: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44": Phase="Pending", Reason="", readiness=false. Elapsed: 150.019586ms
Aug 27 06:48:05.531: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44": Phase="Running", Reason="", readiness=true. Elapsed: 2.155198079s
Aug 27 06:48:05.531: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44" satisfied condition "running"
Aug 27 06:48:05.531: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-q5vgx" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:05.534: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-q5vgx": Phase="Running", Reason="", readiness=true. Elapsed: 3.666771ms
Aug 27 06:48:05.534: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-q5vgx" satisfied condition "running"
Aug 27 06:48:05.535: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-qg76h" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:05.541: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-qg76h": Phase="Running", Reason="", readiness=true. Elapsed: 6.397927ms
Aug 27 06:48:05.541: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-qg76h" satisfied condition "running"
Aug 27 06:48:05.541: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-zpshz" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:05.545: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-zpshz": Phase="Running", Reason="", readiness=true. Elapsed: 3.551862ms
Aug 27 06:48:05.545: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-zpshz" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1 in namespace emptydir-wrapper-4128, will wait for the garbage collector to delete the pods 08/27/22 06:48:05.545
Aug 27 06:48:05.606: INFO: Deleting ReplicationController wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1 took: 7.009103ms
Aug 27 06:48:05.807: INFO: Terminating ReplicationController wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1 pods took: 201.206434ms
STEP: Creating RC which spawns configmap-volume pods 08/27/22 06:48:08.712
Aug 27 06:48:08.727: INFO: Pod name wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499: Found 0 pods out of 5
Aug 27 06:48:13.743: INFO: Pod name wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499: Found 5 pods out of 5
STEP: Ensuring each pod is running 08/27/22 06:48:13.743
Aug 27 06:48:13.743: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:13.746: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.01927ms
Aug 27 06:48:15.751: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007728305s
Aug 27 06:48:17.750: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0071235s
Aug 27 06:48:19.751: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.00848221s
Aug 27 06:48:21.755: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011793873s
Aug 27 06:48:23.750: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Running", Reason="", readiness=true. Elapsed: 10.006891885s
Aug 27 06:48:23.750: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb" satisfied condition "running"
Aug 27 06:48:23.750: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-cnk4t" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:23.753: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-cnk4t": Phase="Running", Reason="", readiness=true. Elapsed: 2.890312ms
Aug 27 06:48:23.753: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-cnk4t" satisfied condition "running"
Aug 27 06:48:23.753: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-jsldk" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:23.756: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-jsldk": Phase="Running", Reason="", readiness=true. Elapsed: 2.904884ms
Aug 27 06:48:23.756: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-jsldk" satisfied condition "running"
Aug 27 06:48:23.756: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-kjxxj" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:23.760: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-kjxxj": Phase="Running", Reason="", readiness=true. Elapsed: 3.556875ms
Aug 27 06:48:23.760: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-kjxxj" satisfied condition "running"
Aug 27 06:48:23.760: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-s2pz8" in namespace "emptydir-wrapper-4128" to be "running"
Aug 27 06:48:23.763: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-s2pz8": Phase="Running", Reason="", readiness=true. Elapsed: 2.638077ms
Aug 27 06:48:23.763: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-s2pz8" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499 in namespace emptydir-wrapper-4128, will wait for the garbage collector to delete the pods 08/27/22 06:48:23.763
Aug 27 06:48:23.822: INFO: Deleting ReplicationController wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499 took: 4.852986ms
Aug 27 06:48:23.922: INFO: Terminating ReplicationController wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499 pods took: 100.260508ms
STEP: Cleaning up the configMaps 08/27/22 06:48:28.223
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Aug 27 06:48:28.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4128" for this suite. 08/27/22 06:48:28.441
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":257,"skipped":4986,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.581 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:47:27.864
    Aug 27 06:47:27.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir-wrapper 08/27/22 06:47:27.868
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:47:27.883
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:47:27.887
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 08/27/22 06:47:27.89
    STEP: Creating RC which spawns configmap-volume pods 08/27/22 06:47:28.123
    Aug 27 06:47:28.274: INFO: Pod name wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2: Found 3 pods out of 5
    Aug 27 06:47:33.281: INFO: Pod name wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/27/22 06:47:33.281
    Aug 27 06:47:33.282: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:47:33.285: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137769ms
    Aug 27 06:47:35.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008047567s
    Aug 27 06:47:37.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008012465s
    Aug 27 06:47:39.292: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009880252s
    Aug 27 06:47:41.331: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Pending", Reason="", readiness=false. Elapsed: 8.049595638s
    Aug 27 06:47:43.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp": Phase="Running", Reason="", readiness=true. Elapsed: 10.007970481s
    Aug 27 06:47:43.290: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-487zp" satisfied condition "running"
    Aug 27 06:47:43.290: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-6c7tk" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:47:43.293: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-6c7tk": Phase="Running", Reason="", readiness=true. Elapsed: 2.98604ms
    Aug 27 06:47:43.293: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-6c7tk" satisfied condition "running"
    Aug 27 06:47:43.293: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-dv85l" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:47:43.296: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-dv85l": Phase="Running", Reason="", readiness=true. Elapsed: 2.788932ms
    Aug 27 06:47:43.296: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-dv85l" satisfied condition "running"
    Aug 27 06:47:43.296: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-njt8f" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:47:43.301: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-njt8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.991707ms
    Aug 27 06:47:43.301: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-njt8f" satisfied condition "running"
    Aug 27 06:47:43.301: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:47:43.304: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230632ms
    Aug 27 06:47:45.309: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd": Phase="Running", Reason="", readiness=true. Elapsed: 2.007878502s
    Aug 27 06:47:45.309: INFO: Pod "wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2-x8kpd" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2 in namespace emptydir-wrapper-4128, will wait for the garbage collector to delete the pods 08/27/22 06:47:45.309
    Aug 27 06:47:45.371: INFO: Deleting ReplicationController wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2 took: 5.473633ms
    Aug 27 06:47:45.471: INFO: Terminating ReplicationController wrapped-volume-race-b3ca099b-0018-415e-aa78-62e06e7a33e2 pods took: 100.277332ms
    STEP: Creating RC which spawns configmap-volume pods 08/27/22 06:47:48.275
    Aug 27 06:47:48.298: INFO: Pod name wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1: Found 0 pods out of 5
    Aug 27 06:47:53.305: INFO: Pod name wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/27/22 06:47:53.305
    Aug 27 06:47:53.305: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:47:53.309: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617339ms
    Aug 27 06:47:55.314: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008990823s
    Aug 27 06:47:57.315: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010506709s
    Aug 27 06:47:59.313: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008600356s
    Aug 27 06:48:01.355: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05067758s
    Aug 27 06:48:03.375: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f": Phase="Running", Reason="", readiness=true. Elapsed: 10.070542858s
    Aug 27 06:48:03.375: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-7dz7f" satisfied condition "running"
    Aug 27 06:48:03.375: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:03.525: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44": Phase="Pending", Reason="", readiness=false. Elapsed: 150.019586ms
    Aug 27 06:48:05.531: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44": Phase="Running", Reason="", readiness=true. Elapsed: 2.155198079s
    Aug 27 06:48:05.531: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-jpd44" satisfied condition "running"
    Aug 27 06:48:05.531: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-q5vgx" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:05.534: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-q5vgx": Phase="Running", Reason="", readiness=true. Elapsed: 3.666771ms
    Aug 27 06:48:05.534: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-q5vgx" satisfied condition "running"
    Aug 27 06:48:05.535: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-qg76h" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:05.541: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-qg76h": Phase="Running", Reason="", readiness=true. Elapsed: 6.397927ms
    Aug 27 06:48:05.541: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-qg76h" satisfied condition "running"
    Aug 27 06:48:05.541: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-zpshz" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:05.545: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-zpshz": Phase="Running", Reason="", readiness=true. Elapsed: 3.551862ms
    Aug 27 06:48:05.545: INFO: Pod "wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1-zpshz" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1 in namespace emptydir-wrapper-4128, will wait for the garbage collector to delete the pods 08/27/22 06:48:05.545
    Aug 27 06:48:05.606: INFO: Deleting ReplicationController wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1 took: 7.009103ms
    Aug 27 06:48:05.807: INFO: Terminating ReplicationController wrapped-volume-race-d77d9b8f-9c66-4f5c-9456-62617247eaa1 pods took: 201.206434ms
    STEP: Creating RC which spawns configmap-volume pods 08/27/22 06:48:08.712
    Aug 27 06:48:08.727: INFO: Pod name wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499: Found 0 pods out of 5
    Aug 27 06:48:13.743: INFO: Pod name wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499: Found 5 pods out of 5
    STEP: Ensuring each pod is running 08/27/22 06:48:13.743
    Aug 27 06:48:13.743: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:13.746: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.01927ms
    Aug 27 06:48:15.751: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007728305s
    Aug 27 06:48:17.750: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0071235s
    Aug 27 06:48:19.751: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.00848221s
    Aug 27 06:48:21.755: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011793873s
    Aug 27 06:48:23.750: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb": Phase="Running", Reason="", readiness=true. Elapsed: 10.006891885s
    Aug 27 06:48:23.750: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-b7zgb" satisfied condition "running"
    Aug 27 06:48:23.750: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-cnk4t" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:23.753: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-cnk4t": Phase="Running", Reason="", readiness=true. Elapsed: 2.890312ms
    Aug 27 06:48:23.753: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-cnk4t" satisfied condition "running"
    Aug 27 06:48:23.753: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-jsldk" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:23.756: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-jsldk": Phase="Running", Reason="", readiness=true. Elapsed: 2.904884ms
    Aug 27 06:48:23.756: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-jsldk" satisfied condition "running"
    Aug 27 06:48:23.756: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-kjxxj" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:23.760: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-kjxxj": Phase="Running", Reason="", readiness=true. Elapsed: 3.556875ms
    Aug 27 06:48:23.760: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-kjxxj" satisfied condition "running"
    Aug 27 06:48:23.760: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-s2pz8" in namespace "emptydir-wrapper-4128" to be "running"
    Aug 27 06:48:23.763: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-s2pz8": Phase="Running", Reason="", readiness=true. Elapsed: 2.638077ms
    Aug 27 06:48:23.763: INFO: Pod "wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499-s2pz8" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499 in namespace emptydir-wrapper-4128, will wait for the garbage collector to delete the pods 08/27/22 06:48:23.763
    Aug 27 06:48:23.822: INFO: Deleting ReplicationController wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499 took: 4.852986ms
    Aug 27 06:48:23.922: INFO: Terminating ReplicationController wrapped-volume-race-2b45f02f-ad9b-4c24-81c6-089125342499 pods took: 100.260508ms
    STEP: Cleaning up the configMaps 08/27/22 06:48:28.223
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:48:28.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-4128" for this suite. 08/27/22 06:48:28.441
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:48:28.446
Aug 27 06:48:28.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:48:28.448
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:28.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:28.472
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 08/27/22 06:48:28.476
Aug 27 06:48:28.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:31.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:48:41.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6192" for this suite. 08/27/22 06:48:41.386
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":258,"skipped":4988,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.944 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:48:28.446
    Aug 27 06:48:28.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:48:28.448
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:28.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:28.472
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 08/27/22 06:48:28.476
    Aug 27 06:48:28.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:31.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:48:41.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6192" for this suite. 08/27/22 06:48:41.386
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:48:41.391
Aug 27 06:48:41.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 08/27/22 06:48:41.392
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:41.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:41.411
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 08/27/22 06:48:41.414
STEP: Creating hostNetwork=false pod 08/27/22 06:48:41.414
Aug 27 06:48:41.420: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1292" to be "running and ready"
Aug 27 06:48:41.423: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.138792ms
Aug 27 06:48:41.423: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:48:43.426: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006061118s
Aug 27 06:48:43.426: INFO: The phase of Pod test-pod is Running (Ready = true)
Aug 27 06:48:43.426: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 08/27/22 06:48:43.429
Aug 27 06:48:43.433: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1292" to be "running and ready"
Aug 27 06:48:43.436: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.409932ms
Aug 27 06:48:43.436: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:48:45.440: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006769903s
Aug 27 06:48:45.440: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Aug 27 06:48:45.440: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 08/27/22 06:48:45.443
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 08/27/22 06:48:45.443
Aug 27 06:48:45.443: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.444: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.444: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 27 06:48:45.542: INFO: Exec stderr: ""
Aug 27 06:48:45.542: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.543: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.543: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 27 06:48:45.622: INFO: Exec stderr: ""
Aug 27 06:48:45.622: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.623: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.623: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 27 06:48:45.687: INFO: Exec stderr: ""
Aug 27 06:48:45.687: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.688: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.688: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 27 06:48:45.747: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 08/27/22 06:48:45.747
Aug 27 06:48:45.748: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.748: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.748: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug 27 06:48:45.811: INFO: Exec stderr: ""
Aug 27 06:48:45.811: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.812: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.812: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Aug 27 06:48:45.877: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 08/27/22 06:48:45.877
Aug 27 06:48:45.878: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.878: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.878: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.878: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 27 06:48:45.989: INFO: Exec stderr: ""
Aug 27 06:48:45.989: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:45.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:45.990: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:45.990: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Aug 27 06:48:46.096: INFO: Exec stderr: ""
Aug 27 06:48:46.096: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:46.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:46.097: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:46.097: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 27 06:48:46.163: INFO: Exec stderr: ""
Aug 27 06:48:46.163: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 27 06:48:46.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 06:48:46.163: INFO: ExecWithOptions: Clientset creation
Aug 27 06:48:46.163: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Aug 27 06:48:46.296: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Aug 27 06:48:46.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1292" for this suite. 08/27/22 06:48:46.299
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":259,"skipped":4994,"failed":0}
------------------------------
â€¢ [4.914 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:48:41.391
    Aug 27 06:48:41.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 08/27/22 06:48:41.392
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:41.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:41.411
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 08/27/22 06:48:41.414
    STEP: Creating hostNetwork=false pod 08/27/22 06:48:41.414
    Aug 27 06:48:41.420: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-1292" to be "running and ready"
    Aug 27 06:48:41.423: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.138792ms
    Aug 27 06:48:41.423: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:48:43.426: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006061118s
    Aug 27 06:48:43.426: INFO: The phase of Pod test-pod is Running (Ready = true)
    Aug 27 06:48:43.426: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 08/27/22 06:48:43.429
    Aug 27 06:48:43.433: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-1292" to be "running and ready"
    Aug 27 06:48:43.436: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.409932ms
    Aug 27 06:48:43.436: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:48:45.440: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.006769903s
    Aug 27 06:48:45.440: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Aug 27 06:48:45.440: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 08/27/22 06:48:45.443
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 08/27/22 06:48:45.443
    Aug 27 06:48:45.443: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.444: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.444: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 27 06:48:45.542: INFO: Exec stderr: ""
    Aug 27 06:48:45.542: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.543: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.543: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 27 06:48:45.622: INFO: Exec stderr: ""
    Aug 27 06:48:45.622: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.623: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.623: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 27 06:48:45.687: INFO: Exec stderr: ""
    Aug 27 06:48:45.687: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.688: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.688: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 27 06:48:45.747: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 08/27/22 06:48:45.747
    Aug 27 06:48:45.748: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.748: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.748: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Aug 27 06:48:45.811: INFO: Exec stderr: ""
    Aug 27 06:48:45.811: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.812: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.812: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Aug 27 06:48:45.877: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 08/27/22 06:48:45.877
    Aug 27 06:48:45.878: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.878: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.878: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.878: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 27 06:48:45.989: INFO: Exec stderr: ""
    Aug 27 06:48:45.989: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:45.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:45.990: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:45.990: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Aug 27 06:48:46.096: INFO: Exec stderr: ""
    Aug 27 06:48:46.096: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:46.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:46.097: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:46.097: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 27 06:48:46.163: INFO: Exec stderr: ""
    Aug 27 06:48:46.163: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1292 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Aug 27 06:48:46.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 06:48:46.163: INFO: ExecWithOptions: Clientset creation
    Aug 27 06:48:46.163: INFO: ExecWithOptions: execute(POST https://10.3.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-1292/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Aug 27 06:48:46.296: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Aug 27 06:48:46.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-1292" for this suite. 08/27/22 06:48:46.299
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:48:46.307
Aug 27 06:48:46.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 06:48:46.308
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:46.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:46.327
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 08/27/22 06:48:46.33
STEP: Wait for the Deployment to create new ReplicaSet 08/27/22 06:48:46.334
STEP: delete the deployment 08/27/22 06:48:46.847
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 08/27/22 06:48:46.851
STEP: Gathering metrics 08/27/22 06:48:47.373
Aug 27 06:48:47.392: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
Aug 27 06:48:47.395: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 3.149039ms
Aug 27 06:48:47.395: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
Aug 27 06:48:47.395: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
Aug 27 06:48:47.468: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 06:48:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4467" for this suite. 08/27/22 06:48:47.475
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":260,"skipped":5002,"failed":0}
------------------------------
â€¢ [1.172 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:48:46.307
    Aug 27 06:48:46.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 06:48:46.308
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:46.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:46.327
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 08/27/22 06:48:46.33
    STEP: Wait for the Deployment to create new ReplicaSet 08/27/22 06:48:46.334
    STEP: delete the deployment 08/27/22 06:48:46.847
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 08/27/22 06:48:46.851
    STEP: Gathering metrics 08/27/22 06:48:47.373
    Aug 27 06:48:47.392: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
    Aug 27 06:48:47.395: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 3.149039ms
    Aug 27 06:48:47.395: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
    Aug 27 06:48:47.395: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
    Aug 27 06:48:47.468: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 06:48:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4467" for this suite. 08/27/22 06:48:47.475
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:48:47.49
Aug 27 06:48:47.490: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:48:47.491
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:47.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:47.514
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Aug 27 06:48:47.533: INFO: Waiting up to 5m0s for pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539" in namespace "container-probe-1955" to be "running and ready"
Aug 27 06:48:47.539: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584183ms
Aug 27 06:48:47.539: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:48:49.542: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 2.009111398s
Aug 27 06:48:49.542: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:48:51.548: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 4.014993845s
Aug 27 06:48:51.548: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:48:53.542: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 6.00926233s
Aug 27 06:48:53.542: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:48:55.545: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 8.01151965s
Aug 27 06:48:55.545: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:48:57.545: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 10.01215772s
Aug 27 06:48:57.545: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:48:59.542: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 12.009242848s
Aug 27 06:48:59.542: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:49:01.544: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 14.010364205s
Aug 27 06:49:01.544: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:49:03.544: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 16.010451702s
Aug 27 06:49:03.544: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:49:05.544: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 18.010400704s
Aug 27 06:49:05.544: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:49:07.546: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 20.012467317s
Aug 27 06:49:07.546: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
Aug 27 06:49:09.543: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=true. Elapsed: 22.010084624s
Aug 27 06:49:09.543: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = true)
Aug 27 06:49:09.543: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539" satisfied condition "running and ready"
Aug 27 06:49:09.548: INFO: Container started at 2022-08-27 06:48:48 +0000 UTC, pod became ready at 2022-08-27 06:49:07 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:49:09.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1955" for this suite. 08/27/22 06:49:09.551
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":261,"skipped":5047,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.067 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:48:47.49
    Aug 27 06:48:47.490: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:48:47.491
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:48:47.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:48:47.514
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Aug 27 06:48:47.533: INFO: Waiting up to 5m0s for pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539" in namespace "container-probe-1955" to be "running and ready"
    Aug 27 06:48:47.539: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584183ms
    Aug 27 06:48:47.539: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:48:49.542: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 2.009111398s
    Aug 27 06:48:49.542: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:48:51.548: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 4.014993845s
    Aug 27 06:48:51.548: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:48:53.542: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 6.00926233s
    Aug 27 06:48:53.542: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:48:55.545: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 8.01151965s
    Aug 27 06:48:55.545: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:48:57.545: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 10.01215772s
    Aug 27 06:48:57.545: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:48:59.542: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 12.009242848s
    Aug 27 06:48:59.542: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:49:01.544: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 14.010364205s
    Aug 27 06:49:01.544: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:49:03.544: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 16.010451702s
    Aug 27 06:49:03.544: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:49:05.544: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 18.010400704s
    Aug 27 06:49:05.544: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:49:07.546: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=false. Elapsed: 20.012467317s
    Aug 27 06:49:07.546: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = false)
    Aug 27 06:49:09.543: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539": Phase="Running", Reason="", readiness=true. Elapsed: 22.010084624s
    Aug 27 06:49:09.543: INFO: The phase of Pod test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539 is Running (Ready = true)
    Aug 27 06:49:09.543: INFO: Pod "test-webserver-81f7a787-c940-4d93-9048-5d3464ddd539" satisfied condition "running and ready"
    Aug 27 06:49:09.548: INFO: Container started at 2022-08-27 06:48:48 +0000 UTC, pod became ready at 2022-08-27 06:49:07 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:49:09.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1955" for this suite. 08/27/22 06:49:09.551
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:09.559
Aug 27 06:49:09.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:49:09.56
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:09.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:09.605
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Aug 27 06:49:09.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/27/22 06:49:13.745
Aug 27 06:49:13.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 create -f -'
Aug 27 06:49:14.377: INFO: stderr: ""
Aug 27 06:49:14.377: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 27 06:49:14.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 delete e2e-test-crd-publish-openapi-648-crds test-cr'
Aug 27 06:49:14.447: INFO: stderr: ""
Aug 27 06:49:14.447: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug 27 06:49:14.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 apply -f -'
Aug 27 06:49:14.684: INFO: stderr: ""
Aug 27 06:49:14.684: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 27 06:49:14.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 delete e2e-test-crd-publish-openapi-648-crds test-cr'
Aug 27 06:49:14.831: INFO: stderr: ""
Aug 27 06:49:14.831: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 08/27/22 06:49:14.831
Aug 27 06:49:14.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 explain e2e-test-crd-publish-openapi-648-crds'
Aug 27 06:49:15.325: INFO: stderr: ""
Aug 27 06:49:15.325: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-648-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:49:17.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3248" for this suite. 08/27/22 06:49:17.782
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":262,"skipped":5065,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.228 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:09.559
    Aug 27 06:49:09.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:49:09.56
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:09.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:09.605
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Aug 27 06:49:09.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/27/22 06:49:13.745
    Aug 27 06:49:13.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 create -f -'
    Aug 27 06:49:14.377: INFO: stderr: ""
    Aug 27 06:49:14.377: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Aug 27 06:49:14.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 delete e2e-test-crd-publish-openapi-648-crds test-cr'
    Aug 27 06:49:14.447: INFO: stderr: ""
    Aug 27 06:49:14.447: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Aug 27 06:49:14.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 apply -f -'
    Aug 27 06:49:14.684: INFO: stderr: ""
    Aug 27 06:49:14.684: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Aug 27 06:49:14.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 --namespace=crd-publish-openapi-3248 delete e2e-test-crd-publish-openapi-648-crds test-cr'
    Aug 27 06:49:14.831: INFO: stderr: ""
    Aug 27 06:49:14.831: INFO: stdout: "e2e-test-crd-publish-openapi-648-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 08/27/22 06:49:14.831
    Aug 27 06:49:14.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-3248 explain e2e-test-crd-publish-openapi-648-crds'
    Aug 27 06:49:15.325: INFO: stderr: ""
    Aug 27 06:49:15.325: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-648-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:49:17.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3248" for this suite. 08/27/22 06:49:17.782
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:17.788
Aug 27 06:49:17.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:49:17.789
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:17.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:17.81
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 08/27/22 06:49:17.813
STEP: submitting the pod to kubernetes 08/27/22 06:49:17.813
STEP: verifying QOS class is set on the pod 08/27/22 06:49:17.824
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Aug 27 06:49:17.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3843" for this suite. 08/27/22 06:49:17.833
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":263,"skipped":5071,"failed":0}
------------------------------
â€¢ [0.053 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:17.788
    Aug 27 06:49:17.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:49:17.789
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:17.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:17.81
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 08/27/22 06:49:17.813
    STEP: submitting the pod to kubernetes 08/27/22 06:49:17.813
    STEP: verifying QOS class is set on the pod 08/27/22 06:49:17.824
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Aug 27 06:49:17.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3843" for this suite. 08/27/22 06:49:17.833
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:17.843
Aug 27 06:49:17.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:49:17.844
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:17.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:17.874
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-aa950f1b-4339-400c-958d-94b482a2dfc8 08/27/22 06:49:17.878
STEP: Creating a pod to test consume configMaps 08/27/22 06:49:17.881
Aug 27 06:49:17.888: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512" in namespace "projected-2442" to be "Succeeded or Failed"
Aug 27 06:49:17.893: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512": Phase="Pending", Reason="", readiness=false. Elapsed: 5.111858ms
Aug 27 06:49:19.897: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008540606s
Aug 27 06:49:21.897: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008876331s
STEP: Saw pod success 08/27/22 06:49:21.897
Aug 27 06:49:21.897: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512" satisfied condition "Succeeded or Failed"
Aug 27 06:49:21.901: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:49:21.925
Aug 27 06:49:21.934: INFO: Waiting for pod pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512 to disappear
Aug 27 06:49:21.944: INFO: Pod pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 06:49:21.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2442" for this suite. 08/27/22 06:49:21.954
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":264,"skipped":5104,"failed":0}
------------------------------
â€¢ [4.124 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:17.843
    Aug 27 06:49:17.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:49:17.844
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:17.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:17.874
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-aa950f1b-4339-400c-958d-94b482a2dfc8 08/27/22 06:49:17.878
    STEP: Creating a pod to test consume configMaps 08/27/22 06:49:17.881
    Aug 27 06:49:17.888: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512" in namespace "projected-2442" to be "Succeeded or Failed"
    Aug 27 06:49:17.893: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512": Phase="Pending", Reason="", readiness=false. Elapsed: 5.111858ms
    Aug 27 06:49:19.897: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008540606s
    Aug 27 06:49:21.897: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008876331s
    STEP: Saw pod success 08/27/22 06:49:21.897
    Aug 27 06:49:21.897: INFO: Pod "pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512" satisfied condition "Succeeded or Failed"
    Aug 27 06:49:21.901: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:49:21.925
    Aug 27 06:49:21.934: INFO: Waiting for pod pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512 to disappear
    Aug 27 06:49:21.944: INFO: Pod pod-projected-configmaps-ba585259-38ea-4e6f-8fab-95ecde1f3512 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 06:49:21.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2442" for this suite. 08/27/22 06:49:21.954
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:21.969
Aug 27 06:49:21.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename job 08/27/22 06:49:21.97
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:22.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:22.019
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 08/27/22 06:49:22.024
STEP: Ensure pods equal to paralellism count is attached to the job 08/27/22 06:49:22.035
STEP: patching /status 08/27/22 06:49:24.039
STEP: updating /status 08/27/22 06:49:24.051
STEP: get /status 08/27/22 06:49:24.078
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Aug 27 06:49:24.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6834" for this suite. 08/27/22 06:49:24.085
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":265,"skipped":5125,"failed":0}
------------------------------
â€¢ [2.122 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:21.969
    Aug 27 06:49:21.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename job 08/27/22 06:49:21.97
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:22.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:22.019
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 08/27/22 06:49:22.024
    STEP: Ensure pods equal to paralellism count is attached to the job 08/27/22 06:49:22.035
    STEP: patching /status 08/27/22 06:49:24.039
    STEP: updating /status 08/27/22 06:49:24.051
    STEP: get /status 08/27/22 06:49:24.078
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Aug 27 06:49:24.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6834" for this suite. 08/27/22 06:49:24.085
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:24.092
Aug 27 06:49:24.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename sysctl 08/27/22 06:49:24.094
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:24.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:24.118
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 08/27/22 06:49:24.121
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 06:49:24.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-6622" for this suite. 08/27/22 06:49:24.129
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":266,"skipped":5127,"failed":0}
------------------------------
â€¢ [0.041 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:24.092
    Aug 27 06:49:24.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename sysctl 08/27/22 06:49:24.094
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:24.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:24.118
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 08/27/22 06:49:24.121
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 06:49:24.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-6622" for this suite. 08/27/22 06:49:24.129
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:24.133
Aug 27 06:49:24.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:49:24.136
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:24.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:24.157
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-99967697-386e-41d5-b123-5b3a2f4492db 08/27/22 06:49:24.161
STEP: Creating a pod to test consume configMaps 08/27/22 06:49:24.164
Aug 27 06:49:24.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c" in namespace "configmap-135" to be "Succeeded or Failed"
Aug 27 06:49:24.175: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.419132ms
Aug 27 06:49:26.178: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006950314s
Aug 27 06:49:28.178: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006909536s
STEP: Saw pod success 08/27/22 06:49:28.178
Aug 27 06:49:28.178: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c" satisfied condition "Succeeded or Failed"
Aug 27 06:49:28.181: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:49:28.186
Aug 27 06:49:28.194: INFO: Waiting for pod pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c to disappear
Aug 27 06:49:28.198: INFO: Pod pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:49:28.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-135" for this suite. 08/27/22 06:49:28.201
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":267,"skipped":5127,"failed":0}
------------------------------
â€¢ [4.072 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:24.133
    Aug 27 06:49:24.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:49:24.136
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:24.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:24.157
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-99967697-386e-41d5-b123-5b3a2f4492db 08/27/22 06:49:24.161
    STEP: Creating a pod to test consume configMaps 08/27/22 06:49:24.164
    Aug 27 06:49:24.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c" in namespace "configmap-135" to be "Succeeded or Failed"
    Aug 27 06:49:24.175: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.419132ms
    Aug 27 06:49:26.178: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006950314s
    Aug 27 06:49:28.178: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006909536s
    STEP: Saw pod success 08/27/22 06:49:28.178
    Aug 27 06:49:28.178: INFO: Pod "pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c" satisfied condition "Succeeded or Failed"
    Aug 27 06:49:28.181: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:49:28.186
    Aug 27 06:49:28.194: INFO: Waiting for pod pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c to disappear
    Aug 27 06:49:28.198: INFO: Pod pod-configmaps-6300bb4b-2b07-4c51-99ad-520b4dfd639c no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:49:28.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-135" for this suite. 08/27/22 06:49:28.201
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:28.208
Aug 27 06:49:28.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename proxy 08/27/22 06:49:28.209
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:28.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:28.231
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Aug 27 06:49:28.235: INFO: Creating pod...
Aug 27 06:49:28.240: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1727" to be "running"
Aug 27 06:49:28.243: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.667491ms
Aug 27 06:49:30.246: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.005905006s
Aug 27 06:49:30.246: INFO: Pod "agnhost" satisfied condition "running"
Aug 27 06:49:30.246: INFO: Creating service...
Aug 27 06:49:30.255: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=DELETE
Aug 27 06:49:30.276: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 27 06:49:30.277: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=OPTIONS
Aug 27 06:49:30.283: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 27 06:49:30.283: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=PATCH
Aug 27 06:49:30.292: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 27 06:49:30.292: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=POST
Aug 27 06:49:30.297: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 27 06:49:30.297: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=PUT
Aug 27 06:49:30.302: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 27 06:49:30.302: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=DELETE
Aug 27 06:49:30.308: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 27 06:49:30.308: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=OPTIONS
Aug 27 06:49:30.315: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 27 06:49:30.316: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=PATCH
Aug 27 06:49:30.324: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 27 06:49:30.325: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=POST
Aug 27 06:49:30.332: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 27 06:49:30.332: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=PUT
Aug 27 06:49:30.338: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 27 06:49:30.339: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=GET
Aug 27 06:49:30.342: INFO: http.Client request:GET StatusCode:301
Aug 27 06:49:30.342: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=GET
Aug 27 06:49:30.345: INFO: http.Client request:GET StatusCode:301
Aug 27 06:49:30.345: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=HEAD
Aug 27 06:49:30.348: INFO: http.Client request:HEAD StatusCode:301
Aug 27 06:49:30.349: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=HEAD
Aug 27 06:49:30.352: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 27 06:49:30.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1727" for this suite. 08/27/22 06:49:30.356
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":268,"skipped":5127,"failed":0}
------------------------------
â€¢ [2.154 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:28.208
    Aug 27 06:49:28.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename proxy 08/27/22 06:49:28.209
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:28.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:28.231
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Aug 27 06:49:28.235: INFO: Creating pod...
    Aug 27 06:49:28.240: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1727" to be "running"
    Aug 27 06:49:28.243: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.667491ms
    Aug 27 06:49:30.246: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.005905006s
    Aug 27 06:49:30.246: INFO: Pod "agnhost" satisfied condition "running"
    Aug 27 06:49:30.246: INFO: Creating service...
    Aug 27 06:49:30.255: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=DELETE
    Aug 27 06:49:30.276: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 27 06:49:30.277: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=OPTIONS
    Aug 27 06:49:30.283: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 27 06:49:30.283: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=PATCH
    Aug 27 06:49:30.292: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 27 06:49:30.292: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=POST
    Aug 27 06:49:30.297: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 27 06:49:30.297: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=PUT
    Aug 27 06:49:30.302: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 27 06:49:30.302: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=DELETE
    Aug 27 06:49:30.308: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Aug 27 06:49:30.308: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Aug 27 06:49:30.315: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Aug 27 06:49:30.316: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=PATCH
    Aug 27 06:49:30.324: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Aug 27 06:49:30.325: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=POST
    Aug 27 06:49:30.332: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Aug 27 06:49:30.332: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=PUT
    Aug 27 06:49:30.338: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Aug 27 06:49:30.339: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=GET
    Aug 27 06:49:30.342: INFO: http.Client request:GET StatusCode:301
    Aug 27 06:49:30.342: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=GET
    Aug 27 06:49:30.345: INFO: http.Client request:GET StatusCode:301
    Aug 27 06:49:30.345: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/pods/agnhost/proxy?method=HEAD
    Aug 27 06:49:30.348: INFO: http.Client request:HEAD StatusCode:301
    Aug 27 06:49:30.349: INFO: Starting http.Client for https://10.3.0.1:443/api/v1/namespaces/proxy-1727/services/e2e-proxy-test-service/proxy?method=HEAD
    Aug 27 06:49:30.352: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 27 06:49:30.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1727" for this suite. 08/27/22 06:49:30.356
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:30.368
Aug 27 06:49:30.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename watch 08/27/22 06:49:30.37
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:30.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:30.396
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 08/27/22 06:49:30.402
STEP: starting a background goroutine to produce watch events 08/27/22 06:49:30.406
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 08/27/22 06:49:30.406
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 27 06:49:33.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7160" for this suite. 08/27/22 06:49:33.252
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":269,"skipped":5140,"failed":0}
------------------------------
â€¢ [2.907 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:30.368
    Aug 27 06:49:30.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename watch 08/27/22 06:49:30.37
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:30.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:30.396
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 08/27/22 06:49:30.402
    STEP: starting a background goroutine to produce watch events 08/27/22 06:49:30.406
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 08/27/22 06:49:30.406
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 27 06:49:33.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7160" for this suite. 08/27/22 06:49:33.252
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:33.282
Aug 27 06:49:33.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename discovery 08/27/22 06:49:33.282
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:33.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:33.313
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 08/27/22 06:49:33.318
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Aug 27 06:49:33.663: INFO: Checking APIGroup: apiregistration.k8s.io
Aug 27 06:49:33.665: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Aug 27 06:49:33.665: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Aug 27 06:49:33.665: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Aug 27 06:49:33.665: INFO: Checking APIGroup: apps
Aug 27 06:49:33.666: INFO: PreferredVersion.GroupVersion: apps/v1
Aug 27 06:49:33.666: INFO: Versions found [{apps/v1 v1}]
Aug 27 06:49:33.666: INFO: apps/v1 matches apps/v1
Aug 27 06:49:33.666: INFO: Checking APIGroup: events.k8s.io
Aug 27 06:49:33.667: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Aug 27 06:49:33.667: INFO: Versions found [{events.k8s.io/v1 v1}]
Aug 27 06:49:33.667: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Aug 27 06:49:33.667: INFO: Checking APIGroup: authentication.k8s.io
Aug 27 06:49:33.669: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Aug 27 06:49:33.669: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Aug 27 06:49:33.669: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Aug 27 06:49:33.669: INFO: Checking APIGroup: authorization.k8s.io
Aug 27 06:49:33.670: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Aug 27 06:49:33.670: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Aug 27 06:49:33.670: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Aug 27 06:49:33.670: INFO: Checking APIGroup: autoscaling
Aug 27 06:49:33.671: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Aug 27 06:49:33.671: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Aug 27 06:49:33.671: INFO: autoscaling/v2 matches autoscaling/v2
Aug 27 06:49:33.671: INFO: Checking APIGroup: batch
Aug 27 06:49:33.672: INFO: PreferredVersion.GroupVersion: batch/v1
Aug 27 06:49:33.672: INFO: Versions found [{batch/v1 v1}]
Aug 27 06:49:33.672: INFO: batch/v1 matches batch/v1
Aug 27 06:49:33.672: INFO: Checking APIGroup: certificates.k8s.io
Aug 27 06:49:33.673: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Aug 27 06:49:33.673: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Aug 27 06:49:33.673: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Aug 27 06:49:33.673: INFO: Checking APIGroup: networking.k8s.io
Aug 27 06:49:33.674: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Aug 27 06:49:33.674: INFO: Versions found [{networking.k8s.io/v1 v1}]
Aug 27 06:49:33.674: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Aug 27 06:49:33.674: INFO: Checking APIGroup: policy
Aug 27 06:49:33.676: INFO: PreferredVersion.GroupVersion: policy/v1
Aug 27 06:49:33.676: INFO: Versions found [{policy/v1 v1}]
Aug 27 06:49:33.676: INFO: policy/v1 matches policy/v1
Aug 27 06:49:33.676: INFO: Checking APIGroup: rbac.authorization.k8s.io
Aug 27 06:49:33.680: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Aug 27 06:49:33.680: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Aug 27 06:49:33.680: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Aug 27 06:49:33.680: INFO: Checking APIGroup: storage.k8s.io
Aug 27 06:49:33.681: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Aug 27 06:49:33.681: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Aug 27 06:49:33.681: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Aug 27 06:49:33.681: INFO: Checking APIGroup: admissionregistration.k8s.io
Aug 27 06:49:33.682: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Aug 27 06:49:33.682: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Aug 27 06:49:33.682: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Aug 27 06:49:33.682: INFO: Checking APIGroup: apiextensions.k8s.io
Aug 27 06:49:33.685: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Aug 27 06:49:33.685: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Aug 27 06:49:33.685: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Aug 27 06:49:33.685: INFO: Checking APIGroup: scheduling.k8s.io
Aug 27 06:49:33.686: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Aug 27 06:49:33.686: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Aug 27 06:49:33.686: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Aug 27 06:49:33.686: INFO: Checking APIGroup: coordination.k8s.io
Aug 27 06:49:33.687: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Aug 27 06:49:33.687: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Aug 27 06:49:33.687: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Aug 27 06:49:33.687: INFO: Checking APIGroup: node.k8s.io
Aug 27 06:49:33.688: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Aug 27 06:49:33.688: INFO: Versions found [{node.k8s.io/v1 v1}]
Aug 27 06:49:33.688: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Aug 27 06:49:33.688: INFO: Checking APIGroup: discovery.k8s.io
Aug 27 06:49:33.689: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Aug 27 06:49:33.689: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Aug 27 06:49:33.689: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Aug 27 06:49:33.689: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Aug 27 06:49:33.690: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Aug 27 06:49:33.690: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Aug 27 06:49:33.690: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Aug 27 06:49:33.690: INFO: Checking APIGroup: crd.projectcalico.org
Aug 27 06:49:33.691: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Aug 27 06:49:33.691: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Aug 27 06:49:33.691: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Aug 27 06:49:33.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-1893" for this suite. 08/27/22 06:49:33.694
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":270,"skipped":5170,"failed":0}
------------------------------
â€¢ [0.421 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:33.282
    Aug 27 06:49:33.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename discovery 08/27/22 06:49:33.282
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:33.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:33.313
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 08/27/22 06:49:33.318
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Aug 27 06:49:33.663: INFO: Checking APIGroup: apiregistration.k8s.io
    Aug 27 06:49:33.665: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Aug 27 06:49:33.665: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Aug 27 06:49:33.665: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Aug 27 06:49:33.665: INFO: Checking APIGroup: apps
    Aug 27 06:49:33.666: INFO: PreferredVersion.GroupVersion: apps/v1
    Aug 27 06:49:33.666: INFO: Versions found [{apps/v1 v1}]
    Aug 27 06:49:33.666: INFO: apps/v1 matches apps/v1
    Aug 27 06:49:33.666: INFO: Checking APIGroup: events.k8s.io
    Aug 27 06:49:33.667: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Aug 27 06:49:33.667: INFO: Versions found [{events.k8s.io/v1 v1}]
    Aug 27 06:49:33.667: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Aug 27 06:49:33.667: INFO: Checking APIGroup: authentication.k8s.io
    Aug 27 06:49:33.669: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Aug 27 06:49:33.669: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Aug 27 06:49:33.669: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Aug 27 06:49:33.669: INFO: Checking APIGroup: authorization.k8s.io
    Aug 27 06:49:33.670: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Aug 27 06:49:33.670: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Aug 27 06:49:33.670: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Aug 27 06:49:33.670: INFO: Checking APIGroup: autoscaling
    Aug 27 06:49:33.671: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Aug 27 06:49:33.671: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Aug 27 06:49:33.671: INFO: autoscaling/v2 matches autoscaling/v2
    Aug 27 06:49:33.671: INFO: Checking APIGroup: batch
    Aug 27 06:49:33.672: INFO: PreferredVersion.GroupVersion: batch/v1
    Aug 27 06:49:33.672: INFO: Versions found [{batch/v1 v1}]
    Aug 27 06:49:33.672: INFO: batch/v1 matches batch/v1
    Aug 27 06:49:33.672: INFO: Checking APIGroup: certificates.k8s.io
    Aug 27 06:49:33.673: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Aug 27 06:49:33.673: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Aug 27 06:49:33.673: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Aug 27 06:49:33.673: INFO: Checking APIGroup: networking.k8s.io
    Aug 27 06:49:33.674: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Aug 27 06:49:33.674: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Aug 27 06:49:33.674: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Aug 27 06:49:33.674: INFO: Checking APIGroup: policy
    Aug 27 06:49:33.676: INFO: PreferredVersion.GroupVersion: policy/v1
    Aug 27 06:49:33.676: INFO: Versions found [{policy/v1 v1}]
    Aug 27 06:49:33.676: INFO: policy/v1 matches policy/v1
    Aug 27 06:49:33.676: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Aug 27 06:49:33.680: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Aug 27 06:49:33.680: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Aug 27 06:49:33.680: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Aug 27 06:49:33.680: INFO: Checking APIGroup: storage.k8s.io
    Aug 27 06:49:33.681: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Aug 27 06:49:33.681: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Aug 27 06:49:33.681: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Aug 27 06:49:33.681: INFO: Checking APIGroup: admissionregistration.k8s.io
    Aug 27 06:49:33.682: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Aug 27 06:49:33.682: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Aug 27 06:49:33.682: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Aug 27 06:49:33.682: INFO: Checking APIGroup: apiextensions.k8s.io
    Aug 27 06:49:33.685: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Aug 27 06:49:33.685: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Aug 27 06:49:33.685: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Aug 27 06:49:33.685: INFO: Checking APIGroup: scheduling.k8s.io
    Aug 27 06:49:33.686: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Aug 27 06:49:33.686: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Aug 27 06:49:33.686: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Aug 27 06:49:33.686: INFO: Checking APIGroup: coordination.k8s.io
    Aug 27 06:49:33.687: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Aug 27 06:49:33.687: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Aug 27 06:49:33.687: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Aug 27 06:49:33.687: INFO: Checking APIGroup: node.k8s.io
    Aug 27 06:49:33.688: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Aug 27 06:49:33.688: INFO: Versions found [{node.k8s.io/v1 v1}]
    Aug 27 06:49:33.688: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Aug 27 06:49:33.688: INFO: Checking APIGroup: discovery.k8s.io
    Aug 27 06:49:33.689: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Aug 27 06:49:33.689: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Aug 27 06:49:33.689: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Aug 27 06:49:33.689: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Aug 27 06:49:33.690: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Aug 27 06:49:33.690: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Aug 27 06:49:33.690: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Aug 27 06:49:33.690: INFO: Checking APIGroup: crd.projectcalico.org
    Aug 27 06:49:33.691: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Aug 27 06:49:33.691: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Aug 27 06:49:33.691: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Aug 27 06:49:33.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-1893" for this suite. 08/27/22 06:49:33.694
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:33.703
Aug 27 06:49:33.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:49:33.704
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:33.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:33.722
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-4426 08/27/22 06:49:33.725
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[] 08/27/22 06:49:33.737
Aug 27 06:49:33.748: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4426 08/27/22 06:49:33.748
Aug 27 06:49:33.756: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4426" to be "running and ready"
Aug 27 06:49:33.761: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.419571ms
Aug 27 06:49:33.762: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:49:35.766: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009604183s
Aug 27 06:49:35.766: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 27 06:49:35.766: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[pod1:[100]] 08/27/22 06:49:35.769
Aug 27 06:49:35.777: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-4426 08/27/22 06:49:35.778
Aug 27 06:49:35.781: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4426" to be "running and ready"
Aug 27 06:49:35.784: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318277ms
Aug 27 06:49:35.784: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:49:37.787: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005498346s
Aug 27 06:49:37.787: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 27 06:49:37.787: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[pod1:[100] pod2:[101]] 08/27/22 06:49:37.79
Aug 27 06:49:37.803: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 08/27/22 06:49:37.803
Aug 27 06:49:37.803: INFO: Creating new exec pod
Aug 27 06:49:37.810: INFO: Waiting up to 5m0s for pod "execpod5t4j5" in namespace "services-4426" to be "running"
Aug 27 06:49:37.816: INFO: Pod "execpod5t4j5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.754943ms
Aug 27 06:49:39.821: INFO: Pod "execpod5t4j5": Phase="Running", Reason="", readiness=true. Elapsed: 2.010447325s
Aug 27 06:49:39.821: INFO: Pod "execpod5t4j5" satisfied condition "running"
Aug 27 06:49:40.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Aug 27 06:49:41.005: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Aug 27 06:49:41.005: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:41.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.166.124 80'
Aug 27 06:49:41.146: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.166.124 80\nConnection to 10.3.166.124 80 port [tcp/http] succeeded!\n"
Aug 27 06:49:41.146: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:41.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Aug 27 06:49:41.336: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Aug 27 06:49:41.336: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:41.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.166.124 81'
Aug 27 06:49:41.488: INFO: stderr: "+ nc -v -t -w 2 10.3.166.124 81\nConnection to 10.3.166.124 81 port [tcp/*] succeeded!\n+ echo hostName\n"
Aug 27 06:49:41.488: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4426 08/27/22 06:49:41.488
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[pod2:[101]] 08/27/22 06:49:41.495
Aug 27 06:49:41.547: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-4426 08/27/22 06:49:41.547
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[] 08/27/22 06:49:41.579
Aug 27 06:49:41.617: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:49:41.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4426" for this suite. 08/27/22 06:49:41.654
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":271,"skipped":5172,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.971 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:33.703
    Aug 27 06:49:33.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:49:33.704
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:33.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:33.722
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-4426 08/27/22 06:49:33.725
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[] 08/27/22 06:49:33.737
    Aug 27 06:49:33.748: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4426 08/27/22 06:49:33.748
    Aug 27 06:49:33.756: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4426" to be "running and ready"
    Aug 27 06:49:33.761: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.419571ms
    Aug 27 06:49:33.762: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:49:35.766: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.009604183s
    Aug 27 06:49:35.766: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 27 06:49:35.766: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[pod1:[100]] 08/27/22 06:49:35.769
    Aug 27 06:49:35.777: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-4426 08/27/22 06:49:35.778
    Aug 27 06:49:35.781: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4426" to be "running and ready"
    Aug 27 06:49:35.784: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318277ms
    Aug 27 06:49:35.784: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:49:37.787: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.005498346s
    Aug 27 06:49:37.787: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 27 06:49:37.787: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[pod1:[100] pod2:[101]] 08/27/22 06:49:37.79
    Aug 27 06:49:37.803: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 08/27/22 06:49:37.803
    Aug 27 06:49:37.803: INFO: Creating new exec pod
    Aug 27 06:49:37.810: INFO: Waiting up to 5m0s for pod "execpod5t4j5" in namespace "services-4426" to be "running"
    Aug 27 06:49:37.816: INFO: Pod "execpod5t4j5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.754943ms
    Aug 27 06:49:39.821: INFO: Pod "execpod5t4j5": Phase="Running", Reason="", readiness=true. Elapsed: 2.010447325s
    Aug 27 06:49:39.821: INFO: Pod "execpod5t4j5" satisfied condition "running"
    Aug 27 06:49:40.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Aug 27 06:49:41.005: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Aug 27 06:49:41.005: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:41.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.166.124 80'
    Aug 27 06:49:41.146: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.166.124 80\nConnection to 10.3.166.124 80 port [tcp/http] succeeded!\n"
    Aug 27 06:49:41.146: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:41.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Aug 27 06:49:41.336: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Aug 27 06:49:41.336: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:41.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4426 exec execpod5t4j5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.166.124 81'
    Aug 27 06:49:41.488: INFO: stderr: "+ nc -v -t -w 2 10.3.166.124 81\nConnection to 10.3.166.124 81 port [tcp/*] succeeded!\n+ echo hostName\n"
    Aug 27 06:49:41.488: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4426 08/27/22 06:49:41.488
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[pod2:[101]] 08/27/22 06:49:41.495
    Aug 27 06:49:41.547: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-4426 08/27/22 06:49:41.547
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4426 to expose endpoints map[] 08/27/22 06:49:41.579
    Aug 27 06:49:41.617: INFO: successfully validated that service multi-endpoint-test in namespace services-4426 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:49:41.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4426" for this suite. 08/27/22 06:49:41.654
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:41.676
Aug 27 06:49:41.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:49:41.678
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:41.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:41.719
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:49:41.725
Aug 27 06:49:41.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda" in namespace "downward-api-3143" to be "Succeeded or Failed"
Aug 27 06:49:41.746: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda": Phase="Pending", Reason="", readiness=false. Elapsed: 11.145165ms
Aug 27 06:49:43.750: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda": Phase="Running", Reason="", readiness=false. Elapsed: 2.015292346s
Aug 27 06:49:45.752: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017191737s
STEP: Saw pod success 08/27/22 06:49:45.752
Aug 27 06:49:45.752: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda" satisfied condition "Succeeded or Failed"
Aug 27 06:49:45.756: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda container client-container: <nil>
STEP: delete the pod 08/27/22 06:49:45.778
Aug 27 06:49:45.794: INFO: Waiting for pod downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda to disappear
Aug 27 06:49:45.797: INFO: Pod downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:49:45.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3143" for this suite. 08/27/22 06:49:45.801
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":272,"skipped":5177,"failed":0}
------------------------------
â€¢ [4.130 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:41.676
    Aug 27 06:49:41.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:49:41.678
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:41.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:41.719
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:49:41.725
    Aug 27 06:49:41.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda" in namespace "downward-api-3143" to be "Succeeded or Failed"
    Aug 27 06:49:41.746: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda": Phase="Pending", Reason="", readiness=false. Elapsed: 11.145165ms
    Aug 27 06:49:43.750: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda": Phase="Running", Reason="", readiness=false. Elapsed: 2.015292346s
    Aug 27 06:49:45.752: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017191737s
    STEP: Saw pod success 08/27/22 06:49:45.752
    Aug 27 06:49:45.752: INFO: Pod "downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda" satisfied condition "Succeeded or Failed"
    Aug 27 06:49:45.756: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda container client-container: <nil>
    STEP: delete the pod 08/27/22 06:49:45.778
    Aug 27 06:49:45.794: INFO: Waiting for pod downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda to disappear
    Aug 27 06:49:45.797: INFO: Pod downwardapi-volume-e54256e3-6711-450d-ae52-60db38775bda no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:49:45.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3143" for this suite. 08/27/22 06:49:45.801
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:45.807
Aug 27 06:49:45.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:49:45.808
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:45.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:45.833
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-734 08/27/22 06:49:45.838
STEP: creating service affinity-nodeport in namespace services-734 08/27/22 06:49:45.838
STEP: creating replication controller affinity-nodeport in namespace services-734 08/27/22 06:49:45.849
I0827 06:49:45.864696      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-734, replica count: 3
I0827 06:49:48.916846      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 06:49:48.925: INFO: Creating new exec pod
Aug 27 06:49:48.929: INFO: Waiting up to 5m0s for pod "execpod-affinity4fjr8" in namespace "services-734" to be "running"
Aug 27 06:49:48.931: INFO: Pod "execpod-affinity4fjr8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281901ms
Aug 27 06:49:50.936: INFO: Pod "execpod-affinity4fjr8": Phase="Running", Reason="", readiness=true. Elapsed: 2.007599203s
Aug 27 06:49:50.936: INFO: Pod "execpod-affinity4fjr8" satisfied condition "running"
Aug 27 06:49:51.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Aug 27 06:49:52.105: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Aug 27 06:49:52.105: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:52.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.169.151 80'
Aug 27 06:49:52.289: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.169.151 80\nConnection to 10.3.169.151 80 port [tcp/http] succeeded!\n"
Aug 27 06:49:52.289: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:52.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 30126'
Aug 27 06:49:52.469: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 30126\nConnection to 10.0.31.158 30126 port [tcp/*] succeeded!\n"
Aug 27 06:49:52.469: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:52.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 30126'
Aug 27 06:49:52.657: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 30126\nConnection to 10.0.47.192 30126 port [tcp/*] succeeded!\n"
Aug 27 06:49:52.657: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:49:52.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30126/ ; done'
Aug 27 06:49:52.957: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n"
Aug 27 06:49:52.957: INFO: stdout: "\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49"
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
Aug 27 06:49:52.957: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-734, will wait for the garbage collector to delete the pods 08/27/22 06:49:52.977
Aug 27 06:49:53.044: INFO: Deleting ReplicationController affinity-nodeport took: 8.275054ms
Aug 27 06:49:53.145: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.958671ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:49:55.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-734" for this suite. 08/27/22 06:49:55.772
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":273,"skipped":5187,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.971 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:45.807
    Aug 27 06:49:45.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:49:45.808
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:45.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:45.833
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-734 08/27/22 06:49:45.838
    STEP: creating service affinity-nodeport in namespace services-734 08/27/22 06:49:45.838
    STEP: creating replication controller affinity-nodeport in namespace services-734 08/27/22 06:49:45.849
    I0827 06:49:45.864696      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-734, replica count: 3
    I0827 06:49:48.916846      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 06:49:48.925: INFO: Creating new exec pod
    Aug 27 06:49:48.929: INFO: Waiting up to 5m0s for pod "execpod-affinity4fjr8" in namespace "services-734" to be "running"
    Aug 27 06:49:48.931: INFO: Pod "execpod-affinity4fjr8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281901ms
    Aug 27 06:49:50.936: INFO: Pod "execpod-affinity4fjr8": Phase="Running", Reason="", readiness=true. Elapsed: 2.007599203s
    Aug 27 06:49:50.936: INFO: Pod "execpod-affinity4fjr8" satisfied condition "running"
    Aug 27 06:49:51.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Aug 27 06:49:52.105: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Aug 27 06:49:52.105: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:52.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.169.151 80'
    Aug 27 06:49:52.289: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.169.151 80\nConnection to 10.3.169.151 80 port [tcp/http] succeeded!\n"
    Aug 27 06:49:52.289: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:52.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 30126'
    Aug 27 06:49:52.469: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 30126\nConnection to 10.0.31.158 30126 port [tcp/*] succeeded!\n"
    Aug 27 06:49:52.469: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:52.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 30126'
    Aug 27 06:49:52.657: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 30126\nConnection to 10.0.47.192 30126 port [tcp/*] succeeded!\n"
    Aug 27 06:49:52.657: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:49:52.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-734 exec execpod-affinity4fjr8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30126/ ; done'
    Aug 27 06:49:52.957: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30126/\n"
    Aug 27 06:49:52.957: INFO: stdout: "\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49\naffinity-nodeport-5cg49"
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Received response from host: affinity-nodeport-5cg49
    Aug 27 06:49:52.957: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-734, will wait for the garbage collector to delete the pods 08/27/22 06:49:52.977
    Aug 27 06:49:53.044: INFO: Deleting ReplicationController affinity-nodeport took: 8.275054ms
    Aug 27 06:49:53.145: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.958671ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:49:55.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-734" for this suite. 08/27/22 06:49:55.772
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:55.781
Aug 27 06:49:55.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:49:55.782
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:55.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:55.811
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:49:55.818
Aug 27 06:49:55.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b" in namespace "projected-4586" to be "Succeeded or Failed"
Aug 27 06:49:55.833: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.74011ms
Aug 27 06:49:57.836: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009081801s
Aug 27 06:49:59.839: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012506946s
STEP: Saw pod success 08/27/22 06:49:59.84
Aug 27 06:49:59.840: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b" satisfied condition "Succeeded or Failed"
Aug 27 06:49:59.845: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b container client-container: <nil>
STEP: delete the pod 08/27/22 06:49:59.854
Aug 27 06:49:59.866: INFO: Waiting for pod downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b to disappear
Aug 27 06:49:59.873: INFO: Pod downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:49:59.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4586" for this suite. 08/27/22 06:49:59.881
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":274,"skipped":5205,"failed":0}
------------------------------
â€¢ [4.106 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:55.781
    Aug 27 06:49:55.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:49:55.782
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:55.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:55.811
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:49:55.818
    Aug 27 06:49:55.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b" in namespace "projected-4586" to be "Succeeded or Failed"
    Aug 27 06:49:55.833: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.74011ms
    Aug 27 06:49:57.836: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009081801s
    Aug 27 06:49:59.839: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012506946s
    STEP: Saw pod success 08/27/22 06:49:59.84
    Aug 27 06:49:59.840: INFO: Pod "downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b" satisfied condition "Succeeded or Failed"
    Aug 27 06:49:59.845: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b container client-container: <nil>
    STEP: delete the pod 08/27/22 06:49:59.854
    Aug 27 06:49:59.866: INFO: Waiting for pod downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b to disappear
    Aug 27 06:49:59.873: INFO: Pod downwardapi-volume-aec5607b-2bba-4250-b7fc-355e4bed397b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:49:59.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4586" for this suite. 08/27/22 06:49:59.881
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:49:59.89
Aug 27 06:49:59.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:49:59.891
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:59.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:59.92
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-3921 08/27/22 06:49:59.934
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[] 08/27/22 06:49:59.96
Aug 27 06:49:59.983: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-3921 08/27/22 06:49:59.984
Aug 27 06:49:59.995: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3921" to be "running and ready"
Aug 27 06:50:00.026: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 30.876412ms
Aug 27 06:50:00.026: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:50:02.036: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.040706518s
Aug 27 06:50:02.036: INFO: The phase of Pod pod1 is Running (Ready = true)
Aug 27 06:50:02.036: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[pod1:[80]] 08/27/22 06:50:02.039
Aug 27 06:50:02.117: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 08/27/22 06:50:02.117
Aug 27 06:50:02.118: INFO: Creating new exec pod
Aug 27 06:50:02.156: INFO: Waiting up to 5m0s for pod "execpodwjwqq" in namespace "services-3921" to be "running"
Aug 27 06:50:02.235: INFO: Pod "execpodwjwqq": Phase="Pending", Reason="", readiness=false. Elapsed: 50.498478ms
Aug 27 06:50:04.245: INFO: Pod "execpodwjwqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060424618s
Aug 27 06:50:06.243: INFO: Pod "execpodwjwqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.05772266s
Aug 27 06:50:06.243: INFO: Pod "execpodwjwqq" satisfied condition "running"
Aug 27 06:50:07.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 27 06:50:07.789: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 27 06:50:07.790: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:50:07.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.103.44 80'
Aug 27 06:50:07.999: INFO: stderr: "+ nc -v -t -w 2 10.3.103.44 80\n+ echo hostName\nConnection to 10.3.103.44 80 port [tcp/http] succeeded!\n"
Aug 27 06:50:07.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-3921 08/27/22 06:50:07.999
Aug 27 06:50:08.013: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3921" to be "running and ready"
Aug 27 06:50:08.019: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380307ms
Aug 27 06:50:08.019: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:50:10.025: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011581781s
Aug 27 06:50:10.025: INFO: The phase of Pod pod2 is Running (Ready = true)
Aug 27 06:50:10.025: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[pod1:[80] pod2:[80]] 08/27/22 06:50:10.028
Aug 27 06:50:10.044: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 08/27/22 06:50:10.044
Aug 27 06:50:11.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 27 06:50:11.229: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 27 06:50:11.229: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:50:11.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.103.44 80'
Aug 27 06:50:11.438: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.103.44 80\nConnection to 10.3.103.44 80 port [tcp/http] succeeded!\n"
Aug 27 06:50:11.438: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-3921 08/27/22 06:50:11.438
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[pod2:[80]] 08/27/22 06:50:11.473
Aug 27 06:50:11.530: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 08/27/22 06:50:11.531
Aug 27 06:50:12.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 27 06:50:12.787: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 27 06:50:12.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 06:50:12.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.103.44 80'
Aug 27 06:50:13.001: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.103.44 80\nConnection to 10.3.103.44 80 port [tcp/http] succeeded!\n"
Aug 27 06:50:13.001: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-3921 08/27/22 06:50:13.001
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[] 08/27/22 06:50:13.018
Aug 27 06:50:14.060: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:50:14.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3921" for this suite. 08/27/22 06:50:14.08
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":275,"skipped":5228,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.203 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:49:59.89
    Aug 27 06:49:59.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:49:59.891
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:49:59.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:49:59.92
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-3921 08/27/22 06:49:59.934
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[] 08/27/22 06:49:59.96
    Aug 27 06:49:59.983: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-3921 08/27/22 06:49:59.984
    Aug 27 06:49:59.995: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-3921" to be "running and ready"
    Aug 27 06:50:00.026: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 30.876412ms
    Aug 27 06:50:00.026: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:50:02.036: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.040706518s
    Aug 27 06:50:02.036: INFO: The phase of Pod pod1 is Running (Ready = true)
    Aug 27 06:50:02.036: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[pod1:[80]] 08/27/22 06:50:02.039
    Aug 27 06:50:02.117: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 08/27/22 06:50:02.117
    Aug 27 06:50:02.118: INFO: Creating new exec pod
    Aug 27 06:50:02.156: INFO: Waiting up to 5m0s for pod "execpodwjwqq" in namespace "services-3921" to be "running"
    Aug 27 06:50:02.235: INFO: Pod "execpodwjwqq": Phase="Pending", Reason="", readiness=false. Elapsed: 50.498478ms
    Aug 27 06:50:04.245: INFO: Pod "execpodwjwqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060424618s
    Aug 27 06:50:06.243: INFO: Pod "execpodwjwqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.05772266s
    Aug 27 06:50:06.243: INFO: Pod "execpodwjwqq" satisfied condition "running"
    Aug 27 06:50:07.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 27 06:50:07.789: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 27 06:50:07.790: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:50:07.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.103.44 80'
    Aug 27 06:50:07.999: INFO: stderr: "+ nc -v -t -w 2 10.3.103.44 80\n+ echo hostName\nConnection to 10.3.103.44 80 port [tcp/http] succeeded!\n"
    Aug 27 06:50:07.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-3921 08/27/22 06:50:07.999
    Aug 27 06:50:08.013: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-3921" to be "running and ready"
    Aug 27 06:50:08.019: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380307ms
    Aug 27 06:50:08.019: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:50:10.025: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011581781s
    Aug 27 06:50:10.025: INFO: The phase of Pod pod2 is Running (Ready = true)
    Aug 27 06:50:10.025: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[pod1:[80] pod2:[80]] 08/27/22 06:50:10.028
    Aug 27 06:50:10.044: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 08/27/22 06:50:10.044
    Aug 27 06:50:11.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 27 06:50:11.229: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 27 06:50:11.229: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:50:11.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.103.44 80'
    Aug 27 06:50:11.438: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.103.44 80\nConnection to 10.3.103.44 80 port [tcp/http] succeeded!\n"
    Aug 27 06:50:11.438: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-3921 08/27/22 06:50:11.438
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[pod2:[80]] 08/27/22 06:50:11.473
    Aug 27 06:50:11.530: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 08/27/22 06:50:11.531
    Aug 27 06:50:12.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Aug 27 06:50:12.787: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Aug 27 06:50:12.787: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 06:50:12.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-3921 exec execpodwjwqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.103.44 80'
    Aug 27 06:50:13.001: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.103.44 80\nConnection to 10.3.103.44 80 port [tcp/http] succeeded!\n"
    Aug 27 06:50:13.001: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-3921 08/27/22 06:50:13.001
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3921 to expose endpoints map[] 08/27/22 06:50:13.018
    Aug 27 06:50:14.060: INFO: successfully validated that service endpoint-test2 in namespace services-3921 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:50:14.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3921" for this suite. 08/27/22 06:50:14.08
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:14.101
Aug 27 06:50:14.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename endpointslice 08/27/22 06:50:14.102
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:14.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:14.128
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 08/27/22 06:50:14.133
STEP: getting /apis/discovery.k8s.io 08/27/22 06:50:14.136
STEP: getting /apis/discovery.k8s.iov1 08/27/22 06:50:14.138
STEP: creating 08/27/22 06:50:14.14
STEP: getting 08/27/22 06:50:14.151
STEP: listing 08/27/22 06:50:14.154
STEP: watching 08/27/22 06:50:14.157
Aug 27 06:50:14.157: INFO: starting watch
STEP: cluster-wide listing 08/27/22 06:50:14.159
STEP: cluster-wide watching 08/27/22 06:50:14.164
Aug 27 06:50:14.164: INFO: starting watch
STEP: patching 08/27/22 06:50:14.166
STEP: updating 08/27/22 06:50:14.171
Aug 27 06:50:14.178: INFO: waiting for watch events with expected annotations
Aug 27 06:50:14.178: INFO: saw patched and updated annotations
STEP: deleting 08/27/22 06:50:14.178
STEP: deleting a collection 08/27/22 06:50:14.188
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 27 06:50:14.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2917" for this suite. 08/27/22 06:50:14.201
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":276,"skipped":5245,"failed":0}
------------------------------
â€¢ [0.104 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:14.101
    Aug 27 06:50:14.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename endpointslice 08/27/22 06:50:14.102
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:14.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:14.128
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 08/27/22 06:50:14.133
    STEP: getting /apis/discovery.k8s.io 08/27/22 06:50:14.136
    STEP: getting /apis/discovery.k8s.iov1 08/27/22 06:50:14.138
    STEP: creating 08/27/22 06:50:14.14
    STEP: getting 08/27/22 06:50:14.151
    STEP: listing 08/27/22 06:50:14.154
    STEP: watching 08/27/22 06:50:14.157
    Aug 27 06:50:14.157: INFO: starting watch
    STEP: cluster-wide listing 08/27/22 06:50:14.159
    STEP: cluster-wide watching 08/27/22 06:50:14.164
    Aug 27 06:50:14.164: INFO: starting watch
    STEP: patching 08/27/22 06:50:14.166
    STEP: updating 08/27/22 06:50:14.171
    Aug 27 06:50:14.178: INFO: waiting for watch events with expected annotations
    Aug 27 06:50:14.178: INFO: saw patched and updated annotations
    STEP: deleting 08/27/22 06:50:14.178
    STEP: deleting a collection 08/27/22 06:50:14.188
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 27 06:50:14.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2917" for this suite. 08/27/22 06:50:14.201
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:14.215
Aug 27 06:50:14.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:50:14.216
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:14.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:14.235
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Aug 27 06:50:14.244: INFO: Waiting up to 5m0s for pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400" in namespace "kubelet-test-2444" to be "running and ready"
Aug 27 06:50:14.247: INFO: Pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400": Phase="Pending", Reason="", readiness=false. Elapsed: 3.676782ms
Aug 27 06:50:14.248: INFO: The phase of Pod busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:50:16.252: INFO: Pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400": Phase="Running", Reason="", readiness=true. Elapsed: 2.008303822s
Aug 27 06:50:16.252: INFO: The phase of Pod busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400 is Running (Ready = true)
Aug 27 06:50:16.252: INFO: Pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 27 06:50:16.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2444" for this suite. 08/27/22 06:50:16.27
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":277,"skipped":5350,"failed":0}
------------------------------
â€¢ [2.071 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:14.215
    Aug 27 06:50:14.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:50:14.216
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:14.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:14.235
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Aug 27 06:50:14.244: INFO: Waiting up to 5m0s for pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400" in namespace "kubelet-test-2444" to be "running and ready"
    Aug 27 06:50:14.247: INFO: Pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400": Phase="Pending", Reason="", readiness=false. Elapsed: 3.676782ms
    Aug 27 06:50:14.248: INFO: The phase of Pod busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:50:16.252: INFO: Pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400": Phase="Running", Reason="", readiness=true. Elapsed: 2.008303822s
    Aug 27 06:50:16.252: INFO: The phase of Pod busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400 is Running (Ready = true)
    Aug 27 06:50:16.252: INFO: Pod "busybox-scheduling-b3bfa944-de7d-4421-9398-b58768a0f400" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 27 06:50:16.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2444" for this suite. 08/27/22 06:50:16.27
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:16.289
Aug 27 06:50:16.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:50:16.29
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:16.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:16.34
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-d2d319b5-9fb9-4f6d-b8ad-6e1a8e26f9a9 08/27/22 06:50:16.344
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:50:16.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8099" for this suite. 08/27/22 06:50:16.351
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":278,"skipped":5356,"failed":0}
------------------------------
â€¢ [0.069 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:16.289
    Aug 27 06:50:16.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:50:16.29
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:16.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:16.34
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-d2d319b5-9fb9-4f6d-b8ad-6e1a8e26f9a9 08/27/22 06:50:16.344
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:50:16.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8099" for this suite. 08/27/22 06:50:16.351
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:16.359
Aug 27 06:50:16.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:50:16.36
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:16.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:16.433
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 08/27/22 06:50:16.436
Aug 27 06:50:16.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6640 cluster-info'
Aug 27 06:50:16.514: INFO: stderr: ""
Aug 27 06:50:16.514: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:50:16.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6640" for this suite. 08/27/22 06:50:16.519
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":279,"skipped":5356,"failed":0}
------------------------------
â€¢ [0.167 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:16.359
    Aug 27 06:50:16.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:50:16.36
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:16.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:16.433
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 08/27/22 06:50:16.436
    Aug 27 06:50:16.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-6640 cluster-info'
    Aug 27 06:50:16.514: INFO: stderr: ""
    Aug 27 06:50:16.514: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:50:16.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6640" for this suite. 08/27/22 06:50:16.519
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:16.526
Aug 27 06:50:16.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 06:50:16.527
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:16.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:16.561
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 08/27/22 06:50:16.567
Aug 27 06:50:16.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 create -f -'
Aug 27 06:50:17.258: INFO: stderr: ""
Aug 27 06:50:17.258: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:50:17.258
Aug 27 06:50:17.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:50:17.403: INFO: stderr: ""
Aug 27 06:50:17.403: INFO: stdout: "update-demo-nautilus-ttbkf update-demo-nautilus-xpjtz "
Aug 27 06:50:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-ttbkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:50:17.480: INFO: stderr: ""
Aug 27 06:50:17.480: INFO: stdout: ""
Aug 27 06:50:17.480: INFO: update-demo-nautilus-ttbkf is created but not running
Aug 27 06:50:22.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 27 06:50:22.556: INFO: stderr: ""
Aug 27 06:50:22.556: INFO: stdout: "update-demo-nautilus-ttbkf update-demo-nautilus-xpjtz "
Aug 27 06:50:22.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-ttbkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:50:22.643: INFO: stderr: ""
Aug 27 06:50:22.643: INFO: stdout: "true"
Aug 27 06:50:22.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-ttbkf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:50:22.738: INFO: stderr: ""
Aug 27 06:50:22.738: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:50:22.738: INFO: validating pod update-demo-nautilus-ttbkf
Aug 27 06:50:22.747: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:50:22.747: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:50:22.747: INFO: update-demo-nautilus-ttbkf is verified up and running
Aug 27 06:50:22.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-xpjtz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 27 06:50:22.851: INFO: stderr: ""
Aug 27 06:50:22.851: INFO: stdout: "true"
Aug 27 06:50:22.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-xpjtz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 27 06:50:22.958: INFO: stderr: ""
Aug 27 06:50:22.958: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Aug 27 06:50:22.958: INFO: validating pod update-demo-nautilus-xpjtz
Aug 27 06:50:22.966: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 27 06:50:22.966: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 27 06:50:22.966: INFO: update-demo-nautilus-xpjtz is verified up and running
STEP: using delete to clean up resources 08/27/22 06:50:22.966
Aug 27 06:50:22.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 delete --grace-period=0 --force -f -'
Aug 27 06:50:23.046: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 06:50:23.046: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 27 06:50:23.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get rc,svc -l name=update-demo --no-headers'
Aug 27 06:50:23.170: INFO: stderr: "No resources found in kubectl-5970 namespace.\n"
Aug 27 06:50:23.170: INFO: stdout: ""
Aug 27 06:50:23.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 27 06:50:23.303: INFO: stderr: ""
Aug 27 06:50:23.303: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 06:50:23.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5970" for this suite. 08/27/22 06:50:23.313
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":280,"skipped":5357,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.791 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:16.526
    Aug 27 06:50:16.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 06:50:16.527
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:16.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:16.561
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 08/27/22 06:50:16.567
    Aug 27 06:50:16.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 create -f -'
    Aug 27 06:50:17.258: INFO: stderr: ""
    Aug 27 06:50:17.258: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 08/27/22 06:50:17.258
    Aug 27 06:50:17.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:50:17.403: INFO: stderr: ""
    Aug 27 06:50:17.403: INFO: stdout: "update-demo-nautilus-ttbkf update-demo-nautilus-xpjtz "
    Aug 27 06:50:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-ttbkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:50:17.480: INFO: stderr: ""
    Aug 27 06:50:17.480: INFO: stdout: ""
    Aug 27 06:50:17.480: INFO: update-demo-nautilus-ttbkf is created but not running
    Aug 27 06:50:22.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Aug 27 06:50:22.556: INFO: stderr: ""
    Aug 27 06:50:22.556: INFO: stdout: "update-demo-nautilus-ttbkf update-demo-nautilus-xpjtz "
    Aug 27 06:50:22.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-ttbkf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:50:22.643: INFO: stderr: ""
    Aug 27 06:50:22.643: INFO: stdout: "true"
    Aug 27 06:50:22.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-ttbkf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:50:22.738: INFO: stderr: ""
    Aug 27 06:50:22.738: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:50:22.738: INFO: validating pod update-demo-nautilus-ttbkf
    Aug 27 06:50:22.747: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:50:22.747: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:50:22.747: INFO: update-demo-nautilus-ttbkf is verified up and running
    Aug 27 06:50:22.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-xpjtz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Aug 27 06:50:22.851: INFO: stderr: ""
    Aug 27 06:50:22.851: INFO: stdout: "true"
    Aug 27 06:50:22.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods update-demo-nautilus-xpjtz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Aug 27 06:50:22.958: INFO: stderr: ""
    Aug 27 06:50:22.958: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Aug 27 06:50:22.958: INFO: validating pod update-demo-nautilus-xpjtz
    Aug 27 06:50:22.966: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Aug 27 06:50:22.966: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Aug 27 06:50:22.966: INFO: update-demo-nautilus-xpjtz is verified up and running
    STEP: using delete to clean up resources 08/27/22 06:50:22.966
    Aug 27 06:50:22.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 delete --grace-period=0 --force -f -'
    Aug 27 06:50:23.046: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 06:50:23.046: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Aug 27 06:50:23.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get rc,svc -l name=update-demo --no-headers'
    Aug 27 06:50:23.170: INFO: stderr: "No resources found in kubectl-5970 namespace.\n"
    Aug 27 06:50:23.170: INFO: stdout: ""
    Aug 27 06:50:23.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5970 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Aug 27 06:50:23.303: INFO: stderr: ""
    Aug 27 06:50:23.303: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 06:50:23.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5970" for this suite. 08/27/22 06:50:23.313
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:23.319
Aug 27 06:50:23.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename containers 08/27/22 06:50:23.32
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:23.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:23.34
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 08/27/22 06:50:23.344
Aug 27 06:50:23.352: INFO: Waiting up to 5m0s for pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba" in namespace "containers-8432" to be "Succeeded or Failed"
Aug 27 06:50:23.355: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba": Phase="Pending", Reason="", readiness=false. Elapsed: 3.011337ms
Aug 27 06:50:25.360: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007949708s
Aug 27 06:50:27.361: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008535189s
STEP: Saw pod success 08/27/22 06:50:27.361
Aug 27 06:50:27.361: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba" satisfied condition "Succeeded or Failed"
Aug 27 06:50:27.364: INFO: Trying to get logs from node ip-10-0-31-158 pod client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:50:27.369
Aug 27 06:50:27.380: INFO: Waiting for pod client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba to disappear
Aug 27 06:50:27.383: INFO: Pod client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 27 06:50:27.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8432" for this suite. 08/27/22 06:50:27.392
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":281,"skipped":5410,"failed":0}
------------------------------
â€¢ [4.077 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:23.319
    Aug 27 06:50:23.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename containers 08/27/22 06:50:23.32
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:23.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:23.34
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 08/27/22 06:50:23.344
    Aug 27 06:50:23.352: INFO: Waiting up to 5m0s for pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba" in namespace "containers-8432" to be "Succeeded or Failed"
    Aug 27 06:50:23.355: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba": Phase="Pending", Reason="", readiness=false. Elapsed: 3.011337ms
    Aug 27 06:50:25.360: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007949708s
    Aug 27 06:50:27.361: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008535189s
    STEP: Saw pod success 08/27/22 06:50:27.361
    Aug 27 06:50:27.361: INFO: Pod "client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba" satisfied condition "Succeeded or Failed"
    Aug 27 06:50:27.364: INFO: Trying to get logs from node ip-10-0-31-158 pod client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:50:27.369
    Aug 27 06:50:27.380: INFO: Waiting for pod client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba to disappear
    Aug 27 06:50:27.383: INFO: Pod client-containers-4aa049b0-cc65-4c24-a0cd-5a97c9dd50ba no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 27 06:50:27.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8432" for this suite. 08/27/22 06:50:27.392
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:27.412
Aug 27 06:50:27.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:50:27.414
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:27.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:27.453
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 08/27/22 06:50:27.459
STEP: setting up watch 08/27/22 06:50:27.459
STEP: submitting the pod to kubernetes 08/27/22 06:50:27.562
STEP: verifying the pod is in kubernetes 08/27/22 06:50:27.58
STEP: verifying pod creation was observed 08/27/22 06:50:27.59
Aug 27 06:50:27.590: INFO: Waiting up to 5m0s for pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b" in namespace "pods-5994" to be "running"
Aug 27 06:50:27.601: INFO: Pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.70506ms
Aug 27 06:50:29.604: INFO: Pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014034244s
Aug 27 06:50:29.604: INFO: Pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b" satisfied condition "running"
STEP: deleting the pod gracefully 08/27/22 06:50:29.607
STEP: verifying pod deletion was observed 08/27/22 06:50:29.612
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:50:31.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5994" for this suite. 08/27/22 06:50:31.788
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":282,"skipped":5454,"failed":0}
------------------------------
â€¢ [4.381 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:27.412
    Aug 27 06:50:27.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:50:27.414
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:27.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:27.453
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 08/27/22 06:50:27.459
    STEP: setting up watch 08/27/22 06:50:27.459
    STEP: submitting the pod to kubernetes 08/27/22 06:50:27.562
    STEP: verifying the pod is in kubernetes 08/27/22 06:50:27.58
    STEP: verifying pod creation was observed 08/27/22 06:50:27.59
    Aug 27 06:50:27.590: INFO: Waiting up to 5m0s for pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b" in namespace "pods-5994" to be "running"
    Aug 27 06:50:27.601: INFO: Pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.70506ms
    Aug 27 06:50:29.604: INFO: Pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014034244s
    Aug 27 06:50:29.604: INFO: Pod "pod-submit-remove-42d1f962-6e8b-4966-9905-0af3629a725b" satisfied condition "running"
    STEP: deleting the pod gracefully 08/27/22 06:50:29.607
    STEP: verifying pod deletion was observed 08/27/22 06:50:29.612
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:50:31.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5994" for this suite. 08/27/22 06:50:31.788
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:31.797
Aug 27 06:50:31.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename init-container 08/27/22 06:50:31.799
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:31.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:31.822
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 08/27/22 06:50:31.826
Aug 27 06:50:31.826: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Aug 27 06:50:36.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6152" for this suite. 08/27/22 06:50:36.783
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":283,"skipped":5468,"failed":0}
------------------------------
â€¢ [4.998 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:31.797
    Aug 27 06:50:31.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename init-container 08/27/22 06:50:31.799
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:31.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:31.822
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 08/27/22 06:50:31.826
    Aug 27 06:50:31.826: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Aug 27 06:50:36.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6152" for this suite. 08/27/22 06:50:36.783
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:36.797
Aug 27 06:50:36.797: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:50:36.799
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:36.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:36.836
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 27 06:50:36.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2216" for this suite. 08/27/22 06:50:36.914
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":284,"skipped":5475,"failed":0}
------------------------------
â€¢ [0.121 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:36.797
    Aug 27 06:50:36.797: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubelet-test 08/27/22 06:50:36.799
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:36.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:36.836
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 27 06:50:36.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2216" for this suite. 08/27/22 06:50:36.914
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:36.921
Aug 27 06:50:36.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename podtemplate 08/27/22 06:50:36.922
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:36.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:36.987
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Aug 27 06:50:37.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7876" for this suite. 08/27/22 06:50:37.037
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":285,"skipped":5513,"failed":0}
------------------------------
â€¢ [0.126 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:36.921
    Aug 27 06:50:36.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename podtemplate 08/27/22 06:50:36.922
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:36.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:36.987
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Aug 27 06:50:37.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7876" for this suite. 08/27/22 06:50:37.037
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:37.048
Aug 27 06:50:37.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:50:37.052
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:37.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:37.088
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:50:37.095
Aug 27 06:50:37.103: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1" in namespace "downward-api-4135" to be "Succeeded or Failed"
Aug 27 06:50:37.115: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.776435ms
Aug 27 06:50:39.119: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015635185s
Aug 27 06:50:41.119: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015529372s
STEP: Saw pod success 08/27/22 06:50:41.119
Aug 27 06:50:41.119: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1" satisfied condition "Succeeded or Failed"
Aug 27 06:50:41.122: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1 container client-container: <nil>
STEP: delete the pod 08/27/22 06:50:41.127
Aug 27 06:50:41.141: INFO: Waiting for pod downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1 to disappear
Aug 27 06:50:41.145: INFO: Pod downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:50:41.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4135" for this suite. 08/27/22 06:50:41.149
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":286,"skipped":5513,"failed":0}
------------------------------
â€¢ [4.107 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:37.048
    Aug 27 06:50:37.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:50:37.052
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:37.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:37.088
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:50:37.095
    Aug 27 06:50:37.103: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1" in namespace "downward-api-4135" to be "Succeeded or Failed"
    Aug 27 06:50:37.115: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.776435ms
    Aug 27 06:50:39.119: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015635185s
    Aug 27 06:50:41.119: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015529372s
    STEP: Saw pod success 08/27/22 06:50:41.119
    Aug 27 06:50:41.119: INFO: Pod "downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1" satisfied condition "Succeeded or Failed"
    Aug 27 06:50:41.122: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1 container client-container: <nil>
    STEP: delete the pod 08/27/22 06:50:41.127
    Aug 27 06:50:41.141: INFO: Waiting for pod downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1 to disappear
    Aug 27 06:50:41.145: INFO: Pod downwardapi-volume-eb89fd57-9246-49d6-be6f-e1d5bdeeb4d1 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:50:41.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4135" for this suite. 08/27/22 06:50:41.149
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:41.157
Aug 27 06:50:41.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:50:41.158
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:41.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:41.276
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:50:41.28
Aug 27 06:50:41.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254" in namespace "projected-265" to be "Succeeded or Failed"
Aug 27 06:50:41.314: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254": Phase="Pending", Reason="", readiness=false. Elapsed: 20.161569ms
Aug 27 06:50:43.318: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023593035s
Aug 27 06:50:45.321: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026558861s
STEP: Saw pod success 08/27/22 06:50:45.321
Aug 27 06:50:45.321: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254" satisfied condition "Succeeded or Failed"
Aug 27 06:50:45.324: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254 container client-container: <nil>
STEP: delete the pod 08/27/22 06:50:45.336
Aug 27 06:50:45.370: INFO: Waiting for pod downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254 to disappear
Aug 27 06:50:45.375: INFO: Pod downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:50:45.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-265" for this suite. 08/27/22 06:50:45.387
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":287,"skipped":5523,"failed":0}
------------------------------
â€¢ [4.252 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:41.157
    Aug 27 06:50:41.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:50:41.158
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:41.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:41.276
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:50:41.28
    Aug 27 06:50:41.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254" in namespace "projected-265" to be "Succeeded or Failed"
    Aug 27 06:50:41.314: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254": Phase="Pending", Reason="", readiness=false. Elapsed: 20.161569ms
    Aug 27 06:50:43.318: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023593035s
    Aug 27 06:50:45.321: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026558861s
    STEP: Saw pod success 08/27/22 06:50:45.321
    Aug 27 06:50:45.321: INFO: Pod "downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254" satisfied condition "Succeeded or Failed"
    Aug 27 06:50:45.324: INFO: Trying to get logs from node ip-10-0-31-158 pod downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254 container client-container: <nil>
    STEP: delete the pod 08/27/22 06:50:45.336
    Aug 27 06:50:45.370: INFO: Waiting for pod downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254 to disappear
    Aug 27 06:50:45.375: INFO: Pod downwardapi-volume-7a0ebe8f-64f3-45d9-bcce-794853caa254 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:50:45.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-265" for this suite. 08/27/22 06:50:45.387
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:45.41
Aug 27 06:50:45.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:50:45.411
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:45.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:45.471
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-336e6d30-a0c7-4651-944a-82950de7ebc0 08/27/22 06:50:45.475
STEP: Creating a pod to test consume secrets 08/27/22 06:50:45.479
Aug 27 06:50:45.492: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626" in namespace "projected-5855" to be "Succeeded or Failed"
Aug 27 06:50:45.502: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626": Phase="Pending", Reason="", readiness=false. Elapsed: 8.946921ms
Aug 27 06:50:47.506: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013431886s
Aug 27 06:50:49.507: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01465671s
STEP: Saw pod success 08/27/22 06:50:49.507
Aug 27 06:50:49.508: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626" satisfied condition "Succeeded or Failed"
Aug 27 06:50:49.511: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626 container projected-secret-volume-test: <nil>
STEP: delete the pod 08/27/22 06:50:49.516
Aug 27 06:50:49.526: INFO: Waiting for pod pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626 to disappear
Aug 27 06:50:49.529: INFO: Pod pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Aug 27 06:50:49.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5855" for this suite. 08/27/22 06:50:49.533
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":288,"skipped":5525,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:45.41
    Aug 27 06:50:45.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:50:45.411
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:45.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:45.471
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-336e6d30-a0c7-4651-944a-82950de7ebc0 08/27/22 06:50:45.475
    STEP: Creating a pod to test consume secrets 08/27/22 06:50:45.479
    Aug 27 06:50:45.492: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626" in namespace "projected-5855" to be "Succeeded or Failed"
    Aug 27 06:50:45.502: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626": Phase="Pending", Reason="", readiness=false. Elapsed: 8.946921ms
    Aug 27 06:50:47.506: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013431886s
    Aug 27 06:50:49.507: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01465671s
    STEP: Saw pod success 08/27/22 06:50:49.507
    Aug 27 06:50:49.508: INFO: Pod "pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626" satisfied condition "Succeeded or Failed"
    Aug 27 06:50:49.511: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626 container projected-secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 06:50:49.516
    Aug 27 06:50:49.526: INFO: Waiting for pod pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626 to disappear
    Aug 27 06:50:49.529: INFO: Pod pod-projected-secrets-c541c0c0-a7ec-44cd-bdde-b6cfc9fd3626 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Aug 27 06:50:49.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5855" for this suite. 08/27/22 06:50:49.533
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:49.542
Aug 27 06:50:49.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:50:49.544
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:49.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:49.569
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-6a328c57-11f3-463f-9bd6-d8e4c5d65567 08/27/22 06:50:49.573
STEP: Creating a pod to test consume configMaps 08/27/22 06:50:49.578
Aug 27 06:50:49.584: INFO: Waiting up to 5m0s for pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683" in namespace "configmap-8900" to be "Succeeded or Failed"
Aug 27 06:50:49.587: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.579904ms
Aug 27 06:50:51.591: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006493506s
Aug 27 06:50:53.591: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006143331s
STEP: Saw pod success 08/27/22 06:50:53.591
Aug 27 06:50:53.591: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683" satisfied condition "Succeeded or Failed"
Aug 27 06:50:53.593: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683 container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:50:53.598
Aug 27 06:50:53.606: INFO: Waiting for pod pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683 to disappear
Aug 27 06:50:53.611: INFO: Pod pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:50:53.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8900" for this suite. 08/27/22 06:50:53.615
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":289,"skipped":5544,"failed":0}
------------------------------
â€¢ [4.078 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:49.542
    Aug 27 06:50:49.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:50:49.544
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:49.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:49.569
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-6a328c57-11f3-463f-9bd6-d8e4c5d65567 08/27/22 06:50:49.573
    STEP: Creating a pod to test consume configMaps 08/27/22 06:50:49.578
    Aug 27 06:50:49.584: INFO: Waiting up to 5m0s for pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683" in namespace "configmap-8900" to be "Succeeded or Failed"
    Aug 27 06:50:49.587: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.579904ms
    Aug 27 06:50:51.591: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006493506s
    Aug 27 06:50:53.591: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006143331s
    STEP: Saw pod success 08/27/22 06:50:53.591
    Aug 27 06:50:53.591: INFO: Pod "pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683" satisfied condition "Succeeded or Failed"
    Aug 27 06:50:53.593: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683 container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:50:53.598
    Aug 27 06:50:53.606: INFO: Waiting for pod pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683 to disappear
    Aug 27 06:50:53.611: INFO: Pod pod-configmaps-c385adf3-cf7b-4349-9c8d-401d3b4fe683 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:50:53.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8900" for this suite. 08/27/22 06:50:53.615
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:50:53.62
Aug 27 06:50:53.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename aggregator 08/27/22 06:50:53.621
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:53.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:53.641
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Aug 27 06:50:53.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 08/27/22 06:50:53.649
Aug 27 06:50:54.041: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 27 06:50:56.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:50:58.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:00.095: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:02.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:04.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:06.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:08.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:10.095: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:12.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:14.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:16.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:18.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 27 06:51:20.473: INFO: Waited 366.55416ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 08/27/22 06:51:20.611
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 08/27/22 06:51:20.614
STEP: List APIServices 08/27/22 06:51:20.622
Aug 27 06:51:20.640: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Aug 27 06:51:20.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-927" for this suite. 08/27/22 06:51:20.866
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":290,"skipped":5545,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.251 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:50:53.62
    Aug 27 06:50:53.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename aggregator 08/27/22 06:50:53.621
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:50:53.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:50:53.641
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Aug 27 06:50:53.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 08/27/22 06:50:53.649
    Aug 27 06:50:54.041: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Aug 27 06:50:56.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:50:58.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:00.095: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:02.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:04.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:06.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:08.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:10.095: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:12.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:14.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:16.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:18.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 6, 50, 54, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Aug 27 06:51:20.473: INFO: Waited 366.55416ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 08/27/22 06:51:20.611
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 08/27/22 06:51:20.614
    STEP: List APIServices 08/27/22 06:51:20.622
    Aug 27 06:51:20.640: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Aug 27 06:51:20.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-927" for this suite. 08/27/22 06:51:20.866
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:20.901
Aug 27 06:51:20.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:51:20.902
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:20.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:20.921
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Aug 27 06:51:20.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:51:21.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2090" for this suite. 08/27/22 06:51:21.68
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":291,"skipped":5557,"failed":0}
------------------------------
â€¢ [0.784 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:20.901
    Aug 27 06:51:20.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename custom-resource-definition 08/27/22 06:51:20.902
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:20.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:20.921
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Aug 27 06:51:20.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:51:21.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2090" for this suite. 08/27/22 06:51:21.68
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:21.685
Aug 27 06:51:21.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename dns 08/27/22 06:51:21.686
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:21.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:21.704
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5076.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5076.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 08/27/22 06:51:21.707
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5076.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5076.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 08/27/22 06:51:21.707
STEP: creating a pod to probe /etc/hosts 08/27/22 06:51:21.707
STEP: submitting the pod to kubernetes 08/27/22 06:51:21.708
Aug 27 06:51:21.713: INFO: Waiting up to 15m0s for pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15" in namespace "dns-5076" to be "running"
Aug 27 06:51:21.715: INFO: Pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328922ms
Aug 27 06:51:23.720: INFO: Pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15": Phase="Running", Reason="", readiness=true. Elapsed: 2.006504676s
Aug 27 06:51:23.720: INFO: Pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15" satisfied condition "running"
STEP: retrieving the pod 08/27/22 06:51:23.72
STEP: looking for the results for each expected name from probers 08/27/22 06:51:23.722
Aug 27 06:51:23.738: INFO: DNS probes using dns-5076/dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15 succeeded

STEP: deleting the pod 08/27/22 06:51:23.738
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Aug 27 06:51:23.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5076" for this suite. 08/27/22 06:51:23.752
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":292,"skipped":5560,"failed":0}
------------------------------
â€¢ [2.071 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:21.685
    Aug 27 06:51:21.685: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename dns 08/27/22 06:51:21.686
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:21.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:21.704
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5076.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5076.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     08/27/22 06:51:21.707
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5076.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5076.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     08/27/22 06:51:21.707
    STEP: creating a pod to probe /etc/hosts 08/27/22 06:51:21.707
    STEP: submitting the pod to kubernetes 08/27/22 06:51:21.708
    Aug 27 06:51:21.713: INFO: Waiting up to 15m0s for pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15" in namespace "dns-5076" to be "running"
    Aug 27 06:51:21.715: INFO: Pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328922ms
    Aug 27 06:51:23.720: INFO: Pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15": Phase="Running", Reason="", readiness=true. Elapsed: 2.006504676s
    Aug 27 06:51:23.720: INFO: Pod "dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15" satisfied condition "running"
    STEP: retrieving the pod 08/27/22 06:51:23.72
    STEP: looking for the results for each expected name from probers 08/27/22 06:51:23.722
    Aug 27 06:51:23.738: INFO: DNS probes using dns-5076/dns-test-0f4d8a17-4e6a-4d12-ae9c-73f8f8600e15 succeeded

    STEP: deleting the pod 08/27/22 06:51:23.738
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Aug 27 06:51:23.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5076" for this suite. 08/27/22 06:51:23.752
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:23.763
Aug 27 06:51:23.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-webhook 08/27/22 06:51:23.763
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:23.777
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:23.782
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 08/27/22 06:51:23.787
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/27/22 06:51:24.663
STEP: Deploying the custom resource conversion webhook pod 08/27/22 06:51:24.669
STEP: Wait for the deployment to be ready 08/27/22 06:51:24.683
Aug 27 06:51:24.704: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 06:51:26.712
STEP: Verifying the service has paired with the endpoint 08/27/22 06:51:26.721
Aug 27 06:51:27.723: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Aug 27 06:51:27.737: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Creating a v1 custom resource 08/27/22 06:51:30.512
STEP: v2 custom resource should be converted 08/27/22 06:51:30.518
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:51:31.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6367" for this suite. 08/27/22 06:51:31.052
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":293,"skipped":5598,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.348 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:23.763
    Aug 27 06:51:23.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-webhook 08/27/22 06:51:23.763
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:23.777
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:23.782
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 08/27/22 06:51:23.787
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/27/22 06:51:24.663
    STEP: Deploying the custom resource conversion webhook pod 08/27/22 06:51:24.669
    STEP: Wait for the deployment to be ready 08/27/22 06:51:24.683
    Aug 27 06:51:24.704: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 06:51:26.712
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:51:26.721
    Aug 27 06:51:27.723: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Aug 27 06:51:27.737: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Creating a v1 custom resource 08/27/22 06:51:30.512
    STEP: v2 custom resource should be converted 08/27/22 06:51:30.518
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:51:31.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-6367" for this suite. 08/27/22 06:51:31.052
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:31.119
Aug 27 06:51:31.119: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename ingressclass 08/27/22 06:51:31.12
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:31.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:31.176
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 08/27/22 06:51:31.181
STEP: getting /apis/networking.k8s.io 08/27/22 06:51:31.184
STEP: getting /apis/networking.k8s.iov1 08/27/22 06:51:31.192
STEP: creating 08/27/22 06:51:31.196
STEP: getting 08/27/22 06:51:31.219
STEP: listing 08/27/22 06:51:31.223
STEP: watching 08/27/22 06:51:31.234
Aug 27 06:51:31.234: INFO: starting watch
STEP: patching 08/27/22 06:51:31.236
STEP: updating 08/27/22 06:51:31.241
Aug 27 06:51:31.247: INFO: waiting for watch events with expected annotations
Aug 27 06:51:31.247: INFO: saw patched and updated annotations
STEP: deleting 08/27/22 06:51:31.248
STEP: deleting a collection 08/27/22 06:51:31.257
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Aug 27 06:51:31.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-793" for this suite. 08/27/22 06:51:31.272
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":294,"skipped":5635,"failed":0}
------------------------------
â€¢ [0.158 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:31.119
    Aug 27 06:51:31.119: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename ingressclass 08/27/22 06:51:31.12
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:31.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:31.176
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 08/27/22 06:51:31.181
    STEP: getting /apis/networking.k8s.io 08/27/22 06:51:31.184
    STEP: getting /apis/networking.k8s.iov1 08/27/22 06:51:31.192
    STEP: creating 08/27/22 06:51:31.196
    STEP: getting 08/27/22 06:51:31.219
    STEP: listing 08/27/22 06:51:31.223
    STEP: watching 08/27/22 06:51:31.234
    Aug 27 06:51:31.234: INFO: starting watch
    STEP: patching 08/27/22 06:51:31.236
    STEP: updating 08/27/22 06:51:31.241
    Aug 27 06:51:31.247: INFO: waiting for watch events with expected annotations
    Aug 27 06:51:31.247: INFO: saw patched and updated annotations
    STEP: deleting 08/27/22 06:51:31.248
    STEP: deleting a collection 08/27/22 06:51:31.257
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Aug 27 06:51:31.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-793" for this suite. 08/27/22 06:51:31.272
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:31.279
Aug 27 06:51:31.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:51:31.28
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:31.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:31.316
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 08/27/22 06:51:31.319
Aug 27 06:51:31.330: INFO: Waiting up to 5m0s for pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb" in namespace "emptydir-5813" to be "Succeeded or Failed"
Aug 27 06:51:31.334: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.451849ms
Aug 27 06:51:33.338: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb": Phase="Running", Reason="", readiness=false. Elapsed: 2.007938903s
Aug 27 06:51:35.338: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007636555s
STEP: Saw pod success 08/27/22 06:51:35.338
Aug 27 06:51:35.338: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb" satisfied condition "Succeeded or Failed"
Aug 27 06:51:35.340: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb container test-container: <nil>
STEP: delete the pod 08/27/22 06:51:35.348
Aug 27 06:51:35.361: INFO: Waiting for pod pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb to disappear
Aug 27 06:51:35.364: INFO: Pod pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:51:35.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5813" for this suite. 08/27/22 06:51:35.368
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":295,"skipped":5638,"failed":0}
------------------------------
â€¢ [4.093 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:31.279
    Aug 27 06:51:31.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:51:31.28
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:31.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:31.316
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 08/27/22 06:51:31.319
    Aug 27 06:51:31.330: INFO: Waiting up to 5m0s for pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb" in namespace "emptydir-5813" to be "Succeeded or Failed"
    Aug 27 06:51:31.334: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.451849ms
    Aug 27 06:51:33.338: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb": Phase="Running", Reason="", readiness=false. Elapsed: 2.007938903s
    Aug 27 06:51:35.338: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007636555s
    STEP: Saw pod success 08/27/22 06:51:35.338
    Aug 27 06:51:35.338: INFO: Pod "pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb" satisfied condition "Succeeded or Failed"
    Aug 27 06:51:35.340: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb container test-container: <nil>
    STEP: delete the pod 08/27/22 06:51:35.348
    Aug 27 06:51:35.361: INFO: Waiting for pod pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb to disappear
    Aug 27 06:51:35.364: INFO: Pod pod-2130ac91-7916-4ed9-93c0-7b0ffd73b4eb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:51:35.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5813" for this suite. 08/27/22 06:51:35.368
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:35.376
Aug 27 06:51:35.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 06:51:35.377
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:35.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:35.405
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-9547/configmap-test-ef341632-4274-4d46-8d58-d8bad80e2af0 08/27/22 06:51:35.409
STEP: Creating a pod to test consume configMaps 08/27/22 06:51:35.412
Aug 27 06:51:35.418: INFO: Waiting up to 5m0s for pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94" in namespace "configmap-9547" to be "Succeeded or Failed"
Aug 27 06:51:35.422: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94": Phase="Pending", Reason="", readiness=false. Elapsed: 3.52969ms
Aug 27 06:51:37.426: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94": Phase="Running", Reason="", readiness=false. Elapsed: 2.007628175s
Aug 27 06:51:39.426: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007684309s
STEP: Saw pod success 08/27/22 06:51:39.426
Aug 27 06:51:39.426: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94" satisfied condition "Succeeded or Failed"
Aug 27 06:51:39.429: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94 container env-test: <nil>
STEP: delete the pod 08/27/22 06:51:39.434
Aug 27 06:51:39.451: INFO: Waiting for pod pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94 to disappear
Aug 27 06:51:39.459: INFO: Pod pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 06:51:39.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9547" for this suite. 08/27/22 06:51:39.463
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":296,"skipped":5660,"failed":0}
------------------------------
â€¢ [4.093 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:35.376
    Aug 27 06:51:35.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 06:51:35.377
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:35.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:35.405
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-9547/configmap-test-ef341632-4274-4d46-8d58-d8bad80e2af0 08/27/22 06:51:35.409
    STEP: Creating a pod to test consume configMaps 08/27/22 06:51:35.412
    Aug 27 06:51:35.418: INFO: Waiting up to 5m0s for pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94" in namespace "configmap-9547" to be "Succeeded or Failed"
    Aug 27 06:51:35.422: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94": Phase="Pending", Reason="", readiness=false. Elapsed: 3.52969ms
    Aug 27 06:51:37.426: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94": Phase="Running", Reason="", readiness=false. Elapsed: 2.007628175s
    Aug 27 06:51:39.426: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007684309s
    STEP: Saw pod success 08/27/22 06:51:39.426
    Aug 27 06:51:39.426: INFO: Pod "pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94" satisfied condition "Succeeded or Failed"
    Aug 27 06:51:39.429: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94 container env-test: <nil>
    STEP: delete the pod 08/27/22 06:51:39.434
    Aug 27 06:51:39.451: INFO: Waiting for pod pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94 to disappear
    Aug 27 06:51:39.459: INFO: Pod pod-configmaps-2d026b74-cd98-46f8-a715-f7e8d3043c94 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 06:51:39.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9547" for this suite. 08/27/22 06:51:39.463
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:39.48
Aug 27 06:51:39.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:51:39.481
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:39.496
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:39.5
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Aug 27 06:51:39.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/27/22 06:51:42.316
Aug 27 06:51:42.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 create -f -'
Aug 27 06:51:43.361: INFO: stderr: ""
Aug 27 06:51:43.361: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 27 06:51:43.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 delete e2e-test-crd-publish-openapi-4103-crds test-cr'
Aug 27 06:51:43.488: INFO: stderr: ""
Aug 27 06:51:43.488: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug 27 06:51:43.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 apply -f -'
Aug 27 06:51:43.718: INFO: stderr: ""
Aug 27 06:51:43.718: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 27 06:51:43.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 delete e2e-test-crd-publish-openapi-4103-crds test-cr'
Aug 27 06:51:43.812: INFO: stderr: ""
Aug 27 06:51:43.812: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 08/27/22 06:51:43.812
Aug 27 06:51:43.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 explain e2e-test-crd-publish-openapi-4103-crds'
Aug 27 06:51:44.054: INFO: stderr: ""
Aug 27 06:51:44.054: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4103-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:51:47.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4991" for this suite. 08/27/22 06:51:47.803
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":297,"skipped":5672,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.326 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:39.48
    Aug 27 06:51:39.481: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 06:51:39.481
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:39.496
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:39.5
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Aug 27 06:51:39.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 08/27/22 06:51:42.316
    Aug 27 06:51:42.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 create -f -'
    Aug 27 06:51:43.361: INFO: stderr: ""
    Aug 27 06:51:43.361: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Aug 27 06:51:43.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 delete e2e-test-crd-publish-openapi-4103-crds test-cr'
    Aug 27 06:51:43.488: INFO: stderr: ""
    Aug 27 06:51:43.488: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Aug 27 06:51:43.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 apply -f -'
    Aug 27 06:51:43.718: INFO: stderr: ""
    Aug 27 06:51:43.718: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Aug 27 06:51:43.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 --namespace=crd-publish-openapi-4991 delete e2e-test-crd-publish-openapi-4103-crds test-cr'
    Aug 27 06:51:43.812: INFO: stderr: ""
    Aug 27 06:51:43.812: INFO: stdout: "e2e-test-crd-publish-openapi-4103-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 08/27/22 06:51:43.812
    Aug 27 06:51:43.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=crd-publish-openapi-4991 explain e2e-test-crd-publish-openapi-4103-crds'
    Aug 27 06:51:44.054: INFO: stderr: ""
    Aug 27 06:51:44.054: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4103-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:51:47.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4991" for this suite. 08/27/22 06:51:47.803
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:47.807
Aug 27 06:51:47.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 06:51:47.808
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:47.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:47.825
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 06:51:47.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6206" for this suite. 08/27/22 06:51:47.859
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":298,"skipped":5683,"failed":0}
------------------------------
â€¢ [0.055 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:47.807
    Aug 27 06:51:47.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 06:51:47.808
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:47.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:47.825
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 06:51:47.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6206" for this suite. 08/27/22 06:51:47.859
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:47.864
Aug 27 06:51:47.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename csistoragecapacity 08/27/22 06:51:47.865
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:47.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:47.885
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 08/27/22 06:51:47.889
STEP: getting /apis/storage.k8s.io 08/27/22 06:51:47.891
STEP: getting /apis/storage.k8s.io/v1 08/27/22 06:51:47.892
STEP: creating 08/27/22 06:51:47.894
STEP: watching 08/27/22 06:51:47.909
Aug 27 06:51:47.909: INFO: starting watch
STEP: getting 08/27/22 06:51:47.915
STEP: listing in namespace 08/27/22 06:51:47.918
STEP: listing across namespaces 08/27/22 06:51:47.92
STEP: patching 08/27/22 06:51:47.922
STEP: updating 08/27/22 06:51:47.926
Aug 27 06:51:47.931: INFO: waiting for watch events with expected annotations in namespace
Aug 27 06:51:47.931: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 08/27/22 06:51:47.931
STEP: deleting a collection 08/27/22 06:51:47.941
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Aug 27 06:51:47.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-6658" for this suite. 08/27/22 06:51:47.952
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":299,"skipped":5693,"failed":0}
------------------------------
â€¢ [0.091 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:47.864
    Aug 27 06:51:47.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename csistoragecapacity 08/27/22 06:51:47.865
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:47.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:47.885
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 08/27/22 06:51:47.889
    STEP: getting /apis/storage.k8s.io 08/27/22 06:51:47.891
    STEP: getting /apis/storage.k8s.io/v1 08/27/22 06:51:47.892
    STEP: creating 08/27/22 06:51:47.894
    STEP: watching 08/27/22 06:51:47.909
    Aug 27 06:51:47.909: INFO: starting watch
    STEP: getting 08/27/22 06:51:47.915
    STEP: listing in namespace 08/27/22 06:51:47.918
    STEP: listing across namespaces 08/27/22 06:51:47.92
    STEP: patching 08/27/22 06:51:47.922
    STEP: updating 08/27/22 06:51:47.926
    Aug 27 06:51:47.931: INFO: waiting for watch events with expected annotations in namespace
    Aug 27 06:51:47.931: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 08/27/22 06:51:47.931
    STEP: deleting a collection 08/27/22 06:51:47.941
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Aug 27 06:51:47.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-6658" for this suite. 08/27/22 06:51:47.952
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:47.96
Aug 27 06:51:47.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:51:47.961
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:47.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:47.98
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  08/27/22 06:51:47.983
Aug 27 06:51:47.988: INFO: Waiting up to 5m0s for pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c" in namespace "svcaccounts-1067" to be "Succeeded or Failed"
Aug 27 06:51:47.991: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.751903ms
Aug 27 06:51:50.015: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026628232s
Aug 27 06:51:51.996: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00723272s
STEP: Saw pod success 08/27/22 06:51:51.996
Aug 27 06:51:51.996: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c" satisfied condition "Succeeded or Failed"
Aug 27 06:51:51.998: INFO: Trying to get logs from node ip-10-0-47-192 pod test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c container agnhost-container: <nil>
STEP: delete the pod 08/27/22 06:51:52.006
Aug 27 06:51:52.014: INFO: Waiting for pod test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c to disappear
Aug 27 06:51:52.018: INFO: Pod test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 27 06:51:52.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1067" for this suite. 08/27/22 06:51:52.021
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":300,"skipped":5712,"failed":0}
------------------------------
â€¢ [4.065 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:47.96
    Aug 27 06:51:47.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:51:47.961
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:47.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:47.98
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  08/27/22 06:51:47.983
    Aug 27 06:51:47.988: INFO: Waiting up to 5m0s for pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c" in namespace "svcaccounts-1067" to be "Succeeded or Failed"
    Aug 27 06:51:47.991: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.751903ms
    Aug 27 06:51:50.015: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026628232s
    Aug 27 06:51:51.996: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00723272s
    STEP: Saw pod success 08/27/22 06:51:51.996
    Aug 27 06:51:51.996: INFO: Pod "test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c" satisfied condition "Succeeded or Failed"
    Aug 27 06:51:51.998: INFO: Trying to get logs from node ip-10-0-47-192 pod test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 06:51:52.006
    Aug 27 06:51:52.014: INFO: Waiting for pod test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c to disappear
    Aug 27 06:51:52.018: INFO: Pod test-pod-c868f288-4bae-4209-b3e6-3eb799a8257c no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 27 06:51:52.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1067" for this suite. 08/27/22 06:51:52.021
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:52.027
Aug 27 06:51:52.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 06:51:52.028
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:52.048
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:52.053
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 08/27/22 06:51:52.056
Aug 27 06:51:52.063: INFO: Waiting up to 5m0s for pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9" in namespace "var-expansion-6144" to be "Succeeded or Failed"
Aug 27 06:51:52.072: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.797671ms
Aug 27 06:51:54.077: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01452417s
Aug 27 06:51:56.077: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014604537s
STEP: Saw pod success 08/27/22 06:51:56.077
Aug 27 06:51:56.078: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9" satisfied condition "Succeeded or Failed"
Aug 27 06:51:56.080: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9 container dapi-container: <nil>
STEP: delete the pod 08/27/22 06:51:56.087
Aug 27 06:51:56.094: INFO: Waiting for pod var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9 to disappear
Aug 27 06:51:56.097: INFO: Pod var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 06:51:56.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6144" for this suite. 08/27/22 06:51:56.101
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":301,"skipped":5716,"failed":0}
------------------------------
â€¢ [4.079 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:52.027
    Aug 27 06:51:52.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 06:51:52.028
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:52.048
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:52.053
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 08/27/22 06:51:52.056
    Aug 27 06:51:52.063: INFO: Waiting up to 5m0s for pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9" in namespace "var-expansion-6144" to be "Succeeded or Failed"
    Aug 27 06:51:52.072: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.797671ms
    Aug 27 06:51:54.077: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01452417s
    Aug 27 06:51:56.077: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014604537s
    STEP: Saw pod success 08/27/22 06:51:56.077
    Aug 27 06:51:56.078: INFO: Pod "var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9" satisfied condition "Succeeded or Failed"
    Aug 27 06:51:56.080: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 06:51:56.087
    Aug 27 06:51:56.094: INFO: Waiting for pod var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9 to disappear
    Aug 27 06:51:56.097: INFO: Pod var-expansion-a8966d20-3479-4721-8d0e-5aad7900bcb9 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 06:51:56.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6144" for this suite. 08/27/22 06:51:56.101
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:51:56.106
Aug 27 06:51:56.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 06:51:56.107
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:56.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:56.141
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 08/27/22 06:51:56.144
Aug 27 06:51:56.150: INFO: Waiting up to 5m0s for pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08" in namespace "var-expansion-2961" to be "Succeeded or Failed"
Aug 27 06:51:56.154: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167823ms
Aug 27 06:51:58.159: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008096899s
Aug 27 06:52:00.158: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007302986s
STEP: Saw pod success 08/27/22 06:52:00.158
Aug 27 06:52:00.158: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08" satisfied condition "Succeeded or Failed"
Aug 27 06:52:00.183: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08 container dapi-container: <nil>
STEP: delete the pod 08/27/22 06:52:00.206
Aug 27 06:52:00.243: INFO: Waiting for pod var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08 to disappear
Aug 27 06:52:00.251: INFO: Pod var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 06:52:00.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2961" for this suite. 08/27/22 06:52:00.268
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":302,"skipped":5720,"failed":0}
------------------------------
â€¢ [4.176 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:51:56.106
    Aug 27 06:51:56.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 06:51:56.107
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:51:56.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:51:56.141
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 08/27/22 06:51:56.144
    Aug 27 06:51:56.150: INFO: Waiting up to 5m0s for pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08" in namespace "var-expansion-2961" to be "Succeeded or Failed"
    Aug 27 06:51:56.154: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167823ms
    Aug 27 06:51:58.159: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008096899s
    Aug 27 06:52:00.158: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007302986s
    STEP: Saw pod success 08/27/22 06:52:00.158
    Aug 27 06:52:00.158: INFO: Pod "var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08" satisfied condition "Succeeded or Failed"
    Aug 27 06:52:00.183: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 06:52:00.206
    Aug 27 06:52:00.243: INFO: Waiting for pod var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08 to disappear
    Aug 27 06:52:00.251: INFO: Pod var-expansion-afc363cc-0753-4f35-a005-b03a2c9dad08 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 06:52:00.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2961" for this suite. 08/27/22 06:52:00.268
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:52:00.299
Aug 27 06:52:00.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:52:00.302
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:52:00.372
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:52:00.387
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Aug 27 06:52:00.437: INFO: created pod
Aug 27 06:52:00.437: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-3556" to be "Succeeded or Failed"
Aug 27 06:52:00.454: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 17.106082ms
Aug 27 06:52:02.458: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020997245s
Aug 27 06:52:04.458: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020509163s
STEP: Saw pod success 08/27/22 06:52:04.458
Aug 27 06:52:04.458: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Aug 27 06:52:34.461: INFO: polling logs
Aug 27 06:52:34.474: INFO: Pod logs: 
I0827 06:52:01.419641       1 log.go:195] OK: Got token
I0827 06:52:01.419680       1 log.go:195] validating with in-cluster discovery
I0827 06:52:01.419970       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0827 06:52:01.420002       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3556:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661583720, NotBefore:1661583120, IssuedAt:1661583120, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3556", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c17ba988-5c2b-42c5-94af-a1c5349e4701"}}}
I0827 06:52:01.461619       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0827 06:52:01.467138       1 log.go:195] OK: Validated signature on JWT
I0827 06:52:01.467245       1 log.go:195] OK: Got valid claims from token!
I0827 06:52:01.467271       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3556:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661583720, NotBefore:1661583120, IssuedAt:1661583120, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3556", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c17ba988-5c2b-42c5-94af-a1c5349e4701"}}}

Aug 27 06:52:34.474: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Aug 27 06:52:34.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3556" for this suite. 08/27/22 06:52:34.489
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":303,"skipped":5745,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.194 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:52:00.299
    Aug 27 06:52:00.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename svcaccounts 08/27/22 06:52:00.302
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:52:00.372
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:52:00.387
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Aug 27 06:52:00.437: INFO: created pod
    Aug 27 06:52:00.437: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-3556" to be "Succeeded or Failed"
    Aug 27 06:52:00.454: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 17.106082ms
    Aug 27 06:52:02.458: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020997245s
    Aug 27 06:52:04.458: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020509163s
    STEP: Saw pod success 08/27/22 06:52:04.458
    Aug 27 06:52:04.458: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Aug 27 06:52:34.461: INFO: polling logs
    Aug 27 06:52:34.474: INFO: Pod logs: 
    I0827 06:52:01.419641       1 log.go:195] OK: Got token
    I0827 06:52:01.419680       1 log.go:195] validating with in-cluster discovery
    I0827 06:52:01.419970       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0827 06:52:01.420002       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3556:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661583720, NotBefore:1661583120, IssuedAt:1661583120, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3556", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c17ba988-5c2b-42c5-94af-a1c5349e4701"}}}
    I0827 06:52:01.461619       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0827 06:52:01.467138       1 log.go:195] OK: Validated signature on JWT
    I0827 06:52:01.467245       1 log.go:195] OK: Got valid claims from token!
    I0827 06:52:01.467271       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3556:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661583720, NotBefore:1661583120, IssuedAt:1661583120, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3556", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c17ba988-5c2b-42c5-94af-a1c5349e4701"}}}

    Aug 27 06:52:34.474: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Aug 27 06:52:34.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3556" for this suite. 08/27/22 06:52:34.489
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:52:34.495
Aug 27 06:52:34.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename endpointslice 08/27/22 06:52:34.496
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:52:34.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:52:34.519
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 08/27/22 06:52:39.653
STEP: referencing matching pods with named port 08/27/22 06:52:44.665
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 08/27/22 06:52:49.676
STEP: recreating EndpointSlices after they've been deleted 08/27/22 06:52:54.683
Aug 27 06:52:54.697: INFO: EndpointSlice for Service endpointslice-6565/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Aug 27 06:53:04.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6565" for this suite. 08/27/22 06:53:04.718
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":304,"skipped":5753,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.229 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:52:34.495
    Aug 27 06:52:34.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename endpointslice 08/27/22 06:52:34.496
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:52:34.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:52:34.519
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 08/27/22 06:52:39.653
    STEP: referencing matching pods with named port 08/27/22 06:52:44.665
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 08/27/22 06:52:49.676
    STEP: recreating EndpointSlices after they've been deleted 08/27/22 06:52:54.683
    Aug 27 06:52:54.697: INFO: EndpointSlice for Service endpointslice-6565/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Aug 27 06:53:04.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6565" for this suite. 08/27/22 06:53:04.718
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:53:04.727
Aug 27 06:53:04.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:53:04.728
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:53:04.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:53:04.759
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-3ae9773e-f8e4-483e-9ffa-4ee38f6ebf66 08/27/22 06:53:04.767
STEP: Creating the pod 08/27/22 06:53:04.771
Aug 27 06:53:04.779: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b" in namespace "projected-1919" to be "running and ready"
Aug 27 06:53:04.789: INFO: Pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.884428ms
Aug 27 06:53:04.789: INFO: The phase of Pod pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:53:06.793: INFO: Pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014124835s
Aug 27 06:53:06.793: INFO: The phase of Pod pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b is Running (Ready = true)
Aug 27 06:53:06.793: INFO: Pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-3ae9773e-f8e4-483e-9ffa-4ee38f6ebf66 08/27/22 06:53:06.803
STEP: waiting to observe update in volume 08/27/22 06:53:06.808
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Aug 27 06:53:08.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1919" for this suite. 08/27/22 06:53:08.828
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":305,"skipped":5756,"failed":0}
------------------------------
â€¢ [4.105 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:53:04.727
    Aug 27 06:53:04.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:53:04.728
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:53:04.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:53:04.759
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-3ae9773e-f8e4-483e-9ffa-4ee38f6ebf66 08/27/22 06:53:04.767
    STEP: Creating the pod 08/27/22 06:53:04.771
    Aug 27 06:53:04.779: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b" in namespace "projected-1919" to be "running and ready"
    Aug 27 06:53:04.789: INFO: Pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.884428ms
    Aug 27 06:53:04.789: INFO: The phase of Pod pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:53:06.793: INFO: Pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014124835s
    Aug 27 06:53:06.793: INFO: The phase of Pod pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b is Running (Ready = true)
    Aug 27 06:53:06.793: INFO: Pod "pod-projected-configmaps-d1e7c88b-0222-4aba-896b-0b433af9c30b" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-3ae9773e-f8e4-483e-9ffa-4ee38f6ebf66 08/27/22 06:53:06.803
    STEP: waiting to observe update in volume 08/27/22 06:53:06.808
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Aug 27 06:53:08.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1919" for this suite. 08/27/22 06:53:08.828
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:53:08.832
Aug 27 06:53:08.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:53:08.833
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:53:08.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:53:08.856
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:54:08.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8037" for this suite. 08/27/22 06:54:08.881
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":306,"skipped":5756,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.054 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:53:08.832
    Aug 27 06:53:08.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:53:08.833
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:53:08.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:53:08.856
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:54:08.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8037" for this suite. 08/27/22 06:54:08.881
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:08.888
Aug 27 06:54:08.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:54:08.893
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:08.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:08.929
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Aug 27 06:54:08.947: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-2214 to be scheduled
Aug 27 06:54:08.953: INFO: 1 pods are not scheduled: [runtimeclass-2214/test-runtimeclass-runtimeclass-2214-preconfigured-handler-lt9qb(06f25ede-37e8-458c-a1e4-072256e2beb2)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Aug 27 06:54:10.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2214" for this suite. 08/27/22 06:54:10.969
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":307,"skipped":5759,"failed":0}
------------------------------
â€¢ [2.086 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:08.888
    Aug 27 06:54:08.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename runtimeclass 08/27/22 06:54:08.893
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:08.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:08.929
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Aug 27 06:54:08.947: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-2214 to be scheduled
    Aug 27 06:54:08.953: INFO: 1 pods are not scheduled: [runtimeclass-2214/test-runtimeclass-runtimeclass-2214-preconfigured-handler-lt9qb(06f25ede-37e8-458c-a1e4-072256e2beb2)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Aug 27 06:54:10.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2214" for this suite. 08/27/22 06:54:10.969
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:10.978
Aug 27 06:54:10.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename watch 08/27/22 06:54:10.979
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:11.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:11.031
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 08/27/22 06:54:11.039
STEP: modifying the configmap once 08/27/22 06:54:11.043
STEP: modifying the configmap a second time 08/27/22 06:54:11.05
STEP: deleting the configmap 08/27/22 06:54:11.056
STEP: creating a watch on configmaps from the resource version returned by the first update 08/27/22 06:54:11.062
STEP: Expecting to observe notifications for all changes to the configmap after the first update 08/27/22 06:54:11.064
Aug 27 06:54:11.065: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7697  7835364d-2dad-4ede-a48e-dedcfbcab9d6 28794 0 2022-08-27 06:54:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-27 06:54:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 27 06:54:11.065: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7697  7835364d-2dad-4ede-a48e-dedcfbcab9d6 28795 0 2022-08-27 06:54:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-27 06:54:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Aug 27 06:54:11.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7697" for this suite. 08/27/22 06:54:11.069
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":308,"skipped":5797,"failed":0}
------------------------------
â€¢ [0.096 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:10.978
    Aug 27 06:54:10.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename watch 08/27/22 06:54:10.979
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:11.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:11.031
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 08/27/22 06:54:11.039
    STEP: modifying the configmap once 08/27/22 06:54:11.043
    STEP: modifying the configmap a second time 08/27/22 06:54:11.05
    STEP: deleting the configmap 08/27/22 06:54:11.056
    STEP: creating a watch on configmaps from the resource version returned by the first update 08/27/22 06:54:11.062
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 08/27/22 06:54:11.064
    Aug 27 06:54:11.065: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7697  7835364d-2dad-4ede-a48e-dedcfbcab9d6 28794 0 2022-08-27 06:54:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-27 06:54:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Aug 27 06:54:11.065: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7697  7835364d-2dad-4ede-a48e-dedcfbcab9d6 28795 0 2022-08-27 06:54:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-08-27 06:54:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Aug 27 06:54:11.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7697" for this suite. 08/27/22 06:54:11.069
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:11.076
Aug 27 06:54:11.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 06:54:11.077
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:11.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:11.118
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 08/27/22 06:54:11.125
Aug 27 06:54:11.134: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d" in namespace "projected-6641" to be "Succeeded or Failed"
Aug 27 06:54:11.139: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.65176ms
Aug 27 06:54:13.143: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008765099s
Aug 27 06:54:15.144: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010250566s
STEP: Saw pod success 08/27/22 06:54:15.144
Aug 27 06:54:15.144: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d" satisfied condition "Succeeded or Failed"
Aug 27 06:54:15.147: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d container client-container: <nil>
STEP: delete the pod 08/27/22 06:54:15.154
Aug 27 06:54:15.165: INFO: Waiting for pod downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d to disappear
Aug 27 06:54:15.168: INFO: Pod downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 06:54:15.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6641" for this suite. 08/27/22 06:54:15.171
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":309,"skipped":5805,"failed":0}
------------------------------
â€¢ [4.100 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:11.076
    Aug 27 06:54:11.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 06:54:11.077
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:11.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:11.118
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 08/27/22 06:54:11.125
    Aug 27 06:54:11.134: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d" in namespace "projected-6641" to be "Succeeded or Failed"
    Aug 27 06:54:11.139: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.65176ms
    Aug 27 06:54:13.143: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008765099s
    Aug 27 06:54:15.144: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010250566s
    STEP: Saw pod success 08/27/22 06:54:15.144
    Aug 27 06:54:15.144: INFO: Pod "downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d" satisfied condition "Succeeded or Failed"
    Aug 27 06:54:15.147: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d container client-container: <nil>
    STEP: delete the pod 08/27/22 06:54:15.154
    Aug 27 06:54:15.165: INFO: Waiting for pod downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d to disappear
    Aug 27 06:54:15.168: INFO: Pod downwardapi-volume-f5f94cf3-9675-4566-9be6-a3a0e5b96e3d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 06:54:15.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6641" for this suite. 08/27/22 06:54:15.171
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:15.179
Aug 27 06:54:15.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 06:54:15.187
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:15.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:15.283
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 08/27/22 06:54:15.322
Aug 27 06:54:15.348: INFO: Waiting up to 5m0s for pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d" in namespace "emptydir-9368" to be "Succeeded or Failed"
Aug 27 06:54:15.355: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.613452ms
Aug 27 06:54:17.359: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011433822s
Aug 27 06:54:19.359: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011497897s
STEP: Saw pod success 08/27/22 06:54:19.359
Aug 27 06:54:19.359: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d" satisfied condition "Succeeded or Failed"
Aug 27 06:54:19.364: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d container test-container: <nil>
STEP: delete the pod 08/27/22 06:54:19.373
Aug 27 06:54:19.387: INFO: Waiting for pod pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d to disappear
Aug 27 06:54:19.393: INFO: Pod pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 06:54:19.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9368" for this suite. 08/27/22 06:54:19.398
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":310,"skipped":5833,"failed":0}
------------------------------
â€¢ [4.228 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:15.179
    Aug 27 06:54:15.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 06:54:15.187
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:15.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:15.283
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 08/27/22 06:54:15.322
    Aug 27 06:54:15.348: INFO: Waiting up to 5m0s for pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d" in namespace "emptydir-9368" to be "Succeeded or Failed"
    Aug 27 06:54:15.355: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.613452ms
    Aug 27 06:54:17.359: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011433822s
    Aug 27 06:54:19.359: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011497897s
    STEP: Saw pod success 08/27/22 06:54:19.359
    Aug 27 06:54:19.359: INFO: Pod "pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d" satisfied condition "Succeeded or Failed"
    Aug 27 06:54:19.364: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d container test-container: <nil>
    STEP: delete the pod 08/27/22 06:54:19.373
    Aug 27 06:54:19.387: INFO: Waiting for pod pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d to disappear
    Aug 27 06:54:19.393: INFO: Pod pod-184fc0f3-3ed6-4e31-ba1b-3f39300a046d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 06:54:19.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9368" for this suite. 08/27/22 06:54:19.398
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:19.407
Aug 27 06:54:19.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:54:19.408
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:19.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:19.452
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 08/27/22 06:54:19.46
Aug 27 06:54:19.477: INFO: Waiting up to 5m0s for pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447" in namespace "pods-159" to be "running and ready"
Aug 27 06:54:19.480: INFO: Pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447": Phase="Pending", Reason="", readiness=false. Elapsed: 3.263931ms
Aug 27 06:54:19.480: INFO: The phase of Pod pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:54:21.483: INFO: Pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447": Phase="Running", Reason="", readiness=true. Elapsed: 2.006300374s
Aug 27 06:54:21.483: INFO: The phase of Pod pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447 is Running (Ready = true)
Aug 27 06:54:21.483: INFO: Pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447" satisfied condition "running and ready"
Aug 27 06:54:21.489: INFO: Pod pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447 has hostIP: 10.0.47.192
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:54:21.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-159" for this suite. 08/27/22 06:54:21.493
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":311,"skipped":5833,"failed":0}
------------------------------
â€¢ [2.091 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:19.407
    Aug 27 06:54:19.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:54:19.408
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:19.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:19.452
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 08/27/22 06:54:19.46
    Aug 27 06:54:19.477: INFO: Waiting up to 5m0s for pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447" in namespace "pods-159" to be "running and ready"
    Aug 27 06:54:19.480: INFO: Pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447": Phase="Pending", Reason="", readiness=false. Elapsed: 3.263931ms
    Aug 27 06:54:19.480: INFO: The phase of Pod pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:54:21.483: INFO: Pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447": Phase="Running", Reason="", readiness=true. Elapsed: 2.006300374s
    Aug 27 06:54:21.483: INFO: The phase of Pod pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447 is Running (Ready = true)
    Aug 27 06:54:21.483: INFO: Pod "pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447" satisfied condition "running and ready"
    Aug 27 06:54:21.489: INFO: Pod pod-hostip-3e6cbf30-3b9e-4686-889e-9082db90c447 has hostIP: 10.0.47.192
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:54:21.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-159" for this suite. 08/27/22 06:54:21.493
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:21.498
Aug 27 06:54:21.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:54:21.5
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:21.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:21.611
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:54:21.651
Aug 27 06:54:21.668: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3340" to be "running and ready"
Aug 27 06:54:21.689: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 20.643276ms
Aug 27 06:54:21.689: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:54:23.693: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.02473488s
Aug 27 06:54:23.693: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Aug 27 06:54:23.693: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 08/27/22 06:54:23.696
Aug 27 06:54:23.708: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-3340" to be "running and ready"
Aug 27 06:54:23.717: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.534716ms
Aug 27 06:54:23.717: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:54:25.720: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012040753s
Aug 27 06:54:25.720: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Aug 27 06:54:25.720: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 08/27/22 06:54:25.723
Aug 27 06:54:25.727: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 06:54:25.730: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 27 06:54:27.730: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 27 06:54:27.737: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 08/27/22 06:54:27.737
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Aug 27 06:54:27.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3340" for this suite. 08/27/22 06:54:27.754
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":312,"skipped":5835,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.260 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:21.498
    Aug 27 06:54:21.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-lifecycle-hook 08/27/22 06:54:21.5
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:21.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:21.611
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 08/27/22 06:54:21.651
    Aug 27 06:54:21.668: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3340" to be "running and ready"
    Aug 27 06:54:21.689: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 20.643276ms
    Aug 27 06:54:21.689: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:54:23.693: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.02473488s
    Aug 27 06:54:23.693: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Aug 27 06:54:23.693: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 08/27/22 06:54:23.696
    Aug 27 06:54:23.708: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-3340" to be "running and ready"
    Aug 27 06:54:23.717: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.534716ms
    Aug 27 06:54:23.717: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:54:25.720: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012040753s
    Aug 27 06:54:25.720: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Aug 27 06:54:25.720: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 08/27/22 06:54:25.723
    Aug 27 06:54:25.727: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Aug 27 06:54:25.730: INFO: Pod pod-with-prestop-exec-hook still exists
    Aug 27 06:54:27.730: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Aug 27 06:54:27.737: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 08/27/22 06:54:27.737
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Aug 27 06:54:27.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3340" for this suite. 08/27/22 06:54:27.754
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:27.759
Aug 27 06:54:27.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:54:27.76
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:27.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:27.781
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 08/27/22 06:54:27.788
Aug 27 06:54:27.795: INFO: Waiting up to 5m0s for pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd" in namespace "downward-api-7696" to be "running and ready"
Aug 27 06:54:27.800: INFO: Pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.742685ms
Aug 27 06:54:27.800: INFO: The phase of Pod labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd is Pending, waiting for it to be Running (with Ready = true)
Aug 27 06:54:29.804: INFO: Pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd": Phase="Running", Reason="", readiness=true. Elapsed: 2.008434559s
Aug 27 06:54:29.804: INFO: The phase of Pod labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd is Running (Ready = true)
Aug 27 06:54:29.804: INFO: Pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd" satisfied condition "running and ready"
Aug 27 06:54:30.324: INFO: Successfully updated pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Aug 27 06:54:34.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7696" for this suite. 08/27/22 06:54:34.347
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":313,"skipped":5837,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.592 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:27.759
    Aug 27 06:54:27.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:54:27.76
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:27.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:27.781
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 08/27/22 06:54:27.788
    Aug 27 06:54:27.795: INFO: Waiting up to 5m0s for pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd" in namespace "downward-api-7696" to be "running and ready"
    Aug 27 06:54:27.800: INFO: Pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.742685ms
    Aug 27 06:54:27.800: INFO: The phase of Pod labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 06:54:29.804: INFO: Pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd": Phase="Running", Reason="", readiness=true. Elapsed: 2.008434559s
    Aug 27 06:54:29.804: INFO: The phase of Pod labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd is Running (Ready = true)
    Aug 27 06:54:29.804: INFO: Pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd" satisfied condition "running and ready"
    Aug 27 06:54:30.324: INFO: Successfully updated pod "labelsupdate72216d06-ba24-4ab8-88c7-2001aea08dfd"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Aug 27 06:54:34.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7696" for this suite. 08/27/22 06:54:34.347
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:34.351
Aug 27 06:54:34.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 06:54:34.353
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:34.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:34.38
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 08/27/22 06:54:34.387
STEP: Wait for the Deployment to create new ReplicaSet 08/27/22 06:54:34.392
STEP: delete the deployment 08/27/22 06:54:34.907
STEP: wait for all rs to be garbage collected 08/27/22 06:54:34.919
STEP: expected 0 rs, got 1 rs 08/27/22 06:54:34.925
STEP: expected 0 pods, got 2 pods 08/27/22 06:54:34.941
STEP: Gathering metrics 08/27/22 06:54:35.456
Aug 27 06:54:35.474: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
Aug 27 06:54:35.476: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 2.85154ms
Aug 27 06:54:35.477: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
Aug 27 06:54:35.477: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
Aug 27 06:54:35.546: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 06:54:35.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1057" for this suite. 08/27/22 06:54:35.552
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":314,"skipped":5839,"failed":0}
------------------------------
â€¢ [1.207 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:34.351
    Aug 27 06:54:34.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 06:54:34.353
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:34.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:34.38
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 08/27/22 06:54:34.387
    STEP: Wait for the Deployment to create new ReplicaSet 08/27/22 06:54:34.392
    STEP: delete the deployment 08/27/22 06:54:34.907
    STEP: wait for all rs to be garbage collected 08/27/22 06:54:34.919
    STEP: expected 0 rs, got 1 rs 08/27/22 06:54:34.925
    STEP: expected 0 pods, got 2 pods 08/27/22 06:54:34.941
    STEP: Gathering metrics 08/27/22 06:54:35.456
    Aug 27 06:54:35.474: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
    Aug 27 06:54:35.476: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 2.85154ms
    Aug 27 06:54:35.477: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
    Aug 27 06:54:35.477: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
    Aug 27 06:54:35.546: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 06:54:35.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1057" for this suite. 08/27/22 06:54:35.552
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:35.559
Aug 27 06:54:35.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 06:54:35.56
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:35.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:35.593
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 08/27/22 06:54:35.602
Aug 27 06:54:35.621: INFO: Waiting up to 5m0s for pod "pod-vjqst" in namespace "pods-4140" to be "running"
Aug 27 06:54:35.627: INFO: Pod "pod-vjqst": Phase="Pending", Reason="", readiness=false. Elapsed: 5.990804ms
Aug 27 06:54:37.634: INFO: Pod "pod-vjqst": Phase="Running", Reason="", readiness=true. Elapsed: 2.012684616s
Aug 27 06:54:37.634: INFO: Pod "pod-vjqst" satisfied condition "running"
STEP: patching /status 08/27/22 06:54:37.638
Aug 27 06:54:37.645: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 06:54:37.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4140" for this suite. 08/27/22 06:54:37.653
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":315,"skipped":5841,"failed":0}
------------------------------
â€¢ [2.100 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:35.559
    Aug 27 06:54:35.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 06:54:35.56
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:35.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:35.593
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 08/27/22 06:54:35.602
    Aug 27 06:54:35.621: INFO: Waiting up to 5m0s for pod "pod-vjqst" in namespace "pods-4140" to be "running"
    Aug 27 06:54:35.627: INFO: Pod "pod-vjqst": Phase="Pending", Reason="", readiness=false. Elapsed: 5.990804ms
    Aug 27 06:54:37.634: INFO: Pod "pod-vjqst": Phase="Running", Reason="", readiness=true. Elapsed: 2.012684616s
    Aug 27 06:54:37.634: INFO: Pod "pod-vjqst" satisfied condition "running"
    STEP: patching /status 08/27/22 06:54:37.638
    Aug 27 06:54:37.645: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 06:54:37.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4140" for this suite. 08/27/22 06:54:37.653
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:37.659
Aug 27 06:54:37.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 06:54:37.66
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:37.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:37.682
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 08/27/22 06:54:37.688
STEP: watching for the Service to be added 08/27/22 06:54:37.695
Aug 27 06:54:37.699: INFO: Found Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Aug 27 06:54:37.700: INFO: Service test-service-dsqcz created
STEP: Getting /status 08/27/22 06:54:37.7
Aug 27 06:54:37.703: INFO: Service test-service-dsqcz has LoadBalancer: {[]}
STEP: patching the ServiceStatus 08/27/22 06:54:37.703
STEP: watching for the Service to be patched 08/27/22 06:54:37.708
Aug 27 06:54:37.713: INFO: observed Service test-service-dsqcz in namespace services-4781 with annotations: map[] & LoadBalancer: {[]}
Aug 27 06:54:37.713: INFO: Found Service test-service-dsqcz in namespace services-4781 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Aug 27 06:54:37.713: INFO: Service test-service-dsqcz has service status patched
STEP: updating the ServiceStatus 08/27/22 06:54:37.713
Aug 27 06:54:37.725: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 08/27/22 06:54:37.725
Aug 27 06:54:37.729: INFO: Observed Service test-service-dsqcz in namespace services-4781 with annotations: map[] & Conditions: {[]}
Aug 27 06:54:37.729: INFO: Observed event: &Service{ObjectMeta:{test-service-dsqcz  services-4781  ea27d037-70b2-41ca-be8f-e2c2c5babfdb 29092 0 2022-08-27 06:54:37 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-08-27 06:54:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-08-27 06:54:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.3.64.94,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.3.64.94],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Aug 27 06:54:37.730: INFO: Found Service test-service-dsqcz in namespace services-4781 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 27 06:54:37.730: INFO: Service test-service-dsqcz has service status updated
STEP: patching the service 08/27/22 06:54:37.73
STEP: watching for the Service to be patched 08/27/22 06:54:37.743
Aug 27 06:54:37.749: INFO: observed Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true]
Aug 27 06:54:37.749: INFO: observed Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true]
Aug 27 06:54:37.749: INFO: observed Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true]
Aug 27 06:54:37.749: INFO: Found Service test-service-dsqcz in namespace services-4781 with labels: map[test-service:patched test-service-static:true]
Aug 27 06:54:37.749: INFO: Service test-service-dsqcz patched
STEP: deleting the service 08/27/22 06:54:37.75
STEP: watching for the Service to be deleted 08/27/22 06:54:37.766
Aug 27 06:54:37.769: INFO: Observed event: ADDED
Aug 27 06:54:37.769: INFO: Observed event: MODIFIED
Aug 27 06:54:37.769: INFO: Observed event: MODIFIED
Aug 27 06:54:37.769: INFO: Observed event: MODIFIED
Aug 27 06:54:37.770: INFO: Found Service test-service-dsqcz in namespace services-4781 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Aug 27 06:54:37.770: INFO: Service test-service-dsqcz deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 06:54:37.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4781" for this suite. 08/27/22 06:54:37.774
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":316,"skipped":5861,"failed":0}
------------------------------
â€¢ [0.120 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:37.659
    Aug 27 06:54:37.659: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 06:54:37.66
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:37.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:37.682
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 08/27/22 06:54:37.688
    STEP: watching for the Service to be added 08/27/22 06:54:37.695
    Aug 27 06:54:37.699: INFO: Found Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Aug 27 06:54:37.700: INFO: Service test-service-dsqcz created
    STEP: Getting /status 08/27/22 06:54:37.7
    Aug 27 06:54:37.703: INFO: Service test-service-dsqcz has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 08/27/22 06:54:37.703
    STEP: watching for the Service to be patched 08/27/22 06:54:37.708
    Aug 27 06:54:37.713: INFO: observed Service test-service-dsqcz in namespace services-4781 with annotations: map[] & LoadBalancer: {[]}
    Aug 27 06:54:37.713: INFO: Found Service test-service-dsqcz in namespace services-4781 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Aug 27 06:54:37.713: INFO: Service test-service-dsqcz has service status patched
    STEP: updating the ServiceStatus 08/27/22 06:54:37.713
    Aug 27 06:54:37.725: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 08/27/22 06:54:37.725
    Aug 27 06:54:37.729: INFO: Observed Service test-service-dsqcz in namespace services-4781 with annotations: map[] & Conditions: {[]}
    Aug 27 06:54:37.729: INFO: Observed event: &Service{ObjectMeta:{test-service-dsqcz  services-4781  ea27d037-70b2-41ca-be8f-e2c2c5babfdb 29092 0 2022-08-27 06:54:37 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-08-27 06:54:37 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-08-27 06:54:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.3.64.94,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.3.64.94],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Aug 27 06:54:37.730: INFO: Found Service test-service-dsqcz in namespace services-4781 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 27 06:54:37.730: INFO: Service test-service-dsqcz has service status updated
    STEP: patching the service 08/27/22 06:54:37.73
    STEP: watching for the Service to be patched 08/27/22 06:54:37.743
    Aug 27 06:54:37.749: INFO: observed Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true]
    Aug 27 06:54:37.749: INFO: observed Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true]
    Aug 27 06:54:37.749: INFO: observed Service test-service-dsqcz in namespace services-4781 with labels: map[test-service-static:true]
    Aug 27 06:54:37.749: INFO: Found Service test-service-dsqcz in namespace services-4781 with labels: map[test-service:patched test-service-static:true]
    Aug 27 06:54:37.749: INFO: Service test-service-dsqcz patched
    STEP: deleting the service 08/27/22 06:54:37.75
    STEP: watching for the Service to be deleted 08/27/22 06:54:37.766
    Aug 27 06:54:37.769: INFO: Observed event: ADDED
    Aug 27 06:54:37.769: INFO: Observed event: MODIFIED
    Aug 27 06:54:37.769: INFO: Observed event: MODIFIED
    Aug 27 06:54:37.769: INFO: Observed event: MODIFIED
    Aug 27 06:54:37.770: INFO: Found Service test-service-dsqcz in namespace services-4781 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Aug 27 06:54:37.770: INFO: Service test-service-dsqcz deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 06:54:37.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4781" for this suite. 08/27/22 06:54:37.774
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:37.783
Aug 27 06:54:37.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename downward-api 08/27/22 06:54:37.785
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:37.813
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:37.817
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 08/27/22 06:54:37.82
Aug 27 06:54:37.827: INFO: Waiting up to 5m0s for pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583" in namespace "downward-api-4171" to be "Succeeded or Failed"
Aug 27 06:54:37.832: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583": Phase="Pending", Reason="", readiness=false. Elapsed: 4.358672ms
Aug 27 06:54:39.837: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583": Phase="Running", Reason="", readiness=false. Elapsed: 2.009378184s
Aug 27 06:54:41.834: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007110731s
STEP: Saw pod success 08/27/22 06:54:41.834
Aug 27 06:54:41.835: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583" satisfied condition "Succeeded or Failed"
Aug 27 06:54:41.837: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583 container dapi-container: <nil>
STEP: delete the pod 08/27/22 06:54:41.843
Aug 27 06:54:41.852: INFO: Waiting for pod downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583 to disappear
Aug 27 06:54:41.855: INFO: Pod downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Aug 27 06:54:41.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4171" for this suite. 08/27/22 06:54:41.863
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":317,"skipped":5868,"failed":0}
------------------------------
â€¢ [4.085 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:37.783
    Aug 27 06:54:37.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename downward-api 08/27/22 06:54:37.785
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:37.813
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:37.817
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 08/27/22 06:54:37.82
    Aug 27 06:54:37.827: INFO: Waiting up to 5m0s for pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583" in namespace "downward-api-4171" to be "Succeeded or Failed"
    Aug 27 06:54:37.832: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583": Phase="Pending", Reason="", readiness=false. Elapsed: 4.358672ms
    Aug 27 06:54:39.837: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583": Phase="Running", Reason="", readiness=false. Elapsed: 2.009378184s
    Aug 27 06:54:41.834: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007110731s
    STEP: Saw pod success 08/27/22 06:54:41.834
    Aug 27 06:54:41.835: INFO: Pod "downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583" satisfied condition "Succeeded or Failed"
    Aug 27 06:54:41.837: INFO: Trying to get logs from node ip-10-0-47-192 pod downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 06:54:41.843
    Aug 27 06:54:41.852: INFO: Waiting for pod downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583 to disappear
    Aug 27 06:54:41.855: INFO: Pod downward-api-e89cb170-2e97-4d87-80cd-d4b43177f583 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Aug 27 06:54:41.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4171" for this suite. 08/27/22 06:54:41.863
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:54:41.871
Aug 27 06:54:41.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:54:41.872
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:41.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:41.889
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e in namespace container-probe-1626 08/27/22 06:54:41.891
Aug 27 06:54:41.896: INFO: Waiting up to 5m0s for pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e" in namespace "container-probe-1626" to be "not pending"
Aug 27 06:54:41.899: INFO: Pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646697ms
Aug 27 06:54:43.905: INFO: Pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008020559s
Aug 27 06:54:43.905: INFO: Pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e" satisfied condition "not pending"
Aug 27 06:54:43.905: INFO: Started pod liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e in namespace container-probe-1626
STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:54:43.905
Aug 27 06:54:43.908: INFO: Initial restart count of pod liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e is 0
STEP: deleting the pod 08/27/22 06:58:44.47
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 06:58:44.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1626" for this suite. 08/27/22 06:58:44.497
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":318,"skipped":5888,"failed":0}
------------------------------
â€¢ [SLOW TEST] [242.633 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:54:41.871
    Aug 27 06:54:41.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:54:41.872
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:54:41.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:54:41.889
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e in namespace container-probe-1626 08/27/22 06:54:41.891
    Aug 27 06:54:41.896: INFO: Waiting up to 5m0s for pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e" in namespace "container-probe-1626" to be "not pending"
    Aug 27 06:54:41.899: INFO: Pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.646697ms
    Aug 27 06:54:43.905: INFO: Pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008020559s
    Aug 27 06:54:43.905: INFO: Pod "liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e" satisfied condition "not pending"
    Aug 27 06:54:43.905: INFO: Started pod liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e in namespace container-probe-1626
    STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:54:43.905
    Aug 27 06:54:43.908: INFO: Initial restart count of pod liveness-c1bde4f8-0e27-4df6-8938-34490cf74e3e is 0
    STEP: deleting the pod 08/27/22 06:58:44.47
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 06:58:44.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1626" for this suite. 08/27/22 06:58:44.497
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:58:44.511
Aug 27 06:58:44.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 06:58:44.514
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:58:44.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:58:44.547
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 06:58:44.565
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:58:45.213
STEP: Deploying the webhook pod 08/27/22 06:58:45.221
STEP: Wait for the deployment to be ready 08/27/22 06:58:45.23
Aug 27 06:58:45.238: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 06:58:47.249
STEP: Verifying the service has paired with the endpoint 08/27/22 06:58:47.257
Aug 27 06:58:48.258: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 08/27/22 06:58:48.31
STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:58:48.356
STEP: Deleting the collection of validation webhooks 08/27/22 06:58:48.399
STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:58:48.433
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 06:58:48.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1295" for this suite. 08/27/22 06:58:48.446
STEP: Destroying namespace "webhook-1295-markers" for this suite. 08/27/22 06:58:48.45
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":319,"skipped":5891,"failed":0}
------------------------------
â€¢ [4.001 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:58:44.511
    Aug 27 06:58:44.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 06:58:44.514
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:58:44.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:58:44.547
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 06:58:44.565
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 06:58:45.213
    STEP: Deploying the webhook pod 08/27/22 06:58:45.221
    STEP: Wait for the deployment to be ready 08/27/22 06:58:45.23
    Aug 27 06:58:45.238: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 06:58:47.249
    STEP: Verifying the service has paired with the endpoint 08/27/22 06:58:47.257
    Aug 27 06:58:48.258: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 08/27/22 06:58:48.31
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:58:48.356
    STEP: Deleting the collection of validation webhooks 08/27/22 06:58:48.399
    STEP: Creating a configMap that does not comply to the validation webhook rules 08/27/22 06:58:48.433
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 06:58:48.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1295" for this suite. 08/27/22 06:58:48.446
    STEP: Destroying namespace "webhook-1295-markers" for this suite. 08/27/22 06:58:48.45
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 06:58:48.512
Aug 27 06:58:48.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-probe 08/27/22 06:58:48.513
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:58:48.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:58:48.551
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 in namespace container-probe-7406 08/27/22 06:58:48.555
Aug 27 06:58:48.562: INFO: Waiting up to 5m0s for pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402" in namespace "container-probe-7406" to be "not pending"
Aug 27 06:58:48.567: INFO: Pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.441435ms
Aug 27 06:58:50.573: INFO: Pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402": Phase="Running", Reason="", readiness=true. Elapsed: 2.010567034s
Aug 27 06:58:50.573: INFO: Pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402" satisfied condition "not pending"
Aug 27 06:58:50.573: INFO: Started pod liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 in namespace container-probe-7406
STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:58:50.574
Aug 27 06:58:50.577: INFO: Initial restart count of pod liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is 0
Aug 27 06:59:10.621: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 1 (20.044181258s elapsed)
Aug 27 06:59:30.665: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 2 (40.088661889s elapsed)
Aug 27 06:59:50.714: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 3 (1m0.13763955s elapsed)
Aug 27 07:00:10.779: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 4 (1m20.201980799s elapsed)
Aug 27 07:01:15.013: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 5 (2m24.436339348s elapsed)
STEP: deleting the pod 08/27/22 07:01:15.013
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Aug 27 07:01:15.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7406" for this suite. 08/27/22 07:01:15.11
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":320,"skipped":5894,"failed":0}
------------------------------
â€¢ [SLOW TEST] [146.618 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 06:58:48.512
    Aug 27 06:58:48.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-probe 08/27/22 06:58:48.513
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 06:58:48.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 06:58:48.551
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 in namespace container-probe-7406 08/27/22 06:58:48.555
    Aug 27 06:58:48.562: INFO: Waiting up to 5m0s for pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402" in namespace "container-probe-7406" to be "not pending"
    Aug 27 06:58:48.567: INFO: Pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.441435ms
    Aug 27 06:58:50.573: INFO: Pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402": Phase="Running", Reason="", readiness=true. Elapsed: 2.010567034s
    Aug 27 06:58:50.573: INFO: Pod "liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402" satisfied condition "not pending"
    Aug 27 06:58:50.573: INFO: Started pod liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 in namespace container-probe-7406
    STEP: checking the pod's current state and verifying that restartCount is present 08/27/22 06:58:50.574
    Aug 27 06:58:50.577: INFO: Initial restart count of pod liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is 0
    Aug 27 06:59:10.621: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 1 (20.044181258s elapsed)
    Aug 27 06:59:30.665: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 2 (40.088661889s elapsed)
    Aug 27 06:59:50.714: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 3 (1m0.13763955s elapsed)
    Aug 27 07:00:10.779: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 4 (1m20.201980799s elapsed)
    Aug 27 07:01:15.013: INFO: Restart count of pod container-probe-7406/liveness-1a31e6e6-ef32-4fca-8df3-1b2139278402 is now 5 (2m24.436339348s elapsed)
    STEP: deleting the pod 08/27/22 07:01:15.013
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Aug 27 07:01:15.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7406" for this suite. 08/27/22 07:01:15.11
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:01:15.133
Aug 27 07:01:15.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 07:01:15.134
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:15.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:15.317
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Aug 27 07:01:15.392: INFO: Waiting up to 2m0s for pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" in namespace "var-expansion-2125" to be "container 0 failed with reason CreateContainerConfigError"
Aug 27 07:01:15.491: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db": Phase="Pending", Reason="", readiness=false. Elapsed: 98.390505ms
Aug 27 07:01:17.494: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101192057s
Aug 27 07:01:19.495: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102488417s
Aug 27 07:01:19.495: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Aug 27 07:01:19.495: INFO: Deleting pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" in namespace "var-expansion-2125"
Aug 27 07:01:19.504: INFO: Wait up to 5m0s for pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 07:01:23.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2125" for this suite. 08/27/22 07:01:23.519
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":321,"skipped":5908,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.390 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:01:15.133
    Aug 27 07:01:15.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 07:01:15.134
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:15.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:15.317
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Aug 27 07:01:15.392: INFO: Waiting up to 2m0s for pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" in namespace "var-expansion-2125" to be "container 0 failed with reason CreateContainerConfigError"
    Aug 27 07:01:15.491: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db": Phase="Pending", Reason="", readiness=false. Elapsed: 98.390505ms
    Aug 27 07:01:17.494: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101192057s
    Aug 27 07:01:19.495: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102488417s
    Aug 27 07:01:19.495: INFO: Pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Aug 27 07:01:19.495: INFO: Deleting pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" in namespace "var-expansion-2125"
    Aug 27 07:01:19.504: INFO: Wait up to 5m0s for pod "var-expansion-d08ddb0f-2709-4ce2-ba79-74a8360b28db" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 07:01:23.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2125" for this suite. 08/27/22 07:01:23.519
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:01:23.524
Aug 27 07:01:23.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replicaset 08/27/22 07:01:23.525
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:23.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:23.549
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 08/27/22 07:01:23.553
STEP: Verify that the required pods have come up 08/27/22 07:01:23.565
Aug 27 07:01:23.573: INFO: Pod name sample-pod: Found 0 pods out of 3
Aug 27 07:01:28.584: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 08/27/22 07:01:28.584
Aug 27 07:01:28.595: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 08/27/22 07:01:28.595
STEP: DeleteCollection of the ReplicaSets 08/27/22 07:01:28.602
STEP: After DeleteCollection verify that ReplicaSets have been deleted 08/27/22 07:01:28.62
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 27 07:01:28.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7583" for this suite. 08/27/22 07:01:28.648
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":322,"skipped":5911,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.174 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:01:23.524
    Aug 27 07:01:23.524: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replicaset 08/27/22 07:01:23.525
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:23.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:23.549
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 08/27/22 07:01:23.553
    STEP: Verify that the required pods have come up 08/27/22 07:01:23.565
    Aug 27 07:01:23.573: INFO: Pod name sample-pod: Found 0 pods out of 3
    Aug 27 07:01:28.584: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 08/27/22 07:01:28.584
    Aug 27 07:01:28.595: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 08/27/22 07:01:28.595
    STEP: DeleteCollection of the ReplicaSets 08/27/22 07:01:28.602
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 08/27/22 07:01:28.62
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 27 07:01:28.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7583" for this suite. 08/27/22 07:01:28.648
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:01:28.719
Aug 27 07:01:28.721: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 07:01:28.729
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:28.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:28.879
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 08/27/22 07:01:28.912
Aug 27 07:01:28.928: INFO: Waiting up to 5m0s for pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82" in namespace "emptydir-7918" to be "Succeeded or Failed"
Aug 27 07:01:28.939: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Pending", Reason="", readiness=false. Elapsed: 10.645414ms
Aug 27 07:01:30.953: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Running", Reason="", readiness=true. Elapsed: 2.024045219s
Aug 27 07:01:32.945: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Running", Reason="", readiness=false. Elapsed: 4.016525712s
Aug 27 07:01:34.943: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014038804s
STEP: Saw pod success 08/27/22 07:01:34.943
Aug 27 07:01:34.943: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82" satisfied condition "Succeeded or Failed"
Aug 27 07:01:34.946: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82 container test-container: <nil>
STEP: delete the pod 08/27/22 07:01:34.964
Aug 27 07:01:34.974: INFO: Waiting for pod pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82 to disappear
Aug 27 07:01:34.977: INFO: Pod pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 07:01:34.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7918" for this suite. 08/27/22 07:01:34.98
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":323,"skipped":5971,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.266 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:01:28.719
    Aug 27 07:01:28.721: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 07:01:28.729
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:28.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:28.879
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 08/27/22 07:01:28.912
    Aug 27 07:01:28.928: INFO: Waiting up to 5m0s for pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82" in namespace "emptydir-7918" to be "Succeeded or Failed"
    Aug 27 07:01:28.939: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Pending", Reason="", readiness=false. Elapsed: 10.645414ms
    Aug 27 07:01:30.953: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Running", Reason="", readiness=true. Elapsed: 2.024045219s
    Aug 27 07:01:32.945: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Running", Reason="", readiness=false. Elapsed: 4.016525712s
    Aug 27 07:01:34.943: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014038804s
    STEP: Saw pod success 08/27/22 07:01:34.943
    Aug 27 07:01:34.943: INFO: Pod "pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82" satisfied condition "Succeeded or Failed"
    Aug 27 07:01:34.946: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82 container test-container: <nil>
    STEP: delete the pod 08/27/22 07:01:34.964
    Aug 27 07:01:34.974: INFO: Waiting for pod pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82 to disappear
    Aug 27 07:01:34.977: INFO: Pod pod-f34ba4ba-46af-47ba-a8ab-49528fa82c82 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 07:01:34.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7918" for this suite. 08/27/22 07:01:34.98
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:01:34.985
Aug 27 07:01:34.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename pods 08/27/22 07:01:34.986
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:35.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:35.01
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 08/27/22 07:01:35.014
Aug 27 07:01:35.021: INFO: created test-pod-1
Aug 27 07:01:35.027: INFO: created test-pod-2
Aug 27 07:01:35.037: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 08/27/22 07:01:35.037
Aug 27 07:01:35.038: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-635' to be running and ready
Aug 27 07:01:35.068: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 27 07:01:35.068: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 27 07:01:35.068: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 27 07:01:35.068: INFO: 0 / 3 pods in namespace 'pods-635' are running and ready (0 seconds elapsed)
Aug 27 07:01:35.068: INFO: expected 0 pod replicas in namespace 'pods-635', 0 are Running and Ready.
Aug 27 07:01:35.068: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Aug 27 07:01:35.068: INFO: test-pod-1  ip-10-0-47-192  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
Aug 27 07:01:35.068: INFO: test-pod-2  ip-10-0-31-158  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
Aug 27 07:01:35.068: INFO: test-pod-3  ip-10-0-47-192  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
Aug 27 07:01:35.068: INFO: 
Aug 27 07:01:37.103: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 27 07:01:37.103: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 27 07:01:37.103: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 27 07:01:37.103: INFO: 0 / 3 pods in namespace 'pods-635' are running and ready (2 seconds elapsed)
Aug 27 07:01:37.103: INFO: expected 0 pod replicas in namespace 'pods-635', 0 are Running and Ready.
Aug 27 07:01:37.103: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Aug 27 07:01:37.103: INFO: test-pod-1  ip-10-0-47-192  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
Aug 27 07:01:37.103: INFO: test-pod-2  ip-10-0-31-158  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
Aug 27 07:01:37.103: INFO: test-pod-3  ip-10-0-47-192  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
Aug 27 07:01:37.103: INFO: 
Aug 27 07:01:39.079: INFO: 3 / 3 pods in namespace 'pods-635' are running and ready (4 seconds elapsed)
Aug 27 07:01:39.079: INFO: expected 0 pod replicas in namespace 'pods-635', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 08/27/22 07:01:39.092
Aug 27 07:01:39.096: INFO: Pod quantity 3 is different from expected quantity 0
Aug 27 07:01:40.102: INFO: Pod quantity 3 is different from expected quantity 0
Aug 27 07:01:41.102: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Aug 27 07:01:42.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-635" for this suite. 08/27/22 07:01:42.114
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":324,"skipped":5976,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.134 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:01:34.985
    Aug 27 07:01:34.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename pods 08/27/22 07:01:34.986
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:35.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:35.01
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 08/27/22 07:01:35.014
    Aug 27 07:01:35.021: INFO: created test-pod-1
    Aug 27 07:01:35.027: INFO: created test-pod-2
    Aug 27 07:01:35.037: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 08/27/22 07:01:35.037
    Aug 27 07:01:35.038: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-635' to be running and ready
    Aug 27 07:01:35.068: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 27 07:01:35.068: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 27 07:01:35.068: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 27 07:01:35.068: INFO: 0 / 3 pods in namespace 'pods-635' are running and ready (0 seconds elapsed)
    Aug 27 07:01:35.068: INFO: expected 0 pod replicas in namespace 'pods-635', 0 are Running and Ready.
    Aug 27 07:01:35.068: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
    Aug 27 07:01:35.068: INFO: test-pod-1  ip-10-0-47-192  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
    Aug 27 07:01:35.068: INFO: test-pod-2  ip-10-0-31-158  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
    Aug 27 07:01:35.068: INFO: test-pod-3  ip-10-0-47-192  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
    Aug 27 07:01:35.068: INFO: 
    Aug 27 07:01:37.103: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 27 07:01:37.103: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 27 07:01:37.103: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Aug 27 07:01:37.103: INFO: 0 / 3 pods in namespace 'pods-635' are running and ready (2 seconds elapsed)
    Aug 27 07:01:37.103: INFO: expected 0 pod replicas in namespace 'pods-635', 0 are Running and Ready.
    Aug 27 07:01:37.103: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
    Aug 27 07:01:37.103: INFO: test-pod-1  ip-10-0-47-192  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
    Aug 27 07:01:37.103: INFO: test-pod-2  ip-10-0-31-158  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
    Aug 27 07:01:37.103: INFO: test-pod-3  ip-10-0-47-192  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-27 07:01:35 +0000 UTC  }]
    Aug 27 07:01:37.103: INFO: 
    Aug 27 07:01:39.079: INFO: 3 / 3 pods in namespace 'pods-635' are running and ready (4 seconds elapsed)
    Aug 27 07:01:39.079: INFO: expected 0 pod replicas in namespace 'pods-635', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 08/27/22 07:01:39.092
    Aug 27 07:01:39.096: INFO: Pod quantity 3 is different from expected quantity 0
    Aug 27 07:01:40.102: INFO: Pod quantity 3 is different from expected quantity 0
    Aug 27 07:01:41.102: INFO: Pod quantity 2 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Aug 27 07:01:42.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-635" for this suite. 08/27/22 07:01:42.114
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:01:42.129
Aug 27 07:01:42.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replicaset 08/27/22 07:01:42.13
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:42.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:42.185
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 08/27/22 07:01:42.191
STEP: Verify that the required pods have come up. 08/27/22 07:01:42.199
Aug 27 07:01:42.207: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 27 07:01:47.223: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 08/27/22 07:01:47.223
STEP: Getting /status 08/27/22 07:01:47.223
Aug 27 07:01:47.233: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 08/27/22 07:01:47.233
Aug 27 07:01:47.248: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 08/27/22 07:01:47.248
Aug 27 07:01:47.252: INFO: Observed &ReplicaSet event: ADDED
Aug 27 07:01:47.252: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.253: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.253: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.253: INFO: Found replicaset test-rs in namespace replicaset-5765 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 27 07:01:47.253: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 08/27/22 07:01:47.253
Aug 27 07:01:47.253: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 27 07:01:47.261: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 08/27/22 07:01:47.261
Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: ADDED
Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.266: INFO: Observed replicaset test-rs in namespace replicaset-5765 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
Aug 27 07:01:47.266: INFO: Found replicaset test-rs in namespace replicaset-5765 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Aug 27 07:01:47.266: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Aug 27 07:01:47.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5765" for this suite. 08/27/22 07:01:47.27
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":325,"skipped":6044,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.148 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:01:42.129
    Aug 27 07:01:42.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replicaset 08/27/22 07:01:42.13
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:42.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:42.185
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 08/27/22 07:01:42.191
    STEP: Verify that the required pods have come up. 08/27/22 07:01:42.199
    Aug 27 07:01:42.207: INFO: Pod name sample-pod: Found 0 pods out of 1
    Aug 27 07:01:47.223: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 08/27/22 07:01:47.223
    STEP: Getting /status 08/27/22 07:01:47.223
    Aug 27 07:01:47.233: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 08/27/22 07:01:47.233
    Aug 27 07:01:47.248: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 08/27/22 07:01:47.248
    Aug 27 07:01:47.252: INFO: Observed &ReplicaSet event: ADDED
    Aug 27 07:01:47.252: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.253: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.253: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.253: INFO: Found replicaset test-rs in namespace replicaset-5765 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Aug 27 07:01:47.253: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 08/27/22 07:01:47.253
    Aug 27 07:01:47.253: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 27 07:01:47.261: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 08/27/22 07:01:47.261
    Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: ADDED
    Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.266: INFO: Observed replicaset test-rs in namespace replicaset-5765 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 27 07:01:47.266: INFO: Observed &ReplicaSet event: MODIFIED
    Aug 27 07:01:47.266: INFO: Found replicaset test-rs in namespace replicaset-5765 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Aug 27 07:01:47.266: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Aug 27 07:01:47.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5765" for this suite. 08/27/22 07:01:47.27
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:01:47.278
Aug 27 07:01:47.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename taint-multiple-pods 08/27/22 07:01:47.279
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:47.309
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:47.315
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Aug 27 07:01:47.319: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 27 07:02:47.338: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Aug 27 07:02:47.341: INFO: Starting informer...
STEP: Starting pods... 08/27/22 07:02:47.341
Aug 27 07:02:47.565: INFO: Pod1 is running on ip-10-0-47-192. Tainting Node
Aug 27 07:02:47.789: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8149" to be "running"
Aug 27 07:02:47.793: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291741ms
Aug 27 07:02:49.798: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008896437s
Aug 27 07:02:49.798: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Aug 27 07:02:49.798: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8149" to be "running"
Aug 27 07:02:49.803: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.62479ms
Aug 27 07:02:49.803: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Aug 27 07:02:49.803: INFO: Pod2 is running on ip-10-0-47-192. Tainting Node
STEP: Trying to apply a taint on the Node 08/27/22 07:02:49.803
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 07:02:49.814
STEP: Waiting for Pod1 and Pod2 to be deleted 08/27/22 07:02:49.83
Aug 27 07:02:55.771: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Aug 27 07:03:15.813: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 07:03:15.827
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Aug 27 07:03:15.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8149" for this suite. 08/27/22 07:03:15.846
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":326,"skipped":6047,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.606 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:01:47.278
    Aug 27 07:01:47.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename taint-multiple-pods 08/27/22 07:01:47.279
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:01:47.309
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:01:47.315
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Aug 27 07:01:47.319: INFO: Waiting up to 1m0s for all nodes to be ready
    Aug 27 07:02:47.338: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Aug 27 07:02:47.341: INFO: Starting informer...
    STEP: Starting pods... 08/27/22 07:02:47.341
    Aug 27 07:02:47.565: INFO: Pod1 is running on ip-10-0-47-192. Tainting Node
    Aug 27 07:02:47.789: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8149" to be "running"
    Aug 27 07:02:47.793: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291741ms
    Aug 27 07:02:49.798: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008896437s
    Aug 27 07:02:49.798: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Aug 27 07:02:49.798: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8149" to be "running"
    Aug 27 07:02:49.803: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.62479ms
    Aug 27 07:02:49.803: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Aug 27 07:02:49.803: INFO: Pod2 is running on ip-10-0-47-192. Tainting Node
    STEP: Trying to apply a taint on the Node 08/27/22 07:02:49.803
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 07:02:49.814
    STEP: Waiting for Pod1 and Pod2 to be deleted 08/27/22 07:02:49.83
    Aug 27 07:02:55.771: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Aug 27 07:03:15.813: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 08/27/22 07:03:15.827
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 07:03:15.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-8149" for this suite. 08/27/22 07:03:15.846
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:15.886
Aug 27 07:03:15.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename events 08/27/22 07:03:15.887
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:15.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:16.002
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 08/27/22 07:03:16.037
STEP: listing events in all namespaces 08/27/22 07:03:16.045
STEP: listing events in test namespace 08/27/22 07:03:16.048
STEP: listing events with field selection filtering on source 08/27/22 07:03:16.055
STEP: listing events with field selection filtering on reportingController 08/27/22 07:03:16.058
STEP: getting the test event 08/27/22 07:03:16.061
STEP: patching the test event 08/27/22 07:03:16.064
STEP: getting the test event 08/27/22 07:03:16.075
STEP: updating the test event 08/27/22 07:03:16.079
STEP: getting the test event 08/27/22 07:03:16.084
STEP: deleting the test event 08/27/22 07:03:16.088
STEP: listing events in all namespaces 08/27/22 07:03:16.093
STEP: listing events in test namespace 08/27/22 07:03:16.096
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Aug 27 07:03:16.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3974" for this suite. 08/27/22 07:03:16.102
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":327,"skipped":6068,"failed":0}
------------------------------
â€¢ [0.221 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:15.886
    Aug 27 07:03:15.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename events 08/27/22 07:03:15.887
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:15.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:16.002
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 08/27/22 07:03:16.037
    STEP: listing events in all namespaces 08/27/22 07:03:16.045
    STEP: listing events in test namespace 08/27/22 07:03:16.048
    STEP: listing events with field selection filtering on source 08/27/22 07:03:16.055
    STEP: listing events with field selection filtering on reportingController 08/27/22 07:03:16.058
    STEP: getting the test event 08/27/22 07:03:16.061
    STEP: patching the test event 08/27/22 07:03:16.064
    STEP: getting the test event 08/27/22 07:03:16.075
    STEP: updating the test event 08/27/22 07:03:16.079
    STEP: getting the test event 08/27/22 07:03:16.084
    STEP: deleting the test event 08/27/22 07:03:16.088
    STEP: listing events in all namespaces 08/27/22 07:03:16.093
    STEP: listing events in test namespace 08/27/22 07:03:16.096
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Aug 27 07:03:16.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-3974" for this suite. 08/27/22 07:03:16.102
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:16.11
Aug 27 07:03:16.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 07:03:16.117
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:16.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:16.148
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 08/27/22 07:03:16.152
Aug 27 07:03:16.159: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68" in namespace "projected-6045" to be "Succeeded or Failed"
Aug 27 07:03:16.162: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.267195ms
Aug 27 07:03:18.168: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008760457s
Aug 27 07:03:20.166: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007449023s
STEP: Saw pod success 08/27/22 07:03:20.166
Aug 27 07:03:20.166: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68" satisfied condition "Succeeded or Failed"
Aug 27 07:03:20.169: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68 container client-container: <nil>
STEP: delete the pod 08/27/22 07:03:20.183
Aug 27 07:03:20.194: INFO: Waiting for pod downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68 to disappear
Aug 27 07:03:20.198: INFO: Pod downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 07:03:20.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6045" for this suite. 08/27/22 07:03:20.201
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":328,"skipped":6086,"failed":0}
------------------------------
â€¢ [4.096 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:16.11
    Aug 27 07:03:16.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 07:03:16.117
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:16.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:16.148
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 08/27/22 07:03:16.152
    Aug 27 07:03:16.159: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68" in namespace "projected-6045" to be "Succeeded or Failed"
    Aug 27 07:03:16.162: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.267195ms
    Aug 27 07:03:18.168: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008760457s
    Aug 27 07:03:20.166: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007449023s
    STEP: Saw pod success 08/27/22 07:03:20.166
    Aug 27 07:03:20.166: INFO: Pod "downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68" satisfied condition "Succeeded or Failed"
    Aug 27 07:03:20.169: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68 container client-container: <nil>
    STEP: delete the pod 08/27/22 07:03:20.183
    Aug 27 07:03:20.194: INFO: Waiting for pod downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68 to disappear
    Aug 27 07:03:20.198: INFO: Pod downwardapi-volume-93e48299-893f-4b92-bb95-39074ca0bc68 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 07:03:20.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6045" for this suite. 08/27/22 07:03:20.201
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:20.207
Aug 27 07:03:20.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 07:03:20.208
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:20.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:20.252
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-1232 08/27/22 07:03:20.255
STEP: creating service affinity-clusterip in namespace services-1232 08/27/22 07:03:20.255
STEP: creating replication controller affinity-clusterip in namespace services-1232 08/27/22 07:03:20.265
I0827 07:03:20.276523      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1232, replica count: 3
I0827 07:03:23.328026      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 07:03:23.334: INFO: Creating new exec pod
Aug 27 07:03:23.338: INFO: Waiting up to 5m0s for pod "execpod-affinitympcbg" in namespace "services-1232" to be "running"
Aug 27 07:03:23.342: INFO: Pod "execpod-affinitympcbg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03972ms
Aug 27 07:03:25.346: INFO: Pod "execpod-affinitympcbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.008118207s
Aug 27 07:03:25.346: INFO: Pod "execpod-affinitympcbg" satisfied condition "running"
Aug 27 07:03:26.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1232 exec execpod-affinitympcbg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Aug 27 07:03:26.544: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Aug 27 07:03:26.544: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 07:03:26.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1232 exec execpod-affinitympcbg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.44.235 80'
Aug 27 07:03:26.743: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.44.235 80\nConnection to 10.3.44.235 80 port [tcp/http] succeeded!\n"
Aug 27 07:03:26.743: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 07:03:26.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1232 exec execpod-affinitympcbg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.44.235:80/ ; done'
Aug 27 07:03:26.952: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n"
Aug 27 07:03:26.952: INFO: stdout: "\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96"
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
Aug 27 07:03:26.952: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-1232, will wait for the garbage collector to delete the pods 08/27/22 07:03:26.967
Aug 27 07:03:27.034: INFO: Deleting ReplicationController affinity-clusterip took: 8.030981ms
Aug 27 07:03:27.140: INFO: Terminating ReplicationController affinity-clusterip pods took: 106.005303ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 07:03:29.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1232" for this suite. 08/27/22 07:03:29.595
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":329,"skipped":6095,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.394 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:20.207
    Aug 27 07:03:20.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 07:03:20.208
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:20.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:20.252
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-1232 08/27/22 07:03:20.255
    STEP: creating service affinity-clusterip in namespace services-1232 08/27/22 07:03:20.255
    STEP: creating replication controller affinity-clusterip in namespace services-1232 08/27/22 07:03:20.265
    I0827 07:03:20.276523      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-1232, replica count: 3
    I0827 07:03:23.328026      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 07:03:23.334: INFO: Creating new exec pod
    Aug 27 07:03:23.338: INFO: Waiting up to 5m0s for pod "execpod-affinitympcbg" in namespace "services-1232" to be "running"
    Aug 27 07:03:23.342: INFO: Pod "execpod-affinitympcbg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03972ms
    Aug 27 07:03:25.346: INFO: Pod "execpod-affinitympcbg": Phase="Running", Reason="", readiness=true. Elapsed: 2.008118207s
    Aug 27 07:03:25.346: INFO: Pod "execpod-affinitympcbg" satisfied condition "running"
    Aug 27 07:03:26.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1232 exec execpod-affinitympcbg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Aug 27 07:03:26.544: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Aug 27 07:03:26.544: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 07:03:26.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1232 exec execpod-affinitympcbg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.44.235 80'
    Aug 27 07:03:26.743: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.44.235 80\nConnection to 10.3.44.235 80 port [tcp/http] succeeded!\n"
    Aug 27 07:03:26.743: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 07:03:26.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-1232 exec execpod-affinitympcbg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.3.44.235:80/ ; done'
    Aug 27 07:03:26.952: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.3.44.235:80/\n"
    Aug 27 07:03:26.952: INFO: stdout: "\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96\naffinity-clusterip-mxv96"
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Received response from host: affinity-clusterip-mxv96
    Aug 27 07:03:26.952: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-1232, will wait for the garbage collector to delete the pods 08/27/22 07:03:26.967
    Aug 27 07:03:27.034: INFO: Deleting ReplicationController affinity-clusterip took: 8.030981ms
    Aug 27 07:03:27.140: INFO: Terminating ReplicationController affinity-clusterip pods took: 106.005303ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 07:03:29.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1232" for this suite. 08/27/22 07:03:29.595
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:29.607
Aug 27 07:03:29.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 07:03:29.609
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:29.65
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:29.659
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 07:03:29.71
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 07:03:30.676
STEP: Deploying the webhook pod 08/27/22 07:03:30.68
STEP: Wait for the deployment to be ready 08/27/22 07:03:30.687
Aug 27 07:03:30.694: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 08/27/22 07:03:32.718
STEP: Verifying the service has paired with the endpoint 08/27/22 07:03:32.775
Aug 27 07:03:33.775: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/27/22 07:03:33.78
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/27/22 07:03:33.796
STEP: Creating a dummy validating-webhook-configuration object 08/27/22 07:03:33.822
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 08/27/22 07:03:33.833
STEP: Creating a dummy mutating-webhook-configuration object 08/27/22 07:03:33.838
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 08/27/22 07:03:33.848
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 07:03:33.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3656" for this suite. 08/27/22 07:03:33.871
STEP: Destroying namespace "webhook-3656-markers" for this suite. 08/27/22 07:03:33.88
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":330,"skipped":6122,"failed":0}
------------------------------
â€¢ [4.334 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:29.607
    Aug 27 07:03:29.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 07:03:29.609
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:29.65
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:29.659
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 07:03:29.71
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 07:03:30.676
    STEP: Deploying the webhook pod 08/27/22 07:03:30.68
    STEP: Wait for the deployment to be ready 08/27/22 07:03:30.687
    Aug 27 07:03:30.694: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 08/27/22 07:03:32.718
    STEP: Verifying the service has paired with the endpoint 08/27/22 07:03:32.775
    Aug 27 07:03:33.775: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/27/22 07:03:33.78
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 08/27/22 07:03:33.796
    STEP: Creating a dummy validating-webhook-configuration object 08/27/22 07:03:33.822
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 08/27/22 07:03:33.833
    STEP: Creating a dummy mutating-webhook-configuration object 08/27/22 07:03:33.838
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 08/27/22 07:03:33.848
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 07:03:33.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3656" for this suite. 08/27/22 07:03:33.871
    STEP: Destroying namespace "webhook-3656-markers" for this suite. 08/27/22 07:03:33.88
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:33.962
Aug 27 07:03:33.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename replication-controller 08/27/22 07:03:33.972
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:33.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:34.013
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7 08/27/22 07:03:34.028
Aug 27 07:03:34.057: INFO: Pod name my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7: Found 0 pods out of 1
Aug 27 07:03:39.064: INFO: Pod name my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7: Found 1 pods out of 1
Aug 27 07:03:39.064: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7" are running
Aug 27 07:03:39.064: INFO: Waiting up to 5m0s for pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg" in namespace "replication-controller-9868" to be "running"
Aug 27 07:03:39.069: INFO: Pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg": Phase="Running", Reason="", readiness=true. Elapsed: 4.90298ms
Aug 27 07:03:39.069: INFO: Pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg" satisfied condition "running"
Aug 27 07:03:39.069: INFO: Pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:34 +0000 UTC Reason: Message:}])
Aug 27 07:03:39.069: INFO: Trying to dial the pod
Aug 27 07:03:44.084: INFO: Controller my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7: Got expected result from replica 1 [my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg]: "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Aug 27 07:03:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9868" for this suite. 08/27/22 07:03:44.088
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":331,"skipped":6139,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.143 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:33.962
    Aug 27 07:03:33.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename replication-controller 08/27/22 07:03:33.972
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:33.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:34.013
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7 08/27/22 07:03:34.028
    Aug 27 07:03:34.057: INFO: Pod name my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7: Found 0 pods out of 1
    Aug 27 07:03:39.064: INFO: Pod name my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7: Found 1 pods out of 1
    Aug 27 07:03:39.064: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7" are running
    Aug 27 07:03:39.064: INFO: Waiting up to 5m0s for pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg" in namespace "replication-controller-9868" to be "running"
    Aug 27 07:03:39.069: INFO: Pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg": Phase="Running", Reason="", readiness=true. Elapsed: 4.90298ms
    Aug 27 07:03:39.069: INFO: Pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg" satisfied condition "running"
    Aug 27 07:03:39.069: INFO: Pod "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-27 07:03:34 +0000 UTC Reason: Message:}])
    Aug 27 07:03:39.069: INFO: Trying to dial the pod
    Aug 27 07:03:44.084: INFO: Controller my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7: Got expected result from replica 1 [my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg]: "my-hostname-basic-643f01c5-3d82-4bc6-8225-54bb6cb37aa7-xw9jg", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Aug 27 07:03:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-9868" for this suite. 08/27/22 07:03:44.088
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:44.107
Aug 27 07:03:44.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 07:03:44.108
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:44.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:44.129
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 08/27/22 07:03:44.136
Aug 27 07:03:44.136: INFO: Creating simple deployment test-deployment-qz2b2
Aug 27 07:03:44.147: INFO: new replicaset for deployment "test-deployment-qz2b2" is yet to be created
STEP: Getting /status 08/27/22 07:03:46.161
Aug 27 07:03:46.166: INFO: Deployment test-deployment-qz2b2 has Conditions: [{Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 08/27/22 07:03:46.166
Aug 27 07:03:46.179: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 7, 3, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 3, 45, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 7, 3, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 3, 44, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-qz2b2-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 08/27/22 07:03:46.179
Aug 27 07:03:46.182: INFO: Observed &Deployment event: ADDED
Aug 27 07:03:46.182: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
Aug 27 07:03:46.182: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.182: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
Aug 27 07:03:46.182: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 27 07:03:46.183: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-qz2b2-777898ffcc" is progressing.}
Aug 27 07:03:46.183: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
Aug 27 07:03:46.183: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
Aug 27 07:03:46.183: INFO: Found Deployment test-deployment-qz2b2 in namespace deployment-3391 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 27 07:03:46.183: INFO: Deployment test-deployment-qz2b2 has an updated status
STEP: patching the Statefulset Status 08/27/22 07:03:46.183
Aug 27 07:03:46.184: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 27 07:03:46.192: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 08/27/22 07:03:46.192
Aug 27 07:03:46.197: INFO: Observed &Deployment event: ADDED
Aug 27 07:03:46.197: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
Aug 27 07:03:46.197: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.197: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
Aug 27 07:03:46.197: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 27 07:03:46.198: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-qz2b2-777898ffcc" is progressing.}
Aug 27 07:03:46.198: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
Aug 27 07:03:46.198: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 27 07:03:46.199: INFO: Observed &Deployment event: MODIFIED
Aug 27 07:03:46.199: INFO: Found deployment test-deployment-qz2b2 in namespace deployment-3391 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Aug 27 07:03:46.199: INFO: Deployment test-deployment-qz2b2 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 07:03:46.206: INFO: Deployment "test-deployment-qz2b2":
&Deployment{ObjectMeta:{test-deployment-qz2b2  deployment-3391  7e65fe1d-337e-47f2-9d74-45d9162170ba 30824 1 2022-08-27 07:03:44 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-08-27 07:03:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-08-27 07:03:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a1c168 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-qz2b2-777898ffcc",LastUpdateTime:2022-08-27 07:03:46 +0000 UTC,LastTransitionTime:2022-08-27 07:03:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 07:03:46.213: INFO: New ReplicaSet "test-deployment-qz2b2-777898ffcc" of Deployment "test-deployment-qz2b2":
&ReplicaSet{ObjectMeta:{test-deployment-qz2b2-777898ffcc  deployment-3391  2540be0b-f233-4dc9-9225-77331f355531 30820 1 2022-08-27 07:03:44 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-qz2b2 7e65fe1d-337e-47f2-9d74-45d9162170ba 0xc005133d40 0xc005133d41}] [] [{kube-controller-manager Update apps/v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e65fe1d-337e-47f2-9d74-45d9162170ba\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 07:03:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005133de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 07:03:46.218: INFO: Pod "test-deployment-qz2b2-777898ffcc-jq8lp" is available:
&Pod{ObjectMeta:{test-deployment-qz2b2-777898ffcc-jq8lp test-deployment-qz2b2-777898ffcc- deployment-3391  00cb00ef-659a-4a4b-8709-5c6f447fd123 30819 0 2022-08-27 07:03:44 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:5463cd1ad0b50f0b38e9d0b0fdf41f67f35210837ac8ace07cefd5d97ccaea9c cni.projectcalico.org/podIP:10.2.137.204/32 cni.projectcalico.org/podIPs:10.2.137.204/32] [{apps/v1 ReplicaSet test-deployment-qz2b2-777898ffcc 2540be0b-f233-4dc9-9225-77331f355531 0xc004a1c520 0xc004a1c521}] [] [{Go-http-client Update v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2540be0b-f233-4dc9-9225-77331f355531\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 07:03:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.204\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g62np,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g62np,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.204,StartTime:2022-08-27 07:03:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 07:03:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0f74021b8040df2068e2c9d2c9b96a49ed1976ff7a81d99a59ec87036c2b6a70,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.204,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 07:03:46.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3391" for this suite. 08/27/22 07:03:46.229
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":332,"skipped":6157,"failed":0}
------------------------------
â€¢ [2.139 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:44.107
    Aug 27 07:03:44.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 07:03:44.108
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:44.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:44.129
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 08/27/22 07:03:44.136
    Aug 27 07:03:44.136: INFO: Creating simple deployment test-deployment-qz2b2
    Aug 27 07:03:44.147: INFO: new replicaset for deployment "test-deployment-qz2b2" is yet to be created
    STEP: Getting /status 08/27/22 07:03:46.161
    Aug 27 07:03:46.166: INFO: Deployment test-deployment-qz2b2 has Conditions: [{Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 08/27/22 07:03:46.166
    Aug 27 07:03:46.179: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 7, 3, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 3, 45, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 7, 3, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 3, 44, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-qz2b2-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 08/27/22 07:03:46.179
    Aug 27 07:03:46.182: INFO: Observed &Deployment event: ADDED
    Aug 27 07:03:46.182: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
    Aug 27 07:03:46.182: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.182: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
    Aug 27 07:03:46.182: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 27 07:03:46.183: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-qz2b2-777898ffcc" is progressing.}
    Aug 27 07:03:46.183: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
    Aug 27 07:03:46.183: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 27 07:03:46.183: INFO: Observed Deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
    Aug 27 07:03:46.183: INFO: Found Deployment test-deployment-qz2b2 in namespace deployment-3391 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 27 07:03:46.183: INFO: Deployment test-deployment-qz2b2 has an updated status
    STEP: patching the Statefulset Status 08/27/22 07:03:46.183
    Aug 27 07:03:46.184: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Aug 27 07:03:46.192: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 08/27/22 07:03:46.192
    Aug 27 07:03:46.197: INFO: Observed &Deployment event: ADDED
    Aug 27 07:03:46.197: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
    Aug 27 07:03:46.197: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.197: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-qz2b2-777898ffcc"}
    Aug 27 07:03:46.197: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 27 07:03:46.198: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:44 +0000 UTC 2022-08-27 07:03:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-qz2b2-777898ffcc" is progressing.}
    Aug 27 07:03:46.198: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
    Aug 27 07:03:46.198: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-27 07:03:45 +0000 UTC 2022-08-27 07:03:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-qz2b2-777898ffcc" has successfully progressed.}
    Aug 27 07:03:46.198: INFO: Observed deployment test-deployment-qz2b2 in namespace deployment-3391 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Aug 27 07:03:46.199: INFO: Observed &Deployment event: MODIFIED
    Aug 27 07:03:46.199: INFO: Found deployment test-deployment-qz2b2 in namespace deployment-3391 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Aug 27 07:03:46.199: INFO: Deployment test-deployment-qz2b2 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 07:03:46.206: INFO: Deployment "test-deployment-qz2b2":
    &Deployment{ObjectMeta:{test-deployment-qz2b2  deployment-3391  7e65fe1d-337e-47f2-9d74-45d9162170ba 30824 1 2022-08-27 07:03:44 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-08-27 07:03:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-08-27 07:03:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a1c168 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-qz2b2-777898ffcc",LastUpdateTime:2022-08-27 07:03:46 +0000 UTC,LastTransitionTime:2022-08-27 07:03:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 27 07:03:46.213: INFO: New ReplicaSet "test-deployment-qz2b2-777898ffcc" of Deployment "test-deployment-qz2b2":
    &ReplicaSet{ObjectMeta:{test-deployment-qz2b2-777898ffcc  deployment-3391  2540be0b-f233-4dc9-9225-77331f355531 30820 1 2022-08-27 07:03:44 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-qz2b2 7e65fe1d-337e-47f2-9d74-45d9162170ba 0xc005133d40 0xc005133d41}] [] [{kube-controller-manager Update apps/v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7e65fe1d-337e-47f2-9d74-45d9162170ba\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 07:03:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005133de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 07:03:46.218: INFO: Pod "test-deployment-qz2b2-777898ffcc-jq8lp" is available:
    &Pod{ObjectMeta:{test-deployment-qz2b2-777898ffcc-jq8lp test-deployment-qz2b2-777898ffcc- deployment-3391  00cb00ef-659a-4a4b-8709-5c6f447fd123 30819 0 2022-08-27 07:03:44 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:5463cd1ad0b50f0b38e9d0b0fdf41f67f35210837ac8ace07cefd5d97ccaea9c cni.projectcalico.org/podIP:10.2.137.204/32 cni.projectcalico.org/podIPs:10.2.137.204/32] [{apps/v1 ReplicaSet test-deployment-qz2b2-777898ffcc 2540be0b-f233-4dc9-9225-77331f355531 0xc004a1c520 0xc004a1c521}] [] [{Go-http-client Update v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-08-27 07:03:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2540be0b-f233-4dc9-9225-77331f355531\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-27 07:03:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.137.204\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g62np,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g62np,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:03:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.31.158,PodIP:10.2.137.204,StartTime:2022-08-27 07:03:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 07:03:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://0f74021b8040df2068e2c9d2c9b96a49ed1976ff7a81d99a59ec87036c2b6a70,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.137.204,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 07:03:46.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3391" for this suite. 08/27/22 07:03:46.229
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:46.247
Aug 27 07:03:46.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 07:03:46.247
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:46.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:46.296
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-03a52833-3665-48c6-9881-ba766e55eb3f 08/27/22 07:03:46.3
STEP: Creating a pod to test consume secrets 08/27/22 07:03:46.304
Aug 27 07:03:46.315: INFO: Waiting up to 5m0s for pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946" in namespace "secrets-4143" to be "Succeeded or Failed"
Aug 27 07:03:46.320: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213492ms
Aug 27 07:03:48.323: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00750909s
Aug 27 07:03:50.324: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008784063s
STEP: Saw pod success 08/27/22 07:03:50.324
Aug 27 07:03:50.324: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946" satisfied condition "Succeeded or Failed"
Aug 27 07:03:50.328: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 07:03:50.334
Aug 27 07:03:50.345: INFO: Waiting for pod pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946 to disappear
Aug 27 07:03:50.348: INFO: Pod pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 07:03:50.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4143" for this suite. 08/27/22 07:03:50.352
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":333,"skipped":6158,"failed":0}
------------------------------
â€¢ [4.110 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:46.247
    Aug 27 07:03:46.247: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 07:03:46.247
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:46.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:46.296
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-03a52833-3665-48c6-9881-ba766e55eb3f 08/27/22 07:03:46.3
    STEP: Creating a pod to test consume secrets 08/27/22 07:03:46.304
    Aug 27 07:03:46.315: INFO: Waiting up to 5m0s for pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946" in namespace "secrets-4143" to be "Succeeded or Failed"
    Aug 27 07:03:46.320: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213492ms
    Aug 27 07:03:48.323: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00750909s
    Aug 27 07:03:50.324: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008784063s
    STEP: Saw pod success 08/27/22 07:03:50.324
    Aug 27 07:03:50.324: INFO: Pod "pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946" satisfied condition "Succeeded or Failed"
    Aug 27 07:03:50.328: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 07:03:50.334
    Aug 27 07:03:50.345: INFO: Waiting for pod pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946 to disappear
    Aug 27 07:03:50.348: INFO: Pod pod-secrets-8b969ba6-1e95-475c-9f38-93b634ba4946 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 07:03:50.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4143" for this suite. 08/27/22 07:03:50.352
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:50.358
Aug 27 07:03:50.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 07:03:50.359
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:50.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:50.38
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 08/27/22 07:03:50.383
Aug 27 07:03:50.391: INFO: Waiting up to 5m0s for pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2" in namespace "var-expansion-7387" to be "Succeeded or Failed"
Aug 27 07:03:50.394: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.070701ms
Aug 27 07:03:52.398: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007308852s
Aug 27 07:03:54.399: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008271789s
STEP: Saw pod success 08/27/22 07:03:54.399
Aug 27 07:03:54.399: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2" satisfied condition "Succeeded or Failed"
Aug 27 07:03:54.402: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2 container dapi-container: <nil>
STEP: delete the pod 08/27/22 07:03:54.408
Aug 27 07:03:54.417: INFO: Waiting for pod var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2 to disappear
Aug 27 07:03:54.422: INFO: Pod var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 07:03:54.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7387" for this suite. 08/27/22 07:03:54.426
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":334,"skipped":6162,"failed":0}
------------------------------
â€¢ [4.076 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:50.358
    Aug 27 07:03:50.359: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 07:03:50.359
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:50.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:50.38
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 08/27/22 07:03:50.383
    Aug 27 07:03:50.391: INFO: Waiting up to 5m0s for pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2" in namespace "var-expansion-7387" to be "Succeeded or Failed"
    Aug 27 07:03:50.394: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.070701ms
    Aug 27 07:03:52.398: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007308852s
    Aug 27 07:03:54.399: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008271789s
    STEP: Saw pod success 08/27/22 07:03:54.399
    Aug 27 07:03:54.399: INFO: Pod "var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2" satisfied condition "Succeeded or Failed"
    Aug 27 07:03:54.402: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2 container dapi-container: <nil>
    STEP: delete the pod 08/27/22 07:03:54.408
    Aug 27 07:03:54.417: INFO: Waiting for pod var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2 to disappear
    Aug 27 07:03:54.422: INFO: Pod var-expansion-2493d009-ecd7-4e73-b6ae-38cd120ff9f2 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 07:03:54.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7387" for this suite. 08/27/22 07:03:54.426
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:54.437
Aug 27 07:03:54.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 07:03:54.438
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:54.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:54.476
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 08/27/22 07:03:54.48
Aug 27 07:03:54.490: INFO: Waiting up to 5m0s for pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e" in namespace "emptydir-270" to be "Succeeded or Failed"
Aug 27 07:03:54.499: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.777785ms
Aug 27 07:03:56.512: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021449774s
Aug 27 07:03:58.507: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016513297s
STEP: Saw pod success 08/27/22 07:03:58.507
Aug 27 07:03:58.507: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e" satisfied condition "Succeeded or Failed"
Aug 27 07:03:58.514: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e container test-container: <nil>
STEP: delete the pod 08/27/22 07:03:58.524
Aug 27 07:03:58.565: INFO: Waiting for pod pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e to disappear
Aug 27 07:03:58.580: INFO: Pod pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 07:03:58.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-270" for this suite. 08/27/22 07:03:58.594
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":335,"skipped":6174,"failed":0}
------------------------------
â€¢ [4.166 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:54.437
    Aug 27 07:03:54.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 07:03:54.438
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:54.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:54.476
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 08/27/22 07:03:54.48
    Aug 27 07:03:54.490: INFO: Waiting up to 5m0s for pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e" in namespace "emptydir-270" to be "Succeeded or Failed"
    Aug 27 07:03:54.499: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.777785ms
    Aug 27 07:03:56.512: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021449774s
    Aug 27 07:03:58.507: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016513297s
    STEP: Saw pod success 08/27/22 07:03:58.507
    Aug 27 07:03:58.507: INFO: Pod "pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e" satisfied condition "Succeeded or Failed"
    Aug 27 07:03:58.514: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e container test-container: <nil>
    STEP: delete the pod 08/27/22 07:03:58.524
    Aug 27 07:03:58.565: INFO: Waiting for pod pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e to disappear
    Aug 27 07:03:58.580: INFO: Pod pod-998d6f45-2889-4b8a-b2a5-82b712b4bc3e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 07:03:58.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-270" for this suite. 08/27/22 07:03:58.594
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:58.618
Aug 27 07:03:58.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename ingress 08/27/22 07:03:58.62
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:58.65
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:58.671
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 08/27/22 07:03:58.683
STEP: getting /apis/networking.k8s.io 08/27/22 07:03:58.687
STEP: getting /apis/networking.k8s.iov1 08/27/22 07:03:58.689
STEP: creating 08/27/22 07:03:58.692
STEP: getting 08/27/22 07:03:58.745
STEP: listing 08/27/22 07:03:58.751
STEP: watching 08/27/22 07:03:58.76
Aug 27 07:03:58.760: INFO: starting watch
STEP: cluster-wide listing 08/27/22 07:03:58.764
STEP: cluster-wide watching 08/27/22 07:03:58.767
Aug 27 07:03:58.767: INFO: starting watch
STEP: patching 08/27/22 07:03:58.77
STEP: updating 08/27/22 07:03:58.778
Aug 27 07:03:58.798: INFO: waiting for watch events with expected annotations
Aug 27 07:03:58.798: INFO: saw patched and updated annotations
STEP: patching /status 08/27/22 07:03:58.798
STEP: updating /status 08/27/22 07:03:58.811
STEP: get /status 08/27/22 07:03:58.83
STEP: deleting 08/27/22 07:03:58.835
STEP: deleting a collection 08/27/22 07:03:58.854
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Aug 27 07:03:58.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-360" for this suite. 08/27/22 07:03:58.918
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":336,"skipped":6226,"failed":0}
------------------------------
â€¢ [0.305 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:58.618
    Aug 27 07:03:58.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename ingress 08/27/22 07:03:58.62
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:58.65
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:58.671
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 08/27/22 07:03:58.683
    STEP: getting /apis/networking.k8s.io 08/27/22 07:03:58.687
    STEP: getting /apis/networking.k8s.iov1 08/27/22 07:03:58.689
    STEP: creating 08/27/22 07:03:58.692
    STEP: getting 08/27/22 07:03:58.745
    STEP: listing 08/27/22 07:03:58.751
    STEP: watching 08/27/22 07:03:58.76
    Aug 27 07:03:58.760: INFO: starting watch
    STEP: cluster-wide listing 08/27/22 07:03:58.764
    STEP: cluster-wide watching 08/27/22 07:03:58.767
    Aug 27 07:03:58.767: INFO: starting watch
    STEP: patching 08/27/22 07:03:58.77
    STEP: updating 08/27/22 07:03:58.778
    Aug 27 07:03:58.798: INFO: waiting for watch events with expected annotations
    Aug 27 07:03:58.798: INFO: saw patched and updated annotations
    STEP: patching /status 08/27/22 07:03:58.798
    STEP: updating /status 08/27/22 07:03:58.811
    STEP: get /status 08/27/22 07:03:58.83
    STEP: deleting 08/27/22 07:03:58.835
    STEP: deleting a collection 08/27/22 07:03:58.854
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Aug 27 07:03:58.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-360" for this suite. 08/27/22 07:03:58.918
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:03:58.924
Aug 27 07:03:58.924: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename services 08/27/22 07:03:58.925
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:58.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:58.952
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-4510 08/27/22 07:03:58.955
STEP: creating service affinity-nodeport-transition in namespace services-4510 08/27/22 07:03:58.956
STEP: creating replication controller affinity-nodeport-transition in namespace services-4510 08/27/22 07:03:58.967
I0827 07:03:58.981826      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4510, replica count: 3
I0827 07:04:02.033360      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 07:04:02.060: INFO: Creating new exec pod
Aug 27 07:04:02.075: INFO: Waiting up to 5m0s for pod "execpod-affinitym6wkf" in namespace "services-4510" to be "running"
Aug 27 07:04:02.099: INFO: Pod "execpod-affinitym6wkf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.945168ms
Aug 27 07:04:04.106: INFO: Pod "execpod-affinitym6wkf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030294419s
Aug 27 07:04:06.103: INFO: Pod "execpod-affinitym6wkf": Phase="Running", Reason="", readiness=true. Elapsed: 4.026985877s
Aug 27 07:04:06.103: INFO: Pod "execpod-affinitym6wkf" satisfied condition "running"
Aug 27 07:04:07.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Aug 27 07:04:07.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Aug 27 07:04:07.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 07:04:07.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.107.231 80'
Aug 27 07:04:07.512: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.107.231 80\nConnection to 10.3.107.231 80 port [tcp/http] succeeded!\n"
Aug 27 07:04:07.512: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 07:04:07.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 30106'
Aug 27 07:04:07.891: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 30106\nConnection to 10.0.31.158 30106 port [tcp/*] succeeded!\n"
Aug 27 07:04:07.891: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 07:04:07.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 30106'
Aug 27 07:04:08.058: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 30106\nConnection to 10.0.47.192 30106 port [tcp/*] succeeded!\n"
Aug 27 07:04:08.058: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 27 07:04:08.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30106/ ; done'
Aug 27 07:04:08.430: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n"
Aug 27 07:04:08.430: INFO: stdout: "\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4"
Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-2f4f4
Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-svxwc
Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-2f4f4
Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-svxwc
Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-svxwc
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-svxwc
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-svxwc
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
Aug 27 07:04:08.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30106/ ; done'
Aug 27 07:04:08.713: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n"
Aug 27 07:04:08.713: INFO: stdout: "\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5"
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
Aug 27 07:04:08.713: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4510, will wait for the garbage collector to delete the pods 08/27/22 07:04:08.732
Aug 27 07:04:08.796: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.379367ms
Aug 27 07:04:08.897: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.123792ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Aug 27 07:04:11.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4510" for this suite. 08/27/22 07:04:11.145
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":337,"skipped":6226,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.225 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:03:58.924
    Aug 27 07:03:58.924: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename services 08/27/22 07:03:58.925
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:03:58.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:03:58.952
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-4510 08/27/22 07:03:58.955
    STEP: creating service affinity-nodeport-transition in namespace services-4510 08/27/22 07:03:58.956
    STEP: creating replication controller affinity-nodeport-transition in namespace services-4510 08/27/22 07:03:58.967
    I0827 07:03:58.981826      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4510, replica count: 3
    I0827 07:04:02.033360      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 07:04:02.060: INFO: Creating new exec pod
    Aug 27 07:04:02.075: INFO: Waiting up to 5m0s for pod "execpod-affinitym6wkf" in namespace "services-4510" to be "running"
    Aug 27 07:04:02.099: INFO: Pod "execpod-affinitym6wkf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.945168ms
    Aug 27 07:04:04.106: INFO: Pod "execpod-affinitym6wkf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030294419s
    Aug 27 07:04:06.103: INFO: Pod "execpod-affinitym6wkf": Phase="Running", Reason="", readiness=true. Elapsed: 4.026985877s
    Aug 27 07:04:06.103: INFO: Pod "execpod-affinitym6wkf" satisfied condition "running"
    Aug 27 07:04:07.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Aug 27 07:04:07.309: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Aug 27 07:04:07.309: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 07:04:07.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.3.107.231 80'
    Aug 27 07:04:07.512: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.3.107.231 80\nConnection to 10.3.107.231 80 port [tcp/http] succeeded!\n"
    Aug 27 07:04:07.512: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 07:04:07.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.31.158 30106'
    Aug 27 07:04:07.891: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.31.158 30106\nConnection to 10.0.31.158 30106 port [tcp/*] succeeded!\n"
    Aug 27 07:04:07.891: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 07:04:07.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.0.47.192 30106'
    Aug 27 07:04:08.058: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.0.47.192 30106\nConnection to 10.0.47.192 30106 port [tcp/*] succeeded!\n"
    Aug 27 07:04:08.058: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Aug 27 07:04:08.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30106/ ; done'
    Aug 27 07:04:08.430: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n"
    Aug 27 07:04:08.430: INFO: stdout: "\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4\naffinity-nodeport-transition-svxwc\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-2f4f4"
    Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-2f4f4
    Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-svxwc
    Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-2f4f4
    Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-svxwc
    Aug 27 07:04:08.430: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-svxwc
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-svxwc
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-svxwc
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.431: INFO: Received response from host: affinity-nodeport-transition-2f4f4
    Aug 27 07:04:08.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=services-4510 exec execpod-affinitym6wkf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.0.31.158:30106/ ; done'
    Aug 27 07:04:08.713: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.0.31.158:30106/\n"
    Aug 27 07:04:08.713: INFO: stdout: "\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5\naffinity-nodeport-transition-6pvg5"
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Received response from host: affinity-nodeport-transition-6pvg5
    Aug 27 07:04:08.713: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4510, will wait for the garbage collector to delete the pods 08/27/22 07:04:08.732
    Aug 27 07:04:08.796: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.379367ms
    Aug 27 07:04:08.897: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.123792ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Aug 27 07:04:11.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4510" for this suite. 08/27/22 07:04:11.145
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:04:11.15
Aug 27 07:04:11.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename configmap 08/27/22 07:04:11.152
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:11.172
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:11.176
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-b8c46f92-bff0-4f0a-ba9b-d4822410d8f3 08/27/22 07:04:11.186
STEP: Creating the pod 08/27/22 07:04:11.191
Aug 27 07:04:11.198: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957" in namespace "configmap-7301" to be "running"
Aug 27 07:04:11.209: INFO: Pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689338ms
Aug 27 07:04:13.218: INFO: Pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957": Phase="Running", Reason="", readiness=false. Elapsed: 2.01614553s
Aug 27 07:04:13.218: INFO: Pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957" satisfied condition "running"
STEP: Waiting for pod with text data 08/27/22 07:04:13.218
STEP: Waiting for pod with binary data 08/27/22 07:04:13.224
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Aug 27 07:04:13.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7301" for this suite. 08/27/22 07:04:13.232
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":338,"skipped":6229,"failed":0}
------------------------------
â€¢ [2.087 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:04:11.15
    Aug 27 07:04:11.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename configmap 08/27/22 07:04:11.152
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:11.172
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:11.176
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-b8c46f92-bff0-4f0a-ba9b-d4822410d8f3 08/27/22 07:04:11.186
    STEP: Creating the pod 08/27/22 07:04:11.191
    Aug 27 07:04:11.198: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957" in namespace "configmap-7301" to be "running"
    Aug 27 07:04:11.209: INFO: Pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689338ms
    Aug 27 07:04:13.218: INFO: Pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957": Phase="Running", Reason="", readiness=false. Elapsed: 2.01614553s
    Aug 27 07:04:13.218: INFO: Pod "pod-configmaps-e3f21b56-906e-414a-819f-129d7175d957" satisfied condition "running"
    STEP: Waiting for pod with text data 08/27/22 07:04:13.218
    STEP: Waiting for pod with binary data 08/27/22 07:04:13.224
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Aug 27 07:04:13.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7301" for this suite. 08/27/22 07:04:13.232
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:04:13.237
Aug 27 07:04:13.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename namespaces 08/27/22 07:04:13.238
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:13.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:13.257
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 08/27/22 07:04:13.261
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:13.275
STEP: Creating a pod in the namespace 08/27/22 07:04:13.279
STEP: Waiting for the pod to have running status 08/27/22 07:04:13.285
Aug 27 07:04:13.285: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7900" to be "running"
Aug 27 07:04:13.290: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.91982ms
Aug 27 07:04:15.294: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008837158s
Aug 27 07:04:15.294: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 08/27/22 07:04:15.294
STEP: Waiting for the namespace to be removed. 08/27/22 07:04:15.303
STEP: Recreating the namespace 08/27/22 07:04:26.306
STEP: Verifying there are no pods in the namespace 08/27/22 07:04:26.327
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 27 07:04:26.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6016" for this suite. 08/27/22 07:04:26.336
STEP: Destroying namespace "nsdeletetest-7900" for this suite. 08/27/22 07:04:26.341
Aug 27 07:04:26.347: INFO: Namespace nsdeletetest-7900 was already deleted
STEP: Destroying namespace "nsdeletetest-3397" for this suite. 08/27/22 07:04:26.347
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":339,"skipped":6233,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.114 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:04:13.237
    Aug 27 07:04:13.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename namespaces 08/27/22 07:04:13.238
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:13.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:13.257
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 08/27/22 07:04:13.261
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:13.275
    STEP: Creating a pod in the namespace 08/27/22 07:04:13.279
    STEP: Waiting for the pod to have running status 08/27/22 07:04:13.285
    Aug 27 07:04:13.285: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-7900" to be "running"
    Aug 27 07:04:13.290: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.91982ms
    Aug 27 07:04:15.294: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008837158s
    Aug 27 07:04:15.294: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 08/27/22 07:04:15.294
    STEP: Waiting for the namespace to be removed. 08/27/22 07:04:15.303
    STEP: Recreating the namespace 08/27/22 07:04:26.306
    STEP: Verifying there are no pods in the namespace 08/27/22 07:04:26.327
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 07:04:26.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-6016" for this suite. 08/27/22 07:04:26.336
    STEP: Destroying namespace "nsdeletetest-7900" for this suite. 08/27/22 07:04:26.341
    Aug 27 07:04:26.347: INFO: Namespace nsdeletetest-7900 was already deleted
    STEP: Destroying namespace "nsdeletetest-3397" for this suite. 08/27/22 07:04:26.347
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:04:26.363
Aug 27 07:04:26.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 07:04:26.363
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:26.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:26.402
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 07:04:26.406
Aug 27 07:04:26.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5856 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 27 07:04:26.491: INFO: stderr: ""
Aug 27 07:04:26.491: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 08/27/22 07:04:26.491
Aug 27 07:04:26.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5856 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Aug 27 07:04:27.132: INFO: stderr: ""
Aug 27 07:04:27.132: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 07:04:27.132
Aug 27 07:04:27.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5856 delete pods e2e-test-httpd-pod'
Aug 27 07:04:29.078: INFO: stderr: ""
Aug 27 07:04:29.078: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 07:04:29.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5856" for this suite. 08/27/22 07:04:29.082
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":340,"skipped":6294,"failed":0}
------------------------------
â€¢ [2.725 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:04:26.363
    Aug 27 07:04:26.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 07:04:26.363
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:26.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:26.402
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 07:04:26.406
    Aug 27 07:04:26.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5856 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Aug 27 07:04:26.491: INFO: stderr: ""
    Aug 27 07:04:26.491: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 08/27/22 07:04:26.491
    Aug 27 07:04:26.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5856 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Aug 27 07:04:27.132: INFO: stderr: ""
    Aug 27 07:04:27.132: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 08/27/22 07:04:27.132
    Aug 27 07:04:27.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-5856 delete pods e2e-test-httpd-pod'
    Aug 27 07:04:29.078: INFO: stderr: ""
    Aug 27 07:04:29.078: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 07:04:29.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5856" for this suite. 08/27/22 07:04:29.082
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:04:29.091
Aug 27 07:04:29.091: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 07:04:29.091
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:29.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:29.124
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 08/27/22 07:04:29.127
Aug 27 07:04:29.127: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 08/27/22 07:04:41.168
Aug 27 07:04:41.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
Aug 27 07:04:45.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 07:04:55.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5117" for this suite. 08/27/22 07:04:55.639
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":341,"skipped":6343,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.554 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:04:29.091
    Aug 27 07:04:29.091: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-publish-openapi 08/27/22 07:04:29.091
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:29.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:29.124
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 08/27/22 07:04:29.127
    Aug 27 07:04:29.127: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 08/27/22 07:04:41.168
    Aug 27 07:04:41.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    Aug 27 07:04:45.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 07:04:55.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5117" for this suite. 08/27/22 07:04:55.639
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:04:55.647
Aug 27 07:04:55.647: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename namespaces 08/27/22 07:04:55.648
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:55.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:55.667
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 08/27/22 07:04:55.678
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:55.693
STEP: Creating a service in the namespace 08/27/22 07:04:55.698
STEP: Deleting the namespace 08/27/22 07:04:55.708
STEP: Waiting for the namespace to be removed. 08/27/22 07:04:55.725
STEP: Recreating the namespace 08/27/22 07:05:01.748
STEP: Verifying there is no service in the namespace 08/27/22 07:05:01.823
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 27 07:05:01.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4703" for this suite. 08/27/22 07:05:01.869
STEP: Destroying namespace "nsdeletetest-3746" for this suite. 08/27/22 07:05:01.913
Aug 27 07:05:01.992: INFO: Namespace nsdeletetest-3746 was already deleted
STEP: Destroying namespace "nsdeletetest-9724" for this suite. 08/27/22 07:05:01.992
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":342,"skipped":6362,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.360 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:04:55.647
    Aug 27 07:04:55.647: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename namespaces 08/27/22 07:04:55.648
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:55.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:04:55.667
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 08/27/22 07:04:55.678
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:04:55.693
    STEP: Creating a service in the namespace 08/27/22 07:04:55.698
    STEP: Deleting the namespace 08/27/22 07:04:55.708
    STEP: Waiting for the namespace to be removed. 08/27/22 07:04:55.725
    STEP: Recreating the namespace 08/27/22 07:05:01.748
    STEP: Verifying there is no service in the namespace 08/27/22 07:05:01.823
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 07:05:01.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4703" for this suite. 08/27/22 07:05:01.869
    STEP: Destroying namespace "nsdeletetest-3746" for this suite. 08/27/22 07:05:01.913
    Aug 27 07:05:01.992: INFO: Namespace nsdeletetest-3746 was already deleted
    STEP: Destroying namespace "nsdeletetest-9724" for this suite. 08/27/22 07:05:01.992
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:02.009
Aug 27 07:05:02.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename var-expansion 08/27/22 07:05:02.012
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:02.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:02.101
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 08/27/22 07:05:02.111
Aug 27 07:05:02.128: INFO: Waiting up to 5m0s for pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b" in namespace "var-expansion-5408" to be "Succeeded or Failed"
Aug 27 07:05:02.143: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.586876ms
Aug 27 07:05:04.148: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020144473s
Aug 27 07:05:06.149: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020563584s
STEP: Saw pod success 08/27/22 07:05:06.149
Aug 27 07:05:06.149: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b" satisfied condition "Succeeded or Failed"
Aug 27 07:05:06.152: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b container dapi-container: <nil>
STEP: delete the pod 08/27/22 07:05:06.159
Aug 27 07:05:06.173: INFO: Waiting for pod var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b to disappear
Aug 27 07:05:06.178: INFO: Pod var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Aug 27 07:05:06.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5408" for this suite. 08/27/22 07:05:06.182
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":343,"skipped":6392,"failed":0}
------------------------------
â€¢ [4.183 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:02.009
    Aug 27 07:05:02.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename var-expansion 08/27/22 07:05:02.012
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:02.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:02.101
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 08/27/22 07:05:02.111
    Aug 27 07:05:02.128: INFO: Waiting up to 5m0s for pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b" in namespace "var-expansion-5408" to be "Succeeded or Failed"
    Aug 27 07:05:02.143: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.586876ms
    Aug 27 07:05:04.148: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020144473s
    Aug 27 07:05:06.149: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020563584s
    STEP: Saw pod success 08/27/22 07:05:06.149
    Aug 27 07:05:06.149: INFO: Pod "var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b" satisfied condition "Succeeded or Failed"
    Aug 27 07:05:06.152: INFO: Trying to get logs from node ip-10-0-47-192 pod var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b container dapi-container: <nil>
    STEP: delete the pod 08/27/22 07:05:06.159
    Aug 27 07:05:06.173: INFO: Waiting for pod var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b to disappear
    Aug 27 07:05:06.178: INFO: Pod var-expansion-ad329275-4c2e-4ebf-9ee4-b84b67c6f96b no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Aug 27 07:05:06.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5408" for this suite. 08/27/22 07:05:06.182
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:06.197
Aug 27 07:05:06.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 07:05:06.197
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:06.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:06.253
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 08/27/22 07:05:06.258
Aug 27 07:05:06.266: INFO: Waiting up to 5m0s for pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce" in namespace "emptydir-6595" to be "Succeeded or Failed"
Aug 27 07:05:06.275: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce": Phase="Pending", Reason="", readiness=false. Elapsed: 8.773425ms
Aug 27 07:05:08.279: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012557629s
Aug 27 07:05:10.279: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013113661s
STEP: Saw pod success 08/27/22 07:05:10.279
Aug 27 07:05:10.279: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce" satisfied condition "Succeeded or Failed"
Aug 27 07:05:10.283: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce container test-container: <nil>
STEP: delete the pod 08/27/22 07:05:10.289
Aug 27 07:05:10.298: INFO: Waiting for pod pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce to disappear
Aug 27 07:05:10.302: INFO: Pod pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 07:05:10.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6595" for this suite. 08/27/22 07:05:10.306
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":344,"skipped":6423,"failed":0}
------------------------------
â€¢ [4.122 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:06.197
    Aug 27 07:05:06.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 07:05:06.197
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:06.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:06.253
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 08/27/22 07:05:06.258
    Aug 27 07:05:06.266: INFO: Waiting up to 5m0s for pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce" in namespace "emptydir-6595" to be "Succeeded or Failed"
    Aug 27 07:05:06.275: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce": Phase="Pending", Reason="", readiness=false. Elapsed: 8.773425ms
    Aug 27 07:05:08.279: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012557629s
    Aug 27 07:05:10.279: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013113661s
    STEP: Saw pod success 08/27/22 07:05:10.279
    Aug 27 07:05:10.279: INFO: Pod "pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce" satisfied condition "Succeeded or Failed"
    Aug 27 07:05:10.283: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce container test-container: <nil>
    STEP: delete the pod 08/27/22 07:05:10.289
    Aug 27 07:05:10.298: INFO: Waiting for pod pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce to disappear
    Aug 27 07:05:10.302: INFO: Pod pod-ed0f2d27-5d68-484b-97d5-a69f1d8bdfce no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 07:05:10.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6595" for this suite. 08/27/22 07:05:10.306
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:10.321
Aug 27 07:05:10.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename disruption 08/27/22 07:05:10.322
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:10.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:10.358
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 08/27/22 07:05:10.366
STEP: Updating PodDisruptionBudget status 08/27/22 07:05:12.373
STEP: Waiting for all pods to be running 08/27/22 07:05:12.38
Aug 27 07:05:12.388: INFO: running pods: 0 < 1
STEP: locating a running pod 08/27/22 07:05:14.391
STEP: Waiting for the pdb to be processed 08/27/22 07:05:14.401
STEP: Patching PodDisruptionBudget status 08/27/22 07:05:14.41
STEP: Waiting for the pdb to be processed 08/27/22 07:05:14.417
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Aug 27 07:05:14.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4088" for this suite. 08/27/22 07:05:14.425
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":345,"skipped":6448,"failed":0}
------------------------------
â€¢ [4.108 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:10.321
    Aug 27 07:05:10.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename disruption 08/27/22 07:05:10.322
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:10.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:10.358
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 08/27/22 07:05:10.366
    STEP: Updating PodDisruptionBudget status 08/27/22 07:05:12.373
    STEP: Waiting for all pods to be running 08/27/22 07:05:12.38
    Aug 27 07:05:12.388: INFO: running pods: 0 < 1
    STEP: locating a running pod 08/27/22 07:05:14.391
    STEP: Waiting for the pdb to be processed 08/27/22 07:05:14.401
    STEP: Patching PodDisruptionBudget status 08/27/22 07:05:14.41
    STEP: Waiting for the pdb to be processed 08/27/22 07:05:14.417
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Aug 27 07:05:14.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4088" for this suite. 08/27/22 07:05:14.425
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:14.434
Aug 27 07:05:14.434: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 07:05:14.435
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:14.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:14.457
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 07:05:14.476
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 07:05:14.939
STEP: Deploying the webhook pod 08/27/22 07:05:14.949
STEP: Wait for the deployment to be ready 08/27/22 07:05:14.96
Aug 27 07:05:14.974: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 07:05:16.984
STEP: Verifying the service has paired with the endpoint 08/27/22 07:05:16.993
Aug 27 07:05:17.994: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 08/27/22 07:05:17.997
STEP: create a namespace for the webhook 08/27/22 07:05:18.023
STEP: create a configmap should be unconditionally rejected by the webhook 08/27/22 07:05:18.029
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 07:05:18.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8658" for this suite. 08/27/22 07:05:18.076
STEP: Destroying namespace "webhook-8658-markers" for this suite. 08/27/22 07:05:18.081
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":346,"skipped":6455,"failed":0}
------------------------------
â€¢ [3.714 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:14.434
    Aug 27 07:05:14.434: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 07:05:14.435
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:14.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:14.457
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 07:05:14.476
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 07:05:14.939
    STEP: Deploying the webhook pod 08/27/22 07:05:14.949
    STEP: Wait for the deployment to be ready 08/27/22 07:05:14.96
    Aug 27 07:05:14.974: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 07:05:16.984
    STEP: Verifying the service has paired with the endpoint 08/27/22 07:05:16.993
    Aug 27 07:05:17.994: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 08/27/22 07:05:17.997
    STEP: create a namespace for the webhook 08/27/22 07:05:18.023
    STEP: create a configmap should be unconditionally rejected by the webhook 08/27/22 07:05:18.029
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 07:05:18.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8658" for this suite. 08/27/22 07:05:18.076
    STEP: Destroying namespace "webhook-8658-markers" for this suite. 08/27/22 07:05:18.081
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:18.155
Aug 27 07:05:18.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename proxy 08/27/22 07:05:18.156
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:18.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:18.189
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 08/27/22 07:05:18.203
STEP: creating replication controller proxy-service-2j67l in namespace proxy-8494 08/27/22 07:05:18.204
I0827 07:05:18.214447      19 runners.go:193] Created replication controller with name: proxy-service-2j67l, namespace: proxy-8494, replica count: 1
I0827 07:05:19.266443      19 runners.go:193] proxy-service-2j67l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 27 07:05:19.273: INFO: setup took 1.078792513s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 08/27/22 07:05:19.273
Aug 27 07:05:19.308: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 32.99185ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 33.205293ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 35.169872ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 33.465646ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 33.724553ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 33.085834ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 35.342576ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 33.716337ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 33.006853ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 34.013992ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 32.928111ms)
Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 33.86099ms)
Aug 27 07:05:19.315: INFO: (0) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 38.900346ms)
Aug 27 07:05:19.332: INFO: (0) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 55.365644ms)
Aug 27 07:05:19.332: INFO: (0) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 55.477127ms)
Aug 27 07:05:19.332: INFO: (0) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 55.598324ms)
Aug 27 07:05:19.357: INFO: (1) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 25.671061ms)
Aug 27 07:05:19.357: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 25.563079ms)
Aug 27 07:05:19.357: INFO: (1) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 25.487946ms)
Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 28.145167ms)
Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 28.337664ms)
Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 28.238503ms)
Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 27.920531ms)
Aug 27 07:05:19.364: INFO: (1) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 31.160868ms)
Aug 27 07:05:19.364: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 31.452966ms)
Aug 27 07:05:19.364: INFO: (1) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 31.110649ms)
Aug 27 07:05:19.368: INFO: (1) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 35.502755ms)
Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 36.722721ms)
Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 36.935265ms)
Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 36.491769ms)
Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 36.463988ms)
Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 36.848323ms)
Aug 27 07:05:19.399: INFO: (2) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 29.750338ms)
Aug 27 07:05:19.427: INFO: (2) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 55.241792ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 55.583544ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 57.337762ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 57.629588ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 57.743695ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 57.69638ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 57.603048ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 57.437268ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 57.904017ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 55.690373ms)
Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 57.510634ms)
Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 61.409467ms)
Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 61.510189ms)
Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 61.063001ms)
Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 61.307611ms)
Aug 27 07:05:19.451: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.505642ms)
Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 19.339383ms)
Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.291291ms)
Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 19.673492ms)
Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 19.761361ms)
Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 20.492111ms)
Aug 27 07:05:19.453: INFO: (3) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 20.580911ms)
Aug 27 07:05:19.453: INFO: (3) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 21.327154ms)
Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 22.188524ms)
Aug 27 07:05:19.454: INFO: (3) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 21.883153ms)
Aug 27 07:05:19.454: INFO: (3) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 22.39902ms)
Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 22.987542ms)
Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 22.798915ms)
Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 22.935632ms)
Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 22.417735ms)
Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 22.886171ms)
Aug 27 07:05:19.480: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 24.129367ms)
Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 24.847064ms)
Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 24.900074ms)
Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 24.805274ms)
Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 25.224863ms)
Aug 27 07:05:19.482: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 26.25613ms)
Aug 27 07:05:19.482: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 26.140059ms)
Aug 27 07:05:19.483: INFO: (4) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 26.780545ms)
Aug 27 07:05:19.483: INFO: (4) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 26.857463ms)
Aug 27 07:05:19.483: INFO: (4) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 27.517725ms)
Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 28.753061ms)
Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 28.873303ms)
Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 28.863414ms)
Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 28.777263ms)
Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 28.883286ms)
Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 29.154303ms)
Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.100276ms)
Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 23.535048ms)
Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 23.782253ms)
Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 23.391321ms)
Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 23.356295ms)
Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.326566ms)
Aug 27 07:05:19.510: INFO: (5) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 24.090293ms)
Aug 27 07:05:19.511: INFO: (5) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 24.971025ms)
Aug 27 07:05:19.511: INFO: (5) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 25.607506ms)
Aug 27 07:05:19.511: INFO: (5) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 25.015494ms)
Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 27.606133ms)
Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 27.136669ms)
Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 27.493253ms)
Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 27.766987ms)
Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 27.685469ms)
Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 28.007205ms)
Aug 27 07:05:19.546: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 32.194837ms)
Aug 27 07:05:19.554: INFO: (6) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 40.419783ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 41.226586ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 41.137011ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 41.871507ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 41.821498ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 42.003196ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 42.148506ms)
Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 41.171044ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 41.987448ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 41.966805ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 42.571059ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 42.110384ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 42.129634ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 42.007871ms)
Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 42.525018ms)
Aug 27 07:05:19.593: INFO: (7) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 35.621452ms)
Aug 27 07:05:19.609: INFO: (7) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 49.511635ms)
Aug 27 07:05:19.609: INFO: (7) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 49.299916ms)
Aug 27 07:05:19.609: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 49.920037ms)
Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 49.821912ms)
Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 50.092892ms)
Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 50.036376ms)
Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 50.680793ms)
Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 50.642239ms)
Aug 27 07:05:19.611: INFO: (7) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 50.576359ms)
Aug 27 07:05:19.612: INFO: (7) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 52.788687ms)
Aug 27 07:05:19.612: INFO: (7) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 52.790302ms)
Aug 27 07:05:19.612: INFO: (7) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 54.898518ms)
Aug 27 07:05:19.613: INFO: (7) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 52.486362ms)
Aug 27 07:05:19.613: INFO: (7) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 53.538934ms)
Aug 27 07:05:19.613: INFO: (7) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 52.998164ms)
Aug 27 07:05:19.635: INFO: (8) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 21.879767ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 33.869681ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 33.642642ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 34.135637ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 34.600065ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 35.067786ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 34.792574ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 35.241487ms)
Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 34.256029ms)
Aug 27 07:05:19.651: INFO: (8) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 37.36047ms)
Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 37.389066ms)
Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 37.942737ms)
Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 37.628307ms)
Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 38.047031ms)
Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 38.227412ms)
Aug 27 07:05:19.653: INFO: (8) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 38.952024ms)
Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 21.404952ms)
Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 22.046627ms)
Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.544125ms)
Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.970566ms)
Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 22.160588ms)
Aug 27 07:05:19.676: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.290241ms)
Aug 27 07:05:19.676: INFO: (9) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 23.092409ms)
Aug 27 07:05:19.676: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.79955ms)
Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 23.294002ms)
Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 23.281859ms)
Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 24.369741ms)
Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 24.056571ms)
Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 24.438942ms)
Aug 27 07:05:19.678: INFO: (9) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 23.899046ms)
Aug 27 07:05:19.678: INFO: (9) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 24.909277ms)
Aug 27 07:05:19.679: INFO: (9) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 25.093427ms)
Aug 27 07:05:19.699: INFO: (10) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 20.244459ms)
Aug 27 07:05:19.701: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 22.36094ms)
Aug 27 07:05:19.701: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.425379ms)
Aug 27 07:05:19.702: INFO: (10) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.390359ms)
Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.430343ms)
Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 23.866781ms)
Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 24.050901ms)
Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 24.217533ms)
Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 24.464475ms)
Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 24.091616ms)
Aug 27 07:05:19.705: INFO: (10) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 26.345819ms)
Aug 27 07:05:19.706: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 26.761372ms)
Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 28.858531ms)
Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 29.008011ms)
Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 29.112512ms)
Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 28.889859ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 29.692912ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.237492ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 30.69005ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 30.56954ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 30.559388ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.544402ms)
Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 30.40094ms)
Aug 27 07:05:19.740: INFO: (11) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 30.9322ms)
Aug 27 07:05:19.740: INFO: (11) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 31.438352ms)
Aug 27 07:05:19.740: INFO: (11) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 30.949639ms)
Aug 27 07:05:19.741: INFO: (11) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 32.715221ms)
Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 32.872612ms)
Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 33.109027ms)
Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 32.656284ms)
Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 33.144221ms)
Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 33.02199ms)
Aug 27 07:05:19.758: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 15.439377ms)
Aug 27 07:05:19.758: INFO: (12) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 15.640752ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 21.999493ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 22.413411ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 22.335702ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 22.417016ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 22.518039ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 23.010724ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 22.159276ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 22.403974ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 22.664085ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 22.719394ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 22.877632ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.707981ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 22.494845ms)
Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 22.593604ms)
Aug 27 07:05:19.783: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 17.382244ms)
Aug 27 07:05:19.783: INFO: (13) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 17.313982ms)
Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 18.91545ms)
Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 19.364919ms)
Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 19.2935ms)
Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 19.290154ms)
Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.18165ms)
Aug 27 07:05:19.786: INFO: (13) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 19.862163ms)
Aug 27 07:05:19.786: INFO: (13) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 19.970784ms)
Aug 27 07:05:19.786: INFO: (13) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 20.13633ms)
Aug 27 07:05:19.791: INFO: (13) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 25.473033ms)
Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 26.14624ms)
Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 26.070304ms)
Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 25.73213ms)
Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 25.852203ms)
Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 26.045269ms)
Aug 27 07:05:19.807: INFO: (14) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 14.378827ms)
Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 15.596686ms)
Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 16.022278ms)
Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 15.905472ms)
Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 15.967223ms)
Aug 27 07:05:19.809: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 16.549742ms)
Aug 27 07:05:19.809: INFO: (14) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 16.312476ms)
Aug 27 07:05:19.809: INFO: (14) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 16.137113ms)
Aug 27 07:05:19.811: INFO: (14) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 18.175395ms)
Aug 27 07:05:19.811: INFO: (14) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 18.604389ms)
Aug 27 07:05:19.811: INFO: (14) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 18.101861ms)
Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 18.973517ms)
Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.001038ms)
Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 18.709206ms)
Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 18.754041ms)
Aug 27 07:05:19.815: INFO: (14) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 22.640392ms)
Aug 27 07:05:19.830: INFO: (15) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 15.459864ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 20.975502ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 21.882278ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.061881ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 20.99419ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 21.342677ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 21.817044ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 21.637296ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.257561ms)
Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.36571ms)
Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 24.206159ms)
Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 24.684025ms)
Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 25.266487ms)
Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 24.341464ms)
Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 24.434335ms)
Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 24.818694ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 13.374392ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 13.5289ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.515019ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.601519ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 13.793988ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 13.746922ms)
Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 13.845471ms)
Aug 27 07:05:19.857: INFO: (16) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 16.093511ms)
Aug 27 07:05:19.857: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 16.135486ms)
Aug 27 07:05:19.857: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 16.413935ms)
Aug 27 07:05:19.858: INFO: (16) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 17.363304ms)
Aug 27 07:05:19.858: INFO: (16) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 17.483676ms)
Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 18.278144ms)
Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 18.526547ms)
Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 18.434479ms)
Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 18.620718ms)
Aug 27 07:05:19.873: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 13.317813ms)
Aug 27 07:05:19.873: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.754296ms)
Aug 27 07:05:19.873: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 13.452747ms)
Aug 27 07:05:19.874: INFO: (17) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.77475ms)
Aug 27 07:05:19.874: INFO: (17) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 13.909024ms)
Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 18.483512ms)
Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 19.100566ms)
Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 19.197005ms)
Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 19.854766ms)
Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 19.608694ms)
Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 19.693057ms)
Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 20.435261ms)
Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 20.524359ms)
Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 20.620271ms)
Aug 27 07:05:19.880: INFO: (17) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 20.330192ms)
Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 21.109585ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 36.34674ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 36.34159ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 36.290323ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 36.807119ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 36.754789ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 36.931024ms)
Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 36.793919ms)
Aug 27 07:05:19.919: INFO: (18) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 37.010358ms)
Aug 27 07:05:19.919: INFO: (18) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 36.846787ms)
Aug 27 07:05:19.919: INFO: (18) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 36.911588ms)
Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 38.275376ms)
Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 38.043821ms)
Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 39.082138ms)
Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 38.997027ms)
Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 38.610166ms)
Aug 27 07:05:19.921: INFO: (18) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 39.308131ms)
Aug 27 07:05:19.950: INFO: (19) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 28.083546ms)
Aug 27 07:05:19.951: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 28.719727ms)
Aug 27 07:05:19.951: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 28.646563ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 30.124823ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 29.925521ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 30.377569ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.503543ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.924105ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 30.330089ms)
Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 30.960465ms)
Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 31.291642ms)
Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 32.010887ms)
Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 31.460297ms)
Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 31.389135ms)
Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 32.247535ms)
Aug 27 07:05:19.955: INFO: (19) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 32.947185ms)
STEP: deleting ReplicationController proxy-service-2j67l in namespace proxy-8494, will wait for the garbage collector to delete the pods 08/27/22 07:05:19.955
Aug 27 07:05:20.014: INFO: Deleting ReplicationController proxy-service-2j67l took: 5.013165ms
Aug 27 07:05:20.115: INFO: Terminating ReplicationController proxy-service-2j67l pods took: 101.124977ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Aug 27 07:05:22.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8494" for this suite. 08/27/22 07:05:22.22
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":347,"skipped":6462,"failed":0}
------------------------------
â€¢ [4.072 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:18.155
    Aug 27 07:05:18.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename proxy 08/27/22 07:05:18.156
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:18.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:18.189
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 08/27/22 07:05:18.203
    STEP: creating replication controller proxy-service-2j67l in namespace proxy-8494 08/27/22 07:05:18.204
    I0827 07:05:18.214447      19 runners.go:193] Created replication controller with name: proxy-service-2j67l, namespace: proxy-8494, replica count: 1
    I0827 07:05:19.266443      19 runners.go:193] proxy-service-2j67l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Aug 27 07:05:19.273: INFO: setup took 1.078792513s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 08/27/22 07:05:19.273
    Aug 27 07:05:19.308: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 32.99185ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 33.205293ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 35.169872ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 33.465646ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 33.724553ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 33.085834ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 35.342576ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 33.716337ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 33.006853ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 34.013992ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 32.928111ms)
    Aug 27 07:05:19.309: INFO: (0) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 33.86099ms)
    Aug 27 07:05:19.315: INFO: (0) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 38.900346ms)
    Aug 27 07:05:19.332: INFO: (0) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 55.365644ms)
    Aug 27 07:05:19.332: INFO: (0) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 55.477127ms)
    Aug 27 07:05:19.332: INFO: (0) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 55.598324ms)
    Aug 27 07:05:19.357: INFO: (1) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 25.671061ms)
    Aug 27 07:05:19.357: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 25.563079ms)
    Aug 27 07:05:19.357: INFO: (1) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 25.487946ms)
    Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 28.145167ms)
    Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 28.337664ms)
    Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 28.238503ms)
    Aug 27 07:05:19.361: INFO: (1) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 27.920531ms)
    Aug 27 07:05:19.364: INFO: (1) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 31.160868ms)
    Aug 27 07:05:19.364: INFO: (1) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 31.452966ms)
    Aug 27 07:05:19.364: INFO: (1) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 31.110649ms)
    Aug 27 07:05:19.368: INFO: (1) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 35.502755ms)
    Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 36.722721ms)
    Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 36.935265ms)
    Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 36.491769ms)
    Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 36.463988ms)
    Aug 27 07:05:19.369: INFO: (1) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 36.848323ms)
    Aug 27 07:05:19.399: INFO: (2) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 29.750338ms)
    Aug 27 07:05:19.427: INFO: (2) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 55.241792ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 55.583544ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 57.337762ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 57.629588ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 57.743695ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 57.69638ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 57.603048ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 57.437268ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 57.904017ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 55.690373ms)
    Aug 27 07:05:19.428: INFO: (2) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 57.510634ms)
    Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 61.409467ms)
    Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 61.510189ms)
    Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 61.063001ms)
    Aug 27 07:05:19.431: INFO: (2) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 61.307611ms)
    Aug 27 07:05:19.451: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.505642ms)
    Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 19.339383ms)
    Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.291291ms)
    Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 19.673492ms)
    Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 19.761361ms)
    Aug 27 07:05:19.452: INFO: (3) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 20.492111ms)
    Aug 27 07:05:19.453: INFO: (3) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 20.580911ms)
    Aug 27 07:05:19.453: INFO: (3) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 21.327154ms)
    Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 22.188524ms)
    Aug 27 07:05:19.454: INFO: (3) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 21.883153ms)
    Aug 27 07:05:19.454: INFO: (3) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 22.39902ms)
    Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 22.987542ms)
    Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 22.798915ms)
    Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 22.935632ms)
    Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 22.417735ms)
    Aug 27 07:05:19.455: INFO: (3) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 22.886171ms)
    Aug 27 07:05:19.480: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 24.129367ms)
    Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 24.847064ms)
    Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 24.900074ms)
    Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 24.805274ms)
    Aug 27 07:05:19.481: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 25.224863ms)
    Aug 27 07:05:19.482: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 26.25613ms)
    Aug 27 07:05:19.482: INFO: (4) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 26.140059ms)
    Aug 27 07:05:19.483: INFO: (4) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 26.780545ms)
    Aug 27 07:05:19.483: INFO: (4) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 26.857463ms)
    Aug 27 07:05:19.483: INFO: (4) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 27.517725ms)
    Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 28.753061ms)
    Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 28.873303ms)
    Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 28.863414ms)
    Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 28.777263ms)
    Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 28.883286ms)
    Aug 27 07:05:19.485: INFO: (4) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 29.154303ms)
    Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.100276ms)
    Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 23.535048ms)
    Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 23.782253ms)
    Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 23.391321ms)
    Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 23.356295ms)
    Aug 27 07:05:19.509: INFO: (5) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.326566ms)
    Aug 27 07:05:19.510: INFO: (5) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 24.090293ms)
    Aug 27 07:05:19.511: INFO: (5) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 24.971025ms)
    Aug 27 07:05:19.511: INFO: (5) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 25.607506ms)
    Aug 27 07:05:19.511: INFO: (5) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 25.015494ms)
    Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 27.606133ms)
    Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 27.136669ms)
    Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 27.493253ms)
    Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 27.766987ms)
    Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 27.685469ms)
    Aug 27 07:05:19.513: INFO: (5) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 28.007205ms)
    Aug 27 07:05:19.546: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 32.194837ms)
    Aug 27 07:05:19.554: INFO: (6) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 40.419783ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 41.226586ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 41.137011ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 41.871507ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 41.821498ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 42.003196ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 42.148506ms)
    Aug 27 07:05:19.555: INFO: (6) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 41.171044ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 41.987448ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 41.966805ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 42.571059ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 42.110384ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 42.129634ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 42.007871ms)
    Aug 27 07:05:19.556: INFO: (6) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 42.525018ms)
    Aug 27 07:05:19.593: INFO: (7) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 35.621452ms)
    Aug 27 07:05:19.609: INFO: (7) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 49.511635ms)
    Aug 27 07:05:19.609: INFO: (7) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 49.299916ms)
    Aug 27 07:05:19.609: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 49.920037ms)
    Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 49.821912ms)
    Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 50.092892ms)
    Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 50.036376ms)
    Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 50.680793ms)
    Aug 27 07:05:19.610: INFO: (7) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 50.642239ms)
    Aug 27 07:05:19.611: INFO: (7) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 50.576359ms)
    Aug 27 07:05:19.612: INFO: (7) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 52.788687ms)
    Aug 27 07:05:19.612: INFO: (7) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 52.790302ms)
    Aug 27 07:05:19.612: INFO: (7) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 54.898518ms)
    Aug 27 07:05:19.613: INFO: (7) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 52.486362ms)
    Aug 27 07:05:19.613: INFO: (7) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 53.538934ms)
    Aug 27 07:05:19.613: INFO: (7) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 52.998164ms)
    Aug 27 07:05:19.635: INFO: (8) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 21.879767ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 33.869681ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 33.642642ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 34.135637ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 34.600065ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 35.067786ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 34.792574ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 35.241487ms)
    Aug 27 07:05:19.648: INFO: (8) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 34.256029ms)
    Aug 27 07:05:19.651: INFO: (8) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 37.36047ms)
    Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 37.389066ms)
    Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 37.942737ms)
    Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 37.628307ms)
    Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 38.047031ms)
    Aug 27 07:05:19.652: INFO: (8) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 38.227412ms)
    Aug 27 07:05:19.653: INFO: (8) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 38.952024ms)
    Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 21.404952ms)
    Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 22.046627ms)
    Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.544125ms)
    Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.970566ms)
    Aug 27 07:05:19.675: INFO: (9) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 22.160588ms)
    Aug 27 07:05:19.676: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.290241ms)
    Aug 27 07:05:19.676: INFO: (9) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 23.092409ms)
    Aug 27 07:05:19.676: INFO: (9) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.79955ms)
    Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 23.294002ms)
    Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 23.281859ms)
    Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 24.369741ms)
    Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 24.056571ms)
    Aug 27 07:05:19.677: INFO: (9) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 24.438942ms)
    Aug 27 07:05:19.678: INFO: (9) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 23.899046ms)
    Aug 27 07:05:19.678: INFO: (9) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 24.909277ms)
    Aug 27 07:05:19.679: INFO: (9) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 25.093427ms)
    Aug 27 07:05:19.699: INFO: (10) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 20.244459ms)
    Aug 27 07:05:19.701: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 22.36094ms)
    Aug 27 07:05:19.701: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.425379ms)
    Aug 27 07:05:19.702: INFO: (10) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.390359ms)
    Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 23.430343ms)
    Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 23.866781ms)
    Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 24.050901ms)
    Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 24.217533ms)
    Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 24.464475ms)
    Aug 27 07:05:19.703: INFO: (10) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 24.091616ms)
    Aug 27 07:05:19.705: INFO: (10) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 26.345819ms)
    Aug 27 07:05:19.706: INFO: (10) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 26.761372ms)
    Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 28.858531ms)
    Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 29.008011ms)
    Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 29.112512ms)
    Aug 27 07:05:19.708: INFO: (10) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 28.889859ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 29.692912ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.237492ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 30.69005ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 30.56954ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 30.559388ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.544402ms)
    Aug 27 07:05:19.739: INFO: (11) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 30.40094ms)
    Aug 27 07:05:19.740: INFO: (11) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 30.9322ms)
    Aug 27 07:05:19.740: INFO: (11) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 31.438352ms)
    Aug 27 07:05:19.740: INFO: (11) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 30.949639ms)
    Aug 27 07:05:19.741: INFO: (11) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 32.715221ms)
    Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 32.872612ms)
    Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 33.109027ms)
    Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 32.656284ms)
    Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 33.144221ms)
    Aug 27 07:05:19.742: INFO: (11) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 33.02199ms)
    Aug 27 07:05:19.758: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 15.439377ms)
    Aug 27 07:05:19.758: INFO: (12) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 15.640752ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 21.999493ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 22.413411ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 22.335702ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 22.417016ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 22.518039ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 23.010724ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 22.159276ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 22.403974ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 22.664085ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 22.719394ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 22.877632ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.707981ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 22.494845ms)
    Aug 27 07:05:19.765: INFO: (12) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 22.593604ms)
    Aug 27 07:05:19.783: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 17.382244ms)
    Aug 27 07:05:19.783: INFO: (13) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 17.313982ms)
    Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 18.91545ms)
    Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 19.364919ms)
    Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 19.2935ms)
    Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 19.290154ms)
    Aug 27 07:05:19.785: INFO: (13) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.18165ms)
    Aug 27 07:05:19.786: INFO: (13) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 19.862163ms)
    Aug 27 07:05:19.786: INFO: (13) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 19.970784ms)
    Aug 27 07:05:19.786: INFO: (13) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 20.13633ms)
    Aug 27 07:05:19.791: INFO: (13) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 25.473033ms)
    Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 26.14624ms)
    Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 26.070304ms)
    Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 25.73213ms)
    Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 25.852203ms)
    Aug 27 07:05:19.792: INFO: (13) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 26.045269ms)
    Aug 27 07:05:19.807: INFO: (14) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 14.378827ms)
    Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 15.596686ms)
    Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 16.022278ms)
    Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 15.905472ms)
    Aug 27 07:05:19.808: INFO: (14) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 15.967223ms)
    Aug 27 07:05:19.809: INFO: (14) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 16.549742ms)
    Aug 27 07:05:19.809: INFO: (14) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 16.312476ms)
    Aug 27 07:05:19.809: INFO: (14) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 16.137113ms)
    Aug 27 07:05:19.811: INFO: (14) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 18.175395ms)
    Aug 27 07:05:19.811: INFO: (14) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 18.604389ms)
    Aug 27 07:05:19.811: INFO: (14) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 18.101861ms)
    Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 18.973517ms)
    Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 19.001038ms)
    Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 18.709206ms)
    Aug 27 07:05:19.812: INFO: (14) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 18.754041ms)
    Aug 27 07:05:19.815: INFO: (14) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 22.640392ms)
    Aug 27 07:05:19.830: INFO: (15) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 15.459864ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 20.975502ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 21.882278ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 22.061881ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 20.99419ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 21.342677ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 21.817044ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 21.637296ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.257561ms)
    Aug 27 07:05:19.837: INFO: (15) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 21.36571ms)
    Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 24.206159ms)
    Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 24.684025ms)
    Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 25.266487ms)
    Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 24.341464ms)
    Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 24.434335ms)
    Aug 27 07:05:19.840: INFO: (15) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 24.818694ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 13.374392ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 13.5289ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.515019ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.601519ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 13.793988ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 13.746922ms)
    Aug 27 07:05:19.854: INFO: (16) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 13.845471ms)
    Aug 27 07:05:19.857: INFO: (16) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 16.093511ms)
    Aug 27 07:05:19.857: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 16.135486ms)
    Aug 27 07:05:19.857: INFO: (16) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 16.413935ms)
    Aug 27 07:05:19.858: INFO: (16) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 17.363304ms)
    Aug 27 07:05:19.858: INFO: (16) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 17.483676ms)
    Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 18.278144ms)
    Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 18.526547ms)
    Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 18.434479ms)
    Aug 27 07:05:19.859: INFO: (16) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 18.620718ms)
    Aug 27 07:05:19.873: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 13.317813ms)
    Aug 27 07:05:19.873: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.754296ms)
    Aug 27 07:05:19.873: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 13.452747ms)
    Aug 27 07:05:19.874: INFO: (17) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 13.77475ms)
    Aug 27 07:05:19.874: INFO: (17) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 13.909024ms)
    Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 18.483512ms)
    Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 19.100566ms)
    Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 19.197005ms)
    Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 19.854766ms)
    Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 19.608694ms)
    Aug 27 07:05:19.879: INFO: (17) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 19.693057ms)
    Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 20.435261ms)
    Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 20.524359ms)
    Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 20.620271ms)
    Aug 27 07:05:19.880: INFO: (17) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 20.330192ms)
    Aug 27 07:05:19.881: INFO: (17) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 21.109585ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 36.34674ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 36.34159ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 36.290323ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 36.807119ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 36.754789ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 36.931024ms)
    Aug 27 07:05:19.918: INFO: (18) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 36.793919ms)
    Aug 27 07:05:19.919: INFO: (18) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 37.010358ms)
    Aug 27 07:05:19.919: INFO: (18) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 36.846787ms)
    Aug 27 07:05:19.919: INFO: (18) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 36.911588ms)
    Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 38.275376ms)
    Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 38.043821ms)
    Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 39.082138ms)
    Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 38.997027ms)
    Aug 27 07:05:19.920: INFO: (18) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 38.610166ms)
    Aug 27 07:05:19.921: INFO: (18) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 39.308131ms)
    Aug 27 07:05:19.950: INFO: (19) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:443/proxy/tlsrewritem... (200; 28.083546ms)
    Aug 27 07:05:19.951: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb/proxy/rewriteme">test</a> (200; 28.719727ms)
    Aug 27 07:05:19.951: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:1080/proxy/rewriteme">test<... (200; 28.646563ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:160/proxy/: foo (200; 30.124823ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:160/proxy/: foo (200; 29.925521ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/: <a href="/api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:1080/proxy/rewriteme">... (200; 30.377569ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/http:proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.503543ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/proxy-service-2j67l-bszlb:162/proxy/: bar (200; 30.924105ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:462/proxy/: tls qux (200; 30.330089ms)
    Aug 27 07:05:19.952: INFO: (19) /api/v1/namespaces/proxy-8494/pods/https:proxy-service-2j67l-bszlb:460/proxy/: tls baz (200; 30.960465ms)
    Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname2/proxy/: bar (200; 31.291642ms)
    Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/http:proxy-service-2j67l:portname1/proxy/: foo (200; 32.010887ms)
    Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname2/proxy/: bar (200; 31.460297ms)
    Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/proxy-service-2j67l:portname1/proxy/: foo (200; 31.389135ms)
    Aug 27 07:05:19.954: INFO: (19) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname2/proxy/: tls qux (200; 32.247535ms)
    Aug 27 07:05:19.955: INFO: (19) /api/v1/namespaces/proxy-8494/services/https:proxy-service-2j67l:tlsportname1/proxy/: tls baz (200; 32.947185ms)
    STEP: deleting ReplicationController proxy-service-2j67l in namespace proxy-8494, will wait for the garbage collector to delete the pods 08/27/22 07:05:19.955
    Aug 27 07:05:20.014: INFO: Deleting ReplicationController proxy-service-2j67l took: 5.013165ms
    Aug 27 07:05:20.115: INFO: Terminating ReplicationController proxy-service-2j67l pods took: 101.124977ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Aug 27 07:05:22.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-8494" for this suite. 08/27/22 07:05:22.22
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:22.228
Aug 27 07:05:22.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename certificates 08/27/22 07:05:22.23
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:22.25
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:22.258
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 08/27/22 07:05:23.334
STEP: getting /apis/certificates.k8s.io 08/27/22 07:05:23.342
STEP: getting /apis/certificates.k8s.io/v1 08/27/22 07:05:23.35
STEP: creating 08/27/22 07:05:23.353
STEP: getting 08/27/22 07:05:23.374
STEP: listing 08/27/22 07:05:23.377
STEP: watching 08/27/22 07:05:23.383
Aug 27 07:05:23.383: INFO: starting watch
STEP: patching 08/27/22 07:05:23.387
STEP: updating 08/27/22 07:05:23.395
Aug 27 07:05:23.403: INFO: waiting for watch events with expected annotations
Aug 27 07:05:23.403: INFO: saw patched and updated annotations
STEP: getting /approval 08/27/22 07:05:23.403
STEP: patching /approval 08/27/22 07:05:23.409
STEP: updating /approval 08/27/22 07:05:23.415
STEP: getting /status 08/27/22 07:05:23.424
STEP: patching /status 08/27/22 07:05:23.427
STEP: updating /status 08/27/22 07:05:23.437
STEP: deleting 08/27/22 07:05:23.446
STEP: deleting a collection 08/27/22 07:05:23.463
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 07:05:23.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-9502" for this suite. 08/27/22 07:05:23.487
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":348,"skipped":6477,"failed":0}
------------------------------
â€¢ [1.267 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:22.228
    Aug 27 07:05:22.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename certificates 08/27/22 07:05:22.23
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:22.25
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:22.258
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 08/27/22 07:05:23.334
    STEP: getting /apis/certificates.k8s.io 08/27/22 07:05:23.342
    STEP: getting /apis/certificates.k8s.io/v1 08/27/22 07:05:23.35
    STEP: creating 08/27/22 07:05:23.353
    STEP: getting 08/27/22 07:05:23.374
    STEP: listing 08/27/22 07:05:23.377
    STEP: watching 08/27/22 07:05:23.383
    Aug 27 07:05:23.383: INFO: starting watch
    STEP: patching 08/27/22 07:05:23.387
    STEP: updating 08/27/22 07:05:23.395
    Aug 27 07:05:23.403: INFO: waiting for watch events with expected annotations
    Aug 27 07:05:23.403: INFO: saw patched and updated annotations
    STEP: getting /approval 08/27/22 07:05:23.403
    STEP: patching /approval 08/27/22 07:05:23.409
    STEP: updating /approval 08/27/22 07:05:23.415
    STEP: getting /status 08/27/22 07:05:23.424
    STEP: patching /status 08/27/22 07:05:23.427
    STEP: updating /status 08/27/22 07:05:23.437
    STEP: deleting 08/27/22 07:05:23.446
    STEP: deleting a collection 08/27/22 07:05:23.463
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 07:05:23.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-9502" for this suite. 08/27/22 07:05:23.487
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:23.497
Aug 27 07:05:23.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubectl 08/27/22 07:05:23.498
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:23.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:23.53
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 08/27/22 07:05:23.545
Aug 27 07:05:23.545: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Aug 27 07:05:23.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
Aug 27 07:05:24.298: INFO: stderr: ""
Aug 27 07:05:24.298: INFO: stdout: "service/agnhost-replica created\n"
Aug 27 07:05:24.298: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Aug 27 07:05:24.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
Aug 27 07:05:24.597: INFO: stderr: ""
Aug 27 07:05:24.597: INFO: stdout: "service/agnhost-primary created\n"
Aug 27 07:05:24.599: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 27 07:05:24.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
Aug 27 07:05:24.899: INFO: stderr: ""
Aug 27 07:05:24.899: INFO: stdout: "service/frontend created\n"
Aug 27 07:05:24.900: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Aug 27 07:05:24.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
Aug 27 07:05:25.220: INFO: stderr: ""
Aug 27 07:05:25.220: INFO: stdout: "deployment.apps/frontend created\n"
Aug 27 07:05:25.220: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 27 07:05:25.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
Aug 27 07:05:25.443: INFO: stderr: ""
Aug 27 07:05:25.443: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Aug 27 07:05:25.443: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 27 07:05:25.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
Aug 27 07:05:25.665: INFO: stderr: ""
Aug 27 07:05:25.665: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 08/27/22 07:05:25.665
Aug 27 07:05:25.665: INFO: Waiting for all frontend pods to be Running.
Aug 27 07:05:30.717: INFO: Waiting for frontend to serve content.
Aug 27 07:05:30.739: INFO: Trying to add a new entry to the guestbook.
Aug 27 07:05:30.775: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 08/27/22 07:05:30.786
Aug 27 07:05:30.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
Aug 27 07:05:30.902: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 07:05:30.902: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 08/27/22 07:05:30.902
Aug 27 07:05:30.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
Aug 27 07:05:31.049: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 07:05:31.049: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 08/27/22 07:05:31.049
Aug 27 07:05:31.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
Aug 27 07:05:31.231: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 07:05:31.231: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 08/27/22 07:05:31.231
Aug 27 07:05:31.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
Aug 27 07:05:31.401: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 07:05:31.402: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 08/27/22 07:05:31.402
Aug 27 07:05:31.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
Aug 27 07:05:31.532: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 07:05:31.532: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 08/27/22 07:05:31.532
Aug 27 07:05:31.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
Aug 27 07:05:31.618: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 27 07:05:31.618: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Aug 27 07:05:31.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8452" for this suite. 08/27/22 07:05:31.649
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":349,"skipped":6479,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.170 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:23.497
    Aug 27 07:05:23.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubectl 08/27/22 07:05:23.498
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:23.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:23.53
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 08/27/22 07:05:23.545
    Aug 27 07:05:23.545: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Aug 27 07:05:23.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
    Aug 27 07:05:24.298: INFO: stderr: ""
    Aug 27 07:05:24.298: INFO: stdout: "service/agnhost-replica created\n"
    Aug 27 07:05:24.298: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Aug 27 07:05:24.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
    Aug 27 07:05:24.597: INFO: stderr: ""
    Aug 27 07:05:24.597: INFO: stdout: "service/agnhost-primary created\n"
    Aug 27 07:05:24.599: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Aug 27 07:05:24.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
    Aug 27 07:05:24.899: INFO: stderr: ""
    Aug 27 07:05:24.899: INFO: stdout: "service/frontend created\n"
    Aug 27 07:05:24.900: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Aug 27 07:05:24.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
    Aug 27 07:05:25.220: INFO: stderr: ""
    Aug 27 07:05:25.220: INFO: stdout: "deployment.apps/frontend created\n"
    Aug 27 07:05:25.220: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Aug 27 07:05:25.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
    Aug 27 07:05:25.443: INFO: stderr: ""
    Aug 27 07:05:25.443: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Aug 27 07:05:25.443: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Aug 27 07:05:25.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 create -f -'
    Aug 27 07:05:25.665: INFO: stderr: ""
    Aug 27 07:05:25.665: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 08/27/22 07:05:25.665
    Aug 27 07:05:25.665: INFO: Waiting for all frontend pods to be Running.
    Aug 27 07:05:30.717: INFO: Waiting for frontend to serve content.
    Aug 27 07:05:30.739: INFO: Trying to add a new entry to the guestbook.
    Aug 27 07:05:30.775: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 08/27/22 07:05:30.786
    Aug 27 07:05:30.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
    Aug 27 07:05:30.902: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 07:05:30.902: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 08/27/22 07:05:30.902
    Aug 27 07:05:30.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
    Aug 27 07:05:31.049: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 07:05:31.049: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 08/27/22 07:05:31.049
    Aug 27 07:05:31.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
    Aug 27 07:05:31.231: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 07:05:31.231: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 08/27/22 07:05:31.231
    Aug 27 07:05:31.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
    Aug 27 07:05:31.401: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 07:05:31.402: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 08/27/22 07:05:31.402
    Aug 27 07:05:31.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
    Aug 27 07:05:31.532: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 07:05:31.532: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 08/27/22 07:05:31.532
    Aug 27 07:05:31.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2032420697 --namespace=kubectl-8452 delete --grace-period=0 --force -f -'
    Aug 27 07:05:31.618: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Aug 27 07:05:31.618: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Aug 27 07:05:31.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8452" for this suite. 08/27/22 07:05:31.649
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:31.667
Aug 27 07:05:31.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename emptydir 08/27/22 07:05:31.668
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:31.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:31.781
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 08/27/22 07:05:31.786
Aug 27 07:05:31.794: INFO: Waiting up to 5m0s for pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e" in namespace "emptydir-8254" to be "Succeeded or Failed"
Aug 27 07:05:31.798: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.888105ms
Aug 27 07:05:33.803: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008696808s
Aug 27 07:05:35.801: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007403944s
STEP: Saw pod success 08/27/22 07:05:35.801
Aug 27 07:05:35.802: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e" satisfied condition "Succeeded or Failed"
Aug 27 07:05:35.804: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e container test-container: <nil>
STEP: delete the pod 08/27/22 07:05:35.829
Aug 27 07:05:35.861: INFO: Waiting for pod pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e to disappear
Aug 27 07:05:35.870: INFO: Pod pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Aug 27 07:05:35.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8254" for this suite. 08/27/22 07:05:35.88
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":350,"skipped":6486,"failed":0}
------------------------------
â€¢ [4.228 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:31.667
    Aug 27 07:05:31.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename emptydir 08/27/22 07:05:31.668
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:31.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:31.781
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 08/27/22 07:05:31.786
    Aug 27 07:05:31.794: INFO: Waiting up to 5m0s for pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e" in namespace "emptydir-8254" to be "Succeeded or Failed"
    Aug 27 07:05:31.798: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.888105ms
    Aug 27 07:05:33.803: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008696808s
    Aug 27 07:05:35.801: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007403944s
    STEP: Saw pod success 08/27/22 07:05:35.801
    Aug 27 07:05:35.802: INFO: Pod "pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e" satisfied condition "Succeeded or Failed"
    Aug 27 07:05:35.804: INFO: Trying to get logs from node ip-10-0-31-158 pod pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e container test-container: <nil>
    STEP: delete the pod 08/27/22 07:05:35.829
    Aug 27 07:05:35.861: INFO: Waiting for pod pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e to disappear
    Aug 27 07:05:35.870: INFO: Pod pod-baed1ad1-abec-4c78-8e30-1d2333cebc7e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Aug 27 07:05:35.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8254" for this suite. 08/27/22 07:05:35.88
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:35.899
Aug 27 07:05:35.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename namespaces 08/27/22 07:05:35.9
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:35.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:35.964
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 08/27/22 07:05:35.976
Aug 27 07:05:35.980: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 08/27/22 07:05:35.98
Aug 27 07:05:35.998: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 08/27/22 07:05:35.998
Aug 27 07:05:36.020: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Aug 27 07:05:36.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1390" for this suite. 08/27/22 07:05:36.028
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":351,"skipped":6491,"failed":0}
------------------------------
â€¢ [0.134 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:35.899
    Aug 27 07:05:35.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename namespaces 08/27/22 07:05:35.9
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:35.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:35.964
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 08/27/22 07:05:35.976
    Aug 27 07:05:35.980: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 08/27/22 07:05:35.98
    Aug 27 07:05:35.998: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 08/27/22 07:05:35.998
    Aug 27 07:05:36.020: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 07:05:36.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1390" for this suite. 08/27/22 07:05:36.028
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:36.034
Aug 27 07:05:36.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 07:05:36.035
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:36.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:36.056
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 08/27/22 07:05:36.066
STEP: delete the rc 08/27/22 07:05:41.103
STEP: wait for the rc to be deleted 08/27/22 07:05:41.165
Aug 27 07:05:42.207: INFO: 80 pods remaining
Aug 27 07:05:42.207: INFO: 80 pods has nil DeletionTimestamp
Aug 27 07:05:42.207: INFO: 
Aug 27 07:05:43.429: INFO: 77 pods remaining
Aug 27 07:05:43.429: INFO: 68 pods has nil DeletionTimestamp
Aug 27 07:05:43.429: INFO: 
Aug 27 07:05:44.209: INFO: 60 pods remaining
Aug 27 07:05:44.209: INFO: 60 pods has nil DeletionTimestamp
Aug 27 07:05:44.209: INFO: 
Aug 27 07:05:45.223: INFO: 40 pods remaining
Aug 27 07:05:45.223: INFO: 40 pods has nil DeletionTimestamp
Aug 27 07:05:45.223: INFO: 
Aug 27 07:05:46.285: INFO: 32 pods remaining
Aug 27 07:05:46.285: INFO: 30 pods has nil DeletionTimestamp
Aug 27 07:05:46.285: INFO: 
Aug 27 07:05:47.215: INFO: 20 pods remaining
Aug 27 07:05:47.215: INFO: 20 pods has nil DeletionTimestamp
Aug 27 07:05:47.215: INFO: 
STEP: Gathering metrics 08/27/22 07:05:48.179
Aug 27 07:05:48.227: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
Aug 27 07:05:48.243: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 16.490161ms
Aug 27 07:05:48.243: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
Aug 27 07:05:48.243: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
Aug 27 07:05:48.429: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 07:05:48.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-885" for this suite. 08/27/22 07:05:48.44
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":352,"skipped":6502,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.420 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:36.034
    Aug 27 07:05:36.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 07:05:36.035
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:36.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:36.056
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 08/27/22 07:05:36.066
    STEP: delete the rc 08/27/22 07:05:41.103
    STEP: wait for the rc to be deleted 08/27/22 07:05:41.165
    Aug 27 07:05:42.207: INFO: 80 pods remaining
    Aug 27 07:05:42.207: INFO: 80 pods has nil DeletionTimestamp
    Aug 27 07:05:42.207: INFO: 
    Aug 27 07:05:43.429: INFO: 77 pods remaining
    Aug 27 07:05:43.429: INFO: 68 pods has nil DeletionTimestamp
    Aug 27 07:05:43.429: INFO: 
    Aug 27 07:05:44.209: INFO: 60 pods remaining
    Aug 27 07:05:44.209: INFO: 60 pods has nil DeletionTimestamp
    Aug 27 07:05:44.209: INFO: 
    Aug 27 07:05:45.223: INFO: 40 pods remaining
    Aug 27 07:05:45.223: INFO: 40 pods has nil DeletionTimestamp
    Aug 27 07:05:45.223: INFO: 
    Aug 27 07:05:46.285: INFO: 32 pods remaining
    Aug 27 07:05:46.285: INFO: 30 pods has nil DeletionTimestamp
    Aug 27 07:05:46.285: INFO: 
    Aug 27 07:05:47.215: INFO: 20 pods remaining
    Aug 27 07:05:47.215: INFO: 20 pods has nil DeletionTimestamp
    Aug 27 07:05:47.215: INFO: 
    STEP: Gathering metrics 08/27/22 07:05:48.179
    Aug 27 07:05:48.227: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
    Aug 27 07:05:48.243: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 16.490161ms
    Aug 27 07:05:48.243: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
    Aug 27 07:05:48.243: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
    Aug 27 07:05:48.429: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 07:05:48.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-885" for this suite. 08/27/22 07:05:48.44
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:05:48.456
Aug 27 07:05:48.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename projected 08/27/22 07:05:48.457
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:48.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:48.493
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 08/27/22 07:05:48.499
Aug 27 07:05:48.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797" in namespace "projected-2036" to be "Succeeded or Failed"
Aug 27 07:05:48.521: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 6.962472ms
Aug 27 07:05:50.526: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011689762s
Aug 27 07:05:52.527: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013090348s
Aug 27 07:05:54.525: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010398823s
Aug 27 07:05:56.525: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010552342s
Aug 27 07:05:58.525: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 10.010476275s
Aug 27 07:06:00.526: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 12.011382286s
Aug 27 07:06:02.545: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.03049222s
STEP: Saw pod success 08/27/22 07:06:02.545
Aug 27 07:06:02.545: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797" satisfied condition "Succeeded or Failed"
Aug 27 07:06:02.555: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797 container client-container: <nil>
STEP: delete the pod 08/27/22 07:06:02.564
Aug 27 07:06:02.578: INFO: Waiting for pod downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797 to disappear
Aug 27 07:06:02.591: INFO: Pod downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Aug 27 07:06:02.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2036" for this suite. 08/27/22 07:06:02.605
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":353,"skipped":6531,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.172 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:05:48.456
    Aug 27 07:05:48.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename projected 08/27/22 07:05:48.457
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:05:48.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:05:48.493
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 08/27/22 07:05:48.499
    Aug 27 07:05:48.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797" in namespace "projected-2036" to be "Succeeded or Failed"
    Aug 27 07:05:48.521: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 6.962472ms
    Aug 27 07:05:50.526: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011689762s
    Aug 27 07:05:52.527: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013090348s
    Aug 27 07:05:54.525: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010398823s
    Aug 27 07:05:56.525: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010552342s
    Aug 27 07:05:58.525: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 10.010476275s
    Aug 27 07:06:00.526: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Pending", Reason="", readiness=false. Elapsed: 12.011382286s
    Aug 27 07:06:02.545: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.03049222s
    STEP: Saw pod success 08/27/22 07:06:02.545
    Aug 27 07:06:02.545: INFO: Pod "downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797" satisfied condition "Succeeded or Failed"
    Aug 27 07:06:02.555: INFO: Trying to get logs from node ip-10-0-47-192 pod downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797 container client-container: <nil>
    STEP: delete the pod 08/27/22 07:06:02.564
    Aug 27 07:06:02.578: INFO: Waiting for pod downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797 to disappear
    Aug 27 07:06:02.591: INFO: Pod downwardapi-volume-b615d5a5-6f7e-4b26-bcfc-d2ade6909797 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Aug 27 07:06:02.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2036" for this suite. 08/27/22 07:06:02.605
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:02.642
Aug 27 07:06:02.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename deployment 08/27/22 07:06:02.662
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:02.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:02.701
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Aug 27 07:06:02.711: INFO: Creating simple deployment test-new-deployment
Aug 27 07:06:02.788: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 08/27/22 07:06:04.805
STEP: updating a scale subresource 08/27/22 07:06:04.81
STEP: verifying the deployment Spec.Replicas was modified 08/27/22 07:06:04.815
STEP: Patch a scale subresource 08/27/22 07:06:04.817
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Aug 27 07:06:04.856: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-7368  363e8fe3-93ca-4d23-b259-b16503419c1f 33404 3 2022-08-27 07:06:02 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-08-27 07:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00401f178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-27 07:06:04 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-08-27 07:06:04 +0000 UTC,LastTransitionTime:2022-08-27 07:06:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 27 07:06:04.880: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-7368  ac6c005f-ab0c-48de-8807-13a231bbda5b 33411 2 2022-08-27 07:06:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 363e8fe3-93ca-4d23-b259-b16503419c1f 0xc00382e347 0xc00382e348}] [] [{kube-controller-manager Update apps/v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"363e8fe3-93ca-4d23-b259-b16503419c1f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00382e3d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 27 07:06:04.899: INFO: Pod "test-new-deployment-845c8977d9-498fg" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-498fg test-new-deployment-845c8977d9- deployment-7368  85293bdc-82d5-4bca-a21a-846b22c72baa 33399 0 2022-08-27 07:06:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:46f261f40e8ea9329683210835f1a5713a976204b75b4f6c4f5343ae6909c204 cni.projectcalico.org/podIP:10.2.35.125/32 cni.projectcalico.org/podIPs:10.2.35.125/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 ac6c005f-ab0c-48de-8807-13a231bbda5b 0xc00382e7b7 0xc00382e7b8}] [] [{kube-controller-manager Update v1 2022-08-27 07:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac6c005f-ab0c-48de-8807-13a231bbda5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 07:06:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.125\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gt8n9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gt8n9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.125,StartTime:2022-08-27 07:06:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 07:06:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c02c5300d38201ee54a918f8587841b501fb0a8f4841c84b6aaa293138423227,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.125,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 27 07:06:04.899: INFO: Pod "test-new-deployment-845c8977d9-k7445" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-k7445 test-new-deployment-845c8977d9- deployment-7368  108099c3-9bc6-4813-8ab1-3569f862ff64 33410 0 2022-08-27 07:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 ac6c005f-ab0c-48de-8807-13a231bbda5b 0xc00382e9c0 0xc00382e9c1}] [] [{kube-controller-manager Update v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac6c005f-ab0c-48de-8807-13a231bbda5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtx9t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtx9t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Aug 27 07:06:04.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7368" for this suite. 08/27/22 07:06:04.925
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":354,"skipped":6557,"failed":0}
------------------------------
â€¢ [2.307 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:02.642
    Aug 27 07:06:02.642: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename deployment 08/27/22 07:06:02.662
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:02.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:02.701
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Aug 27 07:06:02.711: INFO: Creating simple deployment test-new-deployment
    Aug 27 07:06:02.788: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 08/27/22 07:06:04.805
    STEP: updating a scale subresource 08/27/22 07:06:04.81
    STEP: verifying the deployment Spec.Replicas was modified 08/27/22 07:06:04.815
    STEP: Patch a scale subresource 08/27/22 07:06:04.817
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Aug 27 07:06:04.856: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-7368  363e8fe3-93ca-4d23-b259-b16503419c1f 33404 3 2022-08-27 07:06:02 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-08-27 07:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00401f178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-27 07:06:04 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-08-27 07:06:04 +0000 UTC,LastTransitionTime:2022-08-27 07:06:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Aug 27 07:06:04.880: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-7368  ac6c005f-ab0c-48de-8807-13a231bbda5b 33411 2 2022-08-27 07:06:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 363e8fe3-93ca-4d23-b259-b16503419c1f 0xc00382e347 0xc00382e348}] [] [{kube-controller-manager Update apps/v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"363e8fe3-93ca-4d23-b259-b16503419c1f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00382e3d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Aug 27 07:06:04.899: INFO: Pod "test-new-deployment-845c8977d9-498fg" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-498fg test-new-deployment-845c8977d9- deployment-7368  85293bdc-82d5-4bca-a21a-846b22c72baa 33399 0 2022-08-27 07:06:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:46f261f40e8ea9329683210835f1a5713a976204b75b4f6c4f5343ae6909c204 cni.projectcalico.org/podIP:10.2.35.125/32 cni.projectcalico.org/podIPs:10.2.35.125/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 ac6c005f-ab0c-48de-8807-13a231bbda5b 0xc00382e7b7 0xc00382e7b8}] [] [{kube-controller-manager Update v1 2022-08-27 07:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac6c005f-ab0c-48de-8807-13a231bbda5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-08-27 07:06:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.2.35.125\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gt8n9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gt8n9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-47-192,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.47.192,PodIP:10.2.35.125,StartTime:2022-08-27 07:06:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-27 07:06:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c02c5300d38201ee54a918f8587841b501fb0a8f4841c84b6aaa293138423227,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.35.125,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Aug 27 07:06:04.899: INFO: Pod "test-new-deployment-845c8977d9-k7445" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-k7445 test-new-deployment-845c8977d9- deployment-7368  108099c3-9bc6-4813-8ab1-3569f862ff64 33410 0 2022-08-27 07:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 ac6c005f-ab0c-48de-8807-13a231bbda5b 0xc00382e9c0 0xc00382e9c1}] [] [{kube-controller-manager Update v1 2022-08-27 07:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac6c005f-ab0c-48de-8807-13a231bbda5b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dtx9t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dtx9t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-31-158,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-27 07:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Aug 27 07:06:04.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7368" for this suite. 08/27/22 07:06:04.925
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:04.953
Aug 27 07:06:04.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename kubelet-test 08/27/22 07:06:04.954
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:05.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:05.151
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Aug 27 07:06:05.189: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0" in namespace "kubelet-test-1887" to be "running and ready"
Aug 27 07:06:05.195: INFO: Pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285631ms
Aug 27 07:06:05.195: INFO: The phase of Pod busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0 is Pending, waiting for it to be Running (with Ready = true)
Aug 27 07:06:07.199: INFO: Pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0": Phase="Running", Reason="", readiness=true. Elapsed: 2.010282767s
Aug 27 07:06:07.199: INFO: The phase of Pod busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0 is Running (Ready = true)
Aug 27 07:06:07.199: INFO: Pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Aug 27 07:06:07.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1887" for this suite. 08/27/22 07:06:07.212
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":355,"skipped":6591,"failed":0}
------------------------------
â€¢ [2.264 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:04.953
    Aug 27 07:06:04.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename kubelet-test 08/27/22 07:06:04.954
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:05.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:05.151
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Aug 27 07:06:05.189: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0" in namespace "kubelet-test-1887" to be "running and ready"
    Aug 27 07:06:05.195: INFO: Pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285631ms
    Aug 27 07:06:05.195: INFO: The phase of Pod busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0 is Pending, waiting for it to be Running (with Ready = true)
    Aug 27 07:06:07.199: INFO: Pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0": Phase="Running", Reason="", readiness=true. Elapsed: 2.010282767s
    Aug 27 07:06:07.199: INFO: The phase of Pod busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0 is Running (Ready = true)
    Aug 27 07:06:07.199: INFO: Pod "busybox-readonly-fs43151534-0bac-4648-ab95-a40936692ff0" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Aug 27 07:06:07.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-1887" for this suite. 08/27/22 07:06:07.212
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:07.217
Aug 27 07:06:07.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename daemonsets 08/27/22 07:06:07.218
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:07.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:07.243
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Aug 27 07:06:07.273: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 08/27/22 07:06:07.282
Aug 27 07:06:07.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:07.285: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 08/27/22 07:06:07.285
Aug 27 07:06:07.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:07.314: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 07:06:08.318: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:08.318: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 07:06:09.322: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 07:06:09.322: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 08/27/22 07:06:09.326
Aug 27 07:06:09.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 07:06:09.348: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Aug 27 07:06:10.382: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:10.382: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 08/27/22 07:06:10.382
Aug 27 07:06:10.428: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:10.429: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 07:06:11.432: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:11.433: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 07:06:12.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:12.433: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
Aug 27 07:06:13.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 27 07:06:13.433: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 08/27/22 07:06:13.438
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1481, will wait for the garbage collector to delete the pods 08/27/22 07:06:13.438
Aug 27 07:06:13.496: INFO: Deleting DaemonSet.extensions daemon-set took: 4.442798ms
Aug 27 07:06:13.597: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.048404ms
Aug 27 07:06:15.700: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 27 07:06:15.700: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 27 07:06:15.709: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33553"},"items":null}

Aug 27 07:06:15.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33553"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Aug 27 07:06:15.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1481" for this suite. 08/27/22 07:06:15.743
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":356,"skipped":6601,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.530 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:07.217
    Aug 27 07:06:07.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename daemonsets 08/27/22 07:06:07.218
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:07.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:07.243
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Aug 27 07:06:07.273: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 08/27/22 07:06:07.282
    Aug 27 07:06:07.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:07.285: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 08/27/22 07:06:07.285
    Aug 27 07:06:07.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:07.314: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 07:06:08.318: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:08.318: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 07:06:09.322: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 07:06:09.322: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 08/27/22 07:06:09.326
    Aug 27 07:06:09.347: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 07:06:09.348: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Aug 27 07:06:10.382: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:10.382: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 08/27/22 07:06:10.382
    Aug 27 07:06:10.428: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:10.429: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 07:06:11.432: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:11.433: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 07:06:12.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:12.433: INFO: Node ip-10-0-47-192 is running 0 daemon pod, expected 1
    Aug 27 07:06:13.433: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Aug 27 07:06:13.433: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 08/27/22 07:06:13.438
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1481, will wait for the garbage collector to delete the pods 08/27/22 07:06:13.438
    Aug 27 07:06:13.496: INFO: Deleting DaemonSet.extensions daemon-set took: 4.442798ms
    Aug 27 07:06:13.597: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.048404ms
    Aug 27 07:06:15.700: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Aug 27 07:06:15.700: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Aug 27 07:06:15.709: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33553"},"items":null}

    Aug 27 07:06:15.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33553"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Aug 27 07:06:15.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1481" for this suite. 08/27/22 07:06:15.743
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:15.749
Aug 27 07:06:15.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename webhook 08/27/22 07:06:15.755
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:15.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:15.782
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 08/27/22 07:06:15.799
STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 07:06:16.255
STEP: Deploying the webhook pod 08/27/22 07:06:16.267
STEP: Wait for the deployment to be ready 08/27/22 07:06:16.281
Aug 27 07:06:16.291: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 08/27/22 07:06:18.3
STEP: Verifying the service has paired with the endpoint 08/27/22 07:06:18.309
Aug 27 07:06:19.309: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 08/27/22 07:06:19.313
STEP: Updating a mutating webhook configuration's rules to not include the create operation 08/27/22 07:06:19.336
STEP: Creating a configMap that should not be mutated 08/27/22 07:06:19.341
STEP: Patching a mutating webhook configuration's rules to include the create operation 08/27/22 07:06:19.349
STEP: Creating a configMap that should be mutated 08/27/22 07:06:19.355
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 07:06:19.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8027" for this suite. 08/27/22 07:06:19.381
STEP: Destroying namespace "webhook-8027-markers" for this suite. 08/27/22 07:06:19.386
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":357,"skipped":6620,"failed":0}
------------------------------
â€¢ [3.693 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:15.749
    Aug 27 07:06:15.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename webhook 08/27/22 07:06:15.755
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:15.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:15.782
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 08/27/22 07:06:15.799
    STEP: Create role binding to let webhook read extension-apiserver-authentication 08/27/22 07:06:16.255
    STEP: Deploying the webhook pod 08/27/22 07:06:16.267
    STEP: Wait for the deployment to be ready 08/27/22 07:06:16.281
    Aug 27 07:06:16.291: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 08/27/22 07:06:18.3
    STEP: Verifying the service has paired with the endpoint 08/27/22 07:06:18.309
    Aug 27 07:06:19.309: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 08/27/22 07:06:19.313
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 08/27/22 07:06:19.336
    STEP: Creating a configMap that should not be mutated 08/27/22 07:06:19.341
    STEP: Patching a mutating webhook configuration's rules to include the create operation 08/27/22 07:06:19.349
    STEP: Creating a configMap that should be mutated 08/27/22 07:06:19.355
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 07:06:19.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8027" for this suite. 08/27/22 07:06:19.381
    STEP: Destroying namespace "webhook-8027-markers" for this suite. 08/27/22 07:06:19.386
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:19.445
Aug 27 07:06:19.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename gc 08/27/22 07:06:19.474
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:19.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:19.532
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 08/27/22 07:06:19.548
STEP: create the rc2 08/27/22 07:06:19.552
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 08/27/22 07:06:24.602
STEP: delete the rc simpletest-rc-to-be-deleted 08/27/22 07:06:26.716
STEP: wait for the rc to be deleted 08/27/22 07:06:26.743
Aug 27 07:06:31.828: INFO: 70 pods remaining
Aug 27 07:06:31.829: INFO: 70 pods has nil DeletionTimestamp
Aug 27 07:06:31.829: INFO: 
STEP: Gathering metrics 08/27/22 07:06:36.764
Aug 27 07:06:36.790: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
Aug 27 07:06:36.792: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 2.418169ms
Aug 27 07:06:36.792: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
Aug 27 07:06:36.792: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
Aug 27 07:06:37.080: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 27 07:06:37.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hrlb" in namespace "gc-2671"
Aug 27 07:06:37.090: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lj97" in namespace "gc-2671"
Aug 27 07:06:37.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-2t5bv" in namespace "gc-2671"
Aug 27 07:06:37.159: INFO: Deleting pod "simpletest-rc-to-be-deleted-2x8xm" in namespace "gc-2671"
Aug 27 07:06:37.196: INFO: Deleting pod "simpletest-rc-to-be-deleted-47ffs" in namespace "gc-2671"
Aug 27 07:06:37.303: INFO: Deleting pod "simpletest-rc-to-be-deleted-4bchn" in namespace "gc-2671"
Aug 27 07:06:37.343: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nrl2" in namespace "gc-2671"
Aug 27 07:06:37.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-4xnjz" in namespace "gc-2671"
Aug 27 07:06:37.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-546lj" in namespace "gc-2671"
Aug 27 07:06:37.432: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bcx6" in namespace "gc-2671"
Aug 27 07:06:37.452: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h4h5" in namespace "gc-2671"
Aug 27 07:06:37.491: INFO: Deleting pod "simpletest-rc-to-be-deleted-6nntm" in namespace "gc-2671"
Aug 27 07:06:37.556: INFO: Deleting pod "simpletest-rc-to-be-deleted-6pmw8" in namespace "gc-2671"
Aug 27 07:06:37.576: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cmfb" in namespace "gc-2671"
Aug 27 07:06:37.597: INFO: Deleting pod "simpletest-rc-to-be-deleted-7g26m" in namespace "gc-2671"
Aug 27 07:06:37.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jrpg" in namespace "gc-2671"
Aug 27 07:06:37.847: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lmkl" in namespace "gc-2671"
Aug 27 07:06:37.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-7m28k" in namespace "gc-2671"
Aug 27 07:06:37.923: INFO: Deleting pod "simpletest-rc-to-be-deleted-84vd2" in namespace "gc-2671"
Aug 27 07:06:37.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gxpr" in namespace "gc-2671"
Aug 27 07:06:38.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qn5q" in namespace "gc-2671"
Aug 27 07:06:38.082: INFO: Deleting pod "simpletest-rc-to-be-deleted-8r96v" in namespace "gc-2671"
Aug 27 07:06:38.163: INFO: Deleting pod "simpletest-rc-to-be-deleted-8s7l5" in namespace "gc-2671"
Aug 27 07:06:38.220: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tcbh" in namespace "gc-2671"
Aug 27 07:06:38.385: INFO: Deleting pod "simpletest-rc-to-be-deleted-9j2dp" in namespace "gc-2671"
Aug 27 07:06:38.436: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mnmj" in namespace "gc-2671"
Aug 27 07:06:38.459: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rqht" in namespace "gc-2671"
Aug 27 07:06:38.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9j8f" in namespace "gc-2671"
Aug 27 07:06:38.489: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbgpw" in namespace "gc-2671"
Aug 27 07:06:38.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjt28" in namespace "gc-2671"
Aug 27 07:06:38.525: INFO: Deleting pod "simpletest-rc-to-be-deleted-br2qh" in namespace "gc-2671"
Aug 27 07:06:38.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-bx9mj" in namespace "gc-2671"
Aug 27 07:06:38.598: INFO: Deleting pod "simpletest-rc-to-be-deleted-cdmpb" in namespace "gc-2671"
Aug 27 07:06:38.619: INFO: Deleting pod "simpletest-rc-to-be-deleted-cgk7z" in namespace "gc-2671"
Aug 27 07:06:38.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckbhv" in namespace "gc-2671"
Aug 27 07:06:38.687: INFO: Deleting pod "simpletest-rc-to-be-deleted-cpn72" in namespace "gc-2671"
Aug 27 07:06:38.706: INFO: Deleting pod "simpletest-rc-to-be-deleted-czcpz" in namespace "gc-2671"
Aug 27 07:06:38.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5vxz" in namespace "gc-2671"
Aug 27 07:06:38.805: INFO: Deleting pod "simpletest-rc-to-be-deleted-d92sk" in namespace "gc-2671"
Aug 27 07:06:38.832: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddlbz" in namespace "gc-2671"
Aug 27 07:06:38.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhhh4" in namespace "gc-2671"
Aug 27 07:06:38.920: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvdmm" in namespace "gc-2671"
Aug 27 07:06:38.987: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxcp6" in namespace "gc-2671"
Aug 27 07:06:39.017: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6plr" in namespace "gc-2671"
Aug 27 07:06:39.032: INFO: Deleting pod "simpletest-rc-to-be-deleted-f78xg" in namespace "gc-2671"
Aug 27 07:06:39.053: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdntf" in namespace "gc-2671"
Aug 27 07:06:39.074: INFO: Deleting pod "simpletest-rc-to-be-deleted-fnfjq" in namespace "gc-2671"
Aug 27 07:06:39.107: INFO: Deleting pod "simpletest-rc-to-be-deleted-frtnc" in namespace "gc-2671"
Aug 27 07:06:39.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzgrp" in namespace "gc-2671"
Aug 27 07:06:39.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2mr6" in namespace "gc-2671"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Aug 27 07:06:39.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2671" for this suite. 08/27/22 07:06:39.26
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":358,"skipped":6631,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.827 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:19.445
    Aug 27 07:06:19.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename gc 08/27/22 07:06:19.474
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:19.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:19.532
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 08/27/22 07:06:19.548
    STEP: create the rc2 08/27/22 07:06:19.552
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 08/27/22 07:06:24.602
    STEP: delete the rc simpletest-rc-to-be-deleted 08/27/22 07:06:26.716
    STEP: wait for the rc to be deleted 08/27/22 07:06:26.743
    Aug 27 07:06:31.828: INFO: 70 pods remaining
    Aug 27 07:06:31.829: INFO: 70 pods has nil DeletionTimestamp
    Aug 27 07:06:31.829: INFO: 
    STEP: Gathering metrics 08/27/22 07:06:36.764
    Aug 27 07:06:36.790: INFO: Waiting up to 5m0s for pod "kube-controller-manager-ip-10-0-13-52" in namespace "kube-system" to be "running and ready"
    Aug 27 07:06:36.792: INFO: Pod "kube-controller-manager-ip-10-0-13-52": Phase="Running", Reason="", readiness=true. Elapsed: 2.418169ms
    Aug 27 07:06:36.792: INFO: The phase of Pod kube-controller-manager-ip-10-0-13-52 is Running (Ready = true)
    Aug 27 07:06:36.792: INFO: Pod "kube-controller-manager-ip-10-0-13-52" satisfied condition "running and ready"
    Aug 27 07:06:37.080: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Aug 27 07:06:37.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hrlb" in namespace "gc-2671"
    Aug 27 07:06:37.090: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lj97" in namespace "gc-2671"
    Aug 27 07:06:37.110: INFO: Deleting pod "simpletest-rc-to-be-deleted-2t5bv" in namespace "gc-2671"
    Aug 27 07:06:37.159: INFO: Deleting pod "simpletest-rc-to-be-deleted-2x8xm" in namespace "gc-2671"
    Aug 27 07:06:37.196: INFO: Deleting pod "simpletest-rc-to-be-deleted-47ffs" in namespace "gc-2671"
    Aug 27 07:06:37.303: INFO: Deleting pod "simpletest-rc-to-be-deleted-4bchn" in namespace "gc-2671"
    Aug 27 07:06:37.343: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nrl2" in namespace "gc-2671"
    Aug 27 07:06:37.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-4xnjz" in namespace "gc-2671"
    Aug 27 07:06:37.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-546lj" in namespace "gc-2671"
    Aug 27 07:06:37.432: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bcx6" in namespace "gc-2671"
    Aug 27 07:06:37.452: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h4h5" in namespace "gc-2671"
    Aug 27 07:06:37.491: INFO: Deleting pod "simpletest-rc-to-be-deleted-6nntm" in namespace "gc-2671"
    Aug 27 07:06:37.556: INFO: Deleting pod "simpletest-rc-to-be-deleted-6pmw8" in namespace "gc-2671"
    Aug 27 07:06:37.576: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cmfb" in namespace "gc-2671"
    Aug 27 07:06:37.597: INFO: Deleting pod "simpletest-rc-to-be-deleted-7g26m" in namespace "gc-2671"
    Aug 27 07:06:37.634: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jrpg" in namespace "gc-2671"
    Aug 27 07:06:37.847: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lmkl" in namespace "gc-2671"
    Aug 27 07:06:37.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-7m28k" in namespace "gc-2671"
    Aug 27 07:06:37.923: INFO: Deleting pod "simpletest-rc-to-be-deleted-84vd2" in namespace "gc-2671"
    Aug 27 07:06:37.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-8gxpr" in namespace "gc-2671"
    Aug 27 07:06:38.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-8qn5q" in namespace "gc-2671"
    Aug 27 07:06:38.082: INFO: Deleting pod "simpletest-rc-to-be-deleted-8r96v" in namespace "gc-2671"
    Aug 27 07:06:38.163: INFO: Deleting pod "simpletest-rc-to-be-deleted-8s7l5" in namespace "gc-2671"
    Aug 27 07:06:38.220: INFO: Deleting pod "simpletest-rc-to-be-deleted-8tcbh" in namespace "gc-2671"
    Aug 27 07:06:38.385: INFO: Deleting pod "simpletest-rc-to-be-deleted-9j2dp" in namespace "gc-2671"
    Aug 27 07:06:38.436: INFO: Deleting pod "simpletest-rc-to-be-deleted-9mnmj" in namespace "gc-2671"
    Aug 27 07:06:38.459: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rqht" in namespace "gc-2671"
    Aug 27 07:06:38.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9j8f" in namespace "gc-2671"
    Aug 27 07:06:38.489: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbgpw" in namespace "gc-2671"
    Aug 27 07:06:38.511: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjt28" in namespace "gc-2671"
    Aug 27 07:06:38.525: INFO: Deleting pod "simpletest-rc-to-be-deleted-br2qh" in namespace "gc-2671"
    Aug 27 07:06:38.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-bx9mj" in namespace "gc-2671"
    Aug 27 07:06:38.598: INFO: Deleting pod "simpletest-rc-to-be-deleted-cdmpb" in namespace "gc-2671"
    Aug 27 07:06:38.619: INFO: Deleting pod "simpletest-rc-to-be-deleted-cgk7z" in namespace "gc-2671"
    Aug 27 07:06:38.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckbhv" in namespace "gc-2671"
    Aug 27 07:06:38.687: INFO: Deleting pod "simpletest-rc-to-be-deleted-cpn72" in namespace "gc-2671"
    Aug 27 07:06:38.706: INFO: Deleting pod "simpletest-rc-to-be-deleted-czcpz" in namespace "gc-2671"
    Aug 27 07:06:38.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5vxz" in namespace "gc-2671"
    Aug 27 07:06:38.805: INFO: Deleting pod "simpletest-rc-to-be-deleted-d92sk" in namespace "gc-2671"
    Aug 27 07:06:38.832: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddlbz" in namespace "gc-2671"
    Aug 27 07:06:38.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhhh4" in namespace "gc-2671"
    Aug 27 07:06:38.920: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvdmm" in namespace "gc-2671"
    Aug 27 07:06:38.987: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxcp6" in namespace "gc-2671"
    Aug 27 07:06:39.017: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6plr" in namespace "gc-2671"
    Aug 27 07:06:39.032: INFO: Deleting pod "simpletest-rc-to-be-deleted-f78xg" in namespace "gc-2671"
    Aug 27 07:06:39.053: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdntf" in namespace "gc-2671"
    Aug 27 07:06:39.074: INFO: Deleting pod "simpletest-rc-to-be-deleted-fnfjq" in namespace "gc-2671"
    Aug 27 07:06:39.107: INFO: Deleting pod "simpletest-rc-to-be-deleted-frtnc" in namespace "gc-2671"
    Aug 27 07:06:39.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzgrp" in namespace "gc-2671"
    Aug 27 07:06:39.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2mr6" in namespace "gc-2671"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Aug 27 07:06:39.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2671" for this suite. 08/27/22 07:06:39.26
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:39.275
Aug 27 07:06:39.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename container-runtime 08/27/22 07:06:39.307
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:39.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:39.404
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 08/27/22 07:06:39.427
STEP: wait for the container to reach Succeeded 08/27/22 07:06:39.452
STEP: get the container status 08/27/22 07:06:47.606
STEP: the container should be terminated 08/27/22 07:06:47.612
STEP: the termination message should be set 08/27/22 07:06:47.612
Aug 27 07:06:47.612: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 08/27/22 07:06:47.612
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Aug 27 07:06:47.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-754" for this suite. 08/27/22 07:06:47.635
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":359,"skipped":6638,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.365 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:39.275
    Aug 27 07:06:39.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename container-runtime 08/27/22 07:06:39.307
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:39.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:39.404
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 08/27/22 07:06:39.427
    STEP: wait for the container to reach Succeeded 08/27/22 07:06:39.452
    STEP: get the container status 08/27/22 07:06:47.606
    STEP: the container should be terminated 08/27/22 07:06:47.612
    STEP: the termination message should be set 08/27/22 07:06:47.612
    Aug 27 07:06:47.612: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 08/27/22 07:06:47.612
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Aug 27 07:06:47.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-754" for this suite. 08/27/22 07:06:47.635
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:47.641
Aug 27 07:06:47.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename crd-webhook 08/27/22 07:06:47.643
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:47.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:47.662
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 08/27/22 07:06:47.666
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/27/22 07:06:47.997
STEP: Deploying the custom resource conversion webhook pod 08/27/22 07:06:48.005
STEP: Wait for the deployment to be ready 08/27/22 07:06:48.017
Aug 27 07:06:48.042: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Aug 27 07:06:50.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 08/27/22 07:06:52.062
STEP: Verifying the service has paired with the endpoint 08/27/22 07:06:52.068
Aug 27 07:06:53.069: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Aug 27 07:06:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Creating a v1 custom resource 08/27/22 07:06:55.683
STEP: Create a v2 custom resource 08/27/22 07:06:55.704
STEP: List CRs in v1 08/27/22 07:06:55.838
STEP: List CRs in v2 08/27/22 07:06:55.844
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Aug 27 07:06:56.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1358" for this suite. 08/27/22 07:06:56.398
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":360,"skipped":6650,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.829 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:47.641
    Aug 27 07:06:47.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename crd-webhook 08/27/22 07:06:47.643
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:47.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:47.662
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 08/27/22 07:06:47.666
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 08/27/22 07:06:47.997
    STEP: Deploying the custom resource conversion webhook pod 08/27/22 07:06:48.005
    STEP: Wait for the deployment to be ready 08/27/22 07:06:48.017
    Aug 27 07:06:48.042: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Aug 27 07:06:50.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 27, 7, 6, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 08/27/22 07:06:52.062
    STEP: Verifying the service has paired with the endpoint 08/27/22 07:06:52.068
    Aug 27 07:06:53.069: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Aug 27 07:06:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Creating a v1 custom resource 08/27/22 07:06:55.683
    STEP: Create a v2 custom resource 08/27/22 07:06:55.704
    STEP: List CRs in v1 08/27/22 07:06:55.838
    STEP: List CRs in v2 08/27/22 07:06:55.844
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Aug 27 07:06:56.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-1358" for this suite. 08/27/22 07:06:56.398
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:06:56.482
Aug 27 07:06:56.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename secrets 08/27/22 07:06:56.486
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:56.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:56.723
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-4d5b5dfd-75ea-4544-b0f0-d3d0fb2cd362 08/27/22 07:06:56.77
STEP: Creating a pod to test consume secrets 08/27/22 07:06:56.776
Aug 27 07:06:56.782: INFO: Waiting up to 5m0s for pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647" in namespace "secrets-7288" to be "Succeeded or Failed"
Aug 27 07:06:56.791: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647": Phase="Pending", Reason="", readiness=false. Elapsed: 9.1447ms
Aug 27 07:06:58.816: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034324896s
Aug 27 07:07:00.795: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013644063s
STEP: Saw pod success 08/27/22 07:07:00.795
Aug 27 07:07:00.796: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647" satisfied condition "Succeeded or Failed"
Aug 27 07:07:00.798: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647 container secret-volume-test: <nil>
STEP: delete the pod 08/27/22 07:07:00.806
Aug 27 07:07:00.819: INFO: Waiting for pod pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647 to disappear
Aug 27 07:07:00.823: INFO: Pod pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Aug 27 07:07:00.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7288" for this suite. 08/27/22 07:07:00.826
STEP: Destroying namespace "secret-namespace-9748" for this suite. 08/27/22 07:07:00.833
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":361,"skipped":6680,"failed":0}
------------------------------
â€¢ [4.361 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:06:56.482
    Aug 27 07:06:56.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename secrets 08/27/22 07:06:56.486
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:06:56.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:06:56.723
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-4d5b5dfd-75ea-4544-b0f0-d3d0fb2cd362 08/27/22 07:06:56.77
    STEP: Creating a pod to test consume secrets 08/27/22 07:06:56.776
    Aug 27 07:06:56.782: INFO: Waiting up to 5m0s for pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647" in namespace "secrets-7288" to be "Succeeded or Failed"
    Aug 27 07:06:56.791: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647": Phase="Pending", Reason="", readiness=false. Elapsed: 9.1447ms
    Aug 27 07:06:58.816: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034324896s
    Aug 27 07:07:00.795: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013644063s
    STEP: Saw pod success 08/27/22 07:07:00.795
    Aug 27 07:07:00.796: INFO: Pod "pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647" satisfied condition "Succeeded or Failed"
    Aug 27 07:07:00.798: INFO: Trying to get logs from node ip-10-0-47-192 pod pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647 container secret-volume-test: <nil>
    STEP: delete the pod 08/27/22 07:07:00.806
    Aug 27 07:07:00.819: INFO: Waiting for pod pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647 to disappear
    Aug 27 07:07:00.823: INFO: Pod pod-secrets-9074681c-0443-4006-8c21-ba76d52f1647 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Aug 27 07:07:00.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7288" for this suite. 08/27/22 07:07:00.826
    STEP: Destroying namespace "secret-namespace-9748" for this suite. 08/27/22 07:07:00.833
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 08/27/22 07:07:00.844
Aug 27 07:07:00.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
STEP: Building a namespace api object, basename containers 08/27/22 07:07:00.845
STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:07:00.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:07:00.869
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 08/27/22 07:07:00.873
Aug 27 07:07:00.879: INFO: Waiting up to 5m0s for pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c" in namespace "containers-2079" to be "Succeeded or Failed"
Aug 27 07:07:00.882: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.377975ms
Aug 27 07:07:02.886: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007613321s
Aug 27 07:07:04.887: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007712072s
STEP: Saw pod success 08/27/22 07:07:04.887
Aug 27 07:07:04.887: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c" satisfied condition "Succeeded or Failed"
Aug 27 07:07:04.891: INFO: Trying to get logs from node ip-10-0-47-192 pod client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c container agnhost-container: <nil>
STEP: delete the pod 08/27/22 07:07:04.901
Aug 27 07:07:04.911: INFO: Waiting for pod client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c to disappear
Aug 27 07:07:04.915: INFO: Pod client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Aug 27 07:07:04.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2079" for this suite. 08/27/22 07:07:04.919
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":362,"skipped":6694,"failed":0}
------------------------------
â€¢ [4.079 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 08/27/22 07:07:00.844
    Aug 27 07:07:00.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2032420697
    STEP: Building a namespace api object, basename containers 08/27/22 07:07:00.845
    STEP: Waiting for a default service account to be provisioned in namespace 08/27/22 07:07:00.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 08/27/22 07:07:00.869
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 08/27/22 07:07:00.873
    Aug 27 07:07:00.879: INFO: Waiting up to 5m0s for pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c" in namespace "containers-2079" to be "Succeeded or Failed"
    Aug 27 07:07:00.882: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.377975ms
    Aug 27 07:07:02.886: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007613321s
    Aug 27 07:07:04.887: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007712072s
    STEP: Saw pod success 08/27/22 07:07:04.887
    Aug 27 07:07:04.887: INFO: Pod "client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c" satisfied condition "Succeeded or Failed"
    Aug 27 07:07:04.891: INFO: Trying to get logs from node ip-10-0-47-192 pod client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c container agnhost-container: <nil>
    STEP: delete the pod 08/27/22 07:07:04.901
    Aug 27 07:07:04.911: INFO: Waiting for pod client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c to disappear
    Aug 27 07:07:04.915: INFO: Pod client-containers-1a0672c0-fdff-4a70-925b-1af4b468df6c no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Aug 27 07:07:04.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2079" for this suite. 08/27/22 07:07:04.919
    [ReportAfterEach] TOP-LEVEL
      test/e2e/e2e_test.go:142
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S[ReportAfterEach] TOP-LEVEL
  test/e2e/e2e_test.go:142
S
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Aug 27 07:07:04.928: INFO: Running AfterSuite actions on all nodes
Aug 27 07:07:04.928: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Aug 27 07:07:04.930: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Aug 27 07:07:04.930: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Aug 27 07:07:04.931: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Aug 27 07:07:04.932: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Aug 27 07:07:04.932: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Aug 27 07:07:04.933: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Aug 27 07:07:04.934: INFO: Running AfterSuite actions on node 1
Aug 27 07:07:04.934: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.009 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Aug 27 07:07:04.928: INFO: Running AfterSuite actions on all nodes
    Aug 27 07:07:04.928: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Aug 27 07:07:04.930: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Aug 27 07:07:04.930: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Aug 27 07:07:04.931: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Aug 27 07:07:04.932: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Aug 27 07:07:04.932: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Aug 27 07:07:04.933: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Aug 27 07:07:04.934: INFO: Running AfterSuite actions on node 1
    Aug 27 07:07:04.934: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.001 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.117 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5843.845 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h37m24.284402364s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.4[0m

